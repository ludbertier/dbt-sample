2021-11-17 13:33:55.353946 (MainThread): Running with dbt=0.21.0
2021-11-17 13:33:55.412729 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, parse_only=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, full_refresh=False, defer=None, cls=<class 'dbt.task.compile.CompileTask'>, which='compile', rpc_method='compile')
2021-11-17 13:33:55.413328 (MainThread): Tracking: do not track
2021-11-17 13:33:55.427141 (MainThread): Partial parsing not enabled
2021-11-17 13:33:55.445297 (MainThread): Parsing macros/adapters.sql
2021-11-17 13:33:55.465762 (MainThread): Parsing macros/catalog.sql
2021-11-17 13:33:55.468712 (MainThread): Parsing macros/relations.sql
2021-11-17 13:33:55.469965 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 13:33:55.471536 (MainThread): Parsing macros/core.sql
2021-11-17 13:33:55.475164 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 13:33:55.524012 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 13:33:55.526053 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 13:33:55.527706 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 13:33:55.529000 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 13:33:55.536102 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 13:33:55.537342 (MainThread): Parsing macros/etc/query.sql
2021-11-17 13:33:55.538171 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 13:33:55.539374 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 13:33:55.547104 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 13:33:55.552617 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 13:33:55.570709 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 13:33:55.572082 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 13:33:55.595855 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 13:33:55.609574 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 13:33:55.624556 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 13:33:55.632577 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 13:33:55.633968 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 13:33:55.644600 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 13:33:55.647396 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 13:33:55.652626 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 13:33:55.657714 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 13:33:55.658746 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 13:33:55.659632 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 13:33:55.661130 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 13:33:55.818795 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 13:33:55.828383 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 13:33:55.848743 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:33:55.850111 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:33:55.851531 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:33:55.852856 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:33:55.866849 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-17 13:33:55.867119 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-11-17 13:33:55.868350 (MainThread): 
2021-11-17 13:33:55.868620 (MainThread): Acquiring new postgres connection "master".
2021-11-17 13:33:55.869292 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-17 13:33:55.876792 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db_sa".
2021-11-17 13:33:55.876924 (ThreadPoolExecutor-0_0): On list_demo_db_sa: BEGIN
2021-11-17 13:33:55.877026 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-17 13:33:55.884308 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.01 seconds
2021-11-17 13:33:55.884467 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db_sa".
2021-11-17 13:33:55.884557 (ThreadPoolExecutor-0_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-17 13:33:55.886429 (ThreadPoolExecutor-0_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 13:33:55.887399 (ThreadPoolExecutor-0_0): On list_demo_db_sa: ROLLBACK
2021-11-17 13:33:55.887862 (ThreadPoolExecutor-0_0): On list_demo_db_sa: Close
2021-11-17 13:33:55.891026 (MainThread): Using postgres connection "master".
2021-11-17 13:33:55.891138 (MainThread): On master: BEGIN
2021-11-17 13:33:55.891234 (MainThread): Opening a new connection, currently in state init
2021-11-17 13:33:55.897980 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 13:33:55.898136 (MainThread): Using postgres connection "master".
2021-11-17 13:33:55.898224 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-17 13:33:55.900370 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-17 13:33:55.901204 (MainThread): On master: ROLLBACK
2021-11-17 13:33:55.901543 (MainThread): On master: Close
2021-11-17 13:33:55.901877 (MainThread): 14:33:55 | Concurrency: 2 threads (target='dev')
2021-11-17 13:33:55.902048 (MainThread): 14:33:55 | 
2021-11-17 13:33:55.907479 (Thread-1): Began running node model.my_new_project.my_first_dbt_model
2021-11-17 13:33:55.907820 (Thread-1): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 13:33:55.907966 (Thread-1): Compiling model.my_new_project.my_first_dbt_model
2021-11-17 13:33:55.909865 (Thread-1): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-17 13:33:55.910279 (Thread-1): finished collecting timing info
2021-11-17 13:33:55.910412 (Thread-1): finished collecting timing info
2021-11-17 13:33:55.910642 (Thread-1): Finished running node model.my_new_project.my_first_dbt_model
2021-11-17 13:33:55.911537 (Thread-2): Began running node model.my_new_project.my_second_dbt_model
2021-11-17 13:33:55.911821 (Thread-1): Began running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2021-11-17 13:33:55.912132 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 13:33:55.912426 (Thread-1): Acquiring new postgres connection "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710".
2021-11-17 13:33:55.912625 (Thread-2): Compiling model.my_new_project.my_second_dbt_model
2021-11-17 13:33:55.912825 (Thread-1): Compiling test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2021-11-17 13:33:55.914339 (Thread-2): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-17 13:33:55.922248 (Thread-1): Writing injected SQL for node "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"
2021-11-17 13:33:55.922571 (Thread-2): finished collecting timing info
2021-11-17 13:33:55.922749 (Thread-2): finished collecting timing info
2021-11-17 13:33:55.923054 (Thread-2): Finished running node model.my_new_project.my_second_dbt_model
2021-11-17 13:33:55.923239 (Thread-2): Began running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2021-11-17 13:33:55.923529 (Thread-2): Acquiring new postgres connection "test.my_new_project.unique_my_first_dbt_model_id.16e066b321".
2021-11-17 13:33:55.923697 (Thread-2): Compiling test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2021-11-17 13:33:55.928634 (Thread-2): Writing injected SQL for node "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"
2021-11-17 13:33:55.929408 (Thread-2): finished collecting timing info
2021-11-17 13:33:55.929564 (Thread-2): finished collecting timing info
2021-11-17 13:33:55.929818 (Thread-2): Finished running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2021-11-17 13:33:55.929979 (Thread-2): Began running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2021-11-17 13:33:55.930214 (Thread-2): Acquiring new postgres connection "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778".
2021-11-17 13:33:55.930356 (Thread-2): Compiling test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2021-11-17 13:33:55.932526 (Thread-2): Writing injected SQL for node "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"
2021-11-17 13:33:55.933040 (Thread-2): finished collecting timing info
2021-11-17 13:33:55.933192 (Thread-2): finished collecting timing info
2021-11-17 13:33:55.933416 (Thread-1): finished collecting timing info
2021-11-17 13:33:55.933723 (Thread-2): Finished running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2021-11-17 13:33:55.933945 (Thread-1): finished collecting timing info
2021-11-17 13:33:55.934211 (Thread-2): Began running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2021-11-17 13:33:55.934584 (Thread-1): Finished running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2021-11-17 13:33:55.934967 (Thread-2): Acquiring new postgres connection "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493".
2021-11-17 13:33:55.935345 (Thread-2): Compiling test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2021-11-17 13:33:55.937437 (Thread-2): Writing injected SQL for node "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"
2021-11-17 13:33:55.937605 (Thread-2): finished collecting timing info
2021-11-17 13:33:55.937724 (Thread-2): finished collecting timing info
2021-11-17 13:33:55.937933 (Thread-2): Finished running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2021-11-17 13:33:55.939273 (MainThread): Connection 'master' was properly closed.
2021-11-17 13:33:55.939420 (MainThread): Connection 'test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710' was properly closed.
2021-11-17 13:33:55.939541 (MainThread): Connection 'test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
2021-11-17 13:33:55.942195 (MainThread): 14:33:55 | Done.
2021-11-17 13:33:55.942384 (MainThread): Flushing usage events
2021-11-17 13:34:03.461609 (MainThread): Running with dbt=0.21.0
2021-11-17 13:34:03.510366 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, resource_types=[], output='selector', output_keys=None, models=None, select=None, greedy=False, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.list.ListTask'>, which='list', rpc_method=None)
2021-11-17 13:34:03.510791 (MainThread): Tracking: do not track
2021-11-17 13:34:03.520344 (MainThread): Partial parsing not enabled
2021-11-17 13:34:03.527543 (MainThread): Parsing macros/adapters.sql
2021-11-17 13:34:03.545198 (MainThread): Parsing macros/catalog.sql
2021-11-17 13:34:03.546880 (MainThread): Parsing macros/relations.sql
2021-11-17 13:34:03.547858 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 13:34:03.549175 (MainThread): Parsing macros/core.sql
2021-11-17 13:34:03.551866 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 13:34:03.596177 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 13:34:03.598074 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 13:34:03.599517 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 13:34:03.600845 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 13:34:03.607113 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 13:34:03.608429 (MainThread): Parsing macros/etc/query.sql
2021-11-17 13:34:03.609154 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 13:34:03.610284 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 13:34:03.617831 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 13:34:03.622932 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 13:34:03.639940 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 13:34:03.641196 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 13:34:03.663160 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 13:34:03.675997 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 13:34:03.690478 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 13:34:03.698106 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 13:34:03.699469 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 13:34:03.709531 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 13:34:03.712437 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 13:34:03.717703 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 13:34:03.722921 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 13:34:03.723936 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 13:34:03.724819 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 13:34:03.726066 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 13:34:03.880937 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 13:34:03.890726 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 13:34:03.911347 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:34:03.912791 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:34:03.914227 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:34:03.915618 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:34:03.929240 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-17 13:34:03.929542 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-11-17 13:34:03.929980 (MainThread): Flushing usage events
2021-11-17 13:34:03.930121 (MainThread): Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2021-11-17 13:34:10.718492 (MainThread): Running with dbt=0.21.0
2021-11-17 13:34:10.771238 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 13:34:10.771672 (MainThread): Tracking: do not track
2021-11-17 13:34:10.782864 (MainThread): Partial parsing not enabled
2021-11-17 13:34:10.789016 (MainThread): Parsing macros/adapters.sql
2021-11-17 13:34:10.811533 (MainThread): Parsing macros/catalog.sql
2021-11-17 13:34:10.813224 (MainThread): Parsing macros/relations.sql
2021-11-17 13:34:10.814181 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 13:34:10.815816 (MainThread): Parsing macros/core.sql
2021-11-17 13:34:10.818901 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 13:34:10.859573 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 13:34:10.861456 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 13:34:10.862800 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 13:34:10.863978 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 13:34:10.870380 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 13:34:10.871496 (MainThread): Parsing macros/etc/query.sql
2021-11-17 13:34:10.872220 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 13:34:10.873349 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 13:34:10.880825 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 13:34:10.885884 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 13:34:10.903017 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 13:34:10.904271 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 13:34:10.926052 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 13:34:10.939189 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 13:34:10.953188 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 13:34:10.960861 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 13:34:10.962163 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 13:34:10.972217 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 13:34:10.975118 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 13:34:10.980550 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 13:34:10.985715 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 13:34:10.986720 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 13:34:10.987763 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 13:34:10.989009 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 13:34:11.145404 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 13:34:11.155122 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 13:34:11.175783 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:34:11.177143 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:34:11.178667 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:34:11.180094 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:34:11.192827 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-17 13:34:11.193092 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-11-17 13:34:11.194357 (MainThread): 
2021-11-17 13:34:11.194720 (MainThread): Acquiring new postgres connection "master".
2021-11-17 13:34:11.195425 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-17 13:34:11.202605 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-17 13:34:11.202715 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-17 13:34:11.202813 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-17 13:34:11.210434 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.01 seconds
2021-11-17 13:34:11.211466 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-17 13:34:11.212762 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-17 13:34:11.216855 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 13:34:11.216965 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-17 13:34:11.217061 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-17 13:34:11.223123 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-17 13:34:11.223312 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 13:34:11.223402 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-17 13:34:11.225327 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 13:34:11.226244 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-17 13:34:11.226662 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-17 13:34:11.229826 (MainThread): Using postgres connection "master".
2021-11-17 13:34:11.229938 (MainThread): On master: BEGIN
2021-11-17 13:34:11.230035 (MainThread): Opening a new connection, currently in state init
2021-11-17 13:34:11.236469 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 13:34:11.236645 (MainThread): Using postgres connection "master".
2021-11-17 13:34:11.236738 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-17 13:34:11.238768 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-17 13:34:11.239583 (MainThread): On master: ROLLBACK
2021-11-17 13:34:11.239927 (MainThread): Using postgres connection "master".
2021-11-17 13:34:11.240069 (MainThread): On master: BEGIN
2021-11-17 13:34:11.240802 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-17 13:34:11.240986 (MainThread): On master: COMMIT
2021-11-17 13:34:11.241082 (MainThread): Using postgres connection "master".
2021-11-17 13:34:11.241168 (MainThread): On master: COMMIT
2021-11-17 13:34:11.241697 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 13:34:11.241822 (MainThread): On master: Close
2021-11-17 13:34:11.242204 (MainThread): 14:34:11 | Concurrency: 2 threads (target='dev')
2021-11-17 13:34:11.242487 (MainThread): 14:34:11 | 
2021-11-17 13:34:11.245534 (Thread-1): Began running node model.my_new_project.my_first_dbt_model
2021-11-17 13:34:11.245901 (Thread-1): 14:34:11 | 1 of 2 START table model sa.my_first_dbt_model....................... [RUN]
2021-11-17 13:34:11.246392 (Thread-1): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 13:34:11.246572 (Thread-1): Compiling model.my_new_project.my_first_dbt_model
2021-11-17 13:34:11.248418 (Thread-1): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-17 13:34:11.248635 (Thread-1): finished collecting timing info
2021-11-17 13:34:11.266038 (Thread-1): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-17 13:34:11.266481 (Thread-1): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 13:34:11.266585 (Thread-1): On model.my_new_project.my_first_dbt_model: BEGIN
2021-11-17 13:34:11.266684 (Thread-1): Opening a new connection, currently in state closed
2021-11-17 13:34:11.273713 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-17 13:34:11.273935 (Thread-1): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 13:34:11.274028 (Thread-1): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table "demo_db"."sa"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-11-17 13:34:11.275342 (Thread-1): SQL status: SELECT 2 in 0.00 seconds
2021-11-17 13:34:11.279737 (Thread-1): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 13:34:11.279853 (Thread-1): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "demo_db"."sa"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2021-11-17 13:34:11.280376 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-11-17 13:34:11.287962 (Thread-1): On model.my_new_project.my_first_dbt_model: COMMIT
2021-11-17 13:34:11.288091 (Thread-1): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 13:34:11.288179 (Thread-1): On model.my_new_project.my_first_dbt_model: COMMIT
2021-11-17 13:34:11.290219 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-11-17 13:34:11.293782 (Thread-1): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 13:34:11.293911 (Thread-1): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "demo_db"."sa"."my_first_dbt_model__dbt_backup" cascade
2021-11-17 13:34:11.294468 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-11-17 13:34:11.295287 (Thread-1): finished collecting timing info
2021-11-17 13:34:11.295417 (Thread-1): On model.my_new_project.my_first_dbt_model: Close
2021-11-17 13:34:11.295901 (Thread-1): 14:34:11 | 1 of 2 OK created table model sa.my_first_dbt_model.................. [SELECT 2 in 0.05s]
2021-11-17 13:34:11.296141 (Thread-1): Finished running node model.my_new_project.my_first_dbt_model
2021-11-17 13:34:11.297598 (Thread-2): Began running node model.my_new_project.my_second_dbt_model
2021-11-17 13:34:11.297889 (Thread-2): 14:34:11 | 2 of 2 START view model sa.my_second_dbt_model....................... [RUN]
2021-11-17 13:34:11.298200 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 13:34:11.298543 (Thread-2): Compiling model.my_new_project.my_second_dbt_model
2021-11-17 13:34:11.300192 (Thread-2): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-17 13:34:11.300401 (Thread-2): finished collecting timing info
2021-11-17 13:34:11.313033 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-17 13:34:11.313320 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 13:34:11.313422 (Thread-2): On model.my_new_project.my_second_dbt_model: BEGIN
2021-11-17 13:34:11.313521 (Thread-2): Opening a new connection, currently in state init
2021-11-17 13:34:11.319999 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-17 13:34:11.320202 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 13:34:11.320294 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */

  create view "demo_db"."sa"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."sa"."my_first_dbt_model"
where id = 1
  );

2021-11-17 13:34:11.321518 (Thread-2): SQL status: CREATE VIEW in 0.00 seconds
2021-11-17 13:34:11.323056 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 13:34:11.323160 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "demo_db"."sa"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2021-11-17 13:34:11.323664 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-17 13:34:11.324392 (Thread-2): On model.my_new_project.my_second_dbt_model: COMMIT
2021-11-17 13:34:11.324498 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 13:34:11.324585 (Thread-2): On model.my_new_project.my_second_dbt_model: COMMIT
2021-11-17 13:34:11.326251 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-11-17 13:34:11.327159 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 13:34:11.327261 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "demo_db"."sa"."my_second_dbt_model__dbt_backup" cascade
2021-11-17 13:34:11.327714 (Thread-2): SQL status: DROP VIEW in 0.00 seconds
2021-11-17 13:34:11.328587 (Thread-2): finished collecting timing info
2021-11-17 13:34:11.328715 (Thread-2): On model.my_new_project.my_second_dbt_model: Close
2021-11-17 13:34:11.329155 (Thread-2): 14:34:11 | 2 of 2 OK created view model sa.my_second_dbt_model.................. [CREATE VIEW in 0.03s]
2021-11-17 13:34:11.329305 (Thread-2): Finished running node model.my_new_project.my_second_dbt_model
2021-11-17 13:34:11.330631 (MainThread): Acquiring new postgres connection "master".
2021-11-17 13:34:11.330761 (MainThread): Using postgres connection "master".
2021-11-17 13:34:11.330854 (MainThread): On master: BEGIN
2021-11-17 13:34:11.330948 (MainThread): Opening a new connection, currently in state closed
2021-11-17 13:34:11.337066 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 13:34:11.337305 (MainThread): On master: COMMIT
2021-11-17 13:34:11.337438 (MainThread): Using postgres connection "master".
2021-11-17 13:34:11.337582 (MainThread): On master: COMMIT
2021-11-17 13:34:11.337988 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 13:34:11.338121 (MainThread): On master: Close
2021-11-17 13:34:11.338587 (MainThread): 14:34:11 | 
2021-11-17 13:34:11.338868 (MainThread): 14:34:11 | Finished running 1 table model, 1 view model in 0.14s.
2021-11-17 13:34:11.339237 (MainThread): Connection 'master' was properly closed.
2021-11-17 13:34:11.339391 (MainThread): Connection 'model.my_new_project.my_first_dbt_model' was properly closed.
2021-11-17 13:34:11.339523 (MainThread): Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2021-11-17 13:34:11.342432 (MainThread): 
2021-11-17 13:34:11.342595 (MainThread): Completed successfully
2021-11-17 13:34:11.342844 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-11-17 13:34:11.343276 (MainThread): Flushing usage events
2021-11-17 13:40:57.347085 (MainThread): Running with dbt=0.21.0
2021-11-17 13:40:57.397451 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, full_refresh=False, show=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.seed.SeedTask'>, which='seed', rpc_method='seed')
2021-11-17 13:40:57.397970 (MainThread): Tracking: do not track
2021-11-17 13:40:57.409214 (MainThread): Partial parsing not enabled
2021-11-17 13:40:57.415040 (MainThread): Parsing macros/adapters.sql
2021-11-17 13:40:57.432844 (MainThread): Parsing macros/catalog.sql
2021-11-17 13:40:57.434545 (MainThread): Parsing macros/relations.sql
2021-11-17 13:40:57.435484 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 13:40:57.436814 (MainThread): Parsing macros/core.sql
2021-11-17 13:40:57.439853 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 13:40:57.479917 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 13:40:57.481760 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 13:40:57.483093 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 13:40:57.484532 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 13:40:57.491082 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 13:40:57.492260 (MainThread): Parsing macros/etc/query.sql
2021-11-17 13:40:57.492997 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 13:40:57.494105 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 13:40:57.501276 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 13:40:57.506373 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 13:40:57.523119 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 13:40:57.524326 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 13:40:57.546325 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 13:40:57.559503 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 13:40:57.573940 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 13:40:57.581495 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 13:40:57.582965 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 13:40:57.593222 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 13:40:57.596104 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 13:40:57.601577 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 13:40:57.607945 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 13:40:57.611086 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 13:40:57.612886 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 13:40:57.614392 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 13:40:57.768532 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 13:40:57.778159 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 13:40:57.806003 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:40:57.807364 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:40:57.808742 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:40:57.810388 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:40:57.823723 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-17 13:40:57.823992 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-17 13:40:57.825262 (MainThread): 
2021-11-17 13:40:57.825611 (MainThread): Acquiring new postgres connection "master".
2021-11-17 13:40:57.826363 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-17 13:40:57.834006 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-17 13:40:57.834132 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-17 13:40:57.834231 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-17 13:40:57.841245 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.01 seconds
2021-11-17 13:40:57.842160 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-17 13:40:57.843304 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-17 13:40:57.847299 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 13:40:57.847426 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-17 13:40:57.847545 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-17 13:40:57.854140 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-17 13:40:57.854361 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 13:40:57.854508 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-17 13:40:57.857178 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2021-11-17 13:40:57.858344 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-17 13:40:57.858897 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-17 13:40:57.862571 (MainThread): Using postgres connection "master".
2021-11-17 13:40:57.862703 (MainThread): On master: BEGIN
2021-11-17 13:40:57.862798 (MainThread): Opening a new connection, currently in state init
2021-11-17 13:40:57.869930 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 13:40:57.870108 (MainThread): Using postgres connection "master".
2021-11-17 13:40:57.870200 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-17 13:40:57.873150 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 13:40:57.874066 (MainThread): On master: ROLLBACK
2021-11-17 13:40:57.874465 (MainThread): Using postgres connection "master".
2021-11-17 13:40:57.874571 (MainThread): On master: BEGIN
2021-11-17 13:40:57.875186 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-17 13:40:57.875396 (MainThread): On master: COMMIT
2021-11-17 13:40:57.875567 (MainThread): Using postgres connection "master".
2021-11-17 13:40:57.875719 (MainThread): On master: COMMIT
2021-11-17 13:40:57.876151 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 13:40:57.876402 (MainThread): On master: Close
2021-11-17 13:40:57.876767 (MainThread): 14:40:57 | Concurrency: 2 threads (target='dev')
2021-11-17 13:40:57.876970 (MainThread): 14:40:57 | 
2021-11-17 13:40:57.879754 (Thread-1): Began running node seed.my_new_project.ISS-NNIP_Issuers_20211031
2021-11-17 13:40:57.880056 (Thread-1): 14:40:57 | 1 of 1 START seed file sa.ISS-NNIP_Issuers_20211031.................. [RUN]
2021-11-17 13:40:57.880361 (Thread-1): Acquiring new postgres connection "seed.my_new_project.ISS-NNIP_Issuers_20211031".
2021-11-17 13:40:57.880503 (Thread-1): finished collecting timing info
2021-11-17 13:41:03.617187 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.617522 (Thread-1): * Deprecation Warning: The quote_columns parameter was not set for seeds, so the
default value of False was chosen. The default will change to True in a future
release.

For more information, see:
https://docs.getdbt.com/v0.15/docs/seeds#section-specify-column-quoting
2021-11-17 13:41:03.617718 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.617846 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.618022 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.618204 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.618412 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.659924 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.699398 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.740546 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.783319 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.783557 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.783692 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.783814 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.783955 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.784079 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.784197 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.825305 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.826553 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.826691 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.826808 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.826923 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.827037 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.827149 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.827261 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.827373 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.827600 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.827717 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.827829 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.827941 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.828052 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.828163 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.828287 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.828401 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.828543 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.828657 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.828769 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.828888 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.829002 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.829113 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.829223 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.829333 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.829521 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.829728 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.829907 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.830018 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.830151 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.830264 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.830374 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.830539 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.830657 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.830772 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.830883 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.830993 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.831105 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.831216 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.831325 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.831450 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.831574 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.831686 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.831798 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.831911 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.832023 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.832157 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.832349 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.832533 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.832671 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.832809 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.832925 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.833039 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.833153 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.833264 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.833375 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.833506 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.833624 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.833737 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.833848 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.833957 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.834071 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.834184 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.834294 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.834403 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.834543 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.834766 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.834885 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.834996 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.835106 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.835216 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.835325 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.835449 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.835568 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.835681 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.835792 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.835903 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.836013 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.836123 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.836232 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.836341 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.836471 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.836592 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.836706 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.836817 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.836927 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.837037 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.837147 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.837256 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.837420 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.837602 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.837781 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.837926 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.838075 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.838185 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.838304 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.838416 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.838549 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.838661 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.838770 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.838899 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.839011 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.839120 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.839231 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.839340 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.839469 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.839586 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.839697 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.839807 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.839916 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.840026 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.840134 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.840249 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.840359 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.840488 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.840602 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.840712 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.840821 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.840930 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.841041 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.841150 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.841259 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.841368 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.841497 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.841610 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.841721 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.841830 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.841940 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.885421 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.885678 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.885809 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.885927 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.886048 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.886163 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.886281 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.886396 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.886530 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.886645 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.886758 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.886869 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.886980 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.887089 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.887201 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.887321 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.887444 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.887560 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.887883 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.887997 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.888111 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.888223 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.888443 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.888561 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.888671 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.888782 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.888891 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.888999 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.889109 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.889218 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.889326 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.889449 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.889564 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.889673 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.889781 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.889890 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.890017 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.890127 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.890235 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.890343 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.890470 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.890584 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.890693 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.890803 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.890913 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.891027 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.891135 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.891243 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.891352 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.891523 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.891671 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.891781 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.891889 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.891997 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.892104 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.892212 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.892319 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.892436 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.892555 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.892664 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.892772 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.892880 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.892989 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.893097 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.893205 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.893311 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.893418 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.893544 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.893652 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.893761 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.893868 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.893976 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.894083 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.894191 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.894297 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.894403 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.894531 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.894642 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.894750 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 13:41:03.894982 (Thread-1): Using postgres connection "seed.my_new_project.ISS-NNIP_Issuers_20211031".
2021-11-17 13:41:03.895078 (Thread-1): On seed.my_new_project.ISS-NNIP_Issuers_20211031: BEGIN
2021-11-17 13:41:03.895177 (Thread-1): Opening a new connection, currently in state closed
2021-11-17 13:41:03.901786 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-17 13:41:03.901951 (Thread-1): Using postgres connection "seed.my_new_project.ISS-NNIP_Issuers_20211031".
2021-11-17 13:41:03.902045 (Thread-1): On seed.my_new_project.ISS-NNIP_Issuers_20211031: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "seed.my_new_project.ISS-NNIP_Issuers_20211031"} */

    create table "demo_db"."sa"."ISS-NNIP_Issuers_20211031" (IssuerName text,ISIN text,GICSSector text,GICSIndustryGroup text,CountryOfIncorporation text,CountryOfOperations text,ClimateScope1Emissions float8,ClimateScope2Emissions float8,ClimateTotalEmissions float8,ClimateScope3Emissions float8,ClimateCNIEmissionsSource text,ClimateEmissionsReportedTrust text,ClimateEmissionsEstimatedTrust text,ClimateScope1EmissionsIntUSD text,ClimateScope2EmissionsIntUSD text,ClimateTotalEmissionsIntUSD text,ClimateAvePeerEmissionsIntUSD float8,MarketCapDaily text,AdjustedEnterpriseValue text,ClimateCarbonBudget2DegExcdYear text,ClimateCarbonBudget4DegExcdYear text,ClimateCarbonBudget6DegExcdYear text,ClimateEmissionsTrajectoryRatio text,ClimateCarbonBudget2DegRatioAve text,ClimateCarbonBudget4DegRatioAve text,ClimateCarbonBudget6DegRatioAve text,ClimateCarbonBudget2Deg text,ClimateCarbonBudget4Deg text,ClimateCarbonBudget6Deg text,ClimateCarbonBudget2Deg2020 text,ClimateCarbonBudget2Deg2021 text,ClimateCarbonBudget2Deg2022 text,ClimateCarbonBudget2Deg2023 text,ClimateCarbonBudget2Deg2024 text,ClimateCarbonBudget2Deg2025 text,ClimateCarbonBudget2Deg2026 text,ClimateCarbonBudget2Deg2027 text,ClimateCarbonBudget2Deg2028 text,ClimateCarbonBudget2Deg2029 text,ClimateCarbonBudget2Deg2030 text,ClimateCarbonBudget2Deg2031 text,ClimateCarbonBudget2Deg2032 text,ClimateCarbonBudget2Deg2033 text,ClimateCarbonBudget2Deg2034 text,ClimateCarbonBudget2Deg2035 text,ClimateCarbonBudget2Deg2036 text,ClimateCarbonBudget2Deg2037 text,ClimateCarbonBudget2Deg2038 text,ClimateCarbonBudget2Deg2039 text,ClimateCarbonBudget2Deg2040 text,ClimateCarbonBudget2Deg2041 text,ClimateCarbonBudget2Deg2042 text,ClimateCarbonBudget2Deg2043 text,ClimateCarbonBudget2Deg2044 text,ClimateCarbonBudget2Deg2045 text,ClimateCarbonBudget2Deg2046 text,ClimateCarbonBudget2Deg2047 text,ClimateCarbonBudget2Deg2048 text,ClimateCarbonBudget2Deg2049 text,ClimateCarbonBudget2Deg2050 text,ClimateCarbonBudget4Deg2020 text,ClimateCarbonBudget4Deg2021 text,ClimateCarbonBudget4Deg2022 text,ClimateCarbonBudget4Deg2023 text,ClimateCarbonBudget4Deg2024 text,ClimateCarbonBudget4Deg2025 text,ClimateCarbonBudget4Deg2026 text,ClimateCarbonBudget4Deg2027 text,ClimateCarbonBudget4Deg2028 text,ClimateCarbonBudget4Deg2029 text,ClimateCarbonBudget4Deg2030 text,ClimateCarbonBudget4Deg2031 text,ClimateCarbonBudget4Deg2032 text,ClimateCarbonBudget4Deg2033 text,ClimateCarbonBudget4Deg2034 text,ClimateCarbonBudget4Deg2035 text,ClimateCarbonBudget4Deg2036 text,ClimateCarbonBudget4Deg2037 text,ClimateCarbonBudget4Deg2038 text,ClimateCarbonBudget4Deg2039 text,ClimateCarbonBudget4Deg2040 text,ClimateCarbonBudget4Deg2041 text,ClimateCarbonBudget4Deg2042 text,ClimateCarbonBudget4Deg2043 text,ClimateCarbonBudget4Deg2044 text,ClimateCarbonBudget4Deg2045 text,ClimateCarbonBudget4Deg2046 text,ClimateCarbonBudget4Deg2047 text,ClimateCarbonBudget4Deg2048 text,ClimateCarbonBudget4Deg2049 text,ClimateCarbonBudget4Deg2050 text,ClimateCarbonBudget6Deg2020 text,ClimateCarbonBudget6Deg2021 text,ClimateCarbonBudget6Deg2022 text,ClimateCarbonBudget6Deg2023 text,ClimateCarbonBudget6Deg2024 text,ClimateCarbonBudget6Deg2025 text,ClimateCarbonBudget6Deg2026 text,ClimateCarbonBudget6Deg2027 text,ClimateCarbonBudget6Deg2028 text,ClimateCarbonBudget6Deg2029 text,ClimateCarbonBudget6Deg2030 text,ClimateCarbonBudget6Deg2031 text,ClimateCarbonBudget6Deg2032 text,ClimateCarbonBudget6Deg2033 text,ClimateCarbonBudget6Deg2034 text,ClimateCarbonBudget6Deg2035 text,ClimateCarbonBudget6Deg2036 text,ClimateCarbonBudget6Deg2037 text,ClimateCarbonBudget6Deg2038 text,ClimateCarbonBudget6Deg2039 text,ClimateCarbonBudget6Deg2040 text,ClimateCarbonBudget6Deg2041 text,ClimateCarbonBudget6Deg2042 text,ClimateCarbonBudget6Deg2043 text,ClimateCarbonBudget6Deg2044 text,ClimateCarbonBudget6Deg2045 text,ClimateCarbonBudget6Deg2046 text,ClimateCarbonBudget6Deg2047 text,ClimateCarbonBudget6Deg2048 text,ClimateCarbonBudget6Deg2049 text,ClimateCarbonBudget6Deg2050 text,PAETechTypes text,PAETotalPAEPerYear text,PAETotalSold text,PAEBiomassSold text,PAEBiomassPAEPerYear text,PAEBiomassPAGEPerYear text,PAEGeothermalSold text,PAEGeothermalPAEPerYear text,PAEGeothermalPAGEPerYear text,PAEHydroSold text,PAEHydroPAEPerYear text,PAEHydroPAGEPerYear text,PAESolarCSPSold text,PAESolarPVSold text,PAESolarPAEPerYear text,PAESolarCSPPAGEPerYear text,PAESolarPVPAGEPerYear text,PAEOnshoreWindSold text,PAEOffshoreWindSold text,PAEWindPAEPerYear text,PAEWindPAGEPerYear text,PAEWindSold text,ClimateEmissionsFiscalYear integer,ClimateScienceBasedTargets text,ClimateTemperatureScore text,ClimateGHGReductionTargets text,ClimateEmissionsTrajectoryRatioSDS text,ClimateCarbonBudgetSDSDegExcdYear text,ClimateCarbonBudgetSDSRatioAve text,ClimateCarbonBudgetSDS text,ClimateCarbonBudgetSDS2019 text,ClimateCarbonBudgetSDS2020 text,ClimateCarbonBudgetSDS2021 text,ClimateCarbonBudgetSDS2022 text,ClimateCarbonBudgetSDS2023 text,ClimateCarbonBudgetSDS2024 text,ClimateCarbonBudgetSDS2025 text,ClimateCarbonBudgetSDS2026 text,ClimateCarbonBudgetSDS2027 text,ClimateCarbonBudgetSDS2028 text,ClimateCarbonBudgetSDS2029 text,ClimateCarbonBudgetSDS2030 text,ClimateCarbonBudgetSDS2031 text,ClimateCarbonBudgetSDS2032 text,ClimateCarbonBudgetSDS2033 text,ClimateCarbonBudgetSDS2034 text,ClimateCarbonBudgetSDS2035 text,ClimateCarbonBudgetSDS2036 text,ClimateCarbonBudgetSDS2037 text,ClimateCarbonBudgetSDS2038 text,ClimateCarbonBudgetSDS2039 text,ClimateCarbonBudgetSDS2040 text,ClimateCarbonBudgetSDS2041 text,ClimateCarbonBudgetSDS2042 text,ClimateCarbonBudgetSDS2043 text,ClimateCarbonBudgetSDS2044 text,ClimateCarbonBudgetSDS2045 text,ClimateCarbonBudgetSDS2046 text,ClimateCarbonBudgetSDS2047 text,ClimateCarbonBudgetSDS2048 text,ClimateCarbonBudgetSDS2049 text,ClimateCarbonBudgetSDS2050 text,ClimateCarbonBudgetSDSPCT text,ClimateCarbonBudgetSDSPCT2019 text,ClimateCarbonBudgetSDSPCT2020 text,ClimateCarbonBudgetSDSPCT2021 text,ClimateCarbonBudgetSDSPCT2022 text,ClimateCarbonBudgetSDSPCT2023 text,ClimateCarbonBudgetSDSPCT2024 text,ClimateCarbonBudgetSDSPCT2025 text,ClimateCarbonBudgetSDSPCT2026 text,ClimateCarbonBudgetSDSPCT2027 text,ClimateCarbonBudgetSDSPCT2028 text,ClimateCarbonBudgetSDSPCT2029 text,ClimateCarbonBudgetSDSPCT2030 text,ClimateCarbonBudgetSDSPCT2031 text,ClimateCarbonBudgetSDSPCT2032 text,ClimateCarbonBudgetSDSPCT2033 text,ClimateCarbonBudgetSDSPCT2034 text,ClimateCarbonBudgetSDSPCT2035 text,ClimateCarbonBudgetSDSPCT2036 text,ClimateCarbonBudgetSDSPCT2037 text,ClimateCarbonBudgetSDSPCT2038 text,ClimateCarbonBudgetSDSPCT2039 text,ClimateCarbonBudgetSDSPCT2040 text,ClimateCarbonBudgetSDSPCT2041 text,ClimateCarbonBudgetSDSPCT2042 text,ClimateCarbonBudgetSDSPCT2043 text,ClimateCarbonBudgetSDSPCT2044 text,ClimateCarbonBudgetSDSPCT2045 text,ClimateCarbonBudgetSDSPCT2046 text,ClimateCarbonBudgetSDSPCT2047 text,ClimateCarbonBudgetSDSPCT2048 text,ClimateCarbonBudgetSDSPCT2049 text,ClimateCarbonBudgetSDSPCT2050 text,ClimateCarbonBudgetSDSModelType text,ClimateDSGovernanceAlignment text,ClimateDSMandTAlignment text,ClimateDSOverallAlignment text,ClimateDSRiskMgmtAlignment text,ClimateDSStrategyAlignment text)
  
2021-11-17 13:41:03.908526 (Thread-1): SQL status: CREATE TABLE in 0.01 seconds
2021-11-17 13:44:58.751708 (Thread-1): Using postgres connection "seed.my_new_project.ISS-NNIP_Issuers_20211031".
2021-11-17 13:44:58.751968 (Thread-1): On seed.my_new_project.ISS-NNIP_Issuers_20211031: 
          insert into "demo_db"."sa"."ISS-NNIP_Issuers_20211031" (IssuerName, ISIN, GICSSector, GICSIndustryGroup, CountryOfIncorporation, CountryOfOperations, ClimateScope1Emissions, ClimateScope2Emissions, ClimateTotalEmissions, ClimateScope3Emissions, ClimateCNIEmissionsSource, ClimateEmissionsReportedTrust, ClimateEmissionsEstimatedTrust, ClimateScope1EmissionsIntUSD, ClimateScope2EmissionsIntUSD, ClimateTotalEmissionsIntUSD, ClimateAvePeerEmissionsIntUSD, MarketCapDaily, AdjustedEnterpriseValue, Clima...
2021-11-17 13:45:01.986796 (Thread-1): SQL status: INSERT 0 10000 in 3.23 seconds
2021-11-17 13:48:49.580929 (Thread-1): Using postgres connection "seed.my_new_project.ISS-NNIP_Issuers_20211031".
2021-11-17 13:48:49.581186 (Thread-1): On seed.my_new_project.ISS-NNIP_Issuers_20211031: 
          insert into "demo_db"."sa"."ISS-NNIP_Issuers_20211031" (IssuerName, ISIN, GICSSector, GICSIndustryGroup, CountryOfIncorporation, CountryOfOperations, ClimateScope1Emissions, ClimateScope2Emissions, ClimateTotalEmissions, ClimateScope3Emissions, ClimateCNIEmissionsSource, ClimateEmissionsReportedTrust, ClimateEmissionsEstimatedTrust, ClimateScope1EmissionsIntUSD, ClimateScope2EmissionsIntUSD, ClimateTotalEmissionsIntUSD, ClimateAvePeerEmissionsIntUSD, MarketCapDaily, AdjustedEnterpriseValue, Clima...
2021-11-17 13:48:52.868812 (Thread-1): SQL status: INSERT 0 10000 in 3.29 seconds
2021-11-17 13:52:05.269713 (Thread-1): Using postgres connection "seed.my_new_project.ISS-NNIP_Issuers_20211031".
2021-11-17 13:52:05.269914 (Thread-1): On seed.my_new_project.ISS-NNIP_Issuers_20211031: 
          insert into "demo_db"."sa"."ISS-NNIP_Issuers_20211031" (IssuerName, ISIN, GICSSector, GICSIndustryGroup, CountryOfIncorporation, CountryOfOperations, ClimateScope1Emissions, ClimateScope2Emissions, ClimateTotalEmissions, ClimateScope3Emissions, ClimateCNIEmissionsSource, ClimateEmissionsReportedTrust, ClimateEmissionsEstimatedTrust, ClimateScope1EmissionsIntUSD, ClimateScope2EmissionsIntUSD, ClimateTotalEmissionsIntUSD, ClimateAvePeerEmissionsIntUSD, MarketCapDaily, AdjustedEnterpriseValue, Clima...
2021-11-17 13:52:07.880204 (Thread-1): SQL status: INSERT 0 8444 in 2.61 seconds
2021-11-17 13:52:07.896929 (Thread-1): Writing runtime SQL for node "seed.my_new_project.ISS-NNIP_Issuers_20211031"
2021-11-17 13:52:07.908434 (Thread-1): On seed.my_new_project.ISS-NNIP_Issuers_20211031: COMMIT
2021-11-17 13:52:07.908599 (Thread-1): Using postgres connection "seed.my_new_project.ISS-NNIP_Issuers_20211031".
2021-11-17 13:52:07.908703 (Thread-1): On seed.my_new_project.ISS-NNIP_Issuers_20211031: COMMIT
2021-11-17 13:52:07.931484 (Thread-1): SQL status: COMMIT in 0.02 seconds
2021-11-17 13:52:07.931976 (Thread-1): finished collecting timing info
2021-11-17 13:52:07.932117 (Thread-1): On seed.my_new_project.ISS-NNIP_Issuers_20211031: Close
2021-11-17 13:52:07.932543 (Thread-1): 14:52:07 | 1 of 1 OK loaded seed file sa.ISS-NNIP_Issuers_20211031.............. [INSERT 28444 in 670.05s]
2021-11-17 13:52:07.932719 (Thread-1): Finished running node seed.my_new_project.ISS-NNIP_Issuers_20211031
2021-11-17 13:52:07.934549 (MainThread): Acquiring new postgres connection "master".
2021-11-17 13:52:07.934767 (MainThread): Using postgres connection "master".
2021-11-17 13:52:07.934892 (MainThread): On master: BEGIN
2021-11-17 13:52:07.935000 (MainThread): Opening a new connection, currently in state closed
2021-11-17 13:52:07.940541 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 13:52:07.940693 (MainThread): On master: COMMIT
2021-11-17 13:52:07.940796 (MainThread): Using postgres connection "master".
2021-11-17 13:52:07.940899 (MainThread): On master: COMMIT
2021-11-17 13:52:07.941157 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 13:52:07.941295 (MainThread): On master: Close
2021-11-17 13:52:07.941587 (MainThread): 14:52:07 | 
2021-11-17 13:52:07.941806 (MainThread): 14:52:07 | Finished running 1 seed in 670.12s.
2021-11-17 13:52:07.941962 (MainThread): Connection 'master' was properly closed.
2021-11-17 13:52:07.942065 (MainThread): Connection 'seed.my_new_project.ISS-NNIP_Issuers_20211031' was properly closed.
2021-11-17 13:52:07.945675 (MainThread): 
2021-11-17 13:52:07.945955 (MainThread): Completed successfully
2021-11-17 13:52:07.946154 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-11-17 13:52:07.946411 (MainThread): Flushing usage events
2021-11-17 16:30:17.211357 (MainThread): Running with dbt=0.21.0
2021-11-17 16:30:17.262777 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 16:30:17.263200 (MainThread): Tracking: do not track
2021-11-17 16:30:17.272891 (MainThread): Partial parsing not enabled
2021-11-17 16:30:17.279030 (MainThread): Parsing macros/adapters.sql
2021-11-17 16:30:17.296029 (MainThread): Parsing macros/catalog.sql
2021-11-17 16:30:17.297640 (MainThread): Parsing macros/relations.sql
2021-11-17 16:30:17.298643 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 16:30:17.299964 (MainThread): Parsing macros/core.sql
2021-11-17 16:30:17.302904 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 16:30:17.343149 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 16:30:17.345053 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 16:30:17.346387 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 16:30:17.347584 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 16:30:17.354146 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 16:30:17.355290 (MainThread): Parsing macros/etc/query.sql
2021-11-17 16:30:17.356030 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 16:30:17.357158 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 16:30:17.364602 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 16:30:17.369763 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 16:30:17.387260 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 16:30:17.388552 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 16:30:17.411381 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 16:30:17.424813 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 16:30:17.439584 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 16:30:17.447571 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 16:30:17.448940 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 16:30:17.459482 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 16:30:17.462433 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 16:30:17.467988 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 16:30:17.473536 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 16:30:17.474624 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 16:30:17.475556 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 16:30:17.476852 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 16:30:17.625788 (MainThread): Flushing usage events
2021-11-17 16:30:17.626085 (MainThread): Encountered an error:
2021-11-17 16:30:17.626368 (MainThread): the JSON object must be str, bytes or bytearray, not NoneType
2021-11-17 16:30:17.632943 (MainThread): Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 433, in run
    self._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 149, in _runtime_initialize
    super()._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 87, in _runtime_initialize
    self.load_manifest()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 74, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 182, in get_full_manifest
    manifest = loader.load()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 301, in load
    self.parse_project(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 410, in parse_project
    parser.parse_file(block)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/base.py", line 432, in parse_file
    self.parse_node(file_block)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/base.py", line 399, in parse_node
    node = self._create_parsetime_node(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/base.py", line 234, in _create_parsetime_node
    'config': self.config_dict(config),
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/base.py", line 372, in config_dict
    config_dict = config.build_config_dict(base=True)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/context/context_config.py", line 306, in build_config_dict
    return src.calculate_node_config_dict(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/context/context_config.py", line 205, in calculate_node_config_dict
    config = self.calculate_node_config(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/context/context_config.py", line 136, in calculate_node_config
    result = self._update_from_config(result, fqn_config)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/context/context_config.py", line 190, in _update_from_config
    return result.update_from(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/contracts/graph/model_config.py", line 336, in update_from
    return self.from_dict(dct)
  File "<string>", line 3, in from_dict
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/contracts/graph/model_config.py", line 426, in __pre_deserialize__
    data[key] = [hooks.get_hook_dict(h) for h in data[key]]
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/contracts/graph/model_config.py", line 426, in <listcomp>
    data[key] = [hooks.get_hook_dict(h) for h in data[key]]
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/hooks.py", line 19, in get_hook_dict
    return json.loads(source)
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/json/__init__.py", line 339, in loads
    raise TypeError(f'the JSON object must be str, bytes or bytearray, '
TypeError: the JSON object must be str, bytes or bytearray, not NoneType

2021-11-17 16:30:29.891938 (MainThread): Running with dbt=0.21.0
2021-11-17 16:30:29.943563 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag=dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 16:30:29.943981 (MainThread): Tracking: do not track
2021-11-17 16:30:29.954023 (MainThread): Partial parsing not enabled
2021-11-17 16:30:29.959985 (MainThread): Parsing macros/adapters.sql
2021-11-17 16:30:29.977761 (MainThread): Parsing macros/catalog.sql
2021-11-17 16:30:29.979586 (MainThread): Parsing macros/relations.sql
2021-11-17 16:30:29.980509 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 16:30:29.981854 (MainThread): Parsing macros/core.sql
2021-11-17 16:30:29.984683 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 16:30:30.024431 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 16:30:30.026224 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 16:30:30.027571 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 16:30:30.028789 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 16:30:30.035114 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 16:30:30.036239 (MainThread): Parsing macros/etc/query.sql
2021-11-17 16:30:30.036958 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 16:30:30.038054 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 16:30:30.045282 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 16:30:30.050280 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 16:30:30.067067 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 16:30:30.068337 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 16:30:30.090101 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 16:30:30.103201 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 16:30:30.117668 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 16:30:30.125889 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 16:30:30.127180 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 16:30:30.137321 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 16:30:30.140207 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 16:30:30.145344 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 16:30:30.150665 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 16:30:30.151666 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 16:30:30.152545 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 16:30:30.153744 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 16:30:30.299625 (MainThread): Flushing usage events
2021-11-17 16:30:30.299864 (MainThread): Encountered an error:
2021-11-17 16:30:30.300097 (MainThread): the JSON object must be str, bytes or bytearray, not NoneType
2021-11-17 16:30:30.301412 (MainThread): Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 433, in run
    self._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 149, in _runtime_initialize
    super()._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 87, in _runtime_initialize
    self.load_manifest()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 74, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 182, in get_full_manifest
    manifest = loader.load()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 301, in load
    self.parse_project(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 410, in parse_project
    parser.parse_file(block)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/base.py", line 432, in parse_file
    self.parse_node(file_block)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/base.py", line 399, in parse_node
    node = self._create_parsetime_node(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/base.py", line 234, in _create_parsetime_node
    'config': self.config_dict(config),
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/base.py", line 372, in config_dict
    config_dict = config.build_config_dict(base=True)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/context/context_config.py", line 306, in build_config_dict
    return src.calculate_node_config_dict(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/context/context_config.py", line 205, in calculate_node_config_dict
    config = self.calculate_node_config(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/context/context_config.py", line 136, in calculate_node_config
    result = self._update_from_config(result, fqn_config)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/context/context_config.py", line 190, in _update_from_config
    return result.update_from(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/contracts/graph/model_config.py", line 336, in update_from
    return self.from_dict(dct)
  File "<string>", line 3, in from_dict
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/contracts/graph/model_config.py", line 426, in __pre_deserialize__
    data[key] = [hooks.get_hook_dict(h) for h in data[key]]
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/contracts/graph/model_config.py", line 426, in <listcomp>
    data[key] = [hooks.get_hook_dict(h) for h in data[key]]
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/hooks.py", line 19, in get_hook_dict
    return json.loads(source)
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/json/__init__.py", line 339, in loads
    raise TypeError(f'the JSON object must be str, bytes or bytearray, '
TypeError: the JSON object must be str, bytes or bytearray, not NoneType

2021-11-17 16:34:42.164324 (MainThread): Running with dbt=0.21.0
2021-11-17 16:34:42.214977 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 16:34:42.215390 (MainThread): Tracking: do not track
2021-11-17 16:34:42.225815 (MainThread): Partial parsing not enabled
2021-11-17 16:34:42.231798 (MainThread): Parsing macros/adapters.sql
2021-11-17 16:34:42.249245 (MainThread): Parsing macros/catalog.sql
2021-11-17 16:34:42.250864 (MainThread): Parsing macros/relations.sql
2021-11-17 16:34:42.251816 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 16:34:42.253063 (MainThread): Parsing macros/core.sql
2021-11-17 16:34:42.255821 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 16:34:42.299002 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 16:34:42.300983 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 16:34:42.302452 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 16:34:42.303636 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 16:34:42.310350 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 16:34:42.311477 (MainThread): Parsing macros/etc/query.sql
2021-11-17 16:34:42.312243 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 16:34:42.313376 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 16:34:42.321139 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 16:34:42.326250 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 16:34:42.343657 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 16:34:42.344916 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 16:34:42.367667 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 16:34:42.380983 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 16:34:42.395489 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 16:34:42.403817 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 16:34:42.405184 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 16:34:42.415311 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 16:34:42.419265 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 16:34:42.424590 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 16:34:42.430003 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 16:34:42.431074 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 16:34:42.432004 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 16:34:42.433340 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 16:34:42.581569 (MainThread): Flushing usage events
2021-11-17 16:34:42.581979 (MainThread): Encountered an error:
2021-11-17 16:34:42.582246 (MainThread): the JSON object must be str, bytes or bytearray, not NoneType
2021-11-17 16:34:42.584830 (MainThread): Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 433, in run
    self._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 149, in _runtime_initialize
    super()._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 87, in _runtime_initialize
    self.load_manifest()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 74, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 182, in get_full_manifest
    manifest = loader.load()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 301, in load
    self.parse_project(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 410, in parse_project
    parser.parse_file(block)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/base.py", line 432, in parse_file
    self.parse_node(file_block)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/base.py", line 399, in parse_node
    node = self._create_parsetime_node(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/base.py", line 234, in _create_parsetime_node
    'config': self.config_dict(config),
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/base.py", line 372, in config_dict
    config_dict = config.build_config_dict(base=True)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/context/context_config.py", line 306, in build_config_dict
    return src.calculate_node_config_dict(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/context/context_config.py", line 205, in calculate_node_config_dict
    config = self.calculate_node_config(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/context/context_config.py", line 136, in calculate_node_config
    result = self._update_from_config(result, fqn_config)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/context/context_config.py", line 190, in _update_from_config
    return result.update_from(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/contracts/graph/model_config.py", line 336, in update_from
    return self.from_dict(dct)
  File "<string>", line 3, in from_dict
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/contracts/graph/model_config.py", line 426, in __pre_deserialize__
    data[key] = [hooks.get_hook_dict(h) for h in data[key]]
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/contracts/graph/model_config.py", line 426, in <listcomp>
    data[key] = [hooks.get_hook_dict(h) for h in data[key]]
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/hooks.py", line 19, in get_hook_dict
    return json.loads(source)
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/json/__init__.py", line 339, in loads
    raise TypeError(f'the JSON object must be str, bytes or bytearray, '
TypeError: the JSON object must be str, bytes or bytearray, not NoneType

2021-11-17 16:35:09.374620 (MainThread): Running with dbt=0.21.0
2021-11-17 16:35:09.436395 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 16:35:09.436809 (MainThread): Tracking: do not track
2021-11-17 16:35:09.446293 (MainThread): Partial parsing not enabled
2021-11-17 16:35:09.452586 (MainThread): Parsing macros/adapters.sql
2021-11-17 16:35:09.470242 (MainThread): Parsing macros/catalog.sql
2021-11-17 16:35:09.471907 (MainThread): Parsing macros/relations.sql
2021-11-17 16:35:09.472833 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 16:35:09.474071 (MainThread): Parsing macros/core.sql
2021-11-17 16:35:09.476805 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 16:35:09.517057 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 16:35:09.519089 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 16:35:09.520524 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 16:35:09.521705 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 16:35:09.527944 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 16:35:09.529227 (MainThread): Parsing macros/etc/query.sql
2021-11-17 16:35:09.530121 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 16:35:09.531456 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 16:35:09.538839 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 16:35:09.544087 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 16:35:09.561403 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 16:35:09.562637 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 16:35:09.584725 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 16:35:09.597817 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 16:35:09.612297 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 16:35:09.620165 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 16:35:09.621584 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 16:35:09.631714 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 16:35:09.634677 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 16:35:09.639949 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 16:35:09.645660 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 16:35:09.646687 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 16:35:09.647592 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 16:35:09.648853 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 16:35:09.806932 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 16:35:09.817950 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 16:35:09.820820 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:35:09.823367 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:35:09.823590 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:35:09.850169 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:35:09.851614 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:35:09.853004 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:35:09.854488 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:35:09.861046 (MainThread): Flushing usage events
2021-11-17 16:35:09.861188 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-17 16:35:09.861295 (MainThread): Encountered an error:
2021-11-17 16:35:09.861430 (MainThread): Compilation Error
  dbt found two resources with the name "iss_issuer". Since these resources have the same name,
  dbt will be unable to find the correct resource when ref("iss_issuer") is used. To fix this,
  change the name of one of these resources:
  - model.my_new_project.iss_issuer (models/dwh_iss/iss_issuer.sql)
  - seed.my_new_project.iss_issuer (data/iss_issuer.csv)
2021-11-17 16:35:09.865070 (MainThread): Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 433, in run
    self._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 149, in _runtime_initialize
    super()._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 87, in _runtime_initialize
    self.load_manifest()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 74, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 184, in get_full_manifest
    _check_manifest(manifest, config)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 874, in _check_manifest
    _check_resource_uniqueness(manifest, config)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 851, in _check_resource_uniqueness
    dbt.exceptions.raise_duplicate_resource_name(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/exceptions.py", line 788, in raise_duplicate_resource_name
    raise_compiler_error(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/exceptions.py", line 444, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error
  dbt found two resources with the name "iss_issuer". Since these resources have the same name,
  dbt will be unable to find the correct resource when ref("iss_issuer") is used. To fix this,
  change the name of one of these resources:
  - model.my_new_project.iss_issuer (models/dwh_iss/iss_issuer.sql)
  - seed.my_new_project.iss_issuer (data/iss_issuer.csv)

2021-11-17 16:37:03.864883 (MainThread): Running with dbt=0.21.0
2021-11-17 16:37:03.921299 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 16:37:03.921831 (MainThread): Tracking: do not track
2021-11-17 16:37:03.932082 (MainThread): Partial parsing not enabled
2021-11-17 16:37:03.938468 (MainThread): Parsing macros/adapters.sql
2021-11-17 16:37:03.956683 (MainThread): Parsing macros/catalog.sql
2021-11-17 16:37:03.958550 (MainThread): Parsing macros/relations.sql
2021-11-17 16:37:03.959570 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 16:37:03.960919 (MainThread): Parsing macros/core.sql
2021-11-17 16:37:03.963924 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 16:37:04.005458 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 16:37:04.007333 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 16:37:04.008786 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 16:37:04.010244 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 16:37:04.016429 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 16:37:04.017633 (MainThread): Parsing macros/etc/query.sql
2021-11-17 16:37:04.018460 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 16:37:04.019631 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 16:37:04.026822 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 16:37:04.032016 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 16:37:04.048981 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 16:37:04.050329 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 16:37:04.072554 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 16:37:04.085422 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 16:37:04.099622 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 16:37:04.107446 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 16:37:04.108790 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 16:37:04.118795 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 16:37:04.124105 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 16:37:04.129822 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 16:37:04.135275 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 16:37:04.136289 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 16:37:04.137256 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 16:37:04.138652 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 16:37:04.303827 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 16:37:04.314262 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 16:37:04.317245 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:37:04.319913 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:37:04.320138 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:37:04.347944 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:37:04.349443 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:37:04.350843 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:37:04.352437 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:37:04.366343 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-17 16:37:04.366648 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-17 16:37:04.367831 (MainThread): 
2021-11-17 16:37:04.368148 (MainThread): Acquiring new postgres connection "master".
2021-11-17 16:37:04.368911 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-17 16:37:04.376576 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-17 16:37:04.376724 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-17 16:37:04.376832 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-17 16:37:04.384320 (ThreadPoolExecutor-0_0): SQL status: SELECT 7 in 0.01 seconds
2021-11-17 16:37:04.385689 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-17 16:37:04.386476 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_demo_db_sa_dwh".
2021-11-17 16:37:04.386673 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_demo_db_sa_dwh".
2021-11-17 16:37:04.386877 (ThreadPoolExecutor-0_0): Creating schema ""demo_db"."sa_dwh""
2021-11-17 16:37:04.391045 (ThreadPoolExecutor-0_0): Using postgres connection "create_demo_db_sa_dwh".
2021-11-17 16:37:04.391175 (ThreadPoolExecutor-0_0): On create_demo_db_sa_dwh: BEGIN
2021-11-17 16:37:04.391277 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-11-17 16:37:04.397708 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:37:04.397910 (ThreadPoolExecutor-0_0): Using postgres connection "create_demo_db_sa_dwh".
2021-11-17 16:37:04.398007 (ThreadPoolExecutor-0_0): On create_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "create_demo_db_sa_dwh"} */
create schema if not exists "sa_dwh"
2021-11-17 16:37:04.398648 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.00 seconds
2021-11-17 16:37:04.399276 (ThreadPoolExecutor-0_0): On create_demo_db_sa_dwh: COMMIT
2021-11-17 16:37:04.399383 (ThreadPoolExecutor-0_0): Using postgres connection "create_demo_db_sa_dwh".
2021-11-17 16:37:04.399474 (ThreadPoolExecutor-0_0): On create_demo_db_sa_dwh: COMMIT
2021-11-17 16:37:04.400797 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.00 seconds
2021-11-17 16:37:04.400933 (ThreadPoolExecutor-0_0): On create_demo_db_sa_dwh: Close
2021-11-17 16:37:04.402159 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:37:04.402608 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa".
2021-11-17 16:37:04.406931 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:37:04.407868 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-17 16:37:04.408072 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: BEGIN
2021-11-17 16:37:04.408219 (ThreadPoolExecutor-1_1): On list_demo_db_sa: BEGIN
2021-11-17 16:37:04.408457 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-17 16:37:04.408598 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-17 16:37:04.415209 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:37:04.415453 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-17 16:37:04.415617 (ThreadPoolExecutor-1_1): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-17 16:37:04.415809 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:37:04.416054 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:37:04.416198 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-17 16:37:04.417546 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 16:37:04.418578 (ThreadPoolExecutor-1_1): On list_demo_db_sa: ROLLBACK
2021-11-17 16:37:04.418782 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.00 seconds
2021-11-17 16:37:04.419721 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: ROLLBACK
2021-11-17 16:37:04.419956 (ThreadPoolExecutor-1_1): On list_demo_db_sa: Close
2021-11-17 16:37:04.420573 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: Close
2021-11-17 16:37:04.425238 (MainThread): Using postgres connection "master".
2021-11-17 16:37:04.425401 (MainThread): On master: BEGIN
2021-11-17 16:37:04.425515 (MainThread): Opening a new connection, currently in state init
2021-11-17 16:37:04.431380 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:37:04.431526 (MainThread): Using postgres connection "master".
2021-11-17 16:37:04.431628 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-17 16:37:04.433788 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-17 16:37:04.434642 (MainThread): On master: ROLLBACK
2021-11-17 16:37:04.434947 (MainThread): Using postgres connection "master".
2021-11-17 16:37:04.435048 (MainThread): On master: BEGIN
2021-11-17 16:37:04.435650 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-17 16:37:04.435810 (MainThread): On master: COMMIT
2021-11-17 16:37:04.435916 (MainThread): Using postgres connection "master".
2021-11-17 16:37:04.436002 (MainThread): On master: COMMIT
2021-11-17 16:37:04.436396 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 16:37:04.436514 (MainThread): On master: Close
2021-11-17 16:37:04.436858 (MainThread): 17:37:04 | Concurrency: 2 threads (target='dev')
2021-11-17 16:37:04.437051 (MainThread): 17:37:04 | 
2021-11-17 16:37:04.439642 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-17 16:37:04.440088 (Thread-1): 17:37:04 | 1 of 1 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-17 16:37:04.440421 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:37:04.440579 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-17 16:37:04.442918 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-17 16:37:04.443206 (Thread-1): finished collecting timing info
2021-11-17 16:37:04.477082 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-17 16:37:04.477466 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:37:04.477578 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-17 16:37:04.477681 (Thread-1): Opening a new connection, currently in state closed
2021-11-17 16:37:04.484242 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:37:04.484437 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:37:04.484528 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer"
  as (
    

select
     AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,ISIN                             as isin
    ,IssuerName                       as issuer_name
    ,ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,ClimateScope2Emissions           as climate_scope2_emissions
    ,ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,ClimateScope3Emissions           as climate_scope3_emissions
    ,ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,ClimateTotalEmissions            as climate_total_emissions
    ,ClimateScope1Emissions           as climate_scope1_emissions
    ,MarketCapDaily                   as market_capdaily
    ,ClimateEmissionsFiscalYear       as climate_emissions_fiscal_year
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-17 16:37:04.571264 (Thread-1): SQL status: SELECT 28444 in 0.09 seconds
2021-11-17 16:37:04.579065 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-17 16:37:04.579191 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:37:04.579284 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-17 16:37:04.600169 (Thread-1): SQL status: COMMIT in 0.02 seconds
2021-11-17 16:37:04.600672 (Thread-1): finished collecting timing info
2021-11-17 16:37:04.600813 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-17 16:37:04.601297 (Thread-1): 17:37:04 | 1 of 1 OK created incremental model sa_dwh.iss_issuer................ [SELECT 28444 in 0.16s]
2021-11-17 16:37:04.601475 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-17 16:37:04.602770 (MainThread): Acquiring new postgres connection "master".
2021-11-17 16:37:04.602958 (MainThread): Using postgres connection "master".
2021-11-17 16:37:04.603060 (MainThread): On master: BEGIN
2021-11-17 16:37:04.603160 (MainThread): Opening a new connection, currently in state closed
2021-11-17 16:37:04.609102 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:37:04.609248 (MainThread): On master: COMMIT
2021-11-17 16:37:04.609346 (MainThread): Using postgres connection "master".
2021-11-17 16:37:04.609439 (MainThread): On master: COMMIT
2021-11-17 16:37:04.609817 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 16:37:04.609965 (MainThread): On master: Close
2021-11-17 16:37:04.610297 (MainThread): 17:37:04 | 
2021-11-17 16:37:04.610469 (MainThread): 17:37:04 | Finished running 1 incremental model in 0.24s.
2021-11-17 16:37:04.610641 (MainThread): Connection 'master' was properly closed.
2021-11-17 16:37:04.610780 (MainThread): Connection 'list_demo_db_sa_dwh' was properly closed.
2021-11-17 16:37:04.610884 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-17 16:37:04.614302 (MainThread): 
2021-11-17 16:37:04.614476 (MainThread): Completed successfully
2021-11-17 16:37:04.614645 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-11-17 16:37:04.615050 (MainThread): Flushing usage events
2021-11-17 16:43:47.446424 (MainThread): Running with dbt=0.21.0
2021-11-17 16:43:47.498013 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 16:43:47.498738 (MainThread): Tracking: do not track
2021-11-17 16:43:47.508947 (MainThread): Partial parsing not enabled
2021-11-17 16:43:47.514775 (MainThread): Parsing macros/adapters.sql
2021-11-17 16:43:47.532344 (MainThread): Parsing macros/catalog.sql
2021-11-17 16:43:47.533991 (MainThread): Parsing macros/relations.sql
2021-11-17 16:43:47.534892 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 16:43:47.536112 (MainThread): Parsing macros/core.sql
2021-11-17 16:43:47.538970 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 16:43:47.582404 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 16:43:47.584275 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 16:43:47.585641 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 16:43:47.586834 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 16:43:47.593365 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 16:43:47.594523 (MainThread): Parsing macros/etc/query.sql
2021-11-17 16:43:47.595278 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 16:43:47.596407 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 16:43:47.603973 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 16:43:47.609248 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 16:43:47.626282 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 16:43:47.627527 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 16:43:47.649924 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 16:43:47.663276 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 16:43:47.677664 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 16:43:47.685638 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 16:43:47.687103 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 16:43:47.697311 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 16:43:47.700318 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 16:43:47.705519 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 16:43:47.710770 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 16:43:47.711997 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 16:43:47.713034 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 16:43:47.714285 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 16:43:47.871918 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 16:43:47.881713 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 16:43:47.884453 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:43:47.886976 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:43:47.887186 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:43:47.914211 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:43:47.915729 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:43:47.917152 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:43:47.918665 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:43:47.931835 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-17 16:43:47.932138 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-17 16:43:47.933543 (MainThread): 
2021-11-17 16:43:47.933812 (MainThread): Acquiring new postgres connection "master".
2021-11-17 16:43:47.934432 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-17 16:43:47.946851 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-17 16:43:47.947112 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-17 16:43:47.947279 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-17 16:43:47.956117 (ThreadPoolExecutor-0_0): SQL status: SELECT 8 in 0.01 seconds
2021-11-17 16:43:47.957151 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-17 16:43:47.958664 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:43:47.959335 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa".
2021-11-17 16:43:47.964055 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:43:47.965310 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-17 16:43:47.965550 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: BEGIN
2021-11-17 16:43:47.965785 (ThreadPoolExecutor-1_1): On list_demo_db_sa: BEGIN
2021-11-17 16:43:47.966027 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-17 16:43:47.966273 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-17 16:43:47.974342 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:43:47.974547 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:43:47.974640 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-17 16:43:47.976629 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:43:47.976844 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-17 16:43:47.977013 (ThreadPoolExecutor-1_1): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-17 16:43:47.977358 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 16:43:47.978589 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: ROLLBACK
2021-11-17 16:43:47.978921 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: Close
2021-11-17 16:43:47.979638 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 16:43:47.980970 (ThreadPoolExecutor-1_1): On list_demo_db_sa: ROLLBACK
2021-11-17 16:43:47.981445 (ThreadPoolExecutor-1_1): On list_demo_db_sa: Close
2021-11-17 16:43:47.984687 (MainThread): Using postgres connection "master".
2021-11-17 16:43:47.984800 (MainThread): On master: BEGIN
2021-11-17 16:43:47.984899 (MainThread): Opening a new connection, currently in state init
2021-11-17 16:43:47.991386 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:43:47.991542 (MainThread): Using postgres connection "master".
2021-11-17 16:43:47.991643 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-17 16:43:47.994079 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-17 16:43:47.995002 (MainThread): On master: ROLLBACK
2021-11-17 16:43:47.995492 (MainThread): Using postgres connection "master".
2021-11-17 16:43:47.995608 (MainThread): On master: BEGIN
2021-11-17 16:43:47.996387 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-17 16:43:47.996568 (MainThread): On master: COMMIT
2021-11-17 16:43:47.996668 (MainThread): Using postgres connection "master".
2021-11-17 16:43:47.996761 (MainThread): On master: COMMIT
2021-11-17 16:43:47.997106 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 16:43:47.997239 (MainThread): On master: Close
2021-11-17 16:43:47.997531 (MainThread): 17:43:47 | Concurrency: 2 threads (target='dev')
2021-11-17 16:43:47.997688 (MainThread): 17:43:47 | 
2021-11-17 16:43:48.000445 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-17 16:43:48.000717 (Thread-1): 17:43:47 | 1 of 1 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-17 16:43:48.001015 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:43:48.001147 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-17 16:43:48.003419 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-17 16:43:48.003661 (Thread-1): finished collecting timing info
2021-11-17 16:43:48.040179 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:43:48.040342 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

    

  create temporary table "iss_issuer__dbt_tmp174348026276"
  as (
    

select
     AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,ISIN                             as isin
    ,IssuerName                       as issuer_name
    ,ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,ClimateScope2Emissions           as climate_scope2_emissions
    ,ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,ClimateScope3Emissions           as climate_scope3_emissions
    ,ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,ClimateTotalEmissions            as climate_total_emissions
    ,ClimateScope1Emissions           as climate_scope1_emissions
    ,MarketCapDaily                   as market_capdaily
    ,ClimateEmissionsFiscalYear       as climate_emissions_fiscal_year
    ,CURRENT_TIMESTAMP                as meta_insert_timestamp
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-17 16:43:48.040459 (Thread-1): Opening a new connection, currently in state closed
2021-11-17 16:43:48.124577 (Thread-1): SQL status: SELECT 28444 in 0.08 seconds
2021-11-17 16:43:48.129874 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:43:48.129992 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-17 16:43:48.130533 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-11-17 16:43:48.130692 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:43:48.130779 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer__dbt_tmp174348026276'
        
      order by ordinal_position

  
2021-11-17 16:43:48.135377 (Thread-1): SQL status: SELECT 14 in 0.00 seconds
2021-11-17 16:43:48.139568 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:43:48.139685 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-17 16:43:48.142162 (Thread-1): SQL status: SELECT 13 in 0.00 seconds
2021-11-17 16:43:48.149077 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:43:48.149191 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-17 16:43:48.151130 (Thread-1): SQL status: SELECT 13 in 0.00 seconds
2021-11-17 16:43:48.152339 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-17 16:43:48.152586 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:43:48.152701 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      delete
    from "demo_db"."sa_dwh"."iss_issuer"
    where (ISIN) in (
        select (ISIN)
        from "iss_issuer__dbt_tmp174348026276"
    );

    insert into "demo_db"."sa_dwh"."iss_issuer" ("adjusted_enterprise_value", "isin", "issuer_name", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_capdaily", "climate_emissions_fiscal_year")
    (
       select "adjusted_enterprise_value", "isin", "issuer_name", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_capdaily", "climate_emissions_fiscal_year"
       from "iss_issuer__dbt_tmp174348026276"
    );
  
2021-11-17 16:43:48.230535 (Thread-1): SQL status: INSERT 0 28444 in 0.08 seconds
2021-11-17 16:43:48.235556 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-17 16:43:48.235681 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:43:48.235793 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-17 16:43:48.242540 (Thread-1): SQL status: COMMIT in 0.01 seconds
2021-11-17 16:43:48.243005 (Thread-1): finished collecting timing info
2021-11-17 16:43:48.243162 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-17 16:43:48.243609 (Thread-1): 17:43:48 | 1 of 1 OK created incremental model sa_dwh.iss_issuer................ [INSERT 0 28444 in 0.24s]
2021-11-17 16:43:48.243805 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-17 16:43:48.245462 (MainThread): Acquiring new postgres connection "master".
2021-11-17 16:43:48.245616 (MainThread): Using postgres connection "master".
2021-11-17 16:43:48.245710 (MainThread): On master: BEGIN
2021-11-17 16:43:48.245806 (MainThread): Opening a new connection, currently in state closed
2021-11-17 16:43:48.252114 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:43:48.252316 (MainThread): On master: COMMIT
2021-11-17 16:43:48.252464 (MainThread): Using postgres connection "master".
2021-11-17 16:43:48.252564 (MainThread): On master: COMMIT
2021-11-17 16:43:48.252848 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 16:43:48.252994 (MainThread): On master: Close
2021-11-17 16:43:48.253331 (MainThread): 17:43:48 | 
2021-11-17 16:43:48.253499 (MainThread): 17:43:48 | Finished running 1 incremental model in 0.32s.
2021-11-17 16:43:48.253688 (MainThread): Connection 'master' was properly closed.
2021-11-17 16:43:48.253822 (MainThread): Connection 'list_demo_db_sa_dwh' was properly closed.
2021-11-17 16:43:48.253924 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-17 16:43:48.256741 (MainThread): 
2021-11-17 16:43:48.256890 (MainThread): Completed successfully
2021-11-17 16:43:48.257090 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-11-17 16:43:48.257400 (MainThread): Flushing usage events
2021-11-17 16:44:50.854987 (MainThread): Running with dbt=0.21.0
2021-11-17 16:44:50.905052 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=True, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 16:44:50.905469 (MainThread): Tracking: do not track
2021-11-17 16:44:50.915017 (MainThread): Partial parsing not enabled
2021-11-17 16:44:50.920867 (MainThread): Parsing macros/adapters.sql
2021-11-17 16:44:50.937772 (MainThread): Parsing macros/catalog.sql
2021-11-17 16:44:50.939566 (MainThread): Parsing macros/relations.sql
2021-11-17 16:44:50.940489 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 16:44:50.941704 (MainThread): Parsing macros/core.sql
2021-11-17 16:44:50.944424 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 16:44:50.984433 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 16:44:50.986254 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 16:44:50.987644 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 16:44:50.988990 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 16:44:50.995252 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 16:44:50.996362 (MainThread): Parsing macros/etc/query.sql
2021-11-17 16:44:50.997084 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 16:44:50.998243 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 16:44:51.005395 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 16:44:51.010742 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 16:44:51.026986 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 16:44:51.028235 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 16:44:51.049563 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 16:44:51.064268 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 16:44:51.078406 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 16:44:51.086473 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 16:44:51.087729 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 16:44:51.097851 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 16:44:51.101087 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 16:44:51.106320 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 16:44:51.111754 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 16:44:51.112885 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 16:44:51.113774 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 16:44:51.114980 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 16:44:51.265594 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 16:44:51.275030 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 16:44:51.277721 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:44:51.280156 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:44:51.280369 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:44:51.306396 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:44:51.307816 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:44:51.309194 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:44:51.310814 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:44:51.323708 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-17 16:44:51.323982 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-17 16:44:51.325108 (MainThread): 
2021-11-17 16:44:51.325439 (MainThread): Acquiring new postgres connection "master".
2021-11-17 16:44:51.326035 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-17 16:44:51.333348 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-17 16:44:51.333468 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-17 16:44:51.333569 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-17 16:44:51.341983 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.01 seconds
2021-11-17 16:44:51.342920 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-17 16:44:51.344116 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-17 16:44:51.349054 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 16:44:51.349457 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-17 16:44:51.349647 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-17 16:44:51.350111 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:44:51.351385 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:44:51.351660 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-17 16:44:51.351792 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-17 16:44:51.357024 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:44:51.357222 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 16:44:51.357312 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-17 16:44:51.358878 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:44:51.359032 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:44:51.359122 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-17 16:44:51.359581 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 16:44:51.360473 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-17 16:44:51.360778 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 16:44:51.361819 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-17 16:44:51.362051 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-17 16:44:51.362778 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-17 16:44:51.368206 (MainThread): Using postgres connection "master".
2021-11-17 16:44:51.368452 (MainThread): On master: BEGIN
2021-11-17 16:44:51.368567 (MainThread): Opening a new connection, currently in state init
2021-11-17 16:44:51.374198 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:44:51.374356 (MainThread): Using postgres connection "master".
2021-11-17 16:44:51.374450 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-17 16:44:51.376719 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-17 16:44:51.377685 (MainThread): On master: ROLLBACK
2021-11-17 16:44:51.378045 (MainThread): Using postgres connection "master".
2021-11-17 16:44:51.378142 (MainThread): On master: BEGIN
2021-11-17 16:44:51.378719 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-17 16:44:51.378872 (MainThread): On master: COMMIT
2021-11-17 16:44:51.378963 (MainThread): Using postgres connection "master".
2021-11-17 16:44:51.379048 (MainThread): On master: COMMIT
2021-11-17 16:44:51.379335 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 16:44:51.379492 (MainThread): On master: Close
2021-11-17 16:44:51.379785 (MainThread): 17:44:51 | Concurrency: 2 threads (target='dev')
2021-11-17 16:44:51.380004 (MainThread): 17:44:51 | 
2021-11-17 16:44:51.382639 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-17 16:44:51.382975 (Thread-1): 17:44:51 | 1 of 1 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-17 16:44:51.383356 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:44:51.383495 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-17 16:44:51.385674 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-17 16:44:51.385899 (Thread-1): finished collecting timing info
2021-11-17 16:44:51.419346 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-17 16:44:51.419659 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:44:51.419764 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-17 16:44:51.419863 (Thread-1): Opening a new connection, currently in state closed
2021-11-17 16:44:51.426205 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:44:51.426374 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:44:51.426467 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp"
  as (
    

select
     AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,ISIN                             as isin
    ,IssuerName                       as issuer_name
    ,ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,ClimateScope2Emissions           as climate_scope2_emissions
    ,ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,ClimateScope3Emissions           as climate_scope3_emissions
    ,ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,ClimateTotalEmissions            as climate_total_emissions
    ,ClimateScope1Emissions           as climate_scope1_emissions
    ,MarketCapDaily                   as market_capdaily
    ,ClimateEmissionsFiscalYear       as climate_emissions_fiscal_year
    ,CURRENT_TIMESTAMP                as meta_insert_timestamp
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-17 16:44:51.514324 (Thread-1): SQL status: SELECT 28444 in 0.09 seconds
2021-11-17 16:44:51.518688 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:44:51.518807 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */
alter table "demo_db"."sa_dwh"."iss_issuer" rename to "iss_issuer__dbt_backup"
2021-11-17 16:44:51.519380 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-11-17 16:44:51.520599 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:44:51.520704 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */
alter table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp" rename to "iss_issuer"
2021-11-17 16:44:51.521235 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-11-17 16:44:51.529358 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-17 16:44:51.529471 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:44:51.529562 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-17 16:44:51.548742 (Thread-1): SQL status: COMMIT in 0.02 seconds
2021-11-17 16:44:51.552071 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:44:51.552181 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */
drop table if exists "demo_db"."sa_dwh"."iss_issuer__dbt_backup" cascade
2021-11-17 16:44:51.555150 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-11-17 16:44:51.555941 (Thread-1): finished collecting timing info
2021-11-17 16:44:51.556073 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-17 16:44:51.556480 (Thread-1): 17:44:51 | 1 of 1 OK created incremental model sa_dwh.iss_issuer................ [SELECT 28444 in 0.17s]
2021-11-17 16:44:51.556631 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-17 16:44:51.558200 (MainThread): Acquiring new postgres connection "master".
2021-11-17 16:44:51.558471 (MainThread): Using postgres connection "master".
2021-11-17 16:44:51.558567 (MainThread): On master: BEGIN
2021-11-17 16:44:51.558663 (MainThread): Opening a new connection, currently in state closed
2021-11-17 16:44:51.565465 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:44:51.565630 (MainThread): On master: COMMIT
2021-11-17 16:44:51.565722 (MainThread): Using postgres connection "master".
2021-11-17 16:44:51.565807 (MainThread): On master: COMMIT
2021-11-17 16:44:51.566280 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 16:44:51.566420 (MainThread): On master: Close
2021-11-17 16:44:51.566766 (MainThread): 17:44:51 | 
2021-11-17 16:44:51.567000 (MainThread): 17:44:51 | Finished running 1 incremental model in 0.24s.
2021-11-17 16:44:51.567183 (MainThread): Connection 'master' was properly closed.
2021-11-17 16:44:51.567351 (MainThread): Connection 'list_demo_db_sa' was properly closed.
2021-11-17 16:44:51.567506 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-17 16:44:51.570549 (MainThread): 
2021-11-17 16:44:51.570912 (MainThread): Completed successfully
2021-11-17 16:44:51.571197 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-11-17 16:44:51.571579 (MainThread): Flushing usage events
2021-11-17 16:48:40.541713 (MainThread): Running with dbt=0.21.0
2021-11-17 16:48:40.598705 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=True, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 16:48:40.599507 (MainThread): Tracking: do not track
2021-11-17 16:48:40.610850 (MainThread): Partial parsing not enabled
2021-11-17 16:48:40.617317 (MainThread): Parsing macros/adapters.sql
2021-11-17 16:48:40.635676 (MainThread): Parsing macros/catalog.sql
2021-11-17 16:48:40.637516 (MainThread): Parsing macros/relations.sql
2021-11-17 16:48:40.638619 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 16:48:40.639859 (MainThread): Parsing macros/core.sql
2021-11-17 16:48:40.642646 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 16:48:40.690267 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 16:48:40.693539 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 16:48:40.695892 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 16:48:40.698092 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 16:48:40.709702 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 16:48:40.711690 (MainThread): Parsing macros/etc/query.sql
2021-11-17 16:48:40.712933 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 16:48:40.714839 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 16:48:40.727293 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 16:48:40.732814 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 16:48:40.750444 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 16:48:40.751886 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 16:48:40.774216 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 16:48:40.787614 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 16:48:40.802457 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 16:48:40.810118 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 16:48:40.811549 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 16:48:40.821766 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 16:48:40.824583 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 16:48:40.829769 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 16:48:40.835283 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 16:48:40.836300 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 16:48:40.837302 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 16:48:40.838552 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 16:48:40.997313 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 16:48:41.007542 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 16:48:41.010441 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:48:41.013346 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:48:41.013564 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:48:41.041134 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:48:41.042683 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:48:41.044175 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:48:41.045649 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:48:41.059899 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-17 16:48:41.060197 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-17 16:48:41.061419 (MainThread): 
2021-11-17 16:48:41.061928 (MainThread): Acquiring new postgres connection "master".
2021-11-17 16:48:41.062569 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-17 16:48:41.070255 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-17 16:48:41.070393 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-17 16:48:41.070495 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-17 16:48:41.078488 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.01 seconds
2021-11-17 16:48:41.079473 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-17 16:48:41.080714 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-17 16:48:41.085515 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 16:48:41.085698 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-17 16:48:41.085830 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-17 16:48:41.086973 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:48:41.088518 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:48:41.088809 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-17 16:48:41.088948 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-17 16:48:41.093807 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:48:41.093959 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 16:48:41.094052 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-17 16:48:41.096005 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 16:48:41.096264 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:48:41.097223 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-17 16:48:41.097409 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:48:41.097661 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-17 16:48:41.097973 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-17 16:48:41.099532 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 16:48:41.100456 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-17 16:48:41.100876 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-17 16:48:41.104902 (MainThread): Using postgres connection "master".
2021-11-17 16:48:41.105093 (MainThread): On master: BEGIN
2021-11-17 16:48:41.105206 (MainThread): Opening a new connection, currently in state init
2021-11-17 16:48:41.111746 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:48:41.111946 (MainThread): Using postgres connection "master".
2021-11-17 16:48:41.112045 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-17 16:48:41.114501 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-17 16:48:41.115382 (MainThread): On master: ROLLBACK
2021-11-17 16:48:41.115728 (MainThread): Using postgres connection "master".
2021-11-17 16:48:41.115837 (MainThread): On master: BEGIN
2021-11-17 16:48:41.116437 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-17 16:48:41.116673 (MainThread): On master: COMMIT
2021-11-17 16:48:41.116771 (MainThread): Using postgres connection "master".
2021-11-17 16:48:41.116859 (MainThread): On master: COMMIT
2021-11-17 16:48:41.117389 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 16:48:41.117516 (MainThread): On master: Close
2021-11-17 16:48:41.117851 (MainThread): 17:48:41 | Concurrency: 2 threads (target='dev')
2021-11-17 16:48:41.118023 (MainThread): 17:48:41 | 
2021-11-17 16:48:41.120798 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-17 16:48:41.121096 (Thread-1): 17:48:41 | 1 of 1 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-17 16:48:41.121419 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:48:41.121543 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-17 16:48:41.124011 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-17 16:48:41.124243 (Thread-1): finished collecting timing info
2021-11-17 16:48:41.165957 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-17 16:48:41.166280 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:48:41.166387 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-17 16:48:41.166485 (Thread-1): Opening a new connection, currently in state closed
2021-11-17 16:48:41.173194 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:48:41.173512 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:48:41.173611 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp"
  as (
    

select
     AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,ISIN                             as isin
    ,IssuerName                       as issuer_name
    ,ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,ClimateScope2Emissions           as climate_scope2_emissions
    ,ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,ClimateScope3Emissions           as climate_scope3_emissions
    ,ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,ClimateTotalEmissions            as climate_total_emissions
    ,ClimateScope1Emissions           as climate_scope1_emissions
    ,MarketCapDaily                   as market_capdaily
    ,ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,CURRENT_TIMESTAMP                as meta_insert_timestamp
    ,'20211117T164451425627'          as meta_run_id
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-17 16:48:41.263042 (Thread-1): SQL status: SELECT 28444 in 0.09 seconds
2021-11-17 16:48:41.267638 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:48:41.267764 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */
alter table "demo_db"."sa_dwh"."iss_issuer" rename to "iss_issuer__dbt_backup"
2021-11-17 16:48:41.268444 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-11-17 16:48:41.269750 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:48:41.269854 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */
alter table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp" rename to "iss_issuer"
2021-11-17 16:48:41.270368 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-11-17 16:48:41.278940 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-17 16:48:41.279093 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:48:41.279218 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-17 16:48:41.289584 (Thread-1): SQL status: COMMIT in 0.01 seconds
2021-11-17 16:48:41.293288 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:48:41.293413 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */
drop table if exists "demo_db"."sa_dwh"."iss_issuer__dbt_backup" cascade
2021-11-17 16:48:41.296764 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-11-17 16:48:41.298448 (Thread-1): finished collecting timing info
2021-11-17 16:48:41.298631 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-17 16:48:41.299108 (Thread-1): 17:48:41 | 1 of 1 OK created incremental model sa_dwh.iss_issuer................ [SELECT 28444 in 0.18s]
2021-11-17 16:48:41.299291 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-17 16:48:41.301361 (MainThread): Acquiring new postgres connection "master".
2021-11-17 16:48:41.301596 (MainThread): Using postgres connection "master".
2021-11-17 16:48:41.301707 (MainThread): On master: BEGIN
2021-11-17 16:48:41.301817 (MainThread): Opening a new connection, currently in state closed
2021-11-17 16:48:41.307492 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:48:41.307662 (MainThread): On master: COMMIT
2021-11-17 16:48:41.307767 (MainThread): Using postgres connection "master".
2021-11-17 16:48:41.307863 (MainThread): On master: COMMIT
2021-11-17 16:48:41.308118 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 16:48:41.308282 (MainThread): On master: Close
2021-11-17 16:48:41.308612 (MainThread): 17:48:41 | 
2021-11-17 16:48:41.308769 (MainThread): 17:48:41 | Finished running 1 incremental model in 0.25s.
2021-11-17 16:48:41.308907 (MainThread): Connection 'master' was properly closed.
2021-11-17 16:48:41.309007 (MainThread): Connection 'list_demo_db_sa' was properly closed.
2021-11-17 16:48:41.309095 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-17 16:48:41.312083 (MainThread): 
2021-11-17 16:48:41.312247 (MainThread): Completed successfully
2021-11-17 16:48:41.312394 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-11-17 16:48:41.312587 (MainThread): Flushing usage events
2021-11-17 16:55:30.645608 (MainThread): Running with dbt=0.21.0
2021-11-17 16:55:30.696306 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=True, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 16:55:30.696770 (MainThread): Tracking: do not track
2021-11-17 16:55:30.706838 (MainThread): Partial parsing not enabled
2021-11-17 16:55:30.713121 (MainThread): Parsing macros/adapters.sql
2021-11-17 16:55:30.733385 (MainThread): Parsing macros/catalog.sql
2021-11-17 16:55:30.735162 (MainThread): Parsing macros/relations.sql
2021-11-17 16:55:30.736104 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 16:55:30.737349 (MainThread): Parsing macros/core.sql
2021-11-17 16:55:30.740277 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 16:55:30.780509 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 16:55:30.782367 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 16:55:30.783711 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 16:55:30.784880 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 16:55:30.791354 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 16:55:30.792481 (MainThread): Parsing macros/etc/query.sql
2021-11-17 16:55:30.793213 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 16:55:30.794369 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 16:55:30.801753 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 16:55:30.806729 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 16:55:30.823515 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 16:55:30.824883 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 16:55:30.846768 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 16:55:30.860609 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 16:55:30.874724 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 16:55:30.882524 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 16:55:30.883820 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 16:55:30.893784 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 16:55:30.896824 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 16:55:30.902069 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 16:55:30.907376 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 16:55:30.908405 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 16:55:30.909303 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 16:55:30.910581 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 16:55:31.069788 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 16:55:31.079847 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 16:55:31.082536 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:55:31.085546 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:55:31.085781 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:55:31.111596 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:55:31.113002 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:55:31.114418 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:55:31.115907 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:55:31.128972 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-17 16:55:31.129251 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-17 16:55:31.130342 (MainThread): 
2021-11-17 16:55:31.130605 (MainThread): Acquiring new postgres connection "master".
2021-11-17 16:55:31.131259 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-17 16:55:31.138474 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-17 16:55:31.138585 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-17 16:55:31.138683 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-17 16:55:31.146109 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.01 seconds
2021-11-17 16:55:31.147139 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-17 16:55:31.148432 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-17 16:55:31.152441 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 16:55:31.152571 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-17 16:55:31.152706 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-17 16:55:31.153469 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:55:31.154618 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:55:31.154807 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-17 16:55:31.155298 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-17 16:55:31.159762 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:55:31.160042 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 16:55:31.160133 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-17 16:55:31.162144 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 16:55:31.163222 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-17 16:55:31.163410 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:55:31.163610 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:55:31.163800 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-17 16:55:31.163960 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-17 16:55:31.165832 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 16:55:31.166678 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-17 16:55:31.167169 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-17 16:55:31.170504 (MainThread): Using postgres connection "master".
2021-11-17 16:55:31.170622 (MainThread): On master: BEGIN
2021-11-17 16:55:31.170719 (MainThread): Opening a new connection, currently in state init
2021-11-17 16:55:31.176992 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:55:31.177114 (MainThread): Using postgres connection "master".
2021-11-17 16:55:31.177201 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-17 16:55:31.179606 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-17 16:55:31.180589 (MainThread): On master: ROLLBACK
2021-11-17 16:55:31.181033 (MainThread): Using postgres connection "master".
2021-11-17 16:55:31.181151 (MainThread): On master: BEGIN
2021-11-17 16:55:31.181922 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-17 16:55:31.182050 (MainThread): On master: COMMIT
2021-11-17 16:55:31.182152 (MainThread): Using postgres connection "master".
2021-11-17 16:55:31.182246 (MainThread): On master: COMMIT
2021-11-17 16:55:31.182680 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 16:55:31.182816 (MainThread): On master: Close
2021-11-17 16:55:31.183106 (MainThread): 17:55:31 | Concurrency: 2 threads (target='dev')
2021-11-17 16:55:31.183298 (MainThread): 17:55:31 | 
2021-11-17 16:55:31.185763 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-17 16:55:31.186048 (Thread-1): 17:55:31 | 1 of 1 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-17 16:55:31.186363 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:55:31.186532 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-17 16:55:31.189023 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-17 16:55:31.189241 (Thread-1): finished collecting timing info
2021-11-17 16:55:31.223219 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-17 16:55:31.223515 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:55:31.223620 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-17 16:55:31.223718 (Thread-1): Opening a new connection, currently in state closed
2021-11-17 16:55:31.230305 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:55:31.230483 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:55:31.230576 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp"
  as (
    

select
     AdjustedEnterpriseValue::INT     as adjusted_enterprise_value
    ,ISIN::STRING                     as isin
    ,IssuerName::STRING                       as issuer_name
    ,ClimateScope2EmissionsIntUSD::NUMERIC     as climate_scope2_emissions_int_usd
    ,ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,ClimateScope2Emissions           as climate_scope2_emissions
    ,ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,ClimateScope3Emissions           as climate_scope3_emissions
    ,ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,ClimateTotalEmissions            as climate_total_emissions
    ,ClimateScope1Emissions           as climate_scope1_emissions
    ,MarketCapDaily                   as market_capdaily
    ,ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,CURRENT_TIMESTAMP                as meta_insert_timestamp
    ,'20211117T164451425627'          as meta_run_id
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-17 16:55:31.231329 (Thread-1): Postgres error: type "string" does not exist
LINE 11:     ,ISIN::STRING                     as isin
                    ^

2021-11-17 16:55:31.231446 (Thread-1): On model.my_new_project.iss_issuer: ROLLBACK
2021-11-17 16:55:31.231866 (Thread-1): finished collecting timing info
2021-11-17 16:55:31.232005 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-17 16:55:31.232339 (Thread-1): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  type "string" does not exist
  LINE 11:     ,ISIN::STRING                     as isin
                      ^
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedObject: type "string" does not exist
LINE 11:     ,ISIN::STRING                     as isin
                    ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  type "string" does not exist
  LINE 11:     ,ISIN::STRING                     as isin
                      ^
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-17 16:55:31.238230 (Thread-1): 17:55:31 | 1 of 1 ERROR creating incremental model sa_dwh.iss_issuer............ [ERROR in 0.05s]
2021-11-17 16:55:31.238480 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-17 16:55:31.239837 (MainThread): Acquiring new postgres connection "master".
2021-11-17 16:55:31.239985 (MainThread): Using postgres connection "master".
2021-11-17 16:55:31.240084 (MainThread): On master: BEGIN
2021-11-17 16:55:31.240181 (MainThread): Opening a new connection, currently in state closed
2021-11-17 16:55:31.246633 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:55:31.246826 (MainThread): On master: COMMIT
2021-11-17 16:55:31.246920 (MainThread): Using postgres connection "master".
2021-11-17 16:55:31.247006 (MainThread): On master: COMMIT
2021-11-17 16:55:31.247404 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 16:55:31.247547 (MainThread): On master: Close
2021-11-17 16:55:31.247880 (MainThread): 17:55:31 | 
2021-11-17 16:55:31.248046 (MainThread): 17:55:31 | Finished running 1 incremental model in 0.12s.
2021-11-17 16:55:31.248306 (MainThread): Connection 'master' was properly closed.
2021-11-17 16:55:31.248470 (MainThread): Connection 'list_demo_db_sa' was properly closed.
2021-11-17 16:55:31.248554 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-17 16:55:31.251656 (MainThread): 
2021-11-17 16:55:31.251801 (MainThread): Completed with 1 error and 0 warnings:
2021-11-17 16:55:31.251990 (MainThread): 
2021-11-17 16:55:31.252198 (MainThread): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
2021-11-17 16:55:31.252390 (MainThread):   type "string" does not exist
2021-11-17 16:55:31.252521 (MainThread):   LINE 11:     ,ISIN::STRING                     as isin
2021-11-17 16:55:31.252657 (MainThread):                       ^
2021-11-17 16:55:31.252853 (MainThread):   compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-17 16:55:31.253026 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-11-17 16:55:31.253289 (MainThread): Flushing usage events
2021-11-17 16:55:56.566603 (MainThread): Running with dbt=0.21.0
2021-11-17 16:55:56.617753 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=True, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 16:55:56.618153 (MainThread): Tracking: do not track
2021-11-17 16:55:56.631223 (MainThread): Partial parsing not enabled
2021-11-17 16:55:56.637509 (MainThread): Parsing macros/adapters.sql
2021-11-17 16:55:56.655524 (MainThread): Parsing macros/catalog.sql
2021-11-17 16:55:56.657187 (MainThread): Parsing macros/relations.sql
2021-11-17 16:55:56.658150 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 16:55:56.659760 (MainThread): Parsing macros/core.sql
2021-11-17 16:55:56.662672 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 16:55:56.704527 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 16:55:56.706485 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 16:55:56.707851 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 16:55:56.709263 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 16:55:56.715741 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 16:55:56.716876 (MainThread): Parsing macros/etc/query.sql
2021-11-17 16:55:56.717616 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 16:55:56.718813 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 16:55:56.726104 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 16:55:56.731300 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 16:55:56.748347 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 16:55:56.749600 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 16:55:56.772295 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 16:55:56.785367 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 16:55:56.799853 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 16:55:56.807644 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 16:55:56.808998 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 16:55:56.819146 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 16:55:56.822172 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 16:55:56.827429 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 16:55:56.832792 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 16:55:56.833836 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 16:55:56.834758 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 16:55:56.836003 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 16:55:56.996033 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 16:55:57.005940 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 16:55:57.008814 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:55:57.011517 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:55:57.011738 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:55:57.038890 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:55:57.040323 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:55:57.041767 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:55:57.043282 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:55:57.056668 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-17 16:55:57.056953 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-17 16:55:57.058053 (MainThread): 
2021-11-17 16:55:57.058380 (MainThread): Acquiring new postgres connection "master".
2021-11-17 16:55:57.059090 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-17 16:55:57.066170 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-17 16:55:57.066282 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-17 16:55:57.066382 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-17 16:55:57.073048 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.01 seconds
2021-11-17 16:55:57.073986 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-17 16:55:57.075009 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-17 16:55:57.075470 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:55:57.079934 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 16:55:57.080944 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:55:57.081142 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-17 16:55:57.081335 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-17 16:55:57.081538 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-17 16:55:57.081733 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-17 16:55:57.088985 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:55:57.089273 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 16:55:57.089467 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:55:57.090525 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-17 16:55:57.090843 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:55:57.091253 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-17 16:55:57.093050 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 16:55:57.094102 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-17 16:55:57.094279 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 16:55:57.095526 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-17 16:55:57.095806 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-17 16:55:57.096346 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-17 16:55:57.099974 (MainThread): Using postgres connection "master".
2021-11-17 16:55:57.100094 (MainThread): On master: BEGIN
2021-11-17 16:55:57.100192 (MainThread): Opening a new connection, currently in state init
2021-11-17 16:55:57.106168 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:55:57.106338 (MainThread): Using postgres connection "master".
2021-11-17 16:55:57.106431 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-17 16:55:57.108847 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-17 16:55:57.109676 (MainThread): On master: ROLLBACK
2021-11-17 16:55:57.110115 (MainThread): Using postgres connection "master".
2021-11-17 16:55:57.110231 (MainThread): On master: BEGIN
2021-11-17 16:55:57.111038 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-17 16:55:57.111158 (MainThread): On master: COMMIT
2021-11-17 16:55:57.111253 (MainThread): Using postgres connection "master".
2021-11-17 16:55:57.111340 (MainThread): On master: COMMIT
2021-11-17 16:55:57.111719 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 16:55:57.111854 (MainThread): On master: Close
2021-11-17 16:55:57.112142 (MainThread): 17:55:57 | Concurrency: 2 threads (target='dev')
2021-11-17 16:55:57.112289 (MainThread): 17:55:57 | 
2021-11-17 16:55:57.114717 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-17 16:55:57.114972 (Thread-1): 17:55:57 | 1 of 1 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-17 16:55:57.115274 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:55:57.115396 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-17 16:55:57.117728 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-17 16:55:57.117964 (Thread-1): finished collecting timing info
2021-11-17 16:55:57.150966 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-17 16:55:57.151323 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:55:57.151427 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-17 16:55:57.151618 (Thread-1): Opening a new connection, currently in state closed
2021-11-17 16:55:57.158373 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:55:57.158573 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:55:57.158662 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp"
  as (
    

select
     AdjustedEnterpriseValue::INT     as adjusted_enterprise_value
    ,ISIN::VARCHAR                     as isin
    ,IssuerName::VARCHAR                       as issuer_name
    ,ClimateScope2EmissionsIntUSD::NUMERIC     as climate_scope2_emissions_int_usd
    ,ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,ClimateScope2Emissions           as climate_scope2_emissions
    ,ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,ClimateScope3Emissions           as climate_scope3_emissions
    ,ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,ClimateTotalEmissions            as climate_total_emissions
    ,ClimateScope1Emissions           as climate_scope1_emissions
    ,MarketCapDaily                   as market_capdaily
    ,ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,CURRENT_TIMESTAMP                as meta_insert_timestamp
    ,'20211117T164451425627'          as meta_run_id
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-17 16:55:57.164380 (Thread-1): Postgres error: value "3424059914" is out of range for type integer

2021-11-17 16:55:57.164595 (Thread-1): On model.my_new_project.iss_issuer: ROLLBACK
2021-11-17 16:55:57.165166 (Thread-1): finished collecting timing info
2021-11-17 16:55:57.165305 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-17 16:55:57.165672 (Thread-1): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  value "3424059914" is out of range for type integer
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.NumericValueOutOfRange: value "3424059914" is out of range for type integer


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  value "3424059914" is out of range for type integer
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-17 16:55:57.167032 (Thread-1): 17:55:57 | 1 of 1 ERROR creating incremental model sa_dwh.iss_issuer............ [ERROR in 0.05s]
2021-11-17 16:55:57.167182 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-17 16:55:57.168733 (MainThread): Acquiring new postgres connection "master".
2021-11-17 16:55:57.168877 (MainThread): Using postgres connection "master".
2021-11-17 16:55:57.168973 (MainThread): On master: BEGIN
2021-11-17 16:55:57.169070 (MainThread): Opening a new connection, currently in state closed
2021-11-17 16:55:57.174641 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:55:57.174808 (MainThread): On master: COMMIT
2021-11-17 16:55:57.174910 (MainThread): Using postgres connection "master".
2021-11-17 16:55:57.175004 (MainThread): On master: COMMIT
2021-11-17 16:55:57.175306 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 16:55:57.175447 (MainThread): On master: Close
2021-11-17 16:55:57.175784 (MainThread): 17:55:57 | 
2021-11-17 16:55:57.175950 (MainThread): 17:55:57 | Finished running 1 incremental model in 0.12s.
2021-11-17 16:55:57.176101 (MainThread): Connection 'master' was properly closed.
2021-11-17 16:55:57.176204 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-17 16:55:57.176294 (MainThread): Connection 'list_demo_db_sa_dwh' was properly closed.
2021-11-17 16:55:57.179475 (MainThread): 
2021-11-17 16:55:57.179637 (MainThread): Completed with 1 error and 0 warnings:
2021-11-17 16:55:57.179780 (MainThread): 
2021-11-17 16:55:57.179920 (MainThread): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
2021-11-17 16:55:57.180050 (MainThread):   value "3424059914" is out of range for type integer
2021-11-17 16:55:57.180173 (MainThread):   compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-17 16:55:57.180302 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-11-17 16:55:57.180488 (MainThread): Flushing usage events
2021-11-17 16:56:26.690019 (MainThread): Running with dbt=0.21.0
2021-11-17 16:56:26.744922 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=True, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 16:56:26.745408 (MainThread): Tracking: do not track
2021-11-17 16:56:26.755732 (MainThread): Partial parsing not enabled
2021-11-17 16:56:26.762067 (MainThread): Parsing macros/adapters.sql
2021-11-17 16:56:26.780061 (MainThread): Parsing macros/catalog.sql
2021-11-17 16:56:26.781701 (MainThread): Parsing macros/relations.sql
2021-11-17 16:56:26.782628 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 16:56:26.783844 (MainThread): Parsing macros/core.sql
2021-11-17 16:56:26.786750 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 16:56:26.827434 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 16:56:26.829354 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 16:56:26.830707 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 16:56:26.831874 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 16:56:26.838315 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 16:56:26.839472 (MainThread): Parsing macros/etc/query.sql
2021-11-17 16:56:26.840192 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 16:56:26.841287 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 16:56:26.848638 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 16:56:26.853825 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 16:56:26.871284 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 16:56:26.872557 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 16:56:26.895543 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 16:56:26.908800 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 16:56:26.923597 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 16:56:26.931685 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 16:56:26.933011 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 16:56:26.943334 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 16:56:26.946325 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 16:56:26.951830 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 16:56:26.957469 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 16:56:26.958580 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 16:56:26.959546 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 16:56:26.960817 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 16:56:27.119297 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 16:56:27.129032 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 16:56:27.131805 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:56:27.134583 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:56:27.134800 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:56:27.161524 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:56:27.162968 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:56:27.164541 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:56:27.166031 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:56:27.179566 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-17 16:56:27.179875 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-17 16:56:27.181084 (MainThread): 
2021-11-17 16:56:27.181377 (MainThread): Acquiring new postgres connection "master".
2021-11-17 16:56:27.182027 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-17 16:56:27.189477 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-17 16:56:27.189606 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-17 16:56:27.189713 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-17 16:56:27.197226 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.01 seconds
2021-11-17 16:56:27.198352 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-17 16:56:27.199527 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-17 16:56:27.200073 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:56:27.205100 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 16:56:27.206325 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:56:27.206523 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-17 16:56:27.206736 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-17 16:56:27.206933 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-17 16:56:27.207120 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-17 16:56:27.214929 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:56:27.215211 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:56:27.215412 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 16:56:27.215595 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:56:27.215793 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-17 16:56:27.215969 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-17 16:56:27.218001 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 16:56:27.219055 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-17 16:56:27.219255 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 16:56:27.220577 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-17 16:56:27.220707 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-17 16:56:27.221317 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-17 16:56:27.224656 (MainThread): Using postgres connection "master".
2021-11-17 16:56:27.224778 (MainThread): On master: BEGIN
2021-11-17 16:56:27.224884 (MainThread): Opening a new connection, currently in state init
2021-11-17 16:56:27.230534 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:56:27.230692 (MainThread): Using postgres connection "master".
2021-11-17 16:56:27.230784 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-17 16:56:27.233000 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-17 16:56:27.233837 (MainThread): On master: ROLLBACK
2021-11-17 16:56:27.234181 (MainThread): Using postgres connection "master".
2021-11-17 16:56:27.234291 (MainThread): On master: BEGIN
2021-11-17 16:56:27.234885 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-17 16:56:27.235006 (MainThread): On master: COMMIT
2021-11-17 16:56:27.235101 (MainThread): Using postgres connection "master".
2021-11-17 16:56:27.235187 (MainThread): On master: COMMIT
2021-11-17 16:56:27.235577 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 16:56:27.235737 (MainThread): On master: Close
2021-11-17 16:56:27.236114 (MainThread): 17:56:27 | Concurrency: 2 threads (target='dev')
2021-11-17 16:56:27.236360 (MainThread): 17:56:27 | 
2021-11-17 16:56:27.239164 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-17 16:56:27.239474 (Thread-1): 17:56:27 | 1 of 1 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-17 16:56:27.239776 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:56:27.239910 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-17 16:56:27.242424 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-17 16:56:27.242682 (Thread-1): finished collecting timing info
2021-11-17 16:56:27.277568 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-17 16:56:27.277894 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:56:27.278004 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-17 16:56:27.278143 (Thread-1): Opening a new connection, currently in state closed
2021-11-17 16:56:27.284794 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:56:27.284962 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:56:27.285062 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp"
  as (
    

select
     AdjustedEnterpriseValue::NUMERIC     as adjusted_enterprise_value
    ,ISIN::VARCHAR                     as isin
    ,IssuerName::VARCHAR                       as issuer_name
    ,ClimateScope2EmissionsIntUSD::NUMERIC     as climate_scope2_emissions_int_usd
    ,ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,ClimateScope2Emissions           as climate_scope2_emissions
    ,ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,ClimateScope3Emissions           as climate_scope3_emissions
    ,ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,ClimateTotalEmissions            as climate_total_emissions
    ,ClimateScope1Emissions           as climate_scope1_emissions
    ,MarketCapDaily                   as market_capdaily
    ,ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,CURRENT_TIMESTAMP                as meta_insert_timestamp
    ,'20211117T164451425627'          as meta_run_id
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-17 16:56:27.289672 (Thread-1): Postgres error: invalid input syntax for type numeric: "Not Collected"

2021-11-17 16:56:27.289827 (Thread-1): On model.my_new_project.iss_issuer: ROLLBACK
2021-11-17 16:56:27.290160 (Thread-1): finished collecting timing info
2021-11-17 16:56:27.290318 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-17 16:56:27.290668 (Thread-1): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  invalid input syntax for type numeric: "Not Collected"
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type numeric: "Not Collected"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  invalid input syntax for type numeric: "Not Collected"
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-17 16:56:27.291925 (Thread-1): 17:56:27 | 1 of 1 ERROR creating incremental model sa_dwh.iss_issuer............ [ERROR in 0.05s]
2021-11-17 16:56:27.292150 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-17 16:56:27.293778 (MainThread): Acquiring new postgres connection "master".
2021-11-17 16:56:27.293949 (MainThread): Using postgres connection "master".
2021-11-17 16:56:27.294051 (MainThread): On master: BEGIN
2021-11-17 16:56:27.294155 (MainThread): Opening a new connection, currently in state closed
2021-11-17 16:56:27.300549 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:56:27.300745 (MainThread): On master: COMMIT
2021-11-17 16:56:27.300848 (MainThread): Using postgres connection "master".
2021-11-17 16:56:27.300943 (MainThread): On master: COMMIT
2021-11-17 16:56:27.301245 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 16:56:27.301389 (MainThread): On master: Close
2021-11-17 16:56:27.301739 (MainThread): 17:56:27 | 
2021-11-17 16:56:27.301899 (MainThread): 17:56:27 | Finished running 1 incremental model in 0.12s.
2021-11-17 16:56:27.302040 (MainThread): Connection 'master' was properly closed.
2021-11-17 16:56:27.302140 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-17 16:56:27.302230 (MainThread): Connection 'list_demo_db_sa_dwh' was properly closed.
2021-11-17 16:56:27.305304 (MainThread): 
2021-11-17 16:56:27.305462 (MainThread): Completed with 1 error and 0 warnings:
2021-11-17 16:56:27.305606 (MainThread): 
2021-11-17 16:56:27.305731 (MainThread): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
2021-11-17 16:56:27.305858 (MainThread):   invalid input syntax for type numeric: "Not Collected"
2021-11-17 16:56:27.305984 (MainThread):   compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-17 16:56:27.306117 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-11-17 16:56:27.306342 (MainThread): Flushing usage events
2021-11-17 16:56:48.771887 (MainThread): Running with dbt=0.21.0
2021-11-17 16:56:48.832254 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=True, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 16:56:48.832742 (MainThread): Tracking: do not track
2021-11-17 16:56:48.848506 (MainThread): Partial parsing not enabled
2021-11-17 16:56:48.859370 (MainThread): Parsing macros/adapters.sql
2021-11-17 16:56:48.882015 (MainThread): Parsing macros/catalog.sql
2021-11-17 16:56:48.883979 (MainThread): Parsing macros/relations.sql
2021-11-17 16:56:48.885143 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 16:56:48.886619 (MainThread): Parsing macros/core.sql
2021-11-17 16:56:48.889842 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 16:56:48.934142 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 16:56:48.936212 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 16:56:48.937662 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 16:56:48.938970 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 16:56:48.945649 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 16:56:48.946825 (MainThread): Parsing macros/etc/query.sql
2021-11-17 16:56:48.947580 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 16:56:48.948778 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 16:56:48.956294 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 16:56:48.961816 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 16:56:48.979848 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 16:56:48.981267 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 16:56:49.004043 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 16:56:49.020981 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 16:56:49.036442 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 16:56:49.044453 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 16:56:49.046102 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 16:56:49.056499 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 16:56:49.059516 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 16:56:49.064796 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 16:56:49.070160 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 16:56:49.071906 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 16:56:49.073655 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 16:56:49.075450 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 16:56:49.234640 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 16:56:49.244551 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 16:56:49.247327 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:56:49.250074 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:56:49.250297 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:56:49.277313 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:56:49.278782 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:56:49.280234 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:56:49.281705 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 16:56:49.296951 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-17 16:56:49.297359 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-17 16:56:49.298537 (MainThread): 
2021-11-17 16:56:49.298918 (MainThread): Acquiring new postgres connection "master".
2021-11-17 16:56:49.299666 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-17 16:56:49.307417 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-17 16:56:49.307561 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-17 16:56:49.307670 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-17 16:56:49.315681 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.01 seconds
2021-11-17 16:56:49.316787 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-17 16:56:49.318146 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:56:49.322341 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:56:49.322701 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: BEGIN
2021-11-17 16:56:49.323008 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa".
2021-11-17 16:56:49.323224 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-17 16:56:49.324311 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-17 16:56:49.324699 (ThreadPoolExecutor-1_1): On list_demo_db_sa: BEGIN
2021-11-17 16:56:49.324854 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-17 16:56:49.331870 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:56:49.332078 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-17 16:56:49.332200 (ThreadPoolExecutor-1_1): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-17 16:56:49.332387 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:56:49.332614 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 16:56:49.332719 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-17 16:56:49.334165 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 16:56:49.335362 (ThreadPoolExecutor-1_1): On list_demo_db_sa: ROLLBACK
2021-11-17 16:56:49.335778 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 16:56:49.336747 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: ROLLBACK
2021-11-17 16:56:49.336934 (ThreadPoolExecutor-1_1): On list_demo_db_sa: Close
2021-11-17 16:56:49.337741 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: Close
2021-11-17 16:56:49.341554 (MainThread): Using postgres connection "master".
2021-11-17 16:56:49.341676 (MainThread): On master: BEGIN
2021-11-17 16:56:49.341775 (MainThread): Opening a new connection, currently in state init
2021-11-17 16:56:49.348704 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:56:49.348907 (MainThread): Using postgres connection "master".
2021-11-17 16:56:49.349003 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-17 16:56:49.351445 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-17 16:56:49.352326 (MainThread): On master: ROLLBACK
2021-11-17 16:56:49.352873 (MainThread): Using postgres connection "master".
2021-11-17 16:56:49.352982 (MainThread): On master: BEGIN
2021-11-17 16:56:49.353985 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-17 16:56:49.354137 (MainThread): On master: COMMIT
2021-11-17 16:56:49.354231 (MainThread): Using postgres connection "master".
2021-11-17 16:56:49.354316 (MainThread): On master: COMMIT
2021-11-17 16:56:49.354819 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 16:56:49.354965 (MainThread): On master: Close
2021-11-17 16:56:49.355330 (MainThread): 17:56:49 | Concurrency: 2 threads (target='dev')
2021-11-17 16:56:49.355532 (MainThread): 17:56:49 | 
2021-11-17 16:56:49.358038 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-17 16:56:49.358419 (Thread-1): 17:56:49 | 1 of 1 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-17 16:56:49.358844 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:56:49.359020 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-17 16:56:49.361685 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-17 16:56:49.361966 (Thread-1): finished collecting timing info
2021-11-17 16:56:49.403239 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-17 16:56:49.403747 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:56:49.403930 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-17 16:56:49.404105 (Thread-1): Opening a new connection, currently in state closed
2021-11-17 16:56:49.411178 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:56:49.411406 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 16:56:49.411522 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp"
  as (
    

select
     try_cast(AdjustedEnterpriseValue as NUMERIC)     as adjusted_enterprise_value
    ,ISIN::VARCHAR                     as isin
    ,IssuerName::VARCHAR                       as issuer_name
    ,ClimateScope2EmissionsIntUSD::NUMERIC     as climate_scope2_emissions_int_usd
    ,ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,ClimateScope2Emissions           as climate_scope2_emissions
    ,ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,ClimateScope3Emissions           as climate_scope3_emissions
    ,ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,ClimateTotalEmissions            as climate_total_emissions
    ,ClimateScope1Emissions           as climate_scope1_emissions
    ,MarketCapDaily                   as market_capdaily
    ,ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,CURRENT_TIMESTAMP                as meta_insert_timestamp
    ,'20211117T164451425627'          as meta_run_id
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-17 16:56:49.412160 (Thread-1): Postgres error: syntax error at or near "as"
LINE 10:      try_cast(AdjustedEnterpriseValue as NUMERIC)     as adj...
                                               ^

2021-11-17 16:56:49.412368 (Thread-1): On model.my_new_project.iss_issuer: ROLLBACK
2021-11-17 16:56:49.412730 (Thread-1): finished collecting timing info
2021-11-17 16:56:49.412902 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-17 16:56:49.413261 (Thread-1): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  syntax error at or near "as"
  LINE 10:      try_cast(AdjustedEnterpriseValue as NUMERIC)     as adj...
                                                 ^
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "as"
LINE 10:      try_cast(AdjustedEnterpriseValue as NUMERIC)     as adj...
                                               ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  syntax error at or near "as"
  LINE 10:      try_cast(AdjustedEnterpriseValue as NUMERIC)     as adj...
                                                 ^
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-17 16:56:49.414522 (Thread-1): 17:56:49 | 1 of 1 ERROR creating incremental model sa_dwh.iss_issuer............ [ERROR in 0.06s]
2021-11-17 16:56:49.414689 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-17 16:56:49.416126 (MainThread): Acquiring new postgres connection "master".
2021-11-17 16:56:49.416279 (MainThread): Using postgres connection "master".
2021-11-17 16:56:49.416380 (MainThread): On master: BEGIN
2021-11-17 16:56:49.416645 (MainThread): Opening a new connection, currently in state closed
2021-11-17 16:56:49.423435 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 16:56:49.423626 (MainThread): On master: COMMIT
2021-11-17 16:56:49.423732 (MainThread): Using postgres connection "master".
2021-11-17 16:56:49.423828 (MainThread): On master: COMMIT
2021-11-17 16:56:49.424150 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 16:56:49.424309 (MainThread): On master: Close
2021-11-17 16:56:49.424661 (MainThread): 17:56:49 | 
2021-11-17 16:56:49.424817 (MainThread): 17:56:49 | Finished running 1 incremental model in 0.13s.
2021-11-17 16:56:49.425015 (MainThread): Connection 'master' was properly closed.
2021-11-17 16:56:49.425116 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-17 16:56:49.425207 (MainThread): Connection 'list_demo_db_sa' was properly closed.
2021-11-17 16:56:49.428403 (MainThread): 
2021-11-17 16:56:49.428794 (MainThread): Completed with 1 error and 0 warnings:
2021-11-17 16:56:49.429028 (MainThread): 
2021-11-17 16:56:49.429262 (MainThread): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
2021-11-17 16:56:49.429395 (MainThread):   syntax error at or near "as"
2021-11-17 16:56:49.429523 (MainThread):   LINE 10:      try_cast(AdjustedEnterpriseValue as NUMERIC)     as adj...
2021-11-17 16:56:49.429651 (MainThread):                                                  ^
2021-11-17 16:56:49.429777 (MainThread):   compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-17 16:56:49.429911 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-11-17 16:56:49.430104 (MainThread): Flushing usage events
2021-11-17 17:01:32.922196 (MainThread): Running with dbt=0.21.0
2021-11-17 17:01:32.973871 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=True, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 17:01:32.974528 (MainThread): Tracking: do not track
2021-11-17 17:01:32.984768 (MainThread): Partial parsing not enabled
2021-11-17 17:01:32.990841 (MainThread): Parsing macros/adapters.sql
2021-11-17 17:01:33.008193 (MainThread): Parsing macros/catalog.sql
2021-11-17 17:01:33.010005 (MainThread): Parsing macros/relations.sql
2021-11-17 17:01:33.010942 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 17:01:33.012179 (MainThread): Parsing macros/core.sql
2021-11-17 17:01:33.014994 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 17:01:33.055116 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 17:01:33.056994 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 17:01:33.058452 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 17:01:33.059636 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 17:01:33.068272 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 17:01:33.069706 (MainThread): Parsing macros/etc/query.sql
2021-11-17 17:01:33.070530 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 17:01:33.071753 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 17:01:33.079504 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 17:01:33.084869 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 17:01:33.101940 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 17:01:33.103219 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 17:01:33.125456 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 17:01:33.138735 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 17:01:33.153127 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 17:01:33.161045 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 17:01:33.162358 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 17:01:33.172567 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 17:01:33.175441 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 17:01:33.180777 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 17:01:33.186033 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 17:01:33.187282 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 17:01:33.188232 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 17:01:33.189657 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 17:01:33.340136 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 17:01:33.349810 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 17:01:33.352700 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:01:33.355328 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:01:33.355545 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:01:33.383139 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:01:33.385952 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:01:33.387686 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:01:33.389305 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:01:33.403229 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-17 17:01:33.403539 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-17 17:01:33.404720 (MainThread): 
2021-11-17 17:01:33.404988 (MainThread): Acquiring new postgres connection "master".
2021-11-17 17:01:33.405604 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-17 17:01:33.412496 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-17 17:01:33.412605 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-17 17:01:33.412703 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-17 17:01:33.421952 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.01 seconds
2021-11-17 17:01:33.422991 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-17 17:01:33.424112 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:01:33.424644 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa".
2021-11-17 17:01:33.428958 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:01:33.429998 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-17 17:01:33.430154 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: BEGIN
2021-11-17 17:01:33.430334 (ThreadPoolExecutor-1_1): On list_demo_db_sa: BEGIN
2021-11-17 17:01:33.430477 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-17 17:01:33.430612 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-17 17:01:33.437283 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:01:33.437643 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:01:33.437867 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:01:33.438031 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-17 17:01:33.438180 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-17 17:01:33.438366 (ThreadPoolExecutor-1_1): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-17 17:01:33.440166 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 17:01:33.440360 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 17:01:33.441419 (ThreadPoolExecutor-1_1): On list_demo_db_sa: ROLLBACK
2021-11-17 17:01:33.442254 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: ROLLBACK
2021-11-17 17:01:33.442665 (ThreadPoolExecutor-1_1): On list_demo_db_sa: Close
2021-11-17 17:01:33.442815 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: Close
2021-11-17 17:01:33.446288 (MainThread): Using postgres connection "master".
2021-11-17 17:01:33.446409 (MainThread): On master: BEGIN
2021-11-17 17:01:33.446511 (MainThread): Opening a new connection, currently in state init
2021-11-17 17:01:33.452421 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:01:33.452582 (MainThread): Using postgres connection "master".
2021-11-17 17:01:33.452675 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-17 17:01:33.455100 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-17 17:01:33.455975 (MainThread): On master: ROLLBACK
2021-11-17 17:01:33.456271 (MainThread): Using postgres connection "master".
2021-11-17 17:01:33.456396 (MainThread): On master: BEGIN
2021-11-17 17:01:33.456994 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-17 17:01:33.457143 (MainThread): On master: COMMIT
2021-11-17 17:01:33.457236 (MainThread): Using postgres connection "master".
2021-11-17 17:01:33.457322 (MainThread): On master: COMMIT
2021-11-17 17:01:33.457641 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 17:01:33.457765 (MainThread): On master: Close
2021-11-17 17:01:33.458074 (MainThread): 18:01:33 | Concurrency: 2 threads (target='dev')
2021-11-17 17:01:33.458239 (MainThread): 18:01:33 | 
2021-11-17 17:01:33.461013 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-17 17:01:33.461306 (Thread-1): 18:01:33 | 1 of 1 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-17 17:01:33.461673 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:01:33.461804 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-17 17:01:33.464102 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-17 17:01:33.464324 (Thread-1): finished collecting timing info
2021-11-17 17:01:33.497717 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-17 17:01:33.498041 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:01:33.498148 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-17 17:01:33.498246 (Thread-1): Opening a new connection, currently in state closed
2021-11-17 17:01:33.504935 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:01:33.505121 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:01:33.505216 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp"
  as (
    

select
     AdjustedEnterpriseValue           as adjusted_enterprise_value
    ,ISIN::VARCHAR                     as isin
    ,IssuerName::VARCHAR                       as issuer_name
    ,ClimateScope2EmissionsIntUSD::NUMERIC     as climate_scope2_emissions_int_usd
    ,ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,ClimateScope2Emissions           as climate_scope2_emissions
    ,ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,ClimateScope3Emissions           as climate_scope3_emissions
    ,ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,ClimateTotalEmissions            as climate_total_emissions
    ,ClimateScope1Emissions           as climate_scope1_emissions
    ,MarketCapDaily                   as market_capdaily
    ,ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,CURRENT_TIMESTAMP                as meta_insert_timestamp
    ,'20211117T164451425627'          as meta_run_id
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-17 17:01:33.510138 (Thread-1): Postgres error: invalid input syntax for type numeric: "Not Collected"

2021-11-17 17:01:33.510288 (Thread-1): On model.my_new_project.iss_issuer: ROLLBACK
2021-11-17 17:01:33.510675 (Thread-1): finished collecting timing info
2021-11-17 17:01:33.510820 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-17 17:01:33.511172 (Thread-1): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  invalid input syntax for type numeric: "Not Collected"
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type numeric: "Not Collected"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  invalid input syntax for type numeric: "Not Collected"
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-17 17:01:33.512555 (Thread-1): 18:01:33 | 1 of 1 ERROR creating incremental model sa_dwh.iss_issuer............ [ERROR in 0.05s]
2021-11-17 17:01:33.512717 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-17 17:01:33.514440 (MainThread): Acquiring new postgres connection "master".
2021-11-17 17:01:33.514585 (MainThread): Using postgres connection "master".
2021-11-17 17:01:33.514682 (MainThread): On master: BEGIN
2021-11-17 17:01:33.514779 (MainThread): Opening a new connection, currently in state closed
2021-11-17 17:01:33.520730 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:01:33.520885 (MainThread): On master: COMMIT
2021-11-17 17:01:33.520978 (MainThread): Using postgres connection "master".
2021-11-17 17:01:33.521081 (MainThread): On master: COMMIT
2021-11-17 17:01:33.521473 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 17:01:33.521600 (MainThread): On master: Close
2021-11-17 17:01:33.521962 (MainThread): 18:01:33 | 
2021-11-17 17:01:33.522128 (MainThread): 18:01:33 | Finished running 1 incremental model in 0.12s.
2021-11-17 17:01:33.522331 (MainThread): Connection 'master' was properly closed.
2021-11-17 17:01:33.522505 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-17 17:01:33.522621 (MainThread): Connection 'list_demo_db_sa' was properly closed.
2021-11-17 17:01:33.525624 (MainThread): 
2021-11-17 17:01:33.525792 (MainThread): Completed with 1 error and 0 warnings:
2021-11-17 17:01:33.526102 (MainThread): 
2021-11-17 17:01:33.526335 (MainThread): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
2021-11-17 17:01:33.526503 (MainThread):   invalid input syntax for type numeric: "Not Collected"
2021-11-17 17:01:33.526680 (MainThread):   compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-17 17:01:33.526886 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-11-17 17:01:33.527151 (MainThread): Flushing usage events
2021-11-17 17:01:47.842529 (MainThread): Running with dbt=0.21.0
2021-11-17 17:01:47.894892 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=True, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 17:01:47.895380 (MainThread): Tracking: do not track
2021-11-17 17:01:47.905192 (MainThread): Partial parsing not enabled
2021-11-17 17:01:47.911126 (MainThread): Parsing macros/adapters.sql
2021-11-17 17:01:47.928301 (MainThread): Parsing macros/catalog.sql
2021-11-17 17:01:47.929914 (MainThread): Parsing macros/relations.sql
2021-11-17 17:01:47.930881 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 17:01:47.932082 (MainThread): Parsing macros/core.sql
2021-11-17 17:01:47.934949 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 17:01:47.975735 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 17:01:47.978737 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 17:01:47.980653 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 17:01:47.981817 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 17:01:47.988507 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 17:01:47.989625 (MainThread): Parsing macros/etc/query.sql
2021-11-17 17:01:47.990343 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 17:01:47.991442 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 17:01:47.998739 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 17:01:48.003681 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 17:01:48.021701 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 17:01:48.022973 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 17:01:48.048908 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 17:01:48.062042 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 17:01:48.076632 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 17:01:48.084476 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 17:01:48.085802 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 17:01:48.095943 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 17:01:48.099362 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 17:01:48.104576 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 17:01:48.110098 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 17:01:48.111162 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 17:01:48.112074 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 17:01:48.113314 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 17:01:48.265555 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 17:01:48.275052 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 17:01:48.277712 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:01:48.280495 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:01:48.280741 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:01:48.306482 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:01:48.307888 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:01:48.309228 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:01:48.310640 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:01:48.323888 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-17 17:01:48.324161 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-17 17:01:48.325288 (MainThread): 
2021-11-17 17:01:48.325622 (MainThread): Acquiring new postgres connection "master".
2021-11-17 17:01:48.326301 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-17 17:01:48.333437 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-17 17:01:48.333557 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-17 17:01:48.333665 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-17 17:01:48.340619 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.01 seconds
2021-11-17 17:01:48.341561 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-17 17:01:48.342700 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:01:48.346742 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:01:48.346866 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: BEGIN
2021-11-17 17:01:48.346988 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-17 17:01:48.347690 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa".
2021-11-17 17:01:48.348895 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-17 17:01:48.349146 (ThreadPoolExecutor-1_1): On list_demo_db_sa: BEGIN
2021-11-17 17:01:48.349405 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-17 17:01:48.353948 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:01:48.354133 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:01:48.354223 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-17 17:01:48.356030 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:01:48.356254 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-17 17:01:48.356453 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 17:01:48.356800 (ThreadPoolExecutor-1_1): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-17 17:01:48.359572 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: ROLLBACK
2021-11-17 17:01:48.360638 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: Close
2021-11-17 17:01:48.362342 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 17:01:48.363611 (ThreadPoolExecutor-1_1): On list_demo_db_sa: ROLLBACK
2021-11-17 17:01:48.364029 (ThreadPoolExecutor-1_1): On list_demo_db_sa: Close
2021-11-17 17:01:48.367533 (MainThread): Using postgres connection "master".
2021-11-17 17:01:48.367675 (MainThread): On master: BEGIN
2021-11-17 17:01:48.367780 (MainThread): Opening a new connection, currently in state init
2021-11-17 17:01:48.373549 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:01:48.373712 (MainThread): Using postgres connection "master".
2021-11-17 17:01:48.373804 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-17 17:01:48.376156 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-17 17:01:48.377159 (MainThread): On master: ROLLBACK
2021-11-17 17:01:48.377451 (MainThread): Using postgres connection "master".
2021-11-17 17:01:48.377551 (MainThread): On master: BEGIN
2021-11-17 17:01:48.378157 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-17 17:01:48.378318 (MainThread): On master: COMMIT
2021-11-17 17:01:48.378458 (MainThread): Using postgres connection "master".
2021-11-17 17:01:48.378547 (MainThread): On master: COMMIT
2021-11-17 17:01:48.378950 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 17:01:48.379085 (MainThread): On master: Close
2021-11-17 17:01:48.379371 (MainThread): 18:01:48 | Concurrency: 2 threads (target='dev')
2021-11-17 17:01:48.379546 (MainThread): 18:01:48 | 
2021-11-17 17:01:48.381739 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-17 17:01:48.382047 (Thread-1): 18:01:48 | 1 of 1 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-17 17:01:48.382415 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:01:48.382541 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-17 17:01:48.384995 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-17 17:01:48.385223 (Thread-1): finished collecting timing info
2021-11-17 17:01:48.422079 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-17 17:01:48.422440 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:01:48.422559 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-17 17:01:48.422704 (Thread-1): Opening a new connection, currently in state closed
2021-11-17 17:01:48.429505 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:01:48.429701 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:01:48.429809 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp"
  as (
    

select
     AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,ISIN::VARCHAR                    as isin
    ,IssuerName::VARCHAR              as issuer_name
    ,ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,ClimateScope2Emissions           as climate_scope2_emissions
    ,ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,ClimateScope3Emissions           as climate_scope3_emissions
    ,ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,ClimateTotalEmissions            as climate_total_emissions
    ,ClimateScope1Emissions           as climate_scope1_emissions
    ,MarketCapDaily                   as market_capdaily
    ,ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,CURRENT_TIMESTAMP                as meta_insert_timestamp
    ,'20211117T164451425627'          as meta_run_id
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-17 17:01:48.527564 (Thread-1): SQL status: SELECT 28444 in 0.10 seconds
2021-11-17 17:01:48.532487 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:01:48.532659 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */
alter table "demo_db"."sa_dwh"."iss_issuer" rename to "iss_issuer__dbt_backup"
2021-11-17 17:09:44.148490 (MainThread): Acquiring new postgres connection "master".
2021-11-17 17:09:44.148700 (MainThread): Cancelling query 'model.my_new_project.iss_issuer' (1071)
2021-11-17 17:09:44.148847 (MainThread): Using postgres connection "master".
2021-11-17 17:09:44.148936 (MainThread): On master: BEGIN
2021-11-17 17:09:44.149033 (MainThread): Opening a new connection, currently in state closed
2021-11-17 17:09:44.155010 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:09:44.155157 (MainThread): Using postgres connection "master".
2021-11-17 17:09:44.155249 (MainThread): On master: select pg_terminate_backend(1071)
2021-11-17 17:09:44.155923 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 17:09:44.156166 (MainThread): Cancel query 'model.my_new_project.iss_issuer': (True,)
2021-11-17 17:09:44.156302 (MainThread): 18:09:44 | CANCEL query list_demo_db_sa_dwh..................................... [CANCEL]
2021-11-17 17:09:44.156486 (MainThread): 18:09:44 | CANCEL query model.my_new_project.iss_issuer......................... [CANCEL]
2021-11-17 17:09:44.156714 (MainThread): On master: ROLLBACK
2021-11-17 17:09:44.157212 (MainThread): On master: Close
2021-11-17 17:09:44.159574 (Thread-1): Postgres error: terminating connection due to administrator command
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

2021-11-17 17:09:44.159789 (Thread-1): On model.my_new_project.iss_issuer: ROLLBACK
2021-11-17 17:09:44.159885 (Thread-1): Failed to rollback model.my_new_project.iss_issuer
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.OperationalError: terminating connection due to administrator command
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/connections.py", line 221, in _rollback_handle
    connection.handle.rollback()
psycopg2.InterfaceError: connection already closed
2021-11-17 17:09:44.160794 (Thread-1): Error running SQL: macro rename_relation
2021-11-17 17:09:44.160896 (Thread-1): Rolling back transaction.
2021-11-17 17:09:44.161024 (Thread-1): finished collecting timing info
2021-11-17 17:09:44.161144 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-17 17:09:44.161383 (Thread-1): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  terminating connection due to administrator command
  server closed the connection unexpectedly
  	This probably means the server terminated abnormally
  	before or while processing the request.
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.OperationalError: terminating connection due to administrator command
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 178, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/impl.py", line 165, in rename_relation
    self.execute_macro(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 1000, in execute_macro
    result = macro_function(**kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 37, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  terminating connection due to administrator command
  server closed the connection unexpectedly
  	This probably means the server terminated abnormally
  	before or while processing the request.
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-17 17:09:44.162896 (Thread-1): 18:09:44 | 1 of 1 ERROR creating incremental model sa_dwh.iss_issuer............ [ERROR in 475.78s]
2021-11-17 17:09:44.163066 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-17 17:09:44.163515 (MainThread): 
2021-11-17 17:09:44.163712 (MainThread): Exited because of keyboard interrupt.
2021-11-17 17:09:44.164010 (MainThread): 
Done. PASS=0 WARN=0 ERROR=0 SKIP=0 TOTAL=0
2021-11-17 17:09:44.164247 (MainThread): Connection 'master' was properly closed.
2021-11-17 17:09:44.164384 (MainThread): Connection 'list_demo_db_sa_dwh' was properly closed.
2021-11-17 17:09:44.164473 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-17 17:09:44.164577 (MainThread): Flushing usage events
2021-11-17 17:09:44.164715 (MainThread): ctrl-c
2021-11-17 17:10:25.495434 (MainThread): Running with dbt=0.21.0
2021-11-17 17:10:25.549194 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=True, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 17:10:25.549606 (MainThread): Tracking: do not track
2021-11-17 17:10:25.559356 (MainThread): Partial parsing not enabled
2021-11-17 17:10:25.565393 (MainThread): Parsing macros/adapters.sql
2021-11-17 17:10:25.582793 (MainThread): Parsing macros/catalog.sql
2021-11-17 17:10:25.584462 (MainThread): Parsing macros/relations.sql
2021-11-17 17:10:25.585530 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 17:10:25.586762 (MainThread): Parsing macros/core.sql
2021-11-17 17:10:25.589572 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 17:10:25.631384 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 17:10:25.633308 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 17:10:25.634711 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 17:10:25.635864 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 17:10:25.642267 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 17:10:25.643361 (MainThread): Parsing macros/etc/query.sql
2021-11-17 17:10:25.644176 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 17:10:25.645293 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 17:10:25.652563 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 17:10:25.657477 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 17:10:25.674337 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 17:10:25.675552 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 17:10:25.697179 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 17:10:25.710005 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 17:10:25.724148 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 17:10:25.731722 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 17:10:25.733339 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 17:10:25.747583 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 17:10:25.751501 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 17:10:25.757859 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 17:10:25.763520 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 17:10:25.764587 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 17:10:25.765591 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 17:10:25.766833 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 17:10:25.919924 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 17:10:25.929506 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 17:10:25.932153 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:10:25.934762 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:10:25.934976 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:10:25.961086 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:10:25.962487 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:10:25.963855 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:10:25.965379 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:10:25.978607 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-17 17:10:25.978888 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-17 17:10:25.980104 (MainThread): 
2021-11-17 17:10:25.980386 (MainThread): Acquiring new postgres connection "master".
2021-11-17 17:10:25.981047 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-17 17:10:25.988316 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-17 17:10:25.988498 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-17 17:10:25.988596 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-17 17:10:25.995678 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.01 seconds
2021-11-17 17:10:25.996615 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-17 17:10:25.998177 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-17 17:10:25.998865 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:10:26.002980 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 17:10:26.004018 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:10:26.004205 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-17 17:10:26.004392 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-17 17:10:26.004586 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-17 17:10:26.004771 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-17 17:10:26.012457 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:10:26.012700 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:10:26.012943 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 17:10:26.013130 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:10:26.013354 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-17 17:10:26.013558 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-17 17:10:26.015390 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 17:10:26.015584 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 17:10:26.016518 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-17 17:10:26.017857 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-17 17:10:26.018657 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-17 17:10:26.018898 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-17 17:10:26.022833 (MainThread): Using postgres connection "master".
2021-11-17 17:10:26.022957 (MainThread): On master: BEGIN
2021-11-17 17:10:26.023060 (MainThread): Opening a new connection, currently in state init
2021-11-17 17:10:26.029524 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:10:26.029706 (MainThread): Using postgres connection "master".
2021-11-17 17:10:26.029816 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-17 17:10:26.032068 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-17 17:10:26.032919 (MainThread): On master: ROLLBACK
2021-11-17 17:10:26.033335 (MainThread): Using postgres connection "master".
2021-11-17 17:10:26.033444 (MainThread): On master: BEGIN
2021-11-17 17:10:26.034244 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-17 17:10:26.034376 (MainThread): On master: COMMIT
2021-11-17 17:10:26.034470 (MainThread): Using postgres connection "master".
2021-11-17 17:10:26.034555 (MainThread): On master: COMMIT
2021-11-17 17:10:26.034934 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 17:10:26.035074 (MainThread): On master: Close
2021-11-17 17:10:26.035415 (MainThread): 18:10:26 | Concurrency: 2 threads (target='dev')
2021-11-17 17:10:26.035566 (MainThread): 18:10:26 | 
2021-11-17 17:10:26.038190 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-17 17:10:26.038618 (Thread-1): 18:10:26 | 1 of 1 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-17 17:10:26.038943 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:10:26.039076 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-17 17:10:26.041411 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-17 17:10:26.041633 (Thread-1): finished collecting timing info
2021-11-17 17:10:26.077697 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-17 17:10:26.078049 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:10:26.078194 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-17 17:10:26.078370 (Thread-1): Opening a new connection, currently in state closed
2021-11-17 17:10:26.084215 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:10:26.084351 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:10:26.084450 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp"
  as (
    

select
     AdjustedEnterpriseValue::BIGINT          as adjusted_enterprise_value
    ,ISIN::TEXT                as isin
    ,IssuerName::TEXT              as issuer_name
    ,ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,ClimateScope2Emissions           as climate_scope2_emissions
    ,ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,ClimateScope3Emissions           as climate_scope3_emissions
    ,ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,ClimateTotalEmissions            as climate_total_emissions
    ,ClimateScope1Emissions           as climate_scope1_emissions
    ,MarketCapDaily                   as market_capdaily
    ,ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,CURRENT_TIMESTAMP                as meta_insert_timestamp
    ,'20211117T164451425627'          as meta_run_id
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-17 17:10:26.088501 (Thread-1): Postgres error: invalid input syntax for type bigint: "494881500.4793"

2021-11-17 17:10:26.088671 (Thread-1): On model.my_new_project.iss_issuer: ROLLBACK
2021-11-17 17:10:26.089009 (Thread-1): finished collecting timing info
2021-11-17 17:10:26.089174 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-17 17:10:26.089493 (Thread-1): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  invalid input syntax for type bigint: "494881500.4793"
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type bigint: "494881500.4793"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  invalid input syntax for type bigint: "494881500.4793"
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-17 17:10:26.090749 (Thread-1): 18:10:26 | 1 of 1 ERROR creating incremental model sa_dwh.iss_issuer............ [ERROR in 0.05s]
2021-11-17 17:10:26.090930 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-17 17:10:26.092080 (MainThread): Acquiring new postgres connection "master".
2021-11-17 17:10:26.092232 (MainThread): Using postgres connection "master".
2021-11-17 17:10:26.092342 (MainThread): On master: BEGIN
2021-11-17 17:10:26.092453 (MainThread): Opening a new connection, currently in state closed
2021-11-17 17:10:26.098288 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:10:26.098456 (MainThread): On master: COMMIT
2021-11-17 17:10:26.098560 (MainThread): Using postgres connection "master".
2021-11-17 17:10:26.098656 (MainThread): On master: COMMIT
2021-11-17 17:10:26.098916 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 17:10:26.099040 (MainThread): On master: Close
2021-11-17 17:10:26.099366 (MainThread): 18:10:26 | 
2021-11-17 17:10:26.099523 (MainThread): 18:10:26 | Finished running 1 incremental model in 0.12s.
2021-11-17 17:10:26.099662 (MainThread): Connection 'master' was properly closed.
2021-11-17 17:10:26.099763 (MainThread): Connection 'list_demo_db_sa' was properly closed.
2021-11-17 17:10:26.099853 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-17 17:10:26.102855 (MainThread): 
2021-11-17 17:10:26.103020 (MainThread): Completed with 1 error and 0 warnings:
2021-11-17 17:10:26.103177 (MainThread): 
2021-11-17 17:10:26.103319 (MainThread): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
2021-11-17 17:10:26.103452 (MainThread):   invalid input syntax for type bigint: "494881500.4793"
2021-11-17 17:10:26.103579 (MainThread):   compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-17 17:10:26.103713 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-11-17 17:10:26.103904 (MainThread): Flushing usage events
2021-11-17 17:10:40.659438 (MainThread): Running with dbt=0.21.0
2021-11-17 17:10:40.711598 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=True, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 17:10:40.712013 (MainThread): Tracking: do not track
2021-11-17 17:10:40.721846 (MainThread): Partial parsing not enabled
2021-11-17 17:10:40.727926 (MainThread): Parsing macros/adapters.sql
2021-11-17 17:10:40.745046 (MainThread): Parsing macros/catalog.sql
2021-11-17 17:10:40.746787 (MainThread): Parsing macros/relations.sql
2021-11-17 17:10:40.747715 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 17:10:40.749177 (MainThread): Parsing macros/core.sql
2021-11-17 17:10:40.751920 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 17:10:40.792124 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 17:10:40.793991 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 17:10:40.795383 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 17:10:40.796574 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 17:10:40.803100 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 17:10:40.804281 (MainThread): Parsing macros/etc/query.sql
2021-11-17 17:10:40.805029 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 17:10:40.806136 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 17:10:40.813523 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 17:10:40.818645 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 17:10:40.835248 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 17:10:40.836490 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 17:10:40.858927 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 17:10:40.872430 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 17:10:40.886315 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 17:10:40.896621 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 17:10:40.898821 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 17:10:40.909126 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 17:10:40.912207 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 17:10:40.917443 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 17:10:40.922858 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 17:10:40.923868 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 17:10:40.924750 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 17:10:40.926082 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 17:10:41.081903 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 17:10:41.091624 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 17:10:41.094588 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:10:41.098066 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:10:41.098292 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:10:41.125846 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:10:41.127466 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:10:41.128897 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:10:41.130363 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:10:41.144736 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-17 17:10:41.145023 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-17 17:10:41.146445 (MainThread): 
2021-11-17 17:10:41.146797 (MainThread): Acquiring new postgres connection "master".
2021-11-17 17:10:41.147420 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-17 17:10:41.154467 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-17 17:10:41.154607 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-17 17:10:41.154747 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-17 17:10:41.163003 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.01 seconds
2021-11-17 17:10:41.164294 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-17 17:10:41.165528 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:10:41.169930 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:10:41.170063 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: BEGIN
2021-11-17 17:10:41.170184 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-17 17:10:41.170805 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa".
2021-11-17 17:10:41.172064 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-17 17:10:41.172199 (ThreadPoolExecutor-1_1): On list_demo_db_sa: BEGIN
2021-11-17 17:10:41.172363 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-17 17:10:41.177519 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:10:41.177700 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:10:41.177802 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-17 17:10:41.179739 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:10:41.179951 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-17 17:10:41.180086 (ThreadPoolExecutor-1_1): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-17 17:10:41.180463 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 17:10:41.181374 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: ROLLBACK
2021-11-17 17:10:41.181765 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: Close
2021-11-17 17:10:41.181953 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 17:10:41.183418 (ThreadPoolExecutor-1_1): On list_demo_db_sa: ROLLBACK
2021-11-17 17:10:41.184022 (ThreadPoolExecutor-1_1): On list_demo_db_sa: Close
2021-11-17 17:10:41.187227 (MainThread): Using postgres connection "master".
2021-11-17 17:10:41.187346 (MainThread): On master: BEGIN
2021-11-17 17:10:41.187447 (MainThread): Opening a new connection, currently in state init
2021-11-17 17:10:41.193708 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:10:41.193934 (MainThread): Using postgres connection "master".
2021-11-17 17:10:41.194028 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-17 17:10:41.196656 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-17 17:10:41.197500 (MainThread): On master: ROLLBACK
2021-11-17 17:10:41.197869 (MainThread): Using postgres connection "master".
2021-11-17 17:10:41.197979 (MainThread): On master: BEGIN
2021-11-17 17:10:41.198895 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-17 17:10:41.199018 (MainThread): On master: COMMIT
2021-11-17 17:10:41.199115 (MainThread): Using postgres connection "master".
2021-11-17 17:10:41.199203 (MainThread): On master: COMMIT
2021-11-17 17:10:41.199637 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 17:10:41.199776 (MainThread): On master: Close
2021-11-17 17:10:41.200079 (MainThread): 18:10:41 | Concurrency: 2 threads (target='dev')
2021-11-17 17:10:41.200230 (MainThread): 18:10:41 | 
2021-11-17 17:10:41.202582 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-17 17:10:41.202869 (Thread-1): 18:10:41 | 1 of 1 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-17 17:10:41.203149 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:10:41.203273 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-17 17:10:41.205842 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-17 17:10:41.206070 (Thread-1): finished collecting timing info
2021-11-17 17:10:41.240147 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-17 17:10:41.240465 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:10:41.240573 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-17 17:10:41.240670 (Thread-1): Opening a new connection, currently in state closed
2021-11-17 17:10:41.247449 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:10:41.247654 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:10:41.247748 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp"
  as (
    

select
     AdjustedEnterpriseValue::FLOAT          as adjusted_enterprise_value
    ,ISIN::TEXT                as isin
    ,IssuerName::TEXT              as issuer_name
    ,ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,ClimateScope2Emissions           as climate_scope2_emissions
    ,ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,ClimateScope3Emissions           as climate_scope3_emissions
    ,ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,ClimateTotalEmissions            as climate_total_emissions
    ,ClimateScope1Emissions           as climate_scope1_emissions
    ,MarketCapDaily                   as market_capdaily
    ,ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,CURRENT_TIMESTAMP                as meta_insert_timestamp
    ,'20211117T164451425627'          as meta_run_id
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-17 17:10:41.252362 (Thread-1): Postgres error: invalid input syntax for type double precision: "Not Collected"

2021-11-17 17:10:41.252524 (Thread-1): On model.my_new_project.iss_issuer: ROLLBACK
2021-11-17 17:10:41.252973 (Thread-1): finished collecting timing info
2021-11-17 17:10:41.253107 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-17 17:10:41.253431 (Thread-1): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  invalid input syntax for type double precision: "Not Collected"
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type double precision: "Not Collected"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  invalid input syntax for type double precision: "Not Collected"
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-17 17:10:41.254654 (Thread-1): 18:10:41 | 1 of 1 ERROR creating incremental model sa_dwh.iss_issuer............ [ERROR in 0.05s]
2021-11-17 17:10:41.254832 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-17 17:10:41.256699 (MainThread): Acquiring new postgres connection "master".
2021-11-17 17:10:41.257079 (MainThread): Using postgres connection "master".
2021-11-17 17:10:41.257325 (MainThread): On master: BEGIN
2021-11-17 17:10:41.257493 (MainThread): Opening a new connection, currently in state closed
2021-11-17 17:10:41.264107 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:10:41.264317 (MainThread): On master: COMMIT
2021-11-17 17:10:41.264428 (MainThread): Using postgres connection "master".
2021-11-17 17:10:41.264524 (MainThread): On master: COMMIT
2021-11-17 17:10:41.264796 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 17:10:41.264951 (MainThread): On master: Close
2021-11-17 17:10:41.265301 (MainThread): 18:10:41 | 
2021-11-17 17:10:41.265480 (MainThread): 18:10:41 | Finished running 1 incremental model in 0.12s.
2021-11-17 17:10:41.265643 (MainThread): Connection 'master' was properly closed.
2021-11-17 17:10:41.265748 (MainThread): Connection 'list_demo_db_sa_dwh' was properly closed.
2021-11-17 17:10:41.265840 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-17 17:10:41.268927 (MainThread): 
2021-11-17 17:10:41.269109 (MainThread): Completed with 1 error and 0 warnings:
2021-11-17 17:10:41.269268 (MainThread): 
2021-11-17 17:10:41.269475 (MainThread): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
2021-11-17 17:10:41.269625 (MainThread):   invalid input syntax for type double precision: "Not Collected"
2021-11-17 17:10:41.269774 (MainThread):   compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-17 17:10:41.269938 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-11-17 17:10:41.270154 (MainThread): Flushing usage events
2021-11-17 17:11:12.477075 (MainThread): Running with dbt=0.21.0
2021-11-17 17:11:12.527746 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=True, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 17:11:12.528184 (MainThread): Tracking: do not track
2021-11-17 17:11:12.537909 (MainThread): Partial parsing not enabled
2021-11-17 17:11:12.543954 (MainThread): Parsing macros/adapters.sql
2021-11-17 17:11:12.561153 (MainThread): Parsing macros/catalog.sql
2021-11-17 17:11:12.562967 (MainThread): Parsing macros/relations.sql
2021-11-17 17:11:12.563946 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 17:11:12.565274 (MainThread): Parsing macros/core.sql
2021-11-17 17:11:12.568018 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 17:11:12.608009 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 17:11:12.609959 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 17:11:12.611286 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 17:11:12.612453 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 17:11:12.621857 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 17:11:12.623179 (MainThread): Parsing macros/etc/query.sql
2021-11-17 17:11:12.623979 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 17:11:12.625183 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 17:11:12.632560 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 17:11:12.637755 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 17:11:12.654671 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 17:11:12.655967 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 17:11:12.678351 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 17:11:12.691241 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 17:11:12.705551 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 17:11:12.713346 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 17:11:12.714691 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 17:11:12.724832 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 17:11:12.727715 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 17:11:12.733073 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 17:11:12.738516 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 17:11:12.739539 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 17:11:12.740440 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 17:11:12.741658 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 17:11:12.894106 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 17:11:12.904221 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 17:11:12.906986 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:11:12.909656 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:11:12.909872 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:11:12.940495 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:11:12.941926 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:11:12.943316 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:11:12.944894 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:11:12.958521 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-17 17:11:12.958813 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-17 17:11:12.960015 (MainThread): 
2021-11-17 17:11:12.960290 (MainThread): Acquiring new postgres connection "master".
2021-11-17 17:11:12.960966 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-17 17:11:12.967839 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-17 17:11:12.967945 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-17 17:11:12.968043 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-17 17:11:12.975153 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.01 seconds
2021-11-17 17:11:12.976058 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-17 17:11:12.977442 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-17 17:11:12.982301 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 17:11:12.982453 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-17 17:11:12.982583 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-17 17:11:12.983380 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:11:12.984296 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:11:12.984424 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-17 17:11:12.984544 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-17 17:11:12.989431 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:11:12.989591 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 17:11:12.989681 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-17 17:11:12.990952 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:11:12.991146 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:11:12.991239 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-17 17:11:12.991565 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 17:11:12.992463 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-17 17:11:12.992912 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-17 17:11:12.993109 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 17:11:12.994528 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-17 17:11:12.994954 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-17 17:11:12.998203 (MainThread): Using postgres connection "master".
2021-11-17 17:11:12.998456 (MainThread): On master: BEGIN
2021-11-17 17:11:12.998556 (MainThread): Opening a new connection, currently in state init
2021-11-17 17:11:13.004991 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:11:13.005179 (MainThread): Using postgres connection "master".
2021-11-17 17:11:13.005274 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-17 17:11:13.007745 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-17 17:11:13.008701 (MainThread): On master: ROLLBACK
2021-11-17 17:11:13.009185 (MainThread): Using postgres connection "master".
2021-11-17 17:11:13.009294 (MainThread): On master: BEGIN
2021-11-17 17:11:13.010150 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-17 17:11:13.010286 (MainThread): On master: COMMIT
2021-11-17 17:11:13.010381 (MainThread): Using postgres connection "master".
2021-11-17 17:11:13.010469 (MainThread): On master: COMMIT
2021-11-17 17:11:13.010898 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 17:11:13.011059 (MainThread): On master: Close
2021-11-17 17:11:13.011367 (MainThread): 18:11:13 | Concurrency: 2 threads (target='dev')
2021-11-17 17:11:13.011527 (MainThread): 18:11:13 | 
2021-11-17 17:11:13.014329 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-17 17:11:13.014617 (Thread-1): 18:11:13 | 1 of 1 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-17 17:11:13.014928 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:11:13.015066 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-17 17:11:13.017415 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-17 17:11:13.017646 (Thread-1): finished collecting timing info
2021-11-17 17:11:13.050883 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-17 17:11:13.051195 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:11:13.051303 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-17 17:11:13.051403 (Thread-1): Opening a new connection, currently in state closed
2021-11-17 17:11:13.057806 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:11:13.057954 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:11:13.058048 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp"
  as (
    

select
     AdjustedEnterpriseValue::DOUBLE          as adjusted_enterprise_value
    ,ISIN::TEXT                as isin
    ,IssuerName::TEXT              as issuer_name
    ,ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,ClimateScope2Emissions           as climate_scope2_emissions
    ,ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,ClimateScope3Emissions           as climate_scope3_emissions
    ,ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,ClimateTotalEmissions            as climate_total_emissions
    ,ClimateScope1Emissions           as climate_scope1_emissions
    ,MarketCapDaily                   as market_capdaily
    ,ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,CURRENT_TIMESTAMP                as meta_insert_timestamp
    ,'20211117T164451425627'          as meta_run_id
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-17 17:11:13.058867 (Thread-1): Postgres error: type "double" does not exist
LINE 10:      AdjustedEnterpriseValue::DOUBLE          as adjusted_en...
                                       ^

2021-11-17 17:11:13.059003 (Thread-1): On model.my_new_project.iss_issuer: ROLLBACK
2021-11-17 17:11:13.059458 (Thread-1): finished collecting timing info
2021-11-17 17:11:13.059597 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-17 17:11:13.059946 (Thread-1): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  type "double" does not exist
  LINE 10:      AdjustedEnterpriseValue::DOUBLE          as adjusted_en...
                                         ^
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedObject: type "double" does not exist
LINE 10:      AdjustedEnterpriseValue::DOUBLE          as adjusted_en...
                                       ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  type "double" does not exist
  LINE 10:      AdjustedEnterpriseValue::DOUBLE          as adjusted_en...
                                         ^
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-17 17:11:13.061204 (Thread-1): 18:11:13 | 1 of 1 ERROR creating incremental model sa_dwh.iss_issuer............ [ERROR in 0.05s]
2021-11-17 17:11:13.061356 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-17 17:11:13.062762 (MainThread): Acquiring new postgres connection "master".
2021-11-17 17:11:13.062910 (MainThread): Using postgres connection "master".
2021-11-17 17:11:13.063005 (MainThread): On master: BEGIN
2021-11-17 17:11:13.063103 (MainThread): Opening a new connection, currently in state closed
2021-11-17 17:11:13.069073 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:11:13.069352 (MainThread): On master: COMMIT
2021-11-17 17:11:13.069451 (MainThread): Using postgres connection "master".
2021-11-17 17:11:13.069540 (MainThread): On master: COMMIT
2021-11-17 17:11:13.069986 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 17:11:13.070121 (MainThread): On master: Close
2021-11-17 17:11:13.070508 (MainThread): 18:11:13 | 
2021-11-17 17:11:13.070678 (MainThread): 18:11:13 | Finished running 1 incremental model in 0.11s.
2021-11-17 17:11:13.070873 (MainThread): Connection 'master' was properly closed.
2021-11-17 17:11:13.070988 (MainThread): Connection 'list_demo_db_sa' was properly closed.
2021-11-17 17:11:13.071158 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-17 17:11:13.074167 (MainThread): 
2021-11-17 17:11:13.074326 (MainThread): Completed with 1 error and 0 warnings:
2021-11-17 17:11:13.074544 (MainThread): 
2021-11-17 17:11:13.074818 (MainThread): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
2021-11-17 17:11:13.075066 (MainThread):   type "double" does not exist
2021-11-17 17:11:13.075345 (MainThread):   LINE 10:      AdjustedEnterpriseValue::DOUBLE          as adjusted_en...
2021-11-17 17:11:13.075590 (MainThread):                                          ^
2021-11-17 17:11:13.075824 (MainThread):   compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-17 17:11:13.076025 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-11-17 17:11:13.076276 (MainThread): Flushing usage events
2021-11-17 17:12:06.460421 (MainThread): Running with dbt=0.21.0
2021-11-17 17:12:06.511887 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=True, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 17:12:06.512348 (MainThread): Tracking: do not track
2021-11-17 17:12:06.522175 (MainThread): Partial parsing not enabled
2021-11-17 17:12:06.528070 (MainThread): Parsing macros/adapters.sql
2021-11-17 17:12:06.545048 (MainThread): Parsing macros/catalog.sql
2021-11-17 17:12:06.546801 (MainThread): Parsing macros/relations.sql
2021-11-17 17:12:06.547771 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 17:12:06.549192 (MainThread): Parsing macros/core.sql
2021-11-17 17:12:06.552005 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 17:12:06.595779 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 17:12:06.597724 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 17:12:06.599240 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 17:12:06.600434 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 17:12:06.606930 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 17:12:06.608060 (MainThread): Parsing macros/etc/query.sql
2021-11-17 17:12:06.609004 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 17:12:06.610130 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 17:12:06.617404 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 17:12:06.623168 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 17:12:06.640532 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 17:12:06.641804 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 17:12:06.664192 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 17:12:06.677364 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 17:12:06.691535 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 17:12:06.699278 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 17:12:06.700629 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 17:12:06.710743 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 17:12:06.713684 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 17:12:06.719021 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 17:12:06.724287 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 17:12:06.725357 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 17:12:06.726254 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 17:12:06.727470 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 17:12:06.887163 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 17:12:06.900684 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 17:12:06.903584 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:12:06.906365 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:12:06.906594 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:12:06.933033 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:12:06.934588 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:12:06.936043 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:12:06.937521 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:12:06.950733 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-17 17:12:06.951072 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-17 17:12:06.952364 (MainThread): 
2021-11-17 17:12:06.952631 (MainThread): Acquiring new postgres connection "master".
2021-11-17 17:12:06.953281 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-17 17:12:06.960468 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-17 17:12:06.960579 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-17 17:12:06.960678 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-17 17:12:06.967679 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.01 seconds
2021-11-17 17:12:06.968766 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-17 17:12:06.970262 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-17 17:12:06.974553 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 17:12:06.974687 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-17 17:12:06.974809 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-17 17:12:06.975574 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:12:06.976663 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:12:06.976839 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-17 17:12:06.976997 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-17 17:12:06.981713 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:12:06.981904 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 17:12:06.981999 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-17 17:12:06.983276 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:12:06.983459 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:12:06.983552 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-17 17:12:06.983988 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 17:12:06.984933 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-17 17:12:06.985193 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 17:12:06.985390 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-17 17:12:06.986267 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-17 17:12:06.987173 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-17 17:12:06.990676 (MainThread): Using postgres connection "master".
2021-11-17 17:12:06.990817 (MainThread): On master: BEGIN
2021-11-17 17:12:06.990962 (MainThread): Opening a new connection, currently in state init
2021-11-17 17:12:06.997267 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:12:06.997466 (MainThread): Using postgres connection "master".
2021-11-17 17:12:06.997561 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-17 17:12:06.999964 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-17 17:12:07.000854 (MainThread): On master: ROLLBACK
2021-11-17 17:12:07.001203 (MainThread): Using postgres connection "master".
2021-11-17 17:12:07.001315 (MainThread): On master: BEGIN
2021-11-17 17:12:07.001981 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-17 17:12:07.002119 (MainThread): On master: COMMIT
2021-11-17 17:12:07.002215 (MainThread): Using postgres connection "master".
2021-11-17 17:12:07.002303 (MainThread): On master: COMMIT
2021-11-17 17:12:07.002679 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 17:12:07.002810 (MainThread): On master: Close
2021-11-17 17:12:07.003179 (MainThread): 18:12:06 | Concurrency: 2 threads (target='dev')
2021-11-17 17:12:07.003329 (MainThread): 18:12:06 | 
2021-11-17 17:12:07.006384 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-17 17:12:07.006679 (Thread-1): 18:12:06 | 1 of 1 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-17 17:12:07.007001 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:12:07.007127 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-17 17:12:07.009566 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-17 17:12:07.009797 (Thread-1): finished collecting timing info
2021-11-17 17:12:07.043200 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-17 17:12:07.043514 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:12:07.043624 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-17 17:12:07.043724 (Thread-1): Opening a new connection, currently in state closed
2021-11-17 17:12:07.050454 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:12:07.050608 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:12:07.050700 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp"
  as (
    

select
     AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,ISIN::TEXT                as isin
    ,IssuerName::TEXT              as issuer_name
    ,ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,ClimateScope2Emissions           as climate_scope2_emissions
    ,ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,ClimateScope3Emissions           as climate_scope3_emissions
    ,ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,ClimateTotalEmissions            as climate_total_emissions
    ,ClimateScope1Emissions           as climate_scope1_emissions
    ,MarketCapDaily                   as market_capdaily
    ,ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,CURRENT_TIMESTAMP                as meta_insert_timestamp
    ,'20211117T164451425627'          as meta_run_id
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-17 17:12:07.139594 (Thread-1): SQL status: SELECT 28444 in 0.09 seconds
2021-11-17 17:12:07.144031 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:12:07.144154 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */
alter table "demo_db"."sa_dwh"."iss_issuer" rename to "iss_issuer__dbt_backup"
2021-11-17 17:12:20.193406 (MainThread): Acquiring new postgres connection "master".
2021-11-17 17:12:20.193614 (MainThread): Cancelling query 'model.my_new_project.iss_issuer' (1119)
2021-11-17 17:12:20.193727 (MainThread): Using postgres connection "master".
2021-11-17 17:12:20.193817 (MainThread): On master: BEGIN
2021-11-17 17:12:20.193916 (MainThread): Opening a new connection, currently in state closed
2021-11-17 17:12:20.199987 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:12:20.200189 (MainThread): Using postgres connection "master".
2021-11-17 17:12:20.200286 (MainThread): On master: select pg_terminate_backend(1119)
2021-11-17 17:12:20.200939 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 17:12:20.201088 (MainThread): Cancel query 'model.my_new_project.iss_issuer': (True,)
2021-11-17 17:12:20.201252 (MainThread): 18:12:20 | CANCEL query list_demo_db_sa......................................... [CANCEL]
2021-11-17 17:12:20.201581 (MainThread): 18:12:20 | CANCEL query model.my_new_project.iss_issuer......................... [CANCEL]
2021-11-17 17:12:20.201795 (MainThread): On master: ROLLBACK
2021-11-17 17:12:20.202122 (MainThread): On master: Close
2021-11-17 17:12:20.204048 (Thread-1): Postgres error: terminating connection due to administrator command
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

2021-11-17 17:12:20.204180 (Thread-1): On model.my_new_project.iss_issuer: ROLLBACK
2021-11-17 17:12:20.204273 (Thread-1): Failed to rollback model.my_new_project.iss_issuer
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.OperationalError: terminating connection due to administrator command
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/connections.py", line 221, in _rollback_handle
    connection.handle.rollback()
psycopg2.InterfaceError: connection already closed
2021-11-17 17:12:20.204676 (Thread-1): Error running SQL: macro rename_relation
2021-11-17 17:12:20.204774 (Thread-1): Rolling back transaction.
2021-11-17 17:12:20.204906 (Thread-1): finished collecting timing info
2021-11-17 17:12:20.205031 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-17 17:12:20.205267 (Thread-1): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  terminating connection due to administrator command
  server closed the connection unexpectedly
  	This probably means the server terminated abnormally
  	before or while processing the request.
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.OperationalError: terminating connection due to administrator command
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 178, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/impl.py", line 165, in rename_relation
    self.execute_macro(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 1000, in execute_macro
    result = macro_function(**kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 37, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  terminating connection due to administrator command
  server closed the connection unexpectedly
  	This probably means the server terminated abnormally
  	before or while processing the request.
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-17 17:12:20.206384 (Thread-1): 18:12:20 | 1 of 1 ERROR creating incremental model sa_dwh.iss_issuer............ [ERROR in 13.20s]
2021-11-17 17:12:20.206570 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-17 17:12:20.206897 (MainThread): 
2021-11-17 17:12:20.207048 (MainThread): Exited because of keyboard interrupt.
2021-11-17 17:12:20.207252 (MainThread): 
Done. PASS=0 WARN=0 ERROR=0 SKIP=0 TOTAL=0
2021-11-17 17:12:20.207456 (MainThread): Connection 'master' was properly closed.
2021-11-17 17:12:20.207626 (MainThread): Connection 'list_demo_db_sa' was properly closed.
2021-11-17 17:12:20.207710 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-17 17:12:20.207828 (MainThread): Flushing usage events
2021-11-17 17:12:20.207976 (MainThread): ctrl-c
2021-11-17 17:12:53.096977 (MainThread): Running with dbt=0.21.0
2021-11-17 17:12:53.151032 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=True, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 17:12:53.151458 (MainThread): Tracking: do not track
2021-11-17 17:12:53.161138 (MainThread): Partial parsing not enabled
2021-11-17 17:12:53.167281 (MainThread): Parsing macros/adapters.sql
2021-11-17 17:12:53.185073 (MainThread): Parsing macros/catalog.sql
2021-11-17 17:12:53.187020 (MainThread): Parsing macros/relations.sql
2021-11-17 17:12:53.187997 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 17:12:53.189412 (MainThread): Parsing macros/core.sql
2021-11-17 17:12:53.192177 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 17:12:53.233330 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 17:12:53.235188 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 17:12:53.236554 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 17:12:53.237816 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 17:12:53.244621 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 17:12:53.245770 (MainThread): Parsing macros/etc/query.sql
2021-11-17 17:12:53.246532 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 17:12:53.247703 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 17:12:53.255179 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 17:12:53.260589 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 17:12:53.278135 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 17:12:53.279869 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 17:12:53.303198 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 17:12:53.316790 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 17:12:53.331857 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 17:12:53.339942 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 17:12:53.341320 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 17:12:53.351926 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 17:12:53.354856 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 17:12:53.360359 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 17:12:53.365994 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 17:12:53.367061 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 17:12:53.368100 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 17:12:53.369369 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 17:12:53.527973 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 17:12:53.537561 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 17:12:53.540288 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:12:53.542913 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:12:53.543128 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:12:53.569935 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:12:53.571395 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:12:53.572847 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:12:53.574367 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:12:53.588055 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-17 17:12:53.588372 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-17 17:12:53.589449 (MainThread): 
2021-11-17 17:12:53.589794 (MainThread): Acquiring new postgres connection "master".
2021-11-17 17:12:53.590456 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-17 17:12:53.597690 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-17 17:12:53.597806 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-17 17:12:53.597906 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-17 17:12:53.605169 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.01 seconds
2021-11-17 17:12:53.606236 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-17 17:12:53.607526 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-17 17:12:53.611635 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 17:12:53.611797 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-17 17:12:53.611940 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-17 17:12:53.612517 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:12:53.613616 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:12:53.613780 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-17 17:12:53.614031 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-17 17:12:53.619641 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:12:53.619879 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 17:12:53.619970 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-17 17:12:53.621505 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:12:53.621674 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:12:53.621763 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-17 17:12:53.622063 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 17:12:53.622967 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-17 17:12:53.623492 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-17 17:12:53.624069 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 17:12:53.625034 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-17 17:12:53.625456 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-17 17:12:53.629157 (MainThread): Using postgres connection "master".
2021-11-17 17:12:53.629280 (MainThread): On master: BEGIN
2021-11-17 17:12:53.629378 (MainThread): Opening a new connection, currently in state init
2021-11-17 17:12:53.635837 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:12:53.635990 (MainThread): Using postgres connection "master".
2021-11-17 17:12:53.636078 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-17 17:12:53.638627 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-17 17:12:53.639423 (MainThread): On master: ROLLBACK
2021-11-17 17:12:53.639875 (MainThread): Using postgres connection "master".
2021-11-17 17:12:53.640000 (MainThread): On master: BEGIN
2021-11-17 17:12:53.640992 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-17 17:12:53.641217 (MainThread): On master: COMMIT
2021-11-17 17:12:53.641310 (MainThread): Using postgres connection "master".
2021-11-17 17:12:53.641393 (MainThread): On master: COMMIT
2021-11-17 17:12:53.641856 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 17:12:53.642015 (MainThread): On master: Close
2021-11-17 17:12:53.642352 (MainThread): 18:12:53 | Concurrency: 2 threads (target='dev')
2021-11-17 17:12:53.642535 (MainThread): 18:12:53 | 
2021-11-17 17:12:53.645555 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-17 17:12:53.645896 (Thread-1): 18:12:53 | 1 of 1 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-17 17:12:53.646444 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:12:53.646617 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-17 17:12:53.649088 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-17 17:12:53.649319 (Thread-1): finished collecting timing info
2021-11-17 17:12:53.682964 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-17 17:12:53.683296 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:12:53.683472 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-17 17:12:53.683592 (Thread-1): Opening a new connection, currently in state closed
2021-11-17 17:12:53.690322 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:12:53.690457 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:12:53.690550 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp"
  as (
    

select
     AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,ISIN                             as isin
    ,IssuerName                       as issuer_name
    ,ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,ClimateScope2Emissions           as climate_scope2_emissions
    ,ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,ClimateScope3Emissions           as climate_scope3_emissions
    ,ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,ClimateTotalEmissions            as climate_total_emissions
    ,ClimateScope1Emissions           as climate_scope1_emissions
    ,MarketCapDaily                   as market_capdaily
    ,ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,CURRENT_TIMESTAMP                as meta_insert_timestamp
    ,'20211117T164451425627'          as meta_run_id
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-17 17:12:53.782318 (Thread-1): SQL status: SELECT 28444 in 0.09 seconds
2021-11-17 17:12:53.786802 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:12:53.786928 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */
alter table "demo_db"."sa_dwh"."iss_issuer" rename to "iss_issuer__dbt_backup"
2021-11-17 17:13:05.968711 (MainThread): Acquiring new postgres connection "master".
2021-11-17 17:13:05.968923 (MainThread): Cancelling query 'model.my_new_project.iss_issuer' (1126)
2021-11-17 17:13:05.969035 (MainThread): Using postgres connection "master".
2021-11-17 17:13:05.969127 (MainThread): On master: BEGIN
2021-11-17 17:13:05.969226 (MainThread): Opening a new connection, currently in state closed
2021-11-17 17:13:05.974914 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:13:05.975091 (MainThread): Using postgres connection "master".
2021-11-17 17:13:05.975225 (MainThread): On master: select pg_terminate_backend(1126)
2021-11-17 17:13:05.975864 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 17:13:05.976085 (MainThread): Cancel query 'model.my_new_project.iss_issuer': (True,)
2021-11-17 17:13:05.976223 (MainThread): 18:13:05 | CANCEL query list_demo_db_sa......................................... [CANCEL]
2021-11-17 17:13:05.976419 (MainThread): 18:13:05 | CANCEL query model.my_new_project.iss_issuer......................... [CANCEL]
2021-11-17 17:13:05.976648 (MainThread): On master: ROLLBACK
2021-11-17 17:13:05.977032 (MainThread): On master: Close
2021-11-17 17:13:05.979362 (Thread-1): Postgres error: terminating connection due to administrator command
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

2021-11-17 17:13:05.979531 (Thread-1): On model.my_new_project.iss_issuer: ROLLBACK
2021-11-17 17:13:05.979633 (Thread-1): Failed to rollback model.my_new_project.iss_issuer
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.OperationalError: terminating connection due to administrator command
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/connections.py", line 221, in _rollback_handle
    connection.handle.rollback()
psycopg2.InterfaceError: connection already closed
2021-11-17 17:13:05.980084 (Thread-1): Error running SQL: macro rename_relation
2021-11-17 17:13:05.980187 (Thread-1): Rolling back transaction.
2021-11-17 17:13:05.980318 (Thread-1): finished collecting timing info
2021-11-17 17:13:05.980448 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-17 17:13:05.980716 (Thread-1): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  terminating connection due to administrator command
  server closed the connection unexpectedly
  	This probably means the server terminated abnormally
  	before or while processing the request.
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.OperationalError: terminating connection due to administrator command
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 178, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/impl.py", line 165, in rename_relation
    self.execute_macro(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 1000, in execute_macro
    result = macro_function(**kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 37, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  terminating connection due to administrator command
  server closed the connection unexpectedly
  	This probably means the server terminated abnormally
  	before or while processing the request.
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-17 17:13:05.981926 (Thread-1): 18:13:05 | 1 of 1 ERROR creating incremental model sa_dwh.iss_issuer............ [ERROR in 12.34s]
2021-11-17 17:13:05.982085 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-17 17:13:05.982370 (MainThread): 
2021-11-17 17:13:05.982538 (MainThread): Exited because of keyboard interrupt.
2021-11-17 17:13:05.982711 (MainThread): 
Done. PASS=0 WARN=0 ERROR=0 SKIP=0 TOTAL=0
2021-11-17 17:13:05.982873 (MainThread): Connection 'master' was properly closed.
2021-11-17 17:13:05.982979 (MainThread): Connection 'list_demo_db_sa' was properly closed.
2021-11-17 17:13:05.983070 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-17 17:13:05.983175 (MainThread): Flushing usage events
2021-11-17 17:13:05.983318 (MainThread): ctrl-c
2021-11-17 17:20:18.884398 (MainThread): Running with dbt=0.21.0
2021-11-17 17:20:18.936490 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=True, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-17 17:20:18.936951 (MainThread): Tracking: do not track
2021-11-17 17:20:18.946882 (MainThread): Partial parsing not enabled
2021-11-17 17:20:18.953013 (MainThread): Parsing macros/adapters.sql
2021-11-17 17:20:18.970667 (MainThread): Parsing macros/catalog.sql
2021-11-17 17:20:18.972308 (MainThread): Parsing macros/relations.sql
2021-11-17 17:20:18.973249 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-17 17:20:18.974488 (MainThread): Parsing macros/core.sql
2021-11-17 17:20:18.977272 (MainThread): Parsing macros/adapters/common.sql
2021-11-17 17:20:19.017682 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-17 17:20:19.019663 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-17 17:20:19.021142 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-17 17:20:19.022346 (MainThread): Parsing macros/etc/datetime.sql
2021-11-17 17:20:19.028719 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-17 17:20:19.029880 (MainThread): Parsing macros/etc/query.sql
2021-11-17 17:20:19.030610 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-17 17:20:19.031816 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-17 17:20:19.039110 (MainThread): Parsing macros/materializations/test.sql
2021-11-17 17:20:19.044285 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-17 17:20:19.061271 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-17 17:20:19.062566 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-17 17:20:19.084701 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-17 17:20:19.097673 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-17 17:20:19.111982 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-17 17:20:19.119720 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-17 17:20:19.121082 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-17 17:20:19.131401 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-17 17:20:19.134457 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-17 17:20:19.139997 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-17 17:20:19.145305 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-17 17:20:19.146328 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-17 17:20:19.147228 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-17 17:20:19.148590 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-17 17:20:19.305353 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-17 17:20:19.314790 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-17 17:20:19.317597 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:20:19.320306 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:20:19.320563 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:20:19.346523 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:20:19.347906 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:20:19.349372 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:20:19.350805 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-17 17:20:19.365959 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-17 17:20:19.366237 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-17 17:20:19.367511 (MainThread): 
2021-11-17 17:20:19.367804 (MainThread): Acquiring new postgres connection "master".
2021-11-17 17:20:19.368493 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-17 17:20:19.376152 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-17 17:20:19.376271 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-17 17:20:19.376373 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-17 17:20:19.383834 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.01 seconds
2021-11-17 17:20:19.384763 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-17 17:20:19.385934 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-17 17:20:19.390486 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 17:20:19.390626 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-17 17:20:19.390751 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-17 17:20:19.391494 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:20:19.392500 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:20:19.392646 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-17 17:20:19.392811 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-17 17:20:19.398086 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:20:19.398360 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-17 17:20:19.398491 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-17 17:20:19.399992 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:20:19.400178 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-17 17:20:19.400270 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-17 17:20:19.401145 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 17:20:19.402127 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-17 17:20:19.402414 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 17:20:19.403261 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-17 17:20:19.403403 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-17 17:20:19.403988 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-17 17:20:19.408019 (MainThread): Using postgres connection "master".
2021-11-17 17:20:19.408143 (MainThread): On master: BEGIN
2021-11-17 17:20:19.408243 (MainThread): Opening a new connection, currently in state init
2021-11-17 17:20:19.414869 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:20:19.415106 (MainThread): Using postgres connection "master".
2021-11-17 17:20:19.415196 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-17 17:20:19.417995 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-17 17:20:19.419071 (MainThread): On master: ROLLBACK
2021-11-17 17:20:19.419455 (MainThread): Using postgres connection "master".
2021-11-17 17:20:19.419586 (MainThread): On master: BEGIN
2021-11-17 17:20:19.420406 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-17 17:20:19.420554 (MainThread): On master: COMMIT
2021-11-17 17:20:19.420645 (MainThread): Using postgres connection "master".
2021-11-17 17:20:19.420728 (MainThread): On master: COMMIT
2021-11-17 17:20:19.421105 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-17 17:20:19.421269 (MainThread): On master: Close
2021-11-17 17:20:19.421620 (MainThread): 18:20:19 | Concurrency: 2 threads (target='dev')
2021-11-17 17:20:19.421818 (MainThread): 18:20:19 | 
2021-11-17 17:20:19.424113 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-17 17:20:19.424410 (Thread-1): 18:20:19 | 1 of 1 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-17 17:20:19.424887 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:20:19.425022 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-17 17:20:19.427383 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-17 17:20:19.427602 (Thread-1): finished collecting timing info
2021-11-17 17:20:19.461633 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-17 17:20:19.461952 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:20:19.462168 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-17 17:20:19.462290 (Thread-1): Opening a new connection, currently in state closed
2021-11-17 17:20:19.469024 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:20:19.469203 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:20:19.469292 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp"
  as (
    

select
     AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,ISIN                             as isin
    ,IssuerName                       as issuer_name
    ,ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,ClimateScope2Emissions           as climate_scope2_emissions
    ,ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,ClimateScope3Emissions           as climate_scope3_emissions
    ,ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,ClimateTotalEmissions            as climate_total_emissions
    ,ClimateScope1Emissions           as climate_scope1_emissions
    ,MarketCapDaily                   as market_capdaily
    ,ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,CURRENT_TIMESTAMP                as meta_insert_timestamp
    ,'20211117T164451425627'          as meta_run_id
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-17 17:20:19.580844 (Thread-1): SQL status: SELECT 28444 in 0.11 seconds
2021-11-17 17:20:19.585861 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-17 17:20:19.585999 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */
alter table "demo_db"."sa_dwh"."iss_issuer" rename to "iss_issuer__dbt_backup"
2021-11-17 17:20:35.430134 (MainThread): Acquiring new postgres connection "master".
2021-11-17 17:20:35.430319 (MainThread): Cancelling query 'model.my_new_project.iss_issuer' (54)
2021-11-17 17:20:35.430422 (MainThread): Using postgres connection "master".
2021-11-17 17:20:35.430510 (MainThread): On master: BEGIN
2021-11-17 17:20:35.430605 (MainThread): Opening a new connection, currently in state closed
2021-11-17 17:20:35.436242 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-17 17:20:35.436442 (MainThread): Using postgres connection "master".
2021-11-17 17:20:35.436537 (MainThread): On master: select pg_terminate_backend(54)
2021-11-17 17:20:35.437158 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-17 17:20:35.437283 (MainThread): Cancel query 'model.my_new_project.iss_issuer': (True,)
2021-11-17 17:20:35.437443 (MainThread): 18:20:35 | CANCEL query list_demo_db_sa......................................... [CANCEL]
2021-11-17 17:20:35.437636 (MainThread): 18:20:35 | CANCEL query model.my_new_project.iss_issuer......................... [CANCEL]
2021-11-17 17:20:35.437856 (MainThread): On master: ROLLBACK
2021-11-17 17:20:35.438223 (MainThread): On master: Close
2021-11-17 17:20:35.440290 (Thread-1): Postgres error: terminating connection due to administrator command
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

2021-11-17 17:20:35.440456 (Thread-1): On model.my_new_project.iss_issuer: ROLLBACK
2021-11-17 17:20:35.440552 (Thread-1): Failed to rollback model.my_new_project.iss_issuer
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.OperationalError: terminating connection due to administrator command
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/connections.py", line 221, in _rollback_handle
    connection.handle.rollback()
psycopg2.InterfaceError: connection already closed
2021-11-17 17:20:35.440964 (Thread-1): Error running SQL: macro rename_relation
2021-11-17 17:20:35.441063 (Thread-1): Rolling back transaction.
2021-11-17 17:20:35.441183 (Thread-1): finished collecting timing info
2021-11-17 17:20:35.441305 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-17 17:20:35.441541 (Thread-1): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  terminating connection due to administrator command
  server closed the connection unexpectedly
  	This probably means the server terminated abnormally
  	before or while processing the request.
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.OperationalError: terminating connection due to administrator command
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 178, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/impl.py", line 165, in rename_relation
    self.execute_macro(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 1000, in execute_macro
    result = macro_function(**kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 37, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  terminating connection due to administrator command
  server closed the connection unexpectedly
  	This probably means the server terminated abnormally
  	before or while processing the request.
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-17 17:20:35.442672 (Thread-1): 18:20:35 | 1 of 1 ERROR creating incremental model sa_dwh.iss_issuer............ [ERROR in 16.02s]
2021-11-17 17:20:35.442830 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-17 17:20:35.443084 (MainThread): 
2021-11-17 17:20:35.443233 (MainThread): Exited because of keyboard interrupt.
2021-11-17 17:20:35.443439 (MainThread): 
Done. PASS=0 WARN=0 ERROR=0 SKIP=0 TOTAL=0
2021-11-17 17:20:35.443631 (MainThread): Connection 'master' was properly closed.
2021-11-17 17:20:35.443742 (MainThread): Connection 'list_demo_db_sa' was properly closed.
2021-11-17 17:20:35.443863 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-17 17:20:35.443960 (MainThread): Flushing usage events
2021-11-17 17:20:35.444086 (MainThread): ctrl-c
2021-11-18 08:40:38.493885 (MainThread): Running with dbt=0.21.0
2021-11-18 08:40:38.561812 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-18 08:40:38.562311 (MainThread): Tracking: do not track
2021-11-18 08:40:38.574549 (MainThread): Partial parsing not enabled
2021-11-18 08:40:38.581748 (MainThread): Parsing macros/adapters.sql
2021-11-18 08:40:38.602550 (MainThread): Parsing macros/catalog.sql
2021-11-18 08:40:38.604475 (MainThread): Parsing macros/relations.sql
2021-11-18 08:40:38.605558 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-18 08:40:38.606967 (MainThread): Parsing macros/core.sql
2021-11-18 08:40:38.610192 (MainThread): Parsing macros/adapters/common.sql
2021-11-18 08:40:38.660467 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-18 08:40:38.662796 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-18 08:40:38.664469 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-18 08:40:38.666029 (MainThread): Parsing macros/etc/datetime.sql
2021-11-18 08:40:38.674152 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-18 08:40:38.675662 (MainThread): Parsing macros/etc/query.sql
2021-11-18 08:40:38.676570 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-18 08:40:38.677943 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-18 08:40:38.687609 (MainThread): Parsing macros/materializations/test.sql
2021-11-18 08:40:38.694256 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-18 08:40:38.716122 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-18 08:40:38.717931 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-18 08:40:38.746851 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-18 08:40:38.763717 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-18 08:40:38.782474 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-18 08:40:38.792932 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-18 08:40:38.794729 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-18 08:40:38.807792 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-18 08:40:38.811639 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-18 08:40:38.818960 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-18 08:40:38.826052 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-18 08:40:38.827542 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-18 08:40:38.828783 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-18 08:40:38.830373 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-18 08:40:39.033290 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-18 08:40:39.045713 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-18 08:40:39.049631 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:40:39.053582 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:40:39.053901 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:40:39.088830 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:40:39.090882 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:40:39.092791 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:40:39.094738 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:40:39.112686 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-18 08:40:39.113064 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-18 08:40:39.114207 (MainThread): 
2021-11-18 08:40:39.114667 (MainThread): Acquiring new postgres connection "master".
2021-11-18 08:40:39.115637 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-18 08:40:39.124808 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-18 08:40:39.125052 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-18 08:40:39.125213 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-18 08:40:39.133952 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.01 seconds
2021-11-18 08:40:39.135171 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-18 08:40:39.136409 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-18 08:40:39.142083 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-18 08:40:39.142326 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-18 08:40:39.143531 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-18 08:40:39.143760 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-18 08:40:39.143989 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-18 08:40:39.144153 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-18 08:40:39.144318 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-18 08:40:39.151545 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-18 08:40:39.151809 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-18 08:40:39.151950 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-18 08:40:39.152140 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-18 08:40:39.152330 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-18 08:40:39.152554 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-18 08:40:39.154494 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-18 08:40:39.154694 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-18 08:40:39.155753 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-18 08:40:39.156683 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-18 08:40:39.157110 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-18 08:40:39.157281 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-18 08:40:39.161312 (MainThread): Using postgres connection "master".
2021-11-18 08:40:39.161519 (MainThread): On master: BEGIN
2021-11-18 08:40:39.161641 (MainThread): Opening a new connection, currently in state init
2021-11-18 08:40:39.170003 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-18 08:40:39.170211 (MainThread): Using postgres connection "master".
2021-11-18 08:40:39.170321 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-18 08:40:39.172838 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-18 08:40:39.173806 (MainThread): On master: ROLLBACK
2021-11-18 08:40:39.174087 (MainThread): Using postgres connection "master".
2021-11-18 08:40:39.174198 (MainThread): On master: BEGIN
2021-11-18 08:40:39.174690 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-18 08:40:39.174842 (MainThread): On master: COMMIT
2021-11-18 08:40:39.174943 (MainThread): Using postgres connection "master".
2021-11-18 08:40:39.175036 (MainThread): On master: COMMIT
2021-11-18 08:40:39.175306 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-18 08:40:39.175453 (MainThread): On master: Close
2021-11-18 08:40:39.175776 (MainThread): 09:40:39 | Concurrency: 2 threads (target='dev')
2021-11-18 08:40:39.175967 (MainThread): 09:40:39 | 
2021-11-18 08:40:39.178107 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-18 08:40:39.178448 (Thread-1): 09:40:39 | 1 of 1 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-18 08:40:39.178791 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:40:39.178932 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-18 08:40:39.181691 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-18 08:40:39.182040 (Thread-1): finished collecting timing info
2021-11-18 08:40:39.225583 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:40:39.225802 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

    

  create temporary table "iss_issuer__dbt_tmp094039208423"
  as (
    

select
     AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,ISIN                             as isin
    ,IssuerName                       as issuer_name
    ,ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,ClimateScope2Emissions           as climate_scope2_emissions
    ,ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,ClimateScope3Emissions           as climate_scope3_emissions
    ,ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,ClimateTotalEmissions            as climate_total_emissions
    ,ClimateScope1Emissions           as climate_scope1_emissions
    ,MarketCapDaily                   as market_capdaily
    ,ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,CURRENT_TIMESTAMP                as meta_insert_timestamp
    ,'20211117T164451425627'          as meta_run_id
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-18 08:40:39.225948 (Thread-1): Opening a new connection, currently in state closed
2021-11-18 08:40:39.341844 (Thread-1): SQL status: SELECT 28444 in 0.12 seconds
2021-11-18 08:40:39.348403 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:40:39.348955 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-18 08:40:39.350562 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-11-18 08:40:39.350780 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:40:39.350890 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer__dbt_tmp094039208423'
        
      order by ordinal_position

  
2021-11-18 08:40:39.356369 (Thread-1): SQL status: SELECT 15 in 0.01 seconds
2021-11-18 08:40:39.361621 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:40:39.361797 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-18 08:40:39.364786 (Thread-1): SQL status: SELECT 15 in 0.00 seconds
2021-11-18 08:40:39.373420 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:40:39.373602 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-18 08:40:39.376240 (Thread-1): SQL status: SELECT 15 in 0.00 seconds
2021-11-18 08:40:39.377919 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-18 08:40:39.378360 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:40:39.378572 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      delete
    from "demo_db"."sa_dwh"."iss_issuer"
    where (ISIN) in (
        select (ISIN)
        from "iss_issuer__dbt_tmp094039208423"
    );

    insert into "demo_db"."sa_dwh"."iss_issuer" ("adjusted_enterprise_value", "isin", "issuer_name", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_capdaily", "climate_emissions_fiscal_year", "meta_insert_timestamp", "meta_run_id")
    (
       select "adjusted_enterprise_value", "isin", "issuer_name", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_capdaily", "climate_emissions_fiscal_year", "meta_insert_timestamp", "meta_run_id"
       from "iss_issuer__dbt_tmp094039208423"
    );
  
2021-11-18 08:40:39.459340 (Thread-1): SQL status: INSERT 0 28444 in 0.08 seconds
2021-11-18 08:40:39.464919 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-18 08:40:39.465081 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:40:39.465184 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-18 08:40:39.470340 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-11-18 08:40:39.470963 (Thread-1): finished collecting timing info
2021-11-18 08:40:39.471124 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-18 08:40:39.471636 (Thread-1): 09:40:39 | 1 of 1 OK created incremental model sa_dwh.iss_issuer................ [INSERT 0 28444 in 0.29s]
2021-11-18 08:40:39.471834 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-18 08:40:39.473280 (MainThread): Acquiring new postgres connection "master".
2021-11-18 08:40:39.473505 (MainThread): Using postgres connection "master".
2021-11-18 08:40:39.473685 (MainThread): On master: BEGIN
2021-11-18 08:40:39.474000 (MainThread): Opening a new connection, currently in state closed
2021-11-18 08:40:39.480400 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-18 08:40:39.480636 (MainThread): On master: COMMIT
2021-11-18 08:40:39.480765 (MainThread): Using postgres connection "master".
2021-11-18 08:40:39.480868 (MainThread): On master: COMMIT
2021-11-18 08:40:39.481171 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-18 08:40:39.481339 (MainThread): On master: Close
2021-11-18 08:40:39.481831 (MainThread): 09:40:39 | 
2021-11-18 08:40:39.482020 (MainThread): 09:40:39 | Finished running 1 incremental model in 0.37s.
2021-11-18 08:40:39.482174 (MainThread): Connection 'master' was properly closed.
2021-11-18 08:40:39.482280 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-18 08:40:39.482391 (MainThread): Connection 'list_demo_db_sa_dwh' was properly closed.
2021-11-18 08:40:39.486185 (MainThread): 
2021-11-18 08:40:39.486494 (MainThread): Completed successfully
2021-11-18 08:40:39.486697 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-11-18 08:40:39.486968 (MainThread): Flushing usage events
2021-11-18 08:45:02.974756 (MainThread): Running with dbt=0.21.0
2021-11-18 08:45:03.037697 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=True, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-18 08:45:03.038817 (MainThread): Tracking: do not track
2021-11-18 08:45:03.050363 (MainThread): Partial parsing not enabled
2021-11-18 08:45:03.058064 (MainThread): Parsing macros/adapters.sql
2021-11-18 08:45:03.079121 (MainThread): Parsing macros/catalog.sql
2021-11-18 08:45:03.081238 (MainThread): Parsing macros/relations.sql
2021-11-18 08:45:03.082425 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-18 08:45:03.083955 (MainThread): Parsing macros/core.sql
2021-11-18 08:45:03.087460 (MainThread): Parsing macros/adapters/common.sql
2021-11-18 08:45:03.137347 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-18 08:45:03.140638 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-18 08:45:03.142216 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-18 08:45:03.143592 (MainThread): Parsing macros/etc/datetime.sql
2021-11-18 08:45:03.151537 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-18 08:45:03.152878 (MainThread): Parsing macros/etc/query.sql
2021-11-18 08:45:03.154125 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-18 08:45:03.156963 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-18 08:45:03.166309 (MainThread): Parsing macros/materializations/test.sql
2021-11-18 08:45:03.172426 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-18 08:45:03.192955 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-18 08:45:03.194662 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-18 08:45:03.222923 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-18 08:45:03.239455 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-18 08:45:03.257627 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-18 08:45:03.267365 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-18 08:45:03.269239 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-18 08:45:03.282295 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-18 08:45:03.285968 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-18 08:45:03.292894 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-18 08:45:03.299872 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-18 08:45:03.301303 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-18 08:45:03.302438 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-18 08:45:03.304020 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-18 08:45:03.506049 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-18 08:45:03.517465 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-18 08:45:03.521382 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:45:03.525747 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:45:03.526057 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:45:03.559540 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:45:03.561233 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:45:03.562916 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:45:03.564696 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:45:03.581363 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-18 08:45:03.581740 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-18 08:45:03.582918 (MainThread): 
2021-11-18 08:45:03.583430 (MainThread): Acquiring new postgres connection "master".
2021-11-18 08:45:03.584131 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-18 08:45:03.594627 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-18 08:45:03.594837 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-18 08:45:03.594964 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-18 08:45:03.602191 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.01 seconds
2021-11-18 08:45:03.603658 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-18 08:45:03.606058 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-18 08:45:03.606928 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-18 08:45:03.612064 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-18 08:45:03.613685 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-18 08:45:03.613985 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-18 08:45:03.614210 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-18 08:45:03.614412 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-18 08:45:03.614629 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-18 08:45:03.623069 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-18 08:45:03.623390 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-18 08:45:03.623588 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-18 08:45:03.623773 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-18 08:45:03.624039 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-18 08:45:03.624223 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-18 08:45:03.626419 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-18 08:45:03.626662 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-18 08:45:03.627824 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-18 08:45:03.629122 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-18 08:45:03.629688 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-18 08:45:03.629859 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-18 08:45:03.633562 (MainThread): Using postgres connection "master".
2021-11-18 08:45:03.633714 (MainThread): On master: BEGIN
2021-11-18 08:45:03.633844 (MainThread): Opening a new connection, currently in state init
2021-11-18 08:45:03.640857 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-18 08:45:03.641069 (MainThread): Using postgres connection "master".
2021-11-18 08:45:03.641176 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-18 08:45:03.643599 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-18 08:45:03.644579 (MainThread): On master: ROLLBACK
2021-11-18 08:45:03.644933 (MainThread): Using postgres connection "master".
2021-11-18 08:45:03.645072 (MainThread): On master: BEGIN
2021-11-18 08:45:03.645741 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-18 08:45:03.645890 (MainThread): On master: COMMIT
2021-11-18 08:45:03.645996 (MainThread): Using postgres connection "master".
2021-11-18 08:45:03.646117 (MainThread): On master: COMMIT
2021-11-18 08:45:03.646481 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-18 08:45:03.646628 (MainThread): On master: Close
2021-11-18 08:45:03.646981 (MainThread): 09:45:03 | Concurrency: 2 threads (target='dev')
2021-11-18 08:45:03.647149 (MainThread): 09:45:03 | 
2021-11-18 08:45:03.650210 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-18 08:45:03.650610 (Thread-1): 09:45:03 | 1 of 1 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-18 08:45:03.651066 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:45:03.651200 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-18 08:45:03.654985 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-18 08:45:03.655797 (Thread-1): finished collecting timing info
2021-11-18 08:45:03.698738 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-18 08:45:03.699169 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:45:03.699296 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-18 08:45:03.699413 (Thread-1): Opening a new connection, currently in state closed
2021-11-18 08:45:03.706760 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-18 08:45:03.707017 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:45:03.707140 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp"
  as (
    

select
     iss.AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,iss.ISIN                             as isin
    ,iss.IssuerName                       as issuer_name
    ,iss.ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,iss.ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,iss.ClimateScope2Emissions           as climate_scope2_emissions
    ,iss.ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,iss.ClimateScope3Emissions           as climate_scope3_emissions
    ,iss.ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,iss.ClimateTotalEmissions            as climate_total_emissions
    ,iss.ClimateScope1Emissions           as climate_scope1_emissions
    ,iss.MarketCapDaily                   as market_capdaily
    ,iss.ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,'2021-01-01'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-18 08:45:03.841167 (Thread-1): SQL status: SELECT 28444 in 0.13 seconds
2021-11-18 08:45:03.847252 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:45:03.847444 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */
alter table "demo_db"."sa_dwh"."iss_issuer" rename to "iss_issuer__dbt_backup"
2021-11-18 08:45:03.848097 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-11-18 08:45:03.850264 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:45:03.850506 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */
alter table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp" rename to "iss_issuer"
2021-11-18 08:45:03.851224 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-11-18 08:45:03.863865 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-18 08:45:03.864083 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:45:03.864207 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-18 08:45:03.873639 (Thread-1): SQL status: COMMIT in 0.01 seconds
2021-11-18 08:45:03.880179 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:45:03.880390 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */
drop table if exists "demo_db"."sa_dwh"."iss_issuer__dbt_backup" cascade
2021-11-18 08:45:03.884421 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-11-18 08:45:03.885711 (Thread-1): finished collecting timing info
2021-11-18 08:45:03.885932 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-18 08:45:03.886572 (Thread-1): 09:45:03 | 1 of 1 OK created incremental model sa_dwh.iss_issuer................ [SELECT 28444 in 0.24s]
2021-11-18 08:45:03.886902 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-18 08:45:03.889467 (MainThread): Acquiring new postgres connection "master".
2021-11-18 08:45:03.889842 (MainThread): Using postgres connection "master".
2021-11-18 08:45:03.889998 (MainThread): On master: BEGIN
2021-11-18 08:45:03.890124 (MainThread): Opening a new connection, currently in state closed
2021-11-18 08:45:03.897742 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-18 08:45:03.898047 (MainThread): On master: COMMIT
2021-11-18 08:45:03.898155 (MainThread): Using postgres connection "master".
2021-11-18 08:45:03.898306 (MainThread): On master: COMMIT
2021-11-18 08:45:03.898747 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-18 08:45:03.898895 (MainThread): On master: Close
2021-11-18 08:45:03.899256 (MainThread): 09:45:03 | 
2021-11-18 08:45:03.899418 (MainThread): 09:45:03 | Finished running 1 incremental model in 0.32s.
2021-11-18 08:45:03.899560 (MainThread): Connection 'master' was properly closed.
2021-11-18 08:45:03.899660 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-18 08:45:03.899749 (MainThread): Connection 'list_demo_db_sa_dwh' was properly closed.
2021-11-18 08:45:03.903284 (MainThread): 
2021-11-18 08:45:03.903544 (MainThread): Completed successfully
2021-11-18 08:45:03.903713 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-11-18 08:45:03.903987 (MainThread): Flushing usage events
2021-11-18 08:48:04.573984 (MainThread): Running with dbt=0.21.0
2021-11-18 08:48:04.641549 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='var_date: 2021-10-31', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=True, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-18 08:48:04.642144 (MainThread): Tracking: do not track
2021-11-18 08:48:04.654691 (MainThread): Partial parsing not enabled
2021-11-18 08:48:04.663101 (MainThread): Parsing macros/adapters.sql
2021-11-18 08:48:04.682912 (MainThread): Parsing macros/catalog.sql
2021-11-18 08:48:04.684946 (MainThread): Parsing macros/relations.sql
2021-11-18 08:48:04.686042 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-18 08:48:04.687462 (MainThread): Parsing macros/core.sql
2021-11-18 08:48:04.690887 (MainThread): Parsing macros/adapters/common.sql
2021-11-18 08:48:04.737735 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-18 08:48:04.740114 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-18 08:48:04.741986 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-18 08:48:04.743521 (MainThread): Parsing macros/etc/datetime.sql
2021-11-18 08:48:04.751096 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-18 08:48:04.752454 (MainThread): Parsing macros/etc/query.sql
2021-11-18 08:48:04.753317 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-18 08:48:04.754670 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-18 08:48:04.763620 (MainThread): Parsing macros/materializations/test.sql
2021-11-18 08:48:04.769871 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-18 08:48:04.790700 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-18 08:48:04.792354 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-18 08:48:04.820078 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-18 08:48:04.835263 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-18 08:48:04.852681 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-18 08:48:04.862841 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-18 08:48:04.864667 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-18 08:48:04.878188 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-18 08:48:04.882135 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-18 08:48:04.889227 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-18 08:48:04.896486 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-18 08:48:04.898021 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-18 08:48:04.899263 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-18 08:48:04.900893 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-18 08:48:05.094697 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-18 08:48:05.105574 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-18 08:48:05.109356 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:48:05.112770 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:48:05.113046 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:48:05.146391 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:48:05.148044 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:48:05.149833 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:48:05.151655 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:48:05.168361 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-18 08:48:05.168740 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-18 08:48:05.169791 (MainThread): 
2021-11-18 08:48:05.170166 (MainThread): Acquiring new postgres connection "master".
2021-11-18 08:48:05.170867 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-18 08:48:05.184248 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-18 08:48:05.184459 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-18 08:48:05.184670 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-18 08:48:05.194460 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.01 seconds
2021-11-18 08:48:05.196483 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-18 08:48:05.198665 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-18 08:48:05.199754 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-18 08:48:05.206436 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-18 08:48:05.208956 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-18 08:48:05.209428 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-18 08:48:05.209769 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-18 08:48:05.210045 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-18 08:48:05.210363 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-18 08:48:05.221466 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-18 08:48:05.222486 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-18 08:48:05.223929 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-18 08:48:05.226845 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.02 seconds
2021-11-18 08:48:05.227186 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-18 08:48:05.227361 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-18 08:48:05.228202 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-18 08:48:05.230225 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-18 08:48:05.230783 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-18 08:48:05.231092 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-18 08:48:05.232913 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-18 08:48:05.233870 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-18 08:48:05.238080 (MainThread): Using postgres connection "master".
2021-11-18 08:48:05.238335 (MainThread): On master: BEGIN
2021-11-18 08:48:05.238494 (MainThread): Opening a new connection, currently in state init
2021-11-18 08:48:05.246454 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-18 08:48:05.246781 (MainThread): Using postgres connection "master".
2021-11-18 08:48:05.246992 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-18 08:48:05.251637 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-18 08:48:05.252928 (MainThread): On master: ROLLBACK
2021-11-18 08:48:05.253469 (MainThread): Using postgres connection "master".
2021-11-18 08:48:05.253615 (MainThread): On master: BEGIN
2021-11-18 08:48:05.254277 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-18 08:48:05.254441 (MainThread): On master: COMMIT
2021-11-18 08:48:05.254557 (MainThread): Using postgres connection "master".
2021-11-18 08:48:05.254659 (MainThread): On master: COMMIT
2021-11-18 08:48:05.255003 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-18 08:48:05.255147 (MainThread): On master: Close
2021-11-18 08:48:05.255502 (MainThread): 09:48:05 | Concurrency: 2 threads (target='dev')
2021-11-18 08:48:05.255684 (MainThread): 09:48:05 | 
2021-11-18 08:48:05.258488 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-18 08:48:05.259015 (Thread-1): 09:48:05 | 1 of 1 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-18 08:48:05.259506 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:48:05.259675 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-18 08:48:05.263302 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-18 08:48:05.263694 (Thread-1): finished collecting timing info
2021-11-18 08:48:05.310656 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-18 08:48:05.311107 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:48:05.311255 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-18 08:48:05.311410 (Thread-1): Opening a new connection, currently in state closed
2021-11-18 08:48:05.318406 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-18 08:48:05.318648 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:48:05.318780 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp"
  as (
    

select
     iss.AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,iss.ISIN                             as isin
    ,iss.IssuerName                       as issuer_name
    ,iss.ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,iss.ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,iss.ClimateScope2Emissions           as climate_scope2_emissions
    ,iss.ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,iss.ClimateScope3Emissions           as climate_scope3_emissions
    ,iss.ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,iss.ClimateTotalEmissions            as climate_total_emissions
    ,iss.ClimateScope1Emissions           as climate_scope1_emissions
    ,iss.MarketCapDaily                   as market_capdaily
    ,iss.ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,'2021-10-31'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-18 08:48:05.436076 (Thread-1): SQL status: SELECT 28444 in 0.12 seconds
2021-11-18 08:48:05.441262 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:48:05.441501 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */
alter table "demo_db"."sa_dwh"."iss_issuer" rename to "iss_issuer__dbt_backup"
2021-11-18 08:53:48.854209 (MainThread): Acquiring new postgres connection "master".
2021-11-18 08:53:48.854446 (MainThread): Cancelling query 'model.my_new_project.iss_issuer' (1938)
2021-11-18 08:53:48.854575 (MainThread): Using postgres connection "master".
2021-11-18 08:53:48.854675 (MainThread): On master: BEGIN
2021-11-18 08:53:48.854782 (MainThread): Opening a new connection, currently in state closed
2021-11-18 08:53:48.860705 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-18 08:53:48.860887 (MainThread): Using postgres connection "master".
2021-11-18 08:53:48.861006 (MainThread): On master: select pg_terminate_backend(1938)
2021-11-18 08:53:48.861494 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-18 08:53:48.861634 (MainThread): Cancel query 'model.my_new_project.iss_issuer': (True,)
2021-11-18 08:53:48.861805 (MainThread): 09:53:48 | CANCEL query model.my_new_project.iss_issuer......................... [CANCEL]
2021-11-18 08:53:48.861958 (MainThread): 09:53:48 | CANCEL query list_demo_db_sa_dwh..................................... [CANCEL]
2021-11-18 08:53:48.862126 (MainThread): On master: ROLLBACK
2021-11-18 08:53:48.862395 (MainThread): On master: Close
2021-11-18 08:53:48.864164 (Thread-1): Postgres error: terminating connection due to administrator command
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

2021-11-18 08:53:48.864342 (Thread-1): On model.my_new_project.iss_issuer: ROLLBACK
2021-11-18 08:53:48.864445 (Thread-1): Failed to rollback model.my_new_project.iss_issuer
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.OperationalError: terminating connection due to administrator command
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/connections.py", line 221, in _rollback_handle
    connection.handle.rollback()
psycopg2.InterfaceError: connection already closed
2021-11-18 08:53:48.864894 (Thread-1): Error running SQL: macro rename_relation
2021-11-18 08:53:48.865062 (Thread-1): Rolling back transaction.
2021-11-18 08:53:48.865279 (Thread-1): finished collecting timing info
2021-11-18 08:53:48.865562 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-18 08:53:48.866061 (Thread-1): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  terminating connection due to administrator command
  server closed the connection unexpectedly
  	This probably means the server terminated abnormally
  	before or while processing the request.
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.OperationalError: terminating connection due to administrator command
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 178, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/impl.py", line 165, in rename_relation
    self.execute_macro(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 1000, in execute_macro
    result = macro_function(**kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 37, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  terminating connection due to administrator command
  server closed the connection unexpectedly
  	This probably means the server terminated abnormally
  	before or while processing the request.
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-18 08:53:48.869733 (Thread-1): 09:53:48 | 1 of 1 ERROR creating incremental model sa_dwh.iss_issuer............ [ERROR in 343.61s]
2021-11-18 08:53:48.869954 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-18 08:53:48.870349 (MainThread): 
2021-11-18 08:53:48.870570 (MainThread): Exited because of keyboard interrupt.
2021-11-18 08:53:48.870752 (MainThread): 
Done. PASS=0 WARN=0 ERROR=0 SKIP=0 TOTAL=0
2021-11-18 08:53:48.870918 (MainThread): Connection 'master' was properly closed.
2021-11-18 08:53:48.871045 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-18 08:53:48.871143 (MainThread): Connection 'list_demo_db_sa_dwh' was properly closed.
2021-11-18 08:53:48.871273 (MainThread): Flushing usage events
2021-11-18 08:53:48.871420 (MainThread): ctrl-c
2021-11-18 08:55:14.488521 (MainThread): Running with dbt=0.21.0
2021-11-18 08:55:14.553109 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='var_date: 2021-10-31', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=True, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-18 08:55:14.553805 (MainThread): Tracking: do not track
2021-11-18 08:55:14.566508 (MainThread): Partial parsing not enabled
2021-11-18 08:55:14.574337 (MainThread): Parsing macros/adapters.sql
2021-11-18 08:55:14.594962 (MainThread): Parsing macros/catalog.sql
2021-11-18 08:55:14.596904 (MainThread): Parsing macros/relations.sql
2021-11-18 08:55:14.598102 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-18 08:55:14.599853 (MainThread): Parsing macros/core.sql
2021-11-18 08:55:14.603157 (MainThread): Parsing macros/adapters/common.sql
2021-11-18 08:55:14.652760 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-18 08:55:14.655060 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-18 08:55:14.656560 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-18 08:55:14.657896 (MainThread): Parsing macros/etc/datetime.sql
2021-11-18 08:55:14.664903 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-18 08:55:14.666354 (MainThread): Parsing macros/etc/query.sql
2021-11-18 08:55:14.667300 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-18 08:55:14.668983 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-18 08:55:14.677849 (MainThread): Parsing macros/materializations/test.sql
2021-11-18 08:55:14.683986 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-18 08:55:14.703863 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-18 08:55:14.705500 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-18 08:55:14.732143 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-18 08:55:14.747659 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-18 08:55:14.764047 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-18 08:55:14.773784 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-18 08:55:14.775408 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-18 08:55:14.787430 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-18 08:55:14.790964 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-18 08:55:14.797159 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-18 08:55:14.803844 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-18 08:55:14.805302 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-18 08:55:14.806445 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-18 08:55:14.807972 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-18 08:55:15.019026 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-18 08:55:15.031133 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-18 08:55:15.035327 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:55:15.039456 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:55:15.039765 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:55:15.076415 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:55:15.078380 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:55:15.080228 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:55:15.082233 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 08:55:15.100615 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-18 08:55:15.101064 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-18 08:55:15.102342 (MainThread): 
2021-11-18 08:55:15.102827 (MainThread): Acquiring new postgres connection "master".
2021-11-18 08:55:15.103737 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-18 08:55:15.112574 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-18 08:55:15.112829 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-18 08:55:15.112959 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-18 08:55:15.121269 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.01 seconds
2021-11-18 08:55:15.122643 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-18 08:55:15.123998 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-18 08:55:15.128760 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-18 08:55:15.128923 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-18 08:55:15.129057 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-18 08:55:15.129783 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-18 08:55:15.130845 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-18 08:55:15.131017 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-18 08:55:15.131199 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-18 08:55:15.137029 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-18 08:55:15.137397 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-18 08:55:15.137511 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-18 08:55:15.139099 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-18 08:55:15.139237 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-18 08:55:15.139336 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-18 08:55:15.139507 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-18 08:55:15.140627 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-18 08:55:15.140918 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-18 08:55:15.141336 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-18 08:55:15.142414 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-18 08:55:15.142713 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-18 08:55:15.146274 (MainThread): Using postgres connection "master".
2021-11-18 08:55:15.146457 (MainThread): On master: BEGIN
2021-11-18 08:55:15.146572 (MainThread): Opening a new connection, currently in state init
2021-11-18 08:55:15.154269 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-18 08:55:15.154519 (MainThread): Using postgres connection "master".
2021-11-18 08:55:15.154636 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-18 08:55:15.157308 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-18 08:55:15.158421 (MainThread): On master: ROLLBACK
2021-11-18 08:55:15.158746 (MainThread): Using postgres connection "master".
2021-11-18 08:55:15.158858 (MainThread): On master: BEGIN
2021-11-18 08:55:15.159340 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-18 08:55:15.159479 (MainThread): On master: COMMIT
2021-11-18 08:55:15.159585 (MainThread): Using postgres connection "master".
2021-11-18 08:55:15.159679 (MainThread): On master: COMMIT
2021-11-18 08:55:15.159970 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-18 08:55:15.160107 (MainThread): On master: Close
2021-11-18 08:55:15.160455 (MainThread): 09:55:15 | Concurrency: 2 threads (target='dev')
2021-11-18 08:55:15.160627 (MainThread): 09:55:15 | 
2021-11-18 08:55:15.163240 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-18 08:55:15.163621 (Thread-1): 09:55:15 | 1 of 1 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-18 08:55:15.163964 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:55:15.164106 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-18 08:55:15.168047 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-18 08:55:15.168892 (Thread-1): finished collecting timing info
2021-11-18 08:55:15.210574 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-18 08:55:15.210947 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:55:15.211074 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-18 08:55:15.211182 (Thread-1): Opening a new connection, currently in state closed
2021-11-18 08:55:15.219431 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-18 08:55:15.220059 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:55:15.220208 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp"
  as (
    

select
     iss.AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,iss.ISIN                             as isin
    ,iss.IssuerName                       as issuer_name
    ,iss.ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,iss.ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,iss.ClimateScope2Emissions           as climate_scope2_emissions
    ,iss.ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,iss.ClimateScope3Emissions           as climate_scope3_emissions
    ,iss.ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,iss.ClimateTotalEmissions            as climate_total_emissions
    ,iss.ClimateScope1Emissions           as climate_scope1_emissions
    ,iss.MarketCapDaily                   as market_capdaily
    ,iss.ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,'2021-10-31'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-18 08:55:15.344049 (Thread-1): SQL status: SELECT 28444 in 0.12 seconds
2021-11-18 08:55:15.349630 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:55:15.349926 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */
alter table "demo_db"."sa_dwh"."iss_issuer" rename to "iss_issuer__dbt_backup"
2021-11-18 08:57:08.792024 (Thread-1): SQL status: ALTER TABLE in 113.44 seconds
2021-11-18 08:57:08.794528 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:57:08.794705 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */
alter table "demo_db"."sa_dwh"."iss_issuer__dbt_tmp" rename to "iss_issuer"
2021-11-18 08:57:08.795297 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-11-18 08:57:08.807619 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-18 08:57:08.807838 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:57:08.807949 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-18 08:57:08.809525 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-11-18 08:57:08.814017 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 08:57:08.814254 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */
drop table if exists "demo_db"."sa_dwh"."iss_issuer__dbt_backup" cascade
2021-11-18 08:57:08.819115 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-11-18 08:57:08.820594 (Thread-1): finished collecting timing info
2021-11-18 08:57:08.820796 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-18 08:57:08.821581 (Thread-1): 09:57:08 | 1 of 1 OK created incremental model sa_dwh.iss_issuer................ [SELECT 28444 in 113.66s]
2021-11-18 08:57:08.821860 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-18 08:57:08.823863 (MainThread): Acquiring new postgres connection "master".
2021-11-18 08:57:08.824168 (MainThread): Using postgres connection "master".
2021-11-18 08:57:08.824343 (MainThread): On master: BEGIN
2021-11-18 08:57:08.824458 (MainThread): Opening a new connection, currently in state closed
2021-11-18 08:57:08.831504 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-18 08:57:08.831724 (MainThread): On master: COMMIT
2021-11-18 08:57:08.831828 (MainThread): Using postgres connection "master".
2021-11-18 08:57:08.831924 (MainThread): On master: COMMIT
2021-11-18 08:57:08.832330 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-18 08:57:08.832480 (MainThread): On master: Close
2021-11-18 08:57:08.832874 (MainThread): 09:57:08 | 
2021-11-18 08:57:08.833148 (MainThread): 09:57:08 | Finished running 1 incremental model in 113.73s.
2021-11-18 08:57:08.833346 (MainThread): Connection 'master' was properly closed.
2021-11-18 08:57:08.833536 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-18 08:57:08.833697 (MainThread): Connection 'list_demo_db_sa_dwh' was properly closed.
2021-11-18 08:57:08.839055 (MainThread): 
2021-11-18 08:57:08.839327 (MainThread): Completed successfully
2021-11-18 08:57:08.839530 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-11-18 08:57:08.839795 (MainThread): Flushing usage events
2021-11-18 10:22:51.961533 (MainThread): Running with dbt=0.21.0
2021-11-18 10:22:52.024983 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='var_date: 2021-10-31', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-18 10:22:52.025491 (MainThread): Tracking: do not track
2021-11-18 10:22:52.038862 (MainThread): Partial parsing not enabled
2021-11-18 10:22:52.045829 (MainThread): Parsing macros/adapters.sql
2021-11-18 10:22:52.066559 (MainThread): Parsing macros/catalog.sql
2021-11-18 10:22:52.069020 (MainThread): Parsing macros/relations.sql
2021-11-18 10:22:52.070277 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-18 10:22:52.071760 (MainThread): Parsing macros/core.sql
2021-11-18 10:22:52.074912 (MainThread): Parsing macros/adapters/common.sql
2021-11-18 10:22:52.121258 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-18 10:22:52.123577 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-18 10:22:52.125219 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-18 10:22:52.126590 (MainThread): Parsing macros/etc/datetime.sql
2021-11-18 10:22:52.134090 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-18 10:22:52.135542 (MainThread): Parsing macros/etc/query.sql
2021-11-18 10:22:52.136445 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-18 10:22:52.137838 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-18 10:22:52.146173 (MainThread): Parsing macros/materializations/test.sql
2021-11-18 10:22:52.152171 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-18 10:22:52.172426 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-18 10:22:52.174031 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-18 10:22:52.201105 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-18 10:22:52.216651 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-18 10:22:52.233480 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-18 10:22:52.242680 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-18 10:22:52.244335 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-18 10:22:52.256357 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-18 10:22:52.259835 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-18 10:22:52.265968 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-18 10:22:52.272400 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-18 10:22:52.273714 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-18 10:22:52.274817 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-18 10:22:52.276258 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-18 10:22:52.459678 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-18 10:22:52.471337 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-18 10:22:52.475036 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-18 10:22:52.477875 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 10:22:52.478840 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-18 10:22:52.482164 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 10:22:52.482416 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 10:22:52.515258 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 10:22:52.517028 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 10:22:52.519079 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 10:22:52.520904 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 10:22:52.537517 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-18 10:22:52.537913 (MainThread): Found 4 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-18 10:22:52.539276 (MainThread): 
2021-11-18 10:22:52.539739 (MainThread): Acquiring new postgres connection "master".
2021-11-18 10:22:52.540589 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-18 10:22:52.546296 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-18 10:22:52.549282 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-18 10:22:52.550465 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-18 10:22:52.550896 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-18 10:22:52.551221 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-18 10:22:52.551502 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-18 10:22:52.551711 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-18 10:22:52.559732 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.01 seconds
2021-11-18 10:22:52.560023 (ThreadPoolExecutor-0_1): SQL status: SELECT 12 in 0.01 seconds
2021-11-18 10:22:52.561441 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-18 10:22:52.562521 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-18 10:22:52.564419 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-18 10:22:52.569626 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-18 10:22:52.570086 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-18 10:22:52.570339 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-18 10:22:52.571881 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-18 10:22:52.572178 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-18 10:22:52.572454 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-18 10:22:52.572727 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-18 10:22:52.579571 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-18 10:22:52.579794 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-18 10:22:52.579972 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-18 10:22:52.580151 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-18 10:22:52.580323 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-18 10:22:52.580488 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-18 10:22:52.582528 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-18 10:22:52.582756 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-18 10:22:52.583809 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-18 10:22:52.584730 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-18 10:22:52.585138 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-18 10:22:52.585304 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-18 10:22:52.589532 (MainThread): Using postgres connection "master".
2021-11-18 10:22:52.589691 (MainThread): On master: BEGIN
2021-11-18 10:22:52.589799 (MainThread): Opening a new connection, currently in state init
2021-11-18 10:22:52.596053 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-18 10:22:52.596256 (MainThread): Using postgres connection "master".
2021-11-18 10:22:52.596358 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-18 10:22:52.598880 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-18 10:22:52.599833 (MainThread): On master: ROLLBACK
2021-11-18 10:22:52.600203 (MainThread): Using postgres connection "master".
2021-11-18 10:22:52.600316 (MainThread): On master: BEGIN
2021-11-18 10:22:52.600919 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-18 10:22:52.601190 (MainThread): On master: COMMIT
2021-11-18 10:22:52.601412 (MainThread): Using postgres connection "master".
2021-11-18 10:22:52.601599 (MainThread): On master: COMMIT
2021-11-18 10:22:52.602111 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-18 10:22:52.602261 (MainThread): On master: Close
2021-11-18 10:22:52.602656 (MainThread): 11:22:52 | Concurrency: 2 threads (target='dev')
2021-11-18 10:22:52.602850 (MainThread): 11:22:52 | 
2021-11-18 10:22:52.604904 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-18 10:22:52.605234 (Thread-1): 11:22:52 | 1 of 2 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-18 10:22:52.605553 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-18 10:22:52.605697 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-18 10:22:52.608683 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-18 10:22:52.609010 (Thread-1): finished collecting timing info
2021-11-18 10:22:52.653097 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 10:22:52.653303 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

    

  create temporary table "iss_issuer__dbt_tmp112252635043"
  as (
    

select
     iss.AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,iss.ISIN                             as isin
    ,iss.IssuerName                       as issuer_name
    ,iss.ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,iss.ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,iss.ClimateScope2Emissions           as climate_scope2_emissions
    ,iss.ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,iss.ClimateScope3Emissions           as climate_scope3_emissions
    ,iss.ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,iss.ClimateTotalEmissions            as climate_total_emissions
    ,iss.ClimateScope1Emissions           as climate_scope1_emissions
    ,iss.MarketCapDaily                   as market_capdaily
    ,iss.ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,'2021-10-31'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-18 10:22:52.653441 (Thread-1): Opening a new connection, currently in state closed
2021-11-18 10:22:52.770337 (Thread-1): SQL status: SELECT 28444 in 0.12 seconds
2021-11-18 10:22:52.776743 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 10:22:52.776928 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-18 10:22:52.777566 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-11-18 10:22:52.777724 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 10:22:52.777819 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer__dbt_tmp112252635043'
        
      order by ordinal_position

  
2021-11-18 10:22:52.783339 (Thread-1): SQL status: SELECT 16 in 0.01 seconds
2021-11-18 10:22:52.788055 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 10:22:52.788231 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-18 10:22:52.791036 (Thread-1): SQL status: SELECT 16 in 0.00 seconds
2021-11-18 10:22:52.801188 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 10:22:52.801548 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-18 10:22:52.804676 (Thread-1): SQL status: SELECT 16 in 0.00 seconds
2021-11-18 10:22:52.806503 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-18 10:22:52.806823 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 10:22:52.806933 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      delete
    from "demo_db"."sa_dwh"."iss_issuer"
    where (ISIN) in (
        select (ISIN)
        from "iss_issuer__dbt_tmp112252635043"
    );

    insert into "demo_db"."sa_dwh"."iss_issuer" ("adjusted_enterprise_value", "isin", "issuer_name", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_capdaily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp")
    (
       select "adjusted_enterprise_value", "isin", "issuer_name", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_capdaily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp"
       from "iss_issuer__dbt_tmp112252635043"
    );
  
2021-11-18 10:22:52.883011 (Thread-1): SQL status: INSERT 0 28444 in 0.08 seconds
2021-11-18 10:22:52.888787 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-18 10:22:52.889014 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 10:22:52.889132 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-18 10:22:52.896816 (Thread-1): SQL status: COMMIT in 0.01 seconds
2021-11-18 10:22:52.897448 (Thread-1): finished collecting timing info
2021-11-18 10:22:52.897631 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-18 10:22:52.898150 (Thread-1): 11:22:52 | 1 of 2 OK created incremental model sa_dwh.iss_issuer................ [INSERT 0 28444 in 0.29s]
2021-11-18 10:22:52.898361 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-18 10:22:52.899170 (Thread-2): Began running node model.my_new_project.dim_issuer
2021-11-18 10:22:52.899500 (Thread-2): 11:22:52 | 2 of 2 START table model sa.dim_issuer............................... [RUN]
2021-11-18 10:22:52.899841 (Thread-2): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-18 10:22:52.899980 (Thread-2): Compiling model.my_new_project.dim_issuer
2021-11-18 10:22:52.902878 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_issuer"
2021-11-18 10:22:52.903333 (Thread-2): finished collecting timing info
2021-11-18 10:22:52.915514 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_issuer"
2021-11-18 10:22:52.915947 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-18 10:22:52.916059 (Thread-2): On model.my_new_project.dim_issuer: BEGIN
2021-11-18 10:22:52.916165 (Thread-2): Opening a new connection, currently in state closed
2021-11-18 10:22:52.923935 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-18 10:22:52.924174 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-18 10:22:52.924301 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */


  create  table "demo_db"."sa"."dim_issuer__dbt_tmp"
  as (
    

select distinct
     md5(iss.isin)     as dim_issuer_key
    ,iss.isin          as isin
    ,iss.issuer_name   as issuer_name
from "demo_db"."sa_dwh"."iss_issuer" iss
  );
2021-11-18 10:22:53.002367 (Thread-2): SQL status: SELECT 28444 in 0.08 seconds
2021-11-18 10:22:53.007344 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-18 10:22:53.007512 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa"."dim_issuer__dbt_tmp" rename to "dim_issuer"
2021-11-18 10:22:53.008228 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-18 10:22:53.012251 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-18 10:22:53.012374 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-18 10:22:53.012480 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-18 10:22:53.019152 (Thread-2): SQL status: COMMIT in 0.01 seconds
2021-11-18 10:22:53.023520 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-18 10:22:53.023713 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
drop table if exists "demo_db"."sa"."dim_issuer__dbt_backup" cascade
2021-11-18 10:22:53.024251 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-11-18 10:22:53.025271 (Thread-2): finished collecting timing info
2021-11-18 10:22:53.025417 (Thread-2): On model.my_new_project.dim_issuer: Close
2021-11-18 10:22:53.025862 (Thread-2): 11:22:53 | 2 of 2 OK created table model sa.dim_issuer.......................... [SELECT 28444 in 0.13s]
2021-11-18 10:22:53.026061 (Thread-2): Finished running node model.my_new_project.dim_issuer
2021-11-18 10:22:53.027590 (MainThread): Acquiring new postgres connection "master".
2021-11-18 10:22:53.027858 (MainThread): Using postgres connection "master".
2021-11-18 10:22:53.027970 (MainThread): On master: BEGIN
2021-11-18 10:22:53.028102 (MainThread): Opening a new connection, currently in state closed
2021-11-18 10:22:53.034107 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-18 10:22:53.034346 (MainThread): On master: COMMIT
2021-11-18 10:22:53.034469 (MainThread): Using postgres connection "master".
2021-11-18 10:22:53.034568 (MainThread): On master: COMMIT
2021-11-18 10:22:53.034887 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-18 10:22:53.035056 (MainThread): On master: Close
2021-11-18 10:22:53.035444 (MainThread): 11:22:53 | 
2021-11-18 10:22:53.035630 (MainThread): 11:22:53 | Finished running 1 incremental model, 1 table model in 0.50s.
2021-11-18 10:22:53.035784 (MainThread): Connection 'master' was properly closed.
2021-11-18 10:22:53.035886 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-18 10:22:53.035975 (MainThread): Connection 'model.my_new_project.dim_issuer' was properly closed.
2021-11-18 10:22:53.039542 (MainThread): 
2021-11-18 10:22:53.039745 (MainThread): Completed successfully
2021-11-18 10:22:53.039900 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-11-18 10:22:53.040127 (MainThread): Flushing usage events
2021-11-18 10:44:54.183799 (MainThread): Running with dbt=0.21.0
2021-11-18 10:44:54.250446 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='var_date: 2021-10-31', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-18 10:44:54.250942 (MainThread): Tracking: do not track
2021-11-18 10:44:54.262519 (MainThread): Partial parsing not enabled
2021-11-18 10:44:54.270523 (MainThread): Parsing macros/adapters.sql
2021-11-18 10:44:54.297848 (MainThread): Parsing macros/catalog.sql
2021-11-18 10:44:54.300253 (MainThread): Parsing macros/relations.sql
2021-11-18 10:44:54.301608 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-18 10:44:54.303342 (MainThread): Parsing macros/core.sql
2021-11-18 10:44:54.307255 (MainThread): Parsing macros/adapters/common.sql
2021-11-18 10:44:54.362741 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-18 10:44:54.365322 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-18 10:44:54.367169 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-18 10:44:54.368842 (MainThread): Parsing macros/etc/datetime.sql
2021-11-18 10:44:54.377670 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-18 10:44:54.379602 (MainThread): Parsing macros/etc/query.sql
2021-11-18 10:44:54.380658 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-18 10:44:54.382123 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-18 10:44:54.392221 (MainThread): Parsing macros/materializations/test.sql
2021-11-18 10:44:54.399343 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-18 10:44:54.419533 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-18 10:44:54.420994 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-18 10:44:54.451636 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-18 10:44:54.468817 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-18 10:44:54.487200 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-18 10:44:54.498063 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-18 10:44:54.500541 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-18 10:44:54.514017 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-18 10:44:54.518546 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-18 10:44:54.525115 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-18 10:44:54.532368 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-18 10:44:54.533944 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-18 10:44:54.535181 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-18 10:44:54.536913 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-18 10:44:54.747347 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-18 10:44:54.760995 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-18 10:44:54.764959 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-18 10:44:54.768668 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 10:44:54.769033 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 10:44:54.770084 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-18 10:44:54.773968 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 10:44:54.774245 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 10:44:54.808152 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 10:44:54.810126 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 10:44:54.812095 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 10:44:54.813970 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-18 10:44:54.822788 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.dm_emissions

2021-11-18 10:44:54.832396 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-18 10:44:54.832798 (MainThread): Found 4 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-18 10:44:54.834002 (MainThread): 
2021-11-18 10:44:54.834428 (MainThread): Acquiring new postgres connection "master".
2021-11-18 10:44:54.835394 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-18 10:44:54.835873 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-18 10:44:54.846460 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-18 10:44:54.846885 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-18 10:44:54.847052 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-18 10:44:54.847270 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-18 10:44:54.847490 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-18 10:44:54.847737 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-18 10:44:54.854882 (ThreadPoolExecutor-0_1): SQL status: SELECT 14 in 0.01 seconds
2021-11-18 10:44:54.855157 (ThreadPoolExecutor-0_0): SQL status: SELECT 14 in 0.01 seconds
2021-11-18 10:44:54.856372 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-18 10:44:54.857386 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-18 10:44:54.858537 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "create_demo_db_sa_dm".
2021-11-18 10:44:54.858857 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "create_demo_db_sa_dm".
2021-11-18 10:44:54.859028 (ThreadPoolExecutor-0_1): Creating schema ""demo_db"."sa_dm""
2021-11-18 10:44:54.864452 (ThreadPoolExecutor-0_1): Using postgres connection "create_demo_db_sa_dm".
2021-11-18 10:44:54.864643 (ThreadPoolExecutor-0_1): On create_demo_db_sa_dm: BEGIN
2021-11-18 10:44:54.864752 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state closed
2021-11-18 10:44:54.871617 (ThreadPoolExecutor-0_1): SQL status: BEGIN in 0.01 seconds
2021-11-18 10:44:54.871937 (ThreadPoolExecutor-0_1): Using postgres connection "create_demo_db_sa_dm".
2021-11-18 10:44:54.872045 (ThreadPoolExecutor-0_1): On create_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "create_demo_db_sa_dm"} */
create schema if not exists "sa_dm"
2021-11-18 10:44:54.872586 (ThreadPoolExecutor-0_1): SQL status: CREATE SCHEMA in 0.00 seconds
2021-11-18 10:44:54.875008 (ThreadPoolExecutor-0_1): On create_demo_db_sa_dm: COMMIT
2021-11-18 10:44:54.875133 (ThreadPoolExecutor-0_1): Using postgres connection "create_demo_db_sa_dm".
2021-11-18 10:44:54.875231 (ThreadPoolExecutor-0_1): On create_demo_db_sa_dm: COMMIT
2021-11-18 10:44:54.877895 (ThreadPoolExecutor-0_1): SQL status: COMMIT in 0.00 seconds
2021-11-18 10:44:54.878242 (ThreadPoolExecutor-0_1): On create_demo_db_sa_dm: Close
2021-11-18 10:44:54.880056 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-18 10:44:54.880516 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-18 10:44:54.885099 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-18 10:44:54.886280 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-18 10:44:54.886480 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-18 10:44:54.886719 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-18 10:44:54.886976 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-18 10:44:54.887303 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-18 10:44:54.894914 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-18 10:44:54.895304 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-18 10:44:54.895583 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-18 10:44:54.895798 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-18 10:44:54.896021 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-18 10:44:54.896223 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-18 10:44:54.898489 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2021-11-18 10:44:54.898703 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-18 10:44:54.899802 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-18 10:44:54.900703 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-18 10:44:54.901241 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-18 10:44:54.901418 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-18 10:44:54.901885 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-18 10:44:54.903803 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-18 10:44:54.904116 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: BEGIN
2021-11-18 10:44:54.904242 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-18 10:44:54.910278 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-18 10:44:54.910512 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-18 10:44:54.910624 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-18 10:44:54.912616 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.00 seconds
2021-11-18 10:44:54.913678 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: ROLLBACK
2021-11-18 10:44:54.914105 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: Close
2021-11-18 10:44:54.917688 (MainThread): Using postgres connection "master".
2021-11-18 10:44:54.917858 (MainThread): On master: BEGIN
2021-11-18 10:44:54.917975 (MainThread): Opening a new connection, currently in state init
2021-11-18 10:44:54.923999 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-18 10:44:54.924184 (MainThread): Using postgres connection "master".
2021-11-18 10:44:54.924287 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-18 10:44:54.927343 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-18 10:44:54.928476 (MainThread): On master: ROLLBACK
2021-11-18 10:44:54.928964 (MainThread): Using postgres connection "master".
2021-11-18 10:44:54.929111 (MainThread): On master: BEGIN
2021-11-18 10:44:54.929662 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-18 10:44:54.929831 (MainThread): On master: COMMIT
2021-11-18 10:44:54.929935 (MainThread): Using postgres connection "master".
2021-11-18 10:44:54.930030 (MainThread): On master: COMMIT
2021-11-18 10:44:54.930329 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-18 10:44:54.930453 (MainThread): On master: Close
2021-11-18 10:44:54.930761 (MainThread): 11:44:54 | Concurrency: 2 threads (target='dev')
2021-11-18 10:44:54.930958 (MainThread): 11:44:54 | 
2021-11-18 10:44:54.932744 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-18 10:44:54.933093 (Thread-1): 11:44:54 | 1 of 2 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-18 10:44:54.933401 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-18 10:44:54.933542 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-18 10:44:54.936741 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-18 10:44:54.937042 (Thread-1): finished collecting timing info
2021-11-18 10:44:54.983824 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 10:44:54.984048 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

    

  create temporary table "iss_issuer__dbt_tmp114454965321"
  as (
    

select
     iss.AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,iss.ISIN                             as isin
    ,iss.IssuerName                       as issuer_name
    ,iss.ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,iss.ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,iss.ClimateScope2Emissions           as climate_scope2_emissions
    ,iss.ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,iss.ClimateScope3Emissions           as climate_scope3_emissions
    ,iss.ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,iss.ClimateTotalEmissions            as climate_total_emissions
    ,iss.ClimateScope1Emissions           as climate_scope1_emissions
    ,iss.MarketCapDaily                   as market_capdaily
    ,iss.ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,'2021-10-31'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-18 10:44:54.984203 (Thread-1): Opening a new connection, currently in state closed
2021-11-18 10:44:55.097203 (Thread-1): SQL status: SELECT 28444 in 0.11 seconds
2021-11-18 10:44:55.103521 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 10:44:55.103713 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-18 10:44:55.104264 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-11-18 10:44:55.104423 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 10:44:55.104522 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer__dbt_tmp114454965321'
        
      order by ordinal_position

  
2021-11-18 10:44:55.110431 (Thread-1): SQL status: SELECT 16 in 0.01 seconds
2021-11-18 10:44:55.115617 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 10:44:55.115803 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-18 10:44:55.118747 (Thread-1): SQL status: SELECT 16 in 0.00 seconds
2021-11-18 10:44:55.127953 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 10:44:55.128163 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-18 10:44:55.131148 (Thread-1): SQL status: SELECT 16 in 0.00 seconds
2021-11-18 10:44:55.132975 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-18 10:44:55.133368 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 10:44:55.133510 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      delete
    from "demo_db"."sa_dwh"."iss_issuer"
    where (ISIN) in (
        select (ISIN)
        from "iss_issuer__dbt_tmp114454965321"
    );

    insert into "demo_db"."sa_dwh"."iss_issuer" ("adjusted_enterprise_value", "isin", "issuer_name", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_capdaily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp")
    (
       select "adjusted_enterprise_value", "isin", "issuer_name", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_capdaily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp"
       from "iss_issuer__dbt_tmp114454965321"
    );
  
2021-11-18 10:44:55.204956 (Thread-1): SQL status: INSERT 0 28444 in 0.07 seconds
2021-11-18 10:44:55.211276 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-18 10:44:55.211522 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-18 10:44:55.211626 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-18 10:44:55.218963 (Thread-1): SQL status: COMMIT in 0.01 seconds
2021-11-18 10:44:55.219545 (Thread-1): finished collecting timing info
2021-11-18 10:44:55.219726 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-18 10:44:55.220172 (Thread-1): 11:44:55 | 1 of 2 OK created incremental model sa_dwh.iss_issuer................ [INSERT 0 28444 in 0.29s]
2021-11-18 10:44:55.220344 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-18 10:44:55.221127 (Thread-2): Began running node model.my_new_project.dim_issuer
2021-11-18 10:44:55.221381 (Thread-2): 11:44:55 | 2 of 2 START table model sa_dm.dim_issuer............................ [RUN]
2021-11-18 10:44:55.221696 (Thread-2): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-18 10:44:55.221823 (Thread-2): Compiling model.my_new_project.dim_issuer
2021-11-18 10:44:55.224375 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_issuer"
2021-11-18 10:44:55.224695 (Thread-2): finished collecting timing info
2021-11-18 10:44:55.237094 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_issuer"
2021-11-18 10:44:55.237524 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-18 10:44:55.237689 (Thread-2): On model.my_new_project.dim_issuer: BEGIN
2021-11-18 10:44:55.237822 (Thread-2): Opening a new connection, currently in state closed
2021-11-18 10:44:55.245289 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-18 10:44:55.245548 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-18 10:44:55.245679 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */


  create  table "demo_db"."sa_dm"."dim_issuer__dbt_tmp"
  as (
    

select distinct
     md5(iss.isin)     as dim_issuer_key
    ,iss.isin          as isin
    ,iss.issuer_name   as issuer_name
from "demo_db"."sa_dwh"."iss_issuer" iss
  );
2021-11-18 10:44:55.299657 (Thread-2): SQL status: SELECT 28444 in 0.05 seconds
2021-11-18 10:44:55.304926 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-18 10:44:55.305107 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer__dbt_tmp" rename to "dim_issuer"
2021-11-18 10:44:55.305794 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-18 10:44:55.310001 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-18 10:44:55.310212 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-18 10:44:55.310314 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-18 10:44:55.316717 (Thread-2): SQL status: COMMIT in 0.01 seconds
2021-11-18 10:44:55.321218 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-18 10:44:55.321402 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
drop table if exists "demo_db"."sa_dm"."dim_issuer__dbt_backup" cascade
2021-11-18 10:44:55.321898 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-11-18 10:44:55.322807 (Thread-2): finished collecting timing info
2021-11-18 10:44:55.322973 (Thread-2): On model.my_new_project.dim_issuer: Close
2021-11-18 10:44:55.323390 (Thread-2): 11:44:55 | 2 of 2 OK created table model sa_dm.dim_issuer....................... [SELECT 28444 in 0.10s]
2021-11-18 10:44:55.323558 (Thread-2): Finished running node model.my_new_project.dim_issuer
2021-11-18 10:44:55.325096 (MainThread): Acquiring new postgres connection "master".
2021-11-18 10:44:55.325360 (MainThread): Using postgres connection "master".
2021-11-18 10:44:55.325485 (MainThread): On master: BEGIN
2021-11-18 10:44:55.325601 (MainThread): Opening a new connection, currently in state closed
2021-11-18 10:44:55.332663 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-18 10:44:55.332919 (MainThread): On master: COMMIT
2021-11-18 10:44:55.333049 (MainThread): Using postgres connection "master".
2021-11-18 10:44:55.333186 (MainThread): On master: COMMIT
2021-11-18 10:44:55.333468 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-18 10:44:55.333595 (MainThread): On master: Close
2021-11-18 10:44:55.333956 (MainThread): 11:44:55 | 
2021-11-18 10:44:55.334154 (MainThread): 11:44:55 | Finished running 1 incremental model, 1 table model in 0.50s.
2021-11-18 10:44:55.334372 (MainThread): Connection 'master' was properly closed.
2021-11-18 10:44:55.334477 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-18 10:44:55.334678 (MainThread): Connection 'model.my_new_project.dim_issuer' was properly closed.
2021-11-18 10:44:55.338609 (MainThread): 
2021-11-18 10:44:55.338817 (MainThread): Completed successfully
2021-11-18 10:44:55.339042 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-11-18 10:44:55.339320 (MainThread): Flushing usage events
2021-11-19 13:03:21.179149 (MainThread): Running with dbt=0.21.0
2021-11-19 13:03:21.242595 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, parse_only=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, full_refresh=False, defer=None, cls=<class 'dbt.task.compile.CompileTask'>, which='compile', rpc_method='compile')
2021-11-19 13:03:21.246052 (MainThread): Tracking: do not track
2021-11-19 13:03:21.259431 (MainThread): Partial parsing not enabled
2021-11-19 13:03:21.278000 (MainThread): Parsing macros/adapters.sql
2021-11-19 13:03:21.297430 (MainThread): Parsing macros/catalog.sql
2021-11-19 13:03:21.299208 (MainThread): Parsing macros/relations.sql
2021-11-19 13:03:21.300277 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 13:03:21.301719 (MainThread): Parsing macros/core.sql
2021-11-19 13:03:21.304826 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 13:03:21.349348 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 13:03:21.351434 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 13:03:21.352911 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 13:03:21.354202 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 13:03:21.361447 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 13:03:21.363624 (MainThread): Parsing macros/etc/query.sql
2021-11-19 13:03:21.364707 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 13:03:21.365980 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 13:03:21.374170 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 13:03:21.379871 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 13:03:21.399116 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 13:03:21.400598 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 13:03:21.426063 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 13:03:21.440651 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 13:03:21.456859 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 13:03:21.465619 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 13:03:21.467105 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 13:03:21.479813 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 13:03:21.483192 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 13:03:21.489162 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 13:03:21.495242 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 13:03:21.496516 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 13:03:21.497531 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 13:03:21.498901 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 13:03:21.673440 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 13:03:21.685822 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 13:03:21.688792 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 13:03:21.692461 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:03:21.692757 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:03:21.693717 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:03:21.696843 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:03:21.697054 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:03:21.726420 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:03:21.728243 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:03:21.729959 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:03:21.731587 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:03:21.739612 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.dm_emissions

2021-11-19 13:03:21.749219 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 13:03:21.749600 (MainThread): Found 4 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-19 13:03:21.751146 (MainThread): 
2021-11-19 13:03:21.751567 (MainThread): Acquiring new postgres connection "master".
2021-11-19 13:03:21.752462 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 13:03:21.762517 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db_sa".
2021-11-19 13:03:21.762774 (ThreadPoolExecutor-0_0): On list_demo_db_sa: BEGIN
2021-11-19 13:03:21.762916 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 13:03:21.763553 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 13:03:21.765519 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 13:03:21.765742 (ThreadPoolExecutor-0_1): On list_demo_db_sa_dwh: BEGIN
2021-11-19 13:03:21.765976 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 13:03:21.771336 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:03:21.771533 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db_sa".
2021-11-19 13:03:21.771685 (ThreadPoolExecutor-0_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 13:03:21.773409 (ThreadPoolExecutor-0_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:03:21.773781 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 13:03:21.773940 (ThreadPoolExecutor-0_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 13:03:21.774811 (ThreadPoolExecutor-0_0): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 13:03:21.775993 (ThreadPoolExecutor-0_0): On list_demo_db_sa: ROLLBACK
2021-11-19 13:03:21.776249 (ThreadPoolExecutor-0_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 13:03:21.777422 (ThreadPoolExecutor-0_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 13:03:21.777596 (ThreadPoolExecutor-0_0): On list_demo_db_sa: Close
2021-11-19 13:03:21.778238 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 13:03:21.778422 (ThreadPoolExecutor-0_1): On list_demo_db_sa_dwh: Close
2021-11-19 13:03:21.780339 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 13:03:21.780724 (ThreadPoolExecutor-0_0): On list_demo_db_sa_dm: BEGIN
2021-11-19 13:03:21.781203 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-11-19 13:03:21.787261 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:03:21.787489 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 13:03:21.787619 (ThreadPoolExecutor-0_0): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 13:03:21.789648 (ThreadPoolExecutor-0_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 13:03:21.790755 (ThreadPoolExecutor-0_0): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 13:03:21.791163 (ThreadPoolExecutor-0_0): On list_demo_db_sa_dm: Close
2021-11-19 13:03:21.794832 (MainThread): Using postgres connection "master".
2021-11-19 13:03:21.795017 (MainThread): On master: BEGIN
2021-11-19 13:03:21.795145 (MainThread): Opening a new connection, currently in state init
2021-11-19 13:03:21.802026 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:03:21.802247 (MainThread): Using postgres connection "master".
2021-11-19 13:03:21.802368 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 13:03:21.812998 (MainThread): SQL status: SELECT 0 in 0.01 seconds
2021-11-19 13:03:21.814030 (MainThread): On master: ROLLBACK
2021-11-19 13:03:21.814478 (MainThread): On master: Close
2021-11-19 13:03:21.814916 (MainThread): 14:03:21 | Concurrency: 2 threads (target='dev')
2021-11-19 13:03:21.815105 (MainThread): 14:03:21 | 
2021-11-19 13:03:21.817115 (Thread-1): Began running node model.my_new_project.my_first_dbt_model
2021-11-19 13:03:21.817310 (Thread-2): Began running node seed.my_new_project.sa_iss_issuer
2021-11-19 13:03:21.817622 (Thread-1): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 13:03:21.817904 (Thread-2): Acquiring new postgres connection "seed.my_new_project.sa_iss_issuer".
2021-11-19 13:03:21.818079 (Thread-1): Compiling model.my_new_project.my_first_dbt_model
2021-11-19 13:03:21.818232 (Thread-2): Compiling seed.my_new_project.sa_iss_issuer
2021-11-19 13:03:21.820069 (Thread-1): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 13:03:21.821050 (Thread-2): Writing injected SQL for node "seed.my_new_project.sa_iss_issuer"
2021-11-19 13:03:21.821349 (Thread-2): finished collecting timing info
2021-11-19 13:03:21.821614 (Thread-2): finished collecting timing info
2021-11-19 13:03:21.821967 (Thread-2): Finished running node seed.my_new_project.sa_iss_issuer
2021-11-19 13:03:21.822211 (Thread-1): finished collecting timing info
2021-11-19 13:03:21.822551 (Thread-1): finished collecting timing info
2021-11-19 13:03:21.822908 (Thread-1): Finished running node model.my_new_project.my_first_dbt_model
2021-11-19 13:03:21.823811 (Thread-2): Began running node model.my_new_project.iss_issuer
2021-11-19 13:03:21.824189 (Thread-1): Began running node model.my_new_project.my_second_dbt_model
2021-11-19 13:03:21.824555 (Thread-2): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:03:21.824843 (Thread-1): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 13:03:21.825023 (Thread-2): Compiling model.my_new_project.iss_issuer
2021-11-19 13:03:21.825184 (Thread-1): Compiling model.my_new_project.my_second_dbt_model
2021-11-19 13:03:21.828316 (Thread-2): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-19 13:03:21.830375 (Thread-1): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-19 13:03:21.831223 (Thread-2): finished collecting timing info
2021-11-19 13:03:21.831580 (Thread-2): finished collecting timing info
2021-11-19 13:03:21.832203 (Thread-2): Finished running node model.my_new_project.iss_issuer
2021-11-19 13:03:21.832470 (Thread-1): finished collecting timing info
2021-11-19 13:03:21.832724 (Thread-2): Began running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2021-11-19 13:03:21.833203 (Thread-1): finished collecting timing info
2021-11-19 13:03:21.833617 (Thread-2): Acquiring new postgres connection "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710".
2021-11-19 13:03:21.833958 (Thread-1): Finished running node model.my_new_project.my_second_dbt_model
2021-11-19 13:03:21.834222 (Thread-2): Compiling test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2021-11-19 13:03:21.834519 (Thread-1): Began running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2021-11-19 13:03:21.844320 (Thread-2): Writing injected SQL for node "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"
2021-11-19 13:03:21.844821 (Thread-1): Acquiring new postgres connection "test.my_new_project.unique_my_first_dbt_model_id.16e066b321".
2021-11-19 13:03:21.845209 (Thread-1): Compiling test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2021-11-19 13:03:21.851341 (Thread-1): Writing injected SQL for node "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"
2021-11-19 13:03:21.851669 (Thread-2): finished collecting timing info
2021-11-19 13:03:21.851955 (Thread-2): finished collecting timing info
2021-11-19 13:03:21.852386 (Thread-2): Finished running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2021-11-19 13:03:21.852748 (Thread-2): Began running node model.my_new_project.dim_issuer
2021-11-19 13:03:21.853159 (Thread-1): finished collecting timing info
2021-11-19 13:03:21.853679 (Thread-2): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 13:03:21.854143 (Thread-1): finished collecting timing info
2021-11-19 13:03:21.854404 (Thread-2): Compiling model.my_new_project.dim_issuer
2021-11-19 13:03:21.854858 (Thread-1): Finished running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2021-11-19 13:03:21.857768 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_issuer"
2021-11-19 13:03:21.858122 (Thread-1): Began running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2021-11-19 13:03:21.858579 (Thread-2): finished collecting timing info
2021-11-19 13:03:21.858992 (Thread-1): Acquiring new postgres connection "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778".
2021-11-19 13:03:21.859183 (Thread-2): finished collecting timing info
2021-11-19 13:03:21.859399 (Thread-1): Compiling test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2021-11-19 13:03:21.859874 (Thread-2): Finished running node model.my_new_project.dim_issuer
2021-11-19 13:03:21.863473 (Thread-1): Writing injected SQL for node "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"
2021-11-19 13:03:21.863768 (Thread-2): Began running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2021-11-19 13:03:21.864392 (Thread-2): Acquiring new postgres connection "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493".
2021-11-19 13:03:21.864548 (Thread-2): Compiling test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2021-11-19 13:03:21.868432 (Thread-2): Writing injected SQL for node "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"
2021-11-19 13:03:21.868964 (Thread-1): finished collecting timing info
2021-11-19 13:03:21.869266 (Thread-2): finished collecting timing info
2021-11-19 13:03:21.869605 (Thread-1): finished collecting timing info
2021-11-19 13:03:21.869902 (Thread-2): finished collecting timing info
2021-11-19 13:03:21.870352 (Thread-1): Finished running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2021-11-19 13:03:21.870701 (Thread-2): Finished running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2021-11-19 13:03:21.872124 (MainThread): Connection 'master' was properly closed.
2021-11-19 13:03:21.872242 (MainThread): Connection 'test.my_new_project.not_null_my_second_dbt_model_id.151b76d778' was properly closed.
2021-11-19 13:03:21.872333 (MainThread): Connection 'test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
2021-11-19 13:03:21.875760 (MainThread): 14:03:21 | Done.
2021-11-19 13:03:21.876109 (MainThread): Flushing usage events
2021-11-19 13:04:04.162283 (MainThread): Running with dbt=0.21.0
2021-11-19 13:04:04.228269 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 13:04:04.228775 (MainThread): Tracking: do not track
2021-11-19 13:04:04.239939 (MainThread): Partial parsing not enabled
2021-11-19 13:04:04.247142 (MainThread): Parsing macros/adapters.sql
2021-11-19 13:04:04.267418 (MainThread): Parsing macros/catalog.sql
2021-11-19 13:04:04.269338 (MainThread): Parsing macros/relations.sql
2021-11-19 13:04:04.270417 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 13:04:04.271896 (MainThread): Parsing macros/core.sql
2021-11-19 13:04:04.275225 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 13:04:04.320345 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 13:04:04.322520 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 13:04:04.324085 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 13:04:04.325467 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 13:04:04.332566 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 13:04:04.333848 (MainThread): Parsing macros/etc/query.sql
2021-11-19 13:04:04.334679 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 13:04:04.336074 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 13:04:04.344463 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 13:04:04.350347 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 13:04:04.370137 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 13:04:04.371758 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 13:04:04.396822 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 13:04:04.411233 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 13:04:04.427784 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 13:04:04.436663 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 13:04:04.438197 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 13:04:04.449625 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 13:04:04.452930 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 13:04:04.458820 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 13:04:04.464951 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 13:04:04.466235 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 13:04:04.467246 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 13:04:04.468681 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 13:04:04.647432 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 13:04:04.658132 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 13:04:04.661608 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 13:04:04.664502 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:04:04.664736 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:04:04.665611 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:04:04.669041 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:04:04.669351 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:04:04.702048 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:04:04.703794 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:04:04.705454 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:04:04.707643 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:04:04.716060 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.dm_emissions

2021-11-19 13:04:04.724112 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 13:04:04.724503 (MainThread): Found 4 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-19 13:04:04.726021 (MainThread): 
2021-11-19 13:04:04.726511 (MainThread): Acquiring new postgres connection "master".
2021-11-19 13:04:04.727492 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 13:04:04.728045 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 13:04:04.743216 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 13:04:04.743590 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 13:04:04.743841 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 13:04:04.746880 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 13:04:04.747078 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 13:04:04.747190 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 13:04:04.752683 (ThreadPoolExecutor-0_0): SQL status: SELECT 15 in 0.01 seconds
2021-11-19 13:04:04.754000 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 13:04:04.754800 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 13:04:04.756048 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 13:04:04.756340 (ThreadPoolExecutor-0_1): SQL status: SELECT 15 in 0.01 seconds
2021-11-19 13:04:04.756594 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 13:04:04.758003 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 13:04:04.758252 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-11-19 13:04:04.765892 (ThreadPoolExecutor-0_0): SQL status: SELECT 15 in 0.01 seconds
2021-11-19 13:04:04.766881 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 13:04:04.768407 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 13:04:04.773113 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 13:04:04.773518 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 13:04:04.773750 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: BEGIN
2021-11-19 13:04:04.775183 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 13:04:04.775553 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 13:04:04.775716 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-19 13:04:04.776057 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 13:04:04.782177 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:04:04.782535 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:04:04.782687 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 13:04:04.782880 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 13:04:04.783073 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 13:04:04.783219 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 13:04:04.785139 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 13:04:04.785367 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 13:04:04.786291 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 13:04:04.787121 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 13:04:04.787543 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: Close
2021-11-19 13:04:04.787679 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-19 13:04:04.788114 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 13:04:04.789525 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 13:04:04.789723 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-19 13:04:04.790005 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 13:04:04.797683 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:04:04.797888 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 13:04:04.797987 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 13:04:04.799936 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 13:04:04.800971 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-19 13:04:04.801337 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-19 13:04:04.805303 (MainThread): Using postgres connection "master".
2021-11-19 13:04:04.805564 (MainThread): On master: BEGIN
2021-11-19 13:04:04.805671 (MainThread): Opening a new connection, currently in state init
2021-11-19 13:04:04.811956 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:04:04.812139 (MainThread): Using postgres connection "master".
2021-11-19 13:04:04.812242 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 13:04:04.815825 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 13:04:04.816805 (MainThread): On master: ROLLBACK
2021-11-19 13:04:04.817088 (MainThread): Using postgres connection "master".
2021-11-19 13:04:04.817192 (MainThread): On master: BEGIN
2021-11-19 13:04:04.817621 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 13:04:04.817753 (MainThread): On master: COMMIT
2021-11-19 13:04:04.817856 (MainThread): Using postgres connection "master".
2021-11-19 13:04:04.817948 (MainThread): On master: COMMIT
2021-11-19 13:04:04.818201 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 13:04:04.818327 (MainThread): On master: Close
2021-11-19 13:04:04.818634 (MainThread): 14:04:04 | Concurrency: 2 threads (target='dev')
2021-11-19 13:04:04.818811 (MainThread): 14:04:04 | 
2021-11-19 13:04:04.820473 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-19 13:04:04.820657 (Thread-2): Began running node model.my_new_project.my_first_dbt_model
2021-11-19 13:04:04.820918 (Thread-1): 14:04:04 | 1 of 4 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-19 13:04:04.821147 (Thread-2): 14:04:04 | 2 of 4 START table model sa.my_first_dbt_model....................... [RUN]
2021-11-19 13:04:04.821672 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:04:04.821952 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-19 13:04:04.822230 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 13:04:04.825183 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-19 13:04:04.825445 (Thread-2): Compiling model.my_new_project.my_first_dbt_model
2021-11-19 13:04:04.827340 (Thread-2): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 13:04:04.827725 (Thread-1): finished collecting timing info
2021-11-19 13:04:04.843548 (Thread-2): finished collecting timing info
2021-11-19 13:04:04.887883 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 13:04:04.888250 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:04:04.888391 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

    

  create temporary table "iss_issuer__dbt_tmp140404870474"
  as (
    

select
     iss.AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,iss.ISIN                             as isin
    ,iss.IssuerName                       as issuer_name
    ,iss.ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,iss.ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,iss.ClimateScope2Emissions           as climate_scope2_emissions
    ,iss.ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,iss.ClimateScope3Emissions           as climate_scope3_emissions
    ,iss.ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,iss.ClimateTotalEmissions            as climate_total_emissions
    ,iss.ClimateScope1Emissions           as climate_scope1_emissions
    ,iss.MarketCapDaily                   as market_capdaily
    ,iss.ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,'2021-01-01'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-19 13:04:04.888528 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 13:04:04.888895 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 13:04:04.889007 (Thread-2): On model.my_new_project.my_first_dbt_model: BEGIN
2021-11-19 13:04:04.889110 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 13:04:04.895606 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:04:04.895789 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 13:04:04.895906 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table "demo_db"."sa"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-11-19 13:04:04.902119 (Thread-2): SQL status: SELECT 2 in 0.01 seconds
2021-11-19 13:04:04.907061 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 13:04:04.907227 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "demo_db"."sa"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2021-11-19 13:04:04.907729 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 13:04:04.916278 (Thread-2): On model.my_new_project.my_first_dbt_model: COMMIT
2021-11-19 13:04:04.916475 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 13:04:04.916582 (Thread-2): On model.my_new_project.my_first_dbt_model: COMMIT
2021-11-19 13:04:04.918293 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-11-19 13:04:04.922462 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 13:04:04.922625 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "demo_db"."sa"."my_first_dbt_model__dbt_backup" cascade
2021-11-19 13:04:04.923057 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-11-19 13:04:04.924070 (Thread-2): finished collecting timing info
2021-11-19 13:04:04.924241 (Thread-2): On model.my_new_project.my_first_dbt_model: Close
2021-11-19 13:04:04.924749 (Thread-2): 14:04:04 | 2 of 4 OK created table model sa.my_first_dbt_model.................. [SELECT 2 in 0.10s]
2021-11-19 13:04:04.924940 (Thread-2): Finished running node model.my_new_project.my_first_dbt_model
2021-11-19 13:04:04.925821 (Thread-2): Began running node model.my_new_project.my_second_dbt_model
2021-11-19 13:04:04.926354 (Thread-2): 14:04:04 | 3 of 4 START view model sa.my_second_dbt_model....................... [RUN]
2021-11-19 13:04:04.926696 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 13:04:04.926827 (Thread-2): Compiling model.my_new_project.my_second_dbt_model
2021-11-19 13:04:04.928973 (Thread-2): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-19 13:04:04.929270 (Thread-2): finished collecting timing info
2021-11-19 13:04:04.944152 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-19 13:04:04.944553 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 13:04:04.944675 (Thread-2): On model.my_new_project.my_second_dbt_model: BEGIN
2021-11-19 13:04:04.944786 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 13:04:04.951784 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:04:04.952077 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 13:04:04.952210 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */

  create view "demo_db"."sa"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."sa"."my_first_dbt_model"
where id = 1
  );

2021-11-19 13:04:04.954885 (Thread-2): SQL status: CREATE VIEW in 0.00 seconds
2021-11-19 13:04:04.956886 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 13:04:04.957068 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "demo_db"."sa"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2021-11-19 13:04:04.957702 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 13:04:04.958735 (Thread-2): On model.my_new_project.my_second_dbt_model: COMMIT
2021-11-19 13:04:04.958860 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 13:04:04.958956 (Thread-2): On model.my_new_project.my_second_dbt_model: COMMIT
2021-11-19 13:04:04.960180 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-11-19 13:04:04.961477 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 13:04:04.961647 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "demo_db"."sa"."my_second_dbt_model__dbt_backup" cascade
2021-11-19 13:04:04.962667 (Thread-2): SQL status: DROP VIEW in 0.00 seconds
2021-11-19 13:04:04.964308 (Thread-2): finished collecting timing info
2021-11-19 13:04:04.964515 (Thread-2): On model.my_new_project.my_second_dbt_model: Close
2021-11-19 13:04:04.964987 (Thread-2): 14:04:04 | 3 of 4 OK created view model sa.my_second_dbt_model.................. [CREATE VIEW in 0.04s]
2021-11-19 13:04:04.965166 (Thread-2): Finished running node model.my_new_project.my_second_dbt_model
2021-11-19 13:04:05.125864 (Thread-1): SQL status: SELECT 28444 in 0.24 seconds
2021-11-19 13:04:05.131569 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:04:05.131712 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-19 13:04:05.132155 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-11-19 13:04:05.132327 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:04:05.132457 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer__dbt_tmp140404870474'
        
      order by ordinal_position

  
2021-11-19 13:04:05.137132 (Thread-1): SQL status: SELECT 16 in 0.00 seconds
2021-11-19 13:04:05.141751 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:04:05.141934 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-19 13:04:05.144632 (Thread-1): SQL status: SELECT 16 in 0.00 seconds
2021-11-19 13:04:05.154187 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:04:05.154374 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-19 13:04:05.156628 (Thread-1): SQL status: SELECT 16 in 0.00 seconds
2021-11-19 13:04:05.158444 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-19 13:04:05.158702 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:04:05.158799 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      delete
    from "demo_db"."sa_dwh"."iss_issuer"
    where (ISIN) in (
        select (ISIN)
        from "iss_issuer__dbt_tmp140404870474"
    );

    insert into "demo_db"."sa_dwh"."iss_issuer" ("adjusted_enterprise_value", "isin", "issuer_name", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_capdaily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp")
    (
       select "adjusted_enterprise_value", "isin", "issuer_name", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_capdaily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp"
       from "iss_issuer__dbt_tmp140404870474"
    );
  
2021-11-19 13:04:05.220274 (Thread-1): SQL status: INSERT 0 28444 in 0.06 seconds
2021-11-19 13:04:05.221410 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 13:04:05.221527 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:04:05.221652 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 13:04:05.238512 (Thread-1): SQL status: COMMIT in 0.02 seconds
2021-11-19 13:04:05.239026 (Thread-1): finished collecting timing info
2021-11-19 13:04:05.239174 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-19 13:04:05.239586 (Thread-1): 14:04:05 | 1 of 4 OK created incremental model sa_dwh.iss_issuer................ [INSERT 0 28444 in 0.42s]
2021-11-19 13:04:05.239746 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-19 13:04:05.240670 (Thread-2): Began running node model.my_new_project.dim_issuer
2021-11-19 13:04:05.241197 (Thread-2): 14:04:05 | 4 of 4 START table model sa_dm.dim_issuer............................ [RUN]
2021-11-19 13:04:05.241685 (Thread-2): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 13:04:05.241850 (Thread-2): Compiling model.my_new_project.dim_issuer
2021-11-19 13:04:05.244586 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_issuer"
2021-11-19 13:04:05.244872 (Thread-2): finished collecting timing info
2021-11-19 13:04:05.246811 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_issuer"
2021-11-19 13:04:05.247094 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 13:04:05.247205 (Thread-2): On model.my_new_project.dim_issuer: BEGIN
2021-11-19 13:04:05.247309 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 13:04:05.252944 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:04:05.253120 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 13:04:05.253213 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */


  create  table "demo_db"."sa_dm"."dim_issuer__dbt_tmp"
  as (
    

select distinct
     md5(iss.isin)     as dim_issuer_key
    ,iss.isin          as isin
    ,iss.issuer_name   as issuer_name
from "demo_db"."sa_dwh"."iss_issuer" iss
  );
2021-11-19 13:04:05.306131 (Thread-2): SQL status: SELECT 28444 in 0.05 seconds
2021-11-19 13:04:05.308690 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 13:04:05.308877 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer" rename to "dim_issuer__dbt_backup"
2021-11-19 13:04:05.309570 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 13:04:05.311487 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 13:04:05.311619 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer__dbt_tmp" rename to "dim_issuer"
2021-11-19 13:04:05.312126 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 13:04:05.313042 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 13:04:05.313171 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 13:04:05.313283 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 13:04:05.316227 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-11-19 13:04:05.317486 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 13:04:05.317597 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
drop table if exists "demo_db"."sa_dm"."dim_issuer__dbt_backup" cascade
2021-11-19 13:04:05.320303 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-11-19 13:04:05.321166 (Thread-2): finished collecting timing info
2021-11-19 13:04:05.321298 (Thread-2): On model.my_new_project.dim_issuer: Close
2021-11-19 13:04:05.321715 (Thread-2): 14:04:05 | 4 of 4 OK created table model sa_dm.dim_issuer....................... [SELECT 28444 in 0.08s]
2021-11-19 13:04:05.321903 (Thread-2): Finished running node model.my_new_project.dim_issuer
2021-11-19 13:04:05.323090 (MainThread): Acquiring new postgres connection "master".
2021-11-19 13:04:05.323275 (MainThread): Using postgres connection "master".
2021-11-19 13:04:05.323385 (MainThread): On master: BEGIN
2021-11-19 13:04:05.323500 (MainThread): Opening a new connection, currently in state closed
2021-11-19 13:04:05.329778 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:04:05.329979 (MainThread): On master: COMMIT
2021-11-19 13:04:05.330108 (MainThread): Using postgres connection "master".
2021-11-19 13:04:05.330205 (MainThread): On master: COMMIT
2021-11-19 13:04:05.330493 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 13:04:05.330636 (MainThread): On master: Close
2021-11-19 13:04:05.331080 (MainThread): 14:04:05 | 
2021-11-19 13:04:05.331231 (MainThread): 14:04:05 | Finished running 2 table models, 1 view model, 1 incremental model in 0.60s.
2021-11-19 13:04:05.331392 (MainThread): Connection 'master' was properly closed.
2021-11-19 13:04:05.331505 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-19 13:04:05.331594 (MainThread): Connection 'model.my_new_project.dim_issuer' was properly closed.
2021-11-19 13:04:05.334773 (MainThread): 
2021-11-19 13:04:05.334948 (MainThread): Completed successfully
2021-11-19 13:04:05.335131 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-11-19 13:04:05.335412 (MainThread): Flushing usage events
2021-11-19 13:06:14.909775 (MainThread): Running with dbt=0.21.0
2021-11-19 13:06:14.972692 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 13:06:14.973193 (MainThread): Tracking: do not track
2021-11-19 13:06:14.987124 (MainThread): Partial parsing not enabled
2021-11-19 13:06:14.994135 (MainThread): Parsing macros/adapters.sql
2021-11-19 13:06:15.014170 (MainThread): Parsing macros/catalog.sql
2021-11-19 13:06:15.016126 (MainThread): Parsing macros/relations.sql
2021-11-19 13:06:15.017181 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 13:06:15.018555 (MainThread): Parsing macros/core.sql
2021-11-19 13:06:15.021638 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 13:06:15.068235 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 13:06:15.070364 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 13:06:15.071937 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 13:06:15.073327 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 13:06:15.080555 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 13:06:15.081901 (MainThread): Parsing macros/etc/query.sql
2021-11-19 13:06:15.082870 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 13:06:15.084118 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 13:06:15.092263 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 13:06:15.097865 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 13:06:15.116955 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 13:06:15.118509 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 13:06:15.144074 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 13:06:15.158439 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 13:06:15.174948 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 13:06:15.183780 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 13:06:15.185402 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 13:06:15.197244 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 13:06:15.200699 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 13:06:15.206746 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 13:06:15.212949 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 13:06:15.214230 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 13:06:15.215346 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 13:06:15.216735 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 13:06:15.398244 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 13:06:15.409892 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 13:06:15.413138 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 13:06:15.415947 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:06:15.416216 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:06:15.417151 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:06:15.420457 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:06:15.420706 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:06:15.452689 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:06:15.454409 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:06:15.456000 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:06:15.457657 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:06:15.466783 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.dm_emissions

2021-11-19 13:06:15.476037 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 13:06:15.476417 (MainThread): Found 4 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-19 13:06:15.477845 (MainThread): 
2021-11-19 13:06:15.478234 (MainThread): Acquiring new postgres connection "master".
2021-11-19 13:06:15.479192 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 13:06:15.485334 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 13:06:15.488937 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 13:06:15.490127 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 13:06:15.490486 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 13:06:15.490686 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 13:06:15.490918 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 13:06:15.491166 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 13:06:15.500196 (ThreadPoolExecutor-0_1): SQL status: SELECT 17 in 0.01 seconds
2021-11-19 13:06:15.500595 (ThreadPoolExecutor-0_0): SQL status: SELECT 17 in 0.01 seconds
2021-11-19 13:06:15.502257 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 13:06:15.504160 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 13:06:15.504875 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 13:06:15.506504 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 13:06:15.506724 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 13:06:15.506860 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state closed
2021-11-19 13:06:15.514008 (ThreadPoolExecutor-0_1): SQL status: SELECT 17 in 0.01 seconds
2021-11-19 13:06:15.515131 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 13:06:15.516997 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 13:06:15.517551 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 13:06:15.523231 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 13:06:15.524657 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-19 13:06:15.524900 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: BEGIN
2021-11-19 13:06:15.525057 (ThreadPoolExecutor-1_1): On list_demo_db_sa: BEGIN
2021-11-19 13:06:15.525224 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 13:06:15.525501 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 13:06:15.532313 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:06:15.532633 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-19 13:06:15.532838 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:06:15.533110 (ThreadPoolExecutor-1_1): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 13:06:15.533334 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 13:06:15.533672 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 13:06:15.535297 (ThreadPoolExecutor-1_1): SQL status: SELECT 4 in 0.00 seconds
2021-11-19 13:06:15.536644 (ThreadPoolExecutor-1_1): On list_demo_db_sa: ROLLBACK
2021-11-19 13:06:15.536847 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 13:06:15.537709 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 13:06:15.537883 (ThreadPoolExecutor-1_1): On list_demo_db_sa: Close
2021-11-19 13:06:15.538479 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 13:06:15.538847 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: Close
2021-11-19 13:06:15.539975 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 13:06:15.540183 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: BEGIN
2021-11-19 13:06:15.540546 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 13:06:15.547079 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:06:15.547277 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 13:06:15.547380 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 13:06:15.549044 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 13:06:15.550095 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 13:06:15.550450 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: Close
2021-11-19 13:06:15.553774 (MainThread): Using postgres connection "master".
2021-11-19 13:06:15.553932 (MainThread): On master: BEGIN
2021-11-19 13:06:15.554042 (MainThread): Opening a new connection, currently in state init
2021-11-19 13:06:15.560602 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:06:15.560775 (MainThread): Using postgres connection "master".
2021-11-19 13:06:15.560897 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 13:06:15.566108 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-11-19 13:06:15.567165 (MainThread): On master: ROLLBACK
2021-11-19 13:06:15.567480 (MainThread): Using postgres connection "master".
2021-11-19 13:06:15.567602 (MainThread): On master: BEGIN
2021-11-19 13:06:15.568121 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 13:06:15.568270 (MainThread): On master: COMMIT
2021-11-19 13:06:15.568388 (MainThread): Using postgres connection "master".
2021-11-19 13:06:15.568477 (MainThread): On master: COMMIT
2021-11-19 13:06:15.568729 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 13:06:15.568857 (MainThread): On master: Close
2021-11-19 13:06:15.569148 (MainThread): 14:06:15 | Concurrency: 2 threads (target='dev')
2021-11-19 13:06:15.569303 (MainThread): 14:06:15 | 
2021-11-19 13:06:15.571555 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-19 13:06:15.571787 (Thread-2): Began running node model.my_new_project.my_first_dbt_model
2021-11-19 13:06:15.572078 (Thread-1): 14:06:15 | 1 of 4 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-19 13:06:15.572374 (Thread-2): 14:06:15 | 2 of 4 START table model sa.my_first_dbt_model....................... [RUN]
2021-11-19 13:06:15.572948 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:06:15.573233 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-19 13:06:15.573636 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 13:06:15.577123 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-19 13:06:15.577398 (Thread-2): Compiling model.my_new_project.my_first_dbt_model
2021-11-19 13:06:15.580423 (Thread-2): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 13:06:15.580884 (Thread-1): finished collecting timing info
2021-11-19 13:06:15.586360 (Thread-2): finished collecting timing info
2021-11-19 13:06:15.634531 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 13:06:15.641962 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:06:15.642194 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

    

  create temporary table "iss_issuer__dbt_tmp140615632103"
  as (
    

select
     iss.AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,iss.ISIN                             as isin
    ,iss.IssuerName                       as issuer_name
    ,iss.ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,iss.ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,iss.ClimateScope2Emissions           as climate_scope2_emissions
    ,iss.ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,iss.ClimateScope3Emissions           as climate_scope3_emissions
    ,iss.ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,iss.ClimateTotalEmissions            as climate_total_emissions
    ,iss.ClimateScope1Emissions           as climate_scope1_emissions
    ,iss.MarketCapDaily                   as market_capdaily
    ,iss.ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,'2021-01-01'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-19 13:06:15.642696 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 13:06:15.643209 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 13:06:15.643421 (Thread-2): On model.my_new_project.my_first_dbt_model: BEGIN
2021-11-19 13:06:15.643601 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 13:06:15.650281 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:06:15.650483 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 13:06:15.650637 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table "demo_db"."sa"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select id,name
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-11-19 13:06:15.651269 (Thread-2): Postgres error: column "name" does not exist
LINE 24: select id,name
                   ^

2021-11-19 13:06:15.651460 (Thread-2): On model.my_new_project.my_first_dbt_model: ROLLBACK
2021-11-19 13:06:15.652027 (Thread-2): finished collecting timing info
2021-11-19 13:06:15.652184 (Thread-2): On model.my_new_project.my_first_dbt_model: Close
2021-11-19 13:06:15.652602 (Thread-2): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  column "name" does not exist
  LINE 24: select id,name
                     ^
  compiled SQL at target/run/my_new_project/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedColumn: column "name" does not exist
LINE 24: select id,name
                   ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 70, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  column "name" does not exist
  LINE 24: select id,name
                     ^
  compiled SQL at target/run/my_new_project/models/example/my_first_dbt_model.sql
2021-11-19 13:06:15.658304 (Thread-2): 14:06:15 | 2 of 4 ERROR creating table model sa.my_first_dbt_model.............. [ERROR in 0.08s]
2021-11-19 13:06:15.658518 (Thread-2): Finished running node model.my_new_project.my_first_dbt_model
2021-11-19 13:06:15.659020 (Thread-2): Began running node model.my_new_project.my_second_dbt_model
2021-11-19 13:06:15.659255 (Thread-2): 14:06:15 | 3 of 4 SKIP relation sa.my_second_dbt_model.......................... [SKIP]
2021-11-19 13:06:15.659449 (Thread-2): Finished running node model.my_new_project.my_second_dbt_model
2021-11-19 13:06:15.752880 (Thread-1): SQL status: SELECT 28444 in 0.11 seconds
2021-11-19 13:06:15.759430 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:06:15.759632 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-19 13:06:15.760286 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-11-19 13:06:15.760417 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:06:15.760514 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer__dbt_tmp140615632103'
        
      order by ordinal_position

  
2021-11-19 13:06:15.765544 (Thread-1): SQL status: SELECT 16 in 0.00 seconds
2021-11-19 13:06:15.770017 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:06:15.770157 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-19 13:06:15.772642 (Thread-1): SQL status: SELECT 16 in 0.00 seconds
2021-11-19 13:06:15.782762 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:06:15.782959 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-19 13:06:15.785288 (Thread-1): SQL status: SELECT 16 in 0.00 seconds
2021-11-19 13:06:15.787029 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-19 13:06:15.787292 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:06:15.787519 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      delete
    from "demo_db"."sa_dwh"."iss_issuer"
    where (ISIN) in (
        select (ISIN)
        from "iss_issuer__dbt_tmp140615632103"
    );

    insert into "demo_db"."sa_dwh"."iss_issuer" ("adjusted_enterprise_value", "isin", "issuer_name", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_capdaily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp")
    (
       select "adjusted_enterprise_value", "isin", "issuer_name", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_capdaily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp"
       from "iss_issuer__dbt_tmp140615632103"
    );
  
2021-11-19 13:06:15.837804 (Thread-1): SQL status: INSERT 0 28444 in 0.05 seconds
2021-11-19 13:06:15.845128 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 13:06:15.845391 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:06:15.845512 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 13:06:15.857918 (Thread-1): SQL status: COMMIT in 0.01 seconds
2021-11-19 13:06:15.858444 (Thread-1): finished collecting timing info
2021-11-19 13:06:15.858601 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-19 13:06:15.859023 (Thread-1): 14:06:15 | 1 of 4 OK created incremental model sa_dwh.iss_issuer................ [INSERT 0 28444 in 0.29s]
2021-11-19 13:06:15.859186 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-19 13:06:15.860023 (Thread-2): Began running node model.my_new_project.dim_issuer
2021-11-19 13:06:15.860453 (Thread-2): 14:06:15 | 4 of 4 START table model sa_dm.dim_issuer............................ [RUN]
2021-11-19 13:06:15.860933 (Thread-2): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 13:06:15.861253 (Thread-2): Compiling model.my_new_project.dim_issuer
2021-11-19 13:06:15.864226 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_issuer"
2021-11-19 13:06:15.864524 (Thread-2): finished collecting timing info
2021-11-19 13:06:15.866292 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_issuer"
2021-11-19 13:06:15.866560 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 13:06:15.866692 (Thread-2): On model.my_new_project.dim_issuer: BEGIN
2021-11-19 13:06:15.866799 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 13:06:15.873265 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:06:15.873463 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 13:06:15.873558 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */


  create  table "demo_db"."sa_dm"."dim_issuer__dbt_tmp"
  as (
    

select distinct
     md5(iss.isin)     as dim_issuer_key
    ,iss.isin          as isin
    ,iss.issuer_name   as issuer_name
from "demo_db"."sa_dwh"."iss_issuer" iss
  );
2021-11-19 13:06:15.924891 (Thread-2): SQL status: SELECT 28444 in 0.05 seconds
2021-11-19 13:06:15.929984 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 13:06:15.930147 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer" rename to "dim_issuer__dbt_backup"
2021-11-19 13:06:15.930754 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 13:06:15.932845 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 13:06:15.932990 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer__dbt_tmp" rename to "dim_issuer"
2021-11-19 13:06:15.933581 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 13:06:15.938342 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 13:06:15.938499 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 13:06:15.938634 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 13:06:15.945085 (Thread-2): SQL status: COMMIT in 0.01 seconds
2021-11-19 13:06:15.949977 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 13:06:15.950115 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
drop table if exists "demo_db"."sa_dm"."dim_issuer__dbt_backup" cascade
2021-11-19 13:06:15.952449 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-11-19 13:06:15.953350 (Thread-2): finished collecting timing info
2021-11-19 13:06:15.953495 (Thread-2): On model.my_new_project.dim_issuer: Close
2021-11-19 13:06:15.953976 (Thread-2): 14:06:15 | 4 of 4 OK created table model sa_dm.dim_issuer....................... [SELECT 28444 in 0.09s]
2021-11-19 13:06:15.954131 (Thread-2): Finished running node model.my_new_project.dim_issuer
2021-11-19 13:06:15.955556 (MainThread): Acquiring new postgres connection "master".
2021-11-19 13:06:15.955738 (MainThread): Using postgres connection "master".
2021-11-19 13:06:15.955838 (MainThread): On master: BEGIN
2021-11-19 13:06:15.955939 (MainThread): Opening a new connection, currently in state closed
2021-11-19 13:06:15.962294 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:06:15.962496 (MainThread): On master: COMMIT
2021-11-19 13:06:15.962620 (MainThread): Using postgres connection "master".
2021-11-19 13:06:15.962721 (MainThread): On master: COMMIT
2021-11-19 13:06:15.962977 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 13:06:15.963101 (MainThread): On master: Close
2021-11-19 13:06:15.963463 (MainThread): 14:06:15 | 
2021-11-19 13:06:15.963655 (MainThread): 14:06:15 | Finished running 2 table models, 1 view model, 1 incremental model in 0.49s.
2021-11-19 13:06:15.963887 (MainThread): Connection 'master' was properly closed.
2021-11-19 13:06:15.964088 (MainThread): Connection 'model.my_new_project.dim_issuer' was properly closed.
2021-11-19 13:06:15.964293 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-19 13:06:15.968760 (MainThread): 
2021-11-19 13:06:15.968980 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 13:06:15.969147 (MainThread): 
2021-11-19 13:06:15.969300 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-11-19 13:06:15.969440 (MainThread):   column "name" does not exist
2021-11-19 13:06:15.969567 (MainThread):   LINE 24: select id,name
2021-11-19 13:06:15.969724 (MainThread):                      ^
2021-11-19 13:06:15.969843 (MainThread):   compiled SQL at target/run/my_new_project/models/example/my_first_dbt_model.sql
2021-11-19 13:06:15.969976 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=1 TOTAL=4
2021-11-19 13:06:15.970173 (MainThread): Flushing usage events
2021-11-19 13:38:44.223285 (MainThread): Running with dbt=0.21.0
2021-11-19 13:38:44.292979 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, compile=True, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.generate.GenerateTask'>, which='generate', rpc_method='docs.generate')
2021-11-19 13:38:44.293565 (MainThread): Tracking: do not track
2021-11-19 13:38:44.305624 (MainThread): Partial parsing not enabled
2021-11-19 13:38:44.312504 (MainThread): Parsing macros/adapters.sql
2021-11-19 13:38:44.332471 (MainThread): Parsing macros/catalog.sql
2021-11-19 13:38:44.334454 (MainThread): Parsing macros/relations.sql
2021-11-19 13:38:44.335721 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 13:38:44.337258 (MainThread): Parsing macros/core.sql
2021-11-19 13:38:44.340623 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 13:38:44.389958 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 13:38:44.392002 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 13:38:44.393468 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 13:38:44.394756 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 13:38:44.402165 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 13:38:44.403439 (MainThread): Parsing macros/etc/query.sql
2021-11-19 13:38:44.404258 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 13:38:44.405652 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 13:38:44.414003 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 13:38:44.420237 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 13:38:44.440527 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 13:38:44.442139 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 13:38:44.468582 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 13:38:44.484227 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 13:38:44.501548 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 13:38:44.510775 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 13:38:44.512354 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 13:38:44.524044 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 13:38:44.527161 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 13:38:44.534376 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 13:38:44.540889 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 13:38:44.542219 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 13:38:44.543296 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 13:38:44.544748 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 13:38:44.732829 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 13:38:44.745274 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 13:38:44.749286 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 13:38:44.752237 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:38:44.752499 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:38:44.753411 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:38:44.756985 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:38:44.757262 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:38:44.789812 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:38:44.791561 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:38:44.793203 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:38:44.794953 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 13:38:44.804823 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_new_project.dm_emissions

2021-11-19 13:38:44.815018 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 13:38:44.815638 (MainThread): Found 4 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-19 13:38:44.817512 (MainThread): 
2021-11-19 13:38:44.818122 (MainThread): Acquiring new postgres connection "master".
2021-11-19 13:38:44.819077 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 13:38:44.819503 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 13:38:44.827738 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 13:38:44.828829 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db_sa".
2021-11-19 13:38:44.829052 (ThreadPoolExecutor-0_0): On list_demo_db_sa_dwh: BEGIN
2021-11-19 13:38:44.829280 (ThreadPoolExecutor-0_1): On list_demo_db_sa: BEGIN
2021-11-19 13:38:44.829543 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 13:38:44.829746 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 13:38:44.836683 (ThreadPoolExecutor-0_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:38:44.836906 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:38:44.837082 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db_sa".
2021-11-19 13:38:44.837248 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 13:38:44.837407 (ThreadPoolExecutor-0_1): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 13:38:44.837568 (ThreadPoolExecutor-0_0): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 13:38:44.839415 (ThreadPoolExecutor-0_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 13:38:44.840477 (ThreadPoolExecutor-0_0): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 13:38:44.840655 (ThreadPoolExecutor-0_1): SQL status: SELECT 4 in 0.00 seconds
2021-11-19 13:38:44.841638 (ThreadPoolExecutor-0_1): On list_demo_db_sa: ROLLBACK
2021-11-19 13:38:44.841797 (ThreadPoolExecutor-0_0): On list_demo_db_sa_dwh: Close
2021-11-19 13:38:44.842310 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 13:38:44.842583 (ThreadPoolExecutor-0_1): On list_demo_db_sa: Close
2021-11-19 13:38:44.843752 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 13:38:44.843966 (ThreadPoolExecutor-0_0): On list_demo_db_sa_dm: BEGIN
2021-11-19 13:38:44.844314 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-11-19 13:38:44.850187 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:38:44.850376 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 13:38:44.850477 (ThreadPoolExecutor-0_0): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 13:38:44.852160 (ThreadPoolExecutor-0_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 13:38:44.853136 (ThreadPoolExecutor-0_0): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 13:38:44.853470 (ThreadPoolExecutor-0_0): On list_demo_db_sa_dm: Close
2021-11-19 13:38:44.857110 (MainThread): Using postgres connection "master".
2021-11-19 13:38:44.857289 (MainThread): On master: BEGIN
2021-11-19 13:38:44.857398 (MainThread): Opening a new connection, currently in state init
2021-11-19 13:38:44.863300 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:38:44.863507 (MainThread): Using postgres connection "master".
2021-11-19 13:38:44.863614 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 13:38:44.869241 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-11-19 13:38:44.870343 (MainThread): On master: ROLLBACK
2021-11-19 13:38:44.870715 (MainThread): On master: Close
2021-11-19 13:38:44.871056 (MainThread): 14:38:44 | Concurrency: 2 threads (target='dev')
2021-11-19 13:38:44.871225 (MainThread): 14:38:44 | 
2021-11-19 13:38:44.873476 (Thread-1): Began running node model.my_new_project.my_first_dbt_model
2021-11-19 13:38:44.873711 (Thread-2): Began running node seed.my_new_project.sa_iss_issuer
2021-11-19 13:38:44.874061 (Thread-1): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 13:38:44.874377 (Thread-2): Acquiring new postgres connection "seed.my_new_project.sa_iss_issuer".
2021-11-19 13:38:44.874559 (Thread-1): Compiling model.my_new_project.my_first_dbt_model
2021-11-19 13:38:44.874735 (Thread-2): Compiling seed.my_new_project.sa_iss_issuer
2021-11-19 13:38:44.877073 (Thread-1): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 13:38:44.878134 (Thread-2): Writing injected SQL for node "seed.my_new_project.sa_iss_issuer"
2021-11-19 13:38:44.878474 (Thread-2): finished collecting timing info
2021-11-19 13:38:44.878666 (Thread-2): finished collecting timing info
2021-11-19 13:38:44.879081 (Thread-2): Finished running node seed.my_new_project.sa_iss_issuer
2021-11-19 13:38:44.879518 (Thread-1): finished collecting timing info
2021-11-19 13:38:44.880044 (Thread-1): finished collecting timing info
2021-11-19 13:38:44.880576 (Thread-1): Finished running node model.my_new_project.my_first_dbt_model
2021-11-19 13:38:44.880864 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-19 13:38:44.881293 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 13:38:44.881624 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-19 13:38:44.881786 (Thread-2): Began running node model.my_new_project.my_second_dbt_model
2021-11-19 13:38:44.884800 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-19 13:38:44.885122 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 13:38:44.885436 (Thread-2): Compiling model.my_new_project.my_second_dbt_model
2021-11-19 13:38:44.887002 (Thread-2): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-19 13:38:44.887335 (Thread-1): finished collecting timing info
2021-11-19 13:38:44.887514 (Thread-1): finished collecting timing info
2021-11-19 13:38:44.887667 (Thread-2): finished collecting timing info
2021-11-19 13:38:44.887947 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-19 13:38:44.888122 (Thread-2): finished collecting timing info
2021-11-19 13:38:44.888347 (Thread-1): Began running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2021-11-19 13:38:44.888678 (Thread-2): Finished running node model.my_new_project.my_second_dbt_model
2021-11-19 13:38:44.889185 (Thread-1): Acquiring new postgres connection "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710".
2021-11-19 13:38:44.889406 (Thread-2): Began running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2021-11-19 13:38:44.889674 (Thread-1): Compiling test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2021-11-19 13:38:44.890037 (Thread-2): Acquiring new postgres connection "test.my_new_project.unique_my_first_dbt_model_id.16e066b321".
2021-11-19 13:38:44.895546 (Thread-2): Compiling test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2021-11-19 13:38:44.903988 (Thread-1): Writing injected SQL for node "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"
2021-11-19 13:38:44.907513 (Thread-2): Writing injected SQL for node "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"
2021-11-19 13:38:44.907977 (Thread-2): finished collecting timing info
2021-11-19 13:38:44.908184 (Thread-1): finished collecting timing info
2021-11-19 13:38:44.908405 (Thread-2): finished collecting timing info
2021-11-19 13:38:44.908584 (Thread-1): finished collecting timing info
2021-11-19 13:38:44.908941 (Thread-2): Finished running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2021-11-19 13:38:44.909261 (Thread-1): Finished running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2021-11-19 13:38:44.909485 (Thread-2): Began running node model.my_new_project.dim_issuer
2021-11-19 13:38:44.909781 (Thread-1): Began running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2021-11-19 13:38:44.910142 (Thread-2): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 13:38:44.910555 (Thread-1): Acquiring new postgres connection "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778".
2021-11-19 13:38:44.910765 (Thread-2): Compiling model.my_new_project.dim_issuer
2021-11-19 13:38:44.910925 (Thread-1): Compiling test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2021-11-19 13:38:44.913551 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_issuer"
2021-11-19 13:38:44.916632 (Thread-1): Writing injected SQL for node "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"
2021-11-19 13:38:44.917185 (Thread-1): finished collecting timing info
2021-11-19 13:38:44.917379 (Thread-1): finished collecting timing info
2021-11-19 13:38:44.917658 (Thread-1): Finished running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2021-11-19 13:38:44.917839 (Thread-1): Began running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2021-11-19 13:38:44.918203 (Thread-1): Acquiring new postgres connection "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493".
2021-11-19 13:38:44.918483 (Thread-2): finished collecting timing info
2021-11-19 13:38:44.918631 (Thread-1): Compiling test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2021-11-19 13:38:44.918786 (Thread-2): finished collecting timing info
2021-11-19 13:38:44.921119 (Thread-1): Writing injected SQL for node "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"
2021-11-19 13:38:44.921401 (Thread-2): Finished running node model.my_new_project.dim_issuer
2021-11-19 13:38:44.921721 (Thread-1): finished collecting timing info
2021-11-19 13:38:44.921900 (Thread-1): finished collecting timing info
2021-11-19 13:38:44.922270 (Thread-1): Finished running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2021-11-19 13:38:44.923595 (MainThread): Connection 'master' was properly closed.
2021-11-19 13:38:44.923706 (MainThread): Connection 'model.my_new_project.dim_issuer' was properly closed.
2021-11-19 13:38:44.923793 (MainThread): Connection 'test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
2021-11-19 13:38:44.927044 (MainThread): 14:38:44 | Done.
2021-11-19 13:38:44.936399 (MainThread): Acquiring new postgres connection "generate_catalog".
2021-11-19 13:38:44.936579 (MainThread): 14:38:44 | Building catalog
2021-11-19 13:38:44.938746 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "demo_db.information_schema".
2021-11-19 13:38:44.944546 (ThreadPoolExecutor-1_0): Using postgres connection "demo_db.information_schema".
2021-11-19 13:38:44.944715 (ThreadPoolExecutor-1_0): On demo_db.information_schema: BEGIN
2021-11-19 13:38:44.944827 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-11-19 13:38:44.951544 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 13:38:44.951739 (ThreadPoolExecutor-1_0): Using postgres connection "demo_db.information_schema".
2021-11-19 13:38:44.951835 (ThreadPoolExecutor-1_0): On demo_db.information_schema: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "demo_db.information_schema"} */

    
    

    select
        'demo_db' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)

    where (upper(sch.nspname) = upper('sa_dbt_test__audit') or upper(sch.nspname) = upper('sa') or upper(sch.nspname) = upper('sa_dwh') or upper(sch.nspname) = upper('sa_dm'))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence = 'p' -- [p]ermanent table. Other values are [u]nlogged table, [t]emporary table
      and tbl.relkind in ('r', 'v', 'f', 'p') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table, [m]aterialized view
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
2021-11-19 13:38:44.958134 (ThreadPoolExecutor-1_0): SQL status: SELECT 247 in 0.01 seconds
2021-11-19 13:38:44.973430 (ThreadPoolExecutor-1_0): On demo_db.information_schema: ROLLBACK
2021-11-19 13:38:44.973978 (ThreadPoolExecutor-1_0): On demo_db.information_schema: Close
2021-11-19 13:38:44.987692 (MainThread): 14:38:44 | Catalog written to /home/qw40wz/dbt-sample/dbt-sample/target/catalog.json
2021-11-19 13:38:44.988055 (MainThread): Flushing usage events
2021-11-19 13:38:44.988284 (MainThread): Connection 'generate_catalog' was properly closed.
2021-11-19 13:38:44.988418 (MainThread): Connection 'demo_db.information_schema' was properly closed.
2021-11-19 13:38:52.995051 (MainThread): Running with dbt=0.21.0
2021-11-19 13:38:53.060836 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, port=8080, open_browser=True, defer=None, state=None, cls=<class 'dbt.task.serve.ServeTask'>, which='serve', rpc_method=None)
2021-11-19 13:38:53.061265 (MainThread): Tracking: do not track
2021-11-19 13:38:53.065371 (MainThread): Serving docs at 0.0.0.0:8080
2021-11-19 13:38:53.065833 (MainThread): To access from your browser, navigate to:  http://localhost:8080
2021-11-19 13:38:53.066083 (MainThread): Press Ctrl+C to exit.


2021-11-19 13:47:31.174241 (MainThread): Flushing usage events
2021-11-19 13:47:31.175102 (MainThread): ctrl-c
2021-11-19 13:47:34.356833 (MainThread): Running with dbt=0.21.0
2021-11-19 13:47:34.421329 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, port=8080, open_browser=True, defer=None, state=None, cls=<class 'dbt.task.serve.ServeTask'>, which='serve', rpc_method=None)
2021-11-19 13:47:34.421818 (MainThread): Tracking: do not track
2021-11-19 13:47:34.426106 (MainThread): Serving docs at 0.0.0.0:8080
2021-11-19 13:47:34.426475 (MainThread): To access from your browser, navigate to:  http://localhost:8080
2021-11-19 13:47:34.426706 (MainThread): Press Ctrl+C to exit.


2021-11-19 13:48:38.616412 (MainThread): Flushing usage events
2021-11-19 13:48:38.616819 (MainThread): ctrl-c
2021-11-19 17:08:44.469228 (MainThread): Running with dbt=0.21.0
2021-11-19 17:08:44.523499 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 17:08:44.523874 (MainThread): Tracking: do not track
2021-11-19 17:08:44.533342 (MainThread): Partial parsing not enabled
2021-11-19 17:08:44.539886 (MainThread): Parsing macros/adapters.sql
2021-11-19 17:08:44.559824 (MainThread): Parsing macros/catalog.sql
2021-11-19 17:08:44.561547 (MainThread): Parsing macros/relations.sql
2021-11-19 17:08:44.562597 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 17:08:44.563902 (MainThread): Parsing macros/core.sql
2021-11-19 17:08:44.567168 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 17:08:44.608277 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 17:08:44.610139 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 17:08:44.611517 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 17:08:44.612689 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 17:08:44.619363 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 17:08:44.620501 (MainThread): Parsing macros/etc/query.sql
2021-11-19 17:08:44.621228 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 17:08:44.622324 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 17:08:44.629609 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 17:08:44.635094 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 17:08:44.652102 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 17:08:44.653384 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 17:08:44.675994 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 17:08:44.689329 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 17:08:44.704170 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 17:08:44.711897 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 17:08:44.713177 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 17:08:44.723616 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 17:08:44.726552 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 17:08:44.731847 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 17:08:44.737441 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 17:08:44.738481 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 17:08:44.739401 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 17:08:44.740626 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 17:08:44.898862 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:08:44.909008 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:08:44.911761 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:08:44.914167 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:08:44.914373 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:08:44.915410 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:08:44.918985 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:08:44.919209 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:08:44.920055 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:08:44.922862 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:08:44.923063 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:08:44.950516 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:08:44.951962 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:08:44.953360 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:08:44.954828 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:08:44.969153 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 17:08:44.969631 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-19 17:08:44.970988 (MainThread): 
2021-11-19 17:08:44.971251 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:08:44.972210 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:08:44.972585 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:08:44.981712 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 17:08:44.981845 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:08:44.981967 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 17:08:44.984750 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 17:08:44.984917 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:08:44.985017 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 17:08:44.990354 (ThreadPoolExecutor-0_1): SQL status: SELECT 15 in 0.01 seconds
2021-11-19 17:08:44.991417 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 17:08:44.991959 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:08:44.993795 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 17:08:44.993965 (ThreadPoolExecutor-0_0): SQL status: SELECT 15 in 0.01 seconds
2021-11-19 17:08:44.994138 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:08:44.994914 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 17:08:44.995099 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state closed
2021-11-19 17:08:45.002252 (ThreadPoolExecutor-0_1): SQL status: SELECT 15 in 0.01 seconds
2021-11-19 17:08:45.003281 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 17:08:45.004146 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_demo_db_sa_dwh".
2021-11-19 17:08:45.004399 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "create_demo_db_sa_dm".
2021-11-19 17:08:45.004704 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_demo_db_sa_dwh".
2021-11-19 17:08:45.005146 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "create_demo_db_sa_dm".
2021-11-19 17:08:45.005480 (ThreadPoolExecutor-0_0): Creating schema ""demo_db"."sa_dwh""
2021-11-19 17:08:45.005668 (ThreadPoolExecutor-0_1): Creating schema ""demo_db"."sa_dm""
2021-11-19 17:08:45.009297 (ThreadPoolExecutor-0_0): Using postgres connection "create_demo_db_sa_dwh".
2021-11-19 17:08:45.010192 (ThreadPoolExecutor-0_1): Using postgres connection "create_demo_db_sa_dm".
2021-11-19 17:08:45.010383 (ThreadPoolExecutor-0_0): On create_demo_db_sa_dwh: BEGIN
2021-11-19 17:08:45.010520 (ThreadPoolExecutor-0_1): On create_demo_db_sa_dm: BEGIN
2021-11-19 17:08:45.010713 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-11-19 17:08:45.010847 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state closed
2021-11-19 17:08:45.018322 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:08:45.018522 (ThreadPoolExecutor-0_0): Using postgres connection "create_demo_db_sa_dwh".
2021-11-19 17:08:45.018631 (ThreadPoolExecutor-0_0): On create_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "create_demo_db_sa_dwh"} */
create schema if not exists "sa_dwh"
2021-11-19 17:08:45.018800 (ThreadPoolExecutor-0_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:08:45.018987 (ThreadPoolExecutor-0_1): Using postgres connection "create_demo_db_sa_dm".
2021-11-19 17:08:45.019089 (ThreadPoolExecutor-0_1): On create_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "create_demo_db_sa_dm"} */
create schema if not exists "sa_dm"
2021-11-19 17:08:45.019232 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.00 seconds
2021-11-19 17:08:45.020029 (ThreadPoolExecutor-0_0): On create_demo_db_sa_dwh: COMMIT
2021-11-19 17:08:45.020229 (ThreadPoolExecutor-0_1): SQL status: CREATE SCHEMA in 0.00 seconds
2021-11-19 17:08:45.020376 (ThreadPoolExecutor-0_0): Using postgres connection "create_demo_db_sa_dwh".
2021-11-19 17:08:45.020917 (ThreadPoolExecutor-0_1): On create_demo_db_sa_dm: COMMIT
2021-11-19 17:08:45.021047 (ThreadPoolExecutor-0_0): On create_demo_db_sa_dwh: COMMIT
2021-11-19 17:08:45.021178 (ThreadPoolExecutor-0_1): Using postgres connection "create_demo_db_sa_dm".
2021-11-19 17:08:45.021383 (ThreadPoolExecutor-0_1): On create_demo_db_sa_dm: COMMIT
2021-11-19 17:08:45.022622 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:08:45.022840 (ThreadPoolExecutor-0_0): On create_demo_db_sa_dwh: Close
2021-11-19 17:08:45.023380 (ThreadPoolExecutor-0_1): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:08:45.023594 (ThreadPoolExecutor-0_1): On create_demo_db_sa_dm: Close
2021-11-19 17:08:45.025071 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:08:45.029384 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:08:45.029670 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 17:08:45.029904 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: BEGIN
2021-11-19 17:08:45.031535 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:08:45.031753 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 17:08:45.031976 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: BEGIN
2021-11-19 17:08:45.032358 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 17:08:45.038651 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:08:45.038911 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:08:45.039027 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 17:08:45.039181 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:08:45.039292 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:08:45.039381 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 17:08:45.040687 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 17:08:45.041506 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 17:08:45.041682 (ThreadPoolExecutor-1_1): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 17:08:45.042703 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 17:08:45.042904 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: Close
2021-11-19 17:08:45.043519 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 17:08:45.043827 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: Close
2021-11-19 17:08:45.045143 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 17:08:45.045785 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-19 17:08:45.046024 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 17:08:45.052185 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:08:45.052414 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 17:08:45.052507 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 17:08:45.054101 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:08:45.054976 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-19 17:08:45.055275 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-19 17:08:45.058627 (MainThread): Using postgres connection "master".
2021-11-19 17:08:45.058734 (MainThread): On master: BEGIN
2021-11-19 17:08:45.058828 (MainThread): Opening a new connection, currently in state init
2021-11-19 17:08:45.064559 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:08:45.064684 (MainThread): Using postgres connection "master".
2021-11-19 17:08:45.064768 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 17:08:45.067733 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 17:08:45.069137 (MainThread): On master: ROLLBACK
2021-11-19 17:08:45.069644 (MainThread): Using postgres connection "master".
2021-11-19 17:08:45.069857 (MainThread): On master: BEGIN
2021-11-19 17:08:45.070395 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 17:08:45.070528 (MainThread): On master: COMMIT
2021-11-19 17:08:45.070618 (MainThread): Using postgres connection "master".
2021-11-19 17:08:45.070720 (MainThread): On master: COMMIT
2021-11-19 17:08:45.071005 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:08:45.071112 (MainThread): On master: Close
2021-11-19 17:08:45.071389 (MainThread): 18:08:45 | Concurrency: 2 threads (target='dev')
2021-11-19 17:08:45.071553 (MainThread): 18:08:45 | 
2021-11-19 17:08:45.073475 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-19 17:08:45.073703 (Thread-2): Began running node model.my_new_project.my_first_dbt_model
2021-11-19 17:08:45.074005 (Thread-1): 18:08:45 | 1 of 5 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-19 17:08:45.074270 (Thread-2): 18:08:45 | 2 of 5 START table model sa.my_first_dbt_model....................... [RUN]
2021-11-19 17:08:45.074750 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:08:45.075291 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:08:45.075469 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-19 17:08:45.075635 (Thread-2): Compiling model.my_new_project.my_first_dbt_model
2021-11-19 17:08:45.078377 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-19 17:08:45.080079 (Thread-2): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 17:08:45.080553 (Thread-2): finished collecting timing info
2021-11-19 17:08:45.085962 (Thread-1): finished collecting timing info
2021-11-19 17:08:45.118362 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 17:08:45.129145 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:08:45.129326 (Thread-2): On model.my_new_project.my_first_dbt_model: BEGIN
2021-11-19 17:08:45.129462 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 17:08:45.131630 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-19 17:08:45.132027 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:08:45.132141 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-19 17:08:45.132245 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 17:08:45.136747 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:08:45.136959 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:08:45.137057 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table "demo_db"."sa"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select id
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-11-19 17:08:45.138162 (Thread-2): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 17:08:45.143019 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:08:45.143308 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "demo_db"."sa"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2021-11-19 17:08:45.143839 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:08:45.143992 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:08:45.144107 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer"
  as (
    

select
     iss.AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,iss.ISIN                             as isin
    ,iss.IssuerName                       as issuer_name
    ,iss.gicssector                       as gics_sector
    ,iss.gicsindustrygroup                as gics_industry_group
    ,iss.ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,iss.ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,iss.ClimateScope2Emissions           as climate_scope2_emissions
    ,iss.ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,iss.ClimateScope3Emissions           as climate_scope3_emissions
    ,iss.ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,iss.ClimateTotalEmissions            as climate_total_emissions
    ,iss.ClimateScope1Emissions           as climate_scope1_emissions
    ,iss.MarketCapDaily                   as market_cap_daily
    ,iss.ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,'2021-01-01'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-19 17:08:45.144265 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 17:08:45.152497 (Thread-2): On model.my_new_project.my_first_dbt_model: COMMIT
2021-11-19 17:08:45.152654 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:08:45.152750 (Thread-2): On model.my_new_project.my_first_dbt_model: COMMIT
2021-11-19 17:08:45.154297 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:08:45.157815 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:08:45.157931 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "demo_db"."sa"."my_first_dbt_model__dbt_backup" cascade
2021-11-19 17:08:45.158437 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-11-19 17:08:45.159257 (Thread-2): finished collecting timing info
2021-11-19 17:08:45.159392 (Thread-2): On model.my_new_project.my_first_dbt_model: Close
2021-11-19 17:08:45.159778 (Thread-2): 18:08:45 | 2 of 5 OK created table model sa.my_first_dbt_model.................. [SELECT 2 in 0.08s]
2021-11-19 17:08:45.159934 (Thread-2): Finished running node model.my_new_project.my_first_dbt_model
2021-11-19 17:08:45.160445 (Thread-2): Began running node model.my_new_project.my_second_dbt_model
2021-11-19 17:08:45.160689 (Thread-2): 18:08:45 | 3 of 5 START view model sa.my_second_dbt_model....................... [RUN]
2021-11-19 17:08:45.161029 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:08:45.161258 (Thread-2): Compiling model.my_new_project.my_second_dbt_model
2021-11-19 17:08:45.163409 (Thread-2): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-19 17:08:45.163657 (Thread-2): finished collecting timing info
2021-11-19 17:08:45.177389 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-19 17:08:45.177683 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:08:45.177789 (Thread-2): On model.my_new_project.my_second_dbt_model: BEGIN
2021-11-19 17:08:45.177891 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 17:08:45.186298 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:08:45.186562 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:08:45.186664 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */

  create view "demo_db"."sa"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."sa"."my_first_dbt_model"
where id = 1
  );

2021-11-19 17:08:45.188225 (Thread-2): SQL status: CREATE VIEW in 0.00 seconds
2021-11-19 17:08:45.190260 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:08:45.190413 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "demo_db"."sa"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2021-11-19 17:08:45.190867 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 17:08:45.191652 (Thread-2): On model.my_new_project.my_second_dbt_model: COMMIT
2021-11-19 17:08:45.191778 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:08:45.191871 (Thread-2): On model.my_new_project.my_second_dbt_model: COMMIT
2021-11-19 17:08:45.197167 (Thread-2): SQL status: COMMIT in 0.01 seconds
2021-11-19 17:08:45.198270 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:08:45.198381 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "demo_db"."sa"."my_second_dbt_model__dbt_backup" cascade
2021-11-19 17:08:45.198731 (Thread-2): SQL status: DROP VIEW in 0.00 seconds
2021-11-19 17:08:45.199726 (Thread-2): finished collecting timing info
2021-11-19 17:08:45.199871 (Thread-2): On model.my_new_project.my_second_dbt_model: Close
2021-11-19 17:08:45.200433 (Thread-2): 18:08:45 | 3 of 5 OK created view model sa.my_second_dbt_model.................. [CREATE VIEW in 0.04s]
2021-11-19 17:08:45.200602 (Thread-2): Finished running node model.my_new_project.my_second_dbt_model
2021-11-19 17:08:45.273185 (Thread-1): SQL status: SELECT 28444 in 0.13 seconds
2021-11-19 17:08:45.274209 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 17:08:45.274314 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:08:45.274401 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 17:08:45.282930 (Thread-1): SQL status: COMMIT in 0.01 seconds
2021-11-19 17:08:45.283372 (Thread-1): finished collecting timing info
2021-11-19 17:08:45.283505 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-19 17:08:45.283911 (Thread-1): 18:08:45 | 1 of 5 OK created incremental model sa_dwh.iss_issuer................ [SELECT 28444 in 0.21s]
2021-11-19 17:08:45.284050 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-19 17:08:45.285056 (Thread-2): Began running node model.my_new_project.dim_issuer
2021-11-19 17:08:45.285216 (Thread-1): Began running node model.my_new_project.fct_emissions
2021-11-19 17:08:45.285585 (Thread-2): 18:08:45 | 4 of 5 START table model sa_dm.dim_issuer............................ [RUN]
2021-11-19 17:08:45.285817 (Thread-1): 18:08:45 | 5 of 5 START incremental model sa_dm.fct_emissions................... [RUN]
2021-11-19 17:08:45.286231 (Thread-2): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:08:45.286447 (Thread-2): Compiling model.my_new_project.dim_issuer
2021-11-19 17:08:45.286704 (Thread-1): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:08:45.288979 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_issuer"
2021-11-19 17:08:45.289176 (Thread-1): Compiling model.my_new_project.fct_emissions
2021-11-19 17:08:45.291995 (Thread-1): Writing injected SQL for node "model.my_new_project.fct_emissions"
2021-11-19 17:08:45.292235 (Thread-2): finished collecting timing info
2021-11-19 17:08:45.293626 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_issuer"
2021-11-19 17:08:45.293869 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:08:45.294060 (Thread-2): On model.my_new_project.dim_issuer: BEGIN
2021-11-19 17:08:45.294180 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 17:08:45.294480 (Thread-1): finished collecting timing info
2021-11-19 17:08:45.296267 (Thread-1): Writing runtime SQL for node "model.my_new_project.fct_emissions"
2021-11-19 17:08:45.296617 (Thread-1): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:08:45.296758 (Thread-1): On model.my_new_project.fct_emissions: BEGIN
2021-11-19 17:08:45.296853 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 17:08:45.301326 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:08:45.301511 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:08:45.301608 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */


  create  table "demo_db"."sa_dm"."dim_issuer__dbt_tmp"
  as (
    

select distinct
     md5(iss.isin)              as dim_issuer_key
    ,iss.isin                   as isin
    ,iss.issuer_name            as issuer_name
    ,iss.gics_sector            as gics_sector
    ,iss.gics_industry_group    as gics_industry_group
from "demo_db"."sa_dwh"."iss_issuer" iss
  );
2021-11-19 17:08:45.303593 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:08:45.304039 (Thread-1): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:08:45.304174 (Thread-1): On model.my_new_project.fct_emissions: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.fct_emissions"} */

      

  create  table "demo_db"."sa_dm"."fct_emissions"
  as (
    


with fundamental_enterprise_value as (
    select
         iss.ISIN                                                    as isin
        ,'EnterpriseValue'                                           as fundamental
        ,climate_scope1_emissions / climate_scope1_emissions_int_usd as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

with fundamental_revenue as (
    select
         iss.ISIN                                                    as isin
        ,'Revenue'                                                   as fundamental
        ,adjusted_enterprise_value / 1e6                             as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

with fundamental_market_cap as (
    select
         iss.ISIN                                                    as isin
        ,iss.climate_emissions_fiscal_year
        ,'MarketCap'                                                 as fundamental
        ,market_cap_daily / 1e6                                      as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

with cte_union_tables as (
    select * from cte_fundamental_enterprise_value

    union

    select * from cte_fundamental_revenue

    union

    select * from cte_fundamental_market_cap
)

select
     md5(isin||)                            as fct_emissions_key
    ,md5(isin)                        as dim_issuer_key
    ,fundamental
    ,fundamental_value
    ,'2021-01-01'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from cte_union_tables
  );
  
2021-11-19 17:08:45.304716 (Thread-1): Postgres error: syntax error at or near "with"
LINE 18: with fundamental_revenue as (
         ^

2021-11-19 17:08:45.305022 (Thread-1): On model.my_new_project.fct_emissions: ROLLBACK
2021-11-19 17:08:45.305431 (Thread-1): finished collecting timing info
2021-11-19 17:08:45.305658 (Thread-1): On model.my_new_project.fct_emissions: Close
2021-11-19 17:08:45.305964 (Thread-1): Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
  syntax error at or near "with"
  LINE 18: with fundamental_revenue as (
           ^
  compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "with"
LINE 18: with fundamental_revenue as (
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
  syntax error at or near "with"
  LINE 18: with fundamental_revenue as (
           ^
  compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
2021-11-19 17:08:45.307177 (Thread-1): 18:08:45 | 5 of 5 ERROR creating incremental model sa_dm.fct_emissions.......... [ERROR in 0.02s]
2021-11-19 17:08:45.307334 (Thread-1): Finished running node model.my_new_project.fct_emissions
2021-11-19 17:08:45.352365 (Thread-2): SQL status: SELECT 28444 in 0.05 seconds
2021-11-19 17:08:45.354056 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:08:45.354165 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer__dbt_tmp" rename to "dim_issuer"
2021-11-19 17:08:45.354689 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 17:08:45.355606 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 17:08:45.355709 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:08:45.355796 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 17:08:45.360077 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:08:45.361497 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:08:45.361635 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
drop table if exists "demo_db"."sa_dm"."dim_issuer__dbt_backup" cascade
2021-11-19 17:08:45.362196 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-11-19 17:08:45.362973 (Thread-2): finished collecting timing info
2021-11-19 17:08:45.363102 (Thread-2): On model.my_new_project.dim_issuer: Close
2021-11-19 17:08:45.363491 (Thread-2): 18:08:45 | 4 of 5 OK created table model sa_dm.dim_issuer....................... [SELECT 28444 in 0.08s]
2021-11-19 17:08:45.363636 (Thread-2): Finished running node model.my_new_project.dim_issuer
2021-11-19 17:08:45.365149 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:08:45.365377 (MainThread): Using postgres connection "master".
2021-11-19 17:08:45.365510 (MainThread): On master: BEGIN
2021-11-19 17:08:45.365604 (MainThread): Opening a new connection, currently in state closed
2021-11-19 17:08:45.371754 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:08:45.371924 (MainThread): On master: COMMIT
2021-11-19 17:08:45.372016 (MainThread): Using postgres connection "master".
2021-11-19 17:08:45.372101 (MainThread): On master: COMMIT
2021-11-19 17:08:45.372405 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:08:45.372513 (MainThread): On master: Close
2021-11-19 17:08:45.372853 (MainThread): 18:08:45 | 
2021-11-19 17:08:45.372995 (MainThread): 18:08:45 | Finished running 2 table models, 1 view model, 2 incremental models in 0.40s.
2021-11-19 17:08:45.373117 (MainThread): Connection 'master' was properly closed.
2021-11-19 17:08:45.373252 (MainThread): Connection 'model.my_new_project.dim_issuer' was properly closed.
2021-11-19 17:08:45.373392 (MainThread): Connection 'model.my_new_project.fct_emissions' was properly closed.
2021-11-19 17:08:45.376807 (MainThread): 
2021-11-19 17:08:45.377018 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 17:08:45.377237 (MainThread): 
2021-11-19 17:08:45.377449 (MainThread): Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
2021-11-19 17:08:45.377649 (MainThread):   syntax error at or near "with"
2021-11-19 17:08:45.377808 (MainThread):   LINE 18: with fundamental_revenue as (
2021-11-19 17:08:45.377996 (MainThread):            ^
2021-11-19 17:08:45.378171 (MainThread):   compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
2021-11-19 17:08:45.378379 (MainThread): 
Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
2021-11-19 17:08:45.378673 (MainThread): Flushing usage events
2021-11-19 17:13:22.374700 (MainThread): Running with dbt=0.21.0
2021-11-19 17:13:22.428396 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 17:13:22.428831 (MainThread): Tracking: do not track
2021-11-19 17:13:22.438508 (MainThread): Partial parsing not enabled
2021-11-19 17:13:22.444518 (MainThread): Parsing macros/adapters.sql
2021-11-19 17:13:22.462368 (MainThread): Parsing macros/catalog.sql
2021-11-19 17:13:22.463966 (MainThread): Parsing macros/relations.sql
2021-11-19 17:13:22.464897 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 17:13:22.466256 (MainThread): Parsing macros/core.sql
2021-11-19 17:13:22.469084 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 17:13:22.509373 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 17:13:22.511273 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 17:13:22.512681 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 17:13:22.513869 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 17:13:22.520227 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 17:13:22.522206 (MainThread): Parsing macros/etc/query.sql
2021-11-19 17:13:22.523840 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 17:13:22.525914 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 17:13:22.533979 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 17:13:22.539462 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 17:13:22.556545 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 17:13:22.557809 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 17:13:22.580076 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 17:13:22.593714 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 17:13:22.608087 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 17:13:22.615943 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 17:13:22.617224 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 17:13:22.627543 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 17:13:22.630447 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 17:13:22.635780 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 17:13:22.641121 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 17:13:22.642271 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 17:13:22.643171 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 17:13:22.644433 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 17:13:22.798708 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:13:22.808376 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:13:22.810965 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:13:22.813265 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:13:22.813468 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:13:22.814336 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:13:22.817569 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:13:22.817765 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:13:22.818551 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:13:22.821351 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:13:22.821612 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:13:22.851294 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:13:22.852675 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:13:22.853978 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:13:22.855801 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:13:22.869648 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 17:13:22.869922 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-19 17:13:22.871350 (MainThread): 
2021-11-19 17:13:22.871765 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:13:22.872711 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:13:22.878318 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:13:22.882231 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 17:13:22.882621 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:13:22.884847 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 17:13:22.885063 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 17:13:22.885478 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:13:22.885866 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 17:13:22.893203 (ThreadPoolExecutor-0_1): SQL status: SELECT 17 in 0.01 seconds
2021-11-19 17:13:22.894264 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 17:13:22.894445 (ThreadPoolExecutor-0_0): SQL status: SELECT 17 in 0.01 seconds
2021-11-19 17:13:22.894879 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:13:22.895876 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 17:13:22.897002 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 17:13:22.897230 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:13:22.897390 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state closed
2021-11-19 17:13:22.903322 (ThreadPoolExecutor-0_1): SQL status: SELECT 17 in 0.01 seconds
2021-11-19 17:13:22.904129 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 17:13:22.905651 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 17:13:22.909660 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:13:22.909793 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: BEGIN
2021-11-19 17:13:22.909914 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 17:13:22.910509 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:13:22.911471 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:13:22.911593 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-19 17:13:22.911710 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 17:13:22.916725 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:13:22.916880 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:13:22.916971 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 17:13:22.918402 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:13:22.918596 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:13:22.918686 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 17:13:22.918930 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:13:22.919821 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 17:13:22.920066 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: Close
2021-11-19 17:13:22.920591 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 17:13:22.921662 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 17:13:22.922118 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:13:22.922400 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-19 17:13:22.923406 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 17:13:22.923595 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 17:13:22.924038 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-19 17:13:22.929540 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:13:22.929688 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 17:13:22.929779 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 17:13:22.931532 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2021-11-19 17:13:22.932444 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-19 17:13:22.932807 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-19 17:13:22.936163 (MainThread): Using postgres connection "master".
2021-11-19 17:13:22.936273 (MainThread): On master: BEGIN
2021-11-19 17:13:22.936370 (MainThread): Opening a new connection, currently in state init
2021-11-19 17:13:22.942330 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:13:22.942473 (MainThread): Using postgres connection "master".
2021-11-19 17:13:22.942562 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 17:13:22.946559 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:13:22.947459 (MainThread): On master: ROLLBACK
2021-11-19 17:13:22.947771 (MainThread): Using postgres connection "master".
2021-11-19 17:13:22.947867 (MainThread): On master: BEGIN
2021-11-19 17:13:22.948410 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 17:13:22.948567 (MainThread): On master: COMMIT
2021-11-19 17:13:22.948663 (MainThread): Using postgres connection "master".
2021-11-19 17:13:22.948747 (MainThread): On master: COMMIT
2021-11-19 17:13:22.949067 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:13:22.949175 (MainThread): On master: Close
2021-11-19 17:13:22.949530 (MainThread): 18:13:22 | Concurrency: 2 threads (target='dev')
2021-11-19 17:13:22.949724 (MainThread): 18:13:22 | 
2021-11-19 17:13:22.952492 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-19 17:13:22.952686 (Thread-2): Began running node model.my_new_project.my_first_dbt_model
2021-11-19 17:13:22.952954 (Thread-1): 18:13:22 | 1 of 5 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-19 17:13:22.953218 (Thread-2): 18:13:22 | 2 of 5 START table model sa.my_first_dbt_model....................... [RUN]
2021-11-19 17:13:22.953609 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:13:22.953944 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:13:22.954139 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-19 17:13:22.954323 (Thread-2): Compiling model.my_new_project.my_first_dbt_model
2021-11-19 17:13:22.957111 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-19 17:13:22.958647 (Thread-2): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 17:13:22.959184 (Thread-2): finished collecting timing info
2021-11-19 17:13:22.970105 (Thread-1): finished collecting timing info
2021-11-19 17:13:22.997026 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 17:13:23.013225 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:13:23.013563 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:13:23.013711 (Thread-2): On model.my_new_project.my_first_dbt_model: BEGIN
2021-11-19 17:13:23.013863 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

    

  create temporary table "iss_issuer__dbt_tmp181323006601"
  as (
    

select
     iss.AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,iss.ISIN                             as isin
    ,iss.IssuerName                       as issuer_name
    ,iss.gicssector                       as gics_sector
    ,iss.gicsindustrygroup                as gics_industry_group
    ,iss.ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,iss.ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,iss.ClimateScope2Emissions           as climate_scope2_emissions
    ,iss.ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,iss.ClimateScope3Emissions           as climate_scope3_emissions
    ,iss.ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,iss.ClimateTotalEmissions            as climate_total_emissions
    ,iss.ClimateScope1Emissions           as climate_scope1_emissions
    ,iss.MarketCapDaily                   as market_cap_daily
    ,iss.ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,'2021-01-01'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-19 17:13:23.014017 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 17:13:23.014159 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 17:13:23.020405 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:13:23.020588 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:13:23.020694 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table "demo_db"."sa"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)
with source_case as (

    select 1 as id , 'a' as name
    union all
    select 1 as id , 'b' as name

)

select s.id,n.name
from source_data s
inner join source_case n on n.id = s.id

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-11-19 17:13:23.021071 (Thread-2): Postgres error: syntax error at or near "with"
LINE 23: with source_case as (
         ^

2021-11-19 17:13:23.021212 (Thread-2): On model.my_new_project.my_first_dbt_model: ROLLBACK
2021-11-19 17:13:23.021614 (Thread-2): finished collecting timing info
2021-11-19 17:13:23.021787 (Thread-2): On model.my_new_project.my_first_dbt_model: Close
2021-11-19 17:13:23.022109 (Thread-2): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  syntax error at or near "with"
  LINE 23: with source_case as (
           ^
  compiled SQL at target/run/my_new_project/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "with"
LINE 23: with source_case as (
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 70, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  syntax error at or near "with"
  LINE 23: with source_case as (
           ^
  compiled SQL at target/run/my_new_project/models/example/my_first_dbt_model.sql
2021-11-19 17:13:23.023579 (Thread-2): 18:13:23 | 2 of 5 ERROR creating table model sa.my_first_dbt_model.............. [ERROR in 0.07s]
2021-11-19 17:13:23.023759 (Thread-2): Finished running node model.my_new_project.my_first_dbt_model
2021-11-19 17:13:23.024264 (Thread-2): Began running node model.my_new_project.my_second_dbt_model
2021-11-19 17:13:23.024430 (Thread-2): 18:13:23 | 3 of 5 SKIP relation sa.my_second_dbt_model.......................... [SKIP]
2021-11-19 17:13:23.024622 (Thread-2): Finished running node model.my_new_project.my_second_dbt_model
2021-11-19 17:13:23.158360 (Thread-1): SQL status: SELECT 28444 in 0.14 seconds
2021-11-19 17:13:23.165241 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:13:23.165447 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-19 17:13:23.166022 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-11-19 17:13:23.166148 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:13:23.166245 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer__dbt_tmp181323006601'
        
      order by ordinal_position

  
2021-11-19 17:13:23.170993 (Thread-1): SQL status: SELECT 18 in 0.00 seconds
2021-11-19 17:13:23.175274 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:13:23.175448 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-19 17:13:23.177749 (Thread-1): SQL status: SELECT 18 in 0.00 seconds
2021-11-19 17:13:23.185231 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:13:23.185444 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-19 17:13:23.187599 (Thread-1): SQL status: SELECT 18 in 0.00 seconds
2021-11-19 17:13:23.189149 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-19 17:13:23.189403 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:13:23.189504 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      delete
    from "demo_db"."sa_dwh"."iss_issuer"
    where (ISIN) in (
        select (ISIN)
        from "iss_issuer__dbt_tmp181323006601"
    );

    insert into "demo_db"."sa_dwh"."iss_issuer" ("adjusted_enterprise_value", "isin", "issuer_name", "gics_sector", "gics_industry_group", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_cap_daily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp")
    (
       select "adjusted_enterprise_value", "isin", "issuer_name", "gics_sector", "gics_industry_group", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_cap_daily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp"
       from "iss_issuer__dbt_tmp181323006601"
    );
  
2021-11-19 17:13:23.252721 (Thread-1): SQL status: INSERT 0 28444 in 0.06 seconds
2021-11-19 17:13:23.257868 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 17:13:23.257998 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:13:23.258094 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 17:13:23.279394 (Thread-1): SQL status: COMMIT in 0.02 seconds
2021-11-19 17:13:23.279867 (Thread-1): finished collecting timing info
2021-11-19 17:13:23.280007 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-19 17:13:23.280403 (Thread-1): 18:13:23 | 1 of 5 OK created incremental model sa_dwh.iss_issuer................ [INSERT 0 28444 in 0.33s]
2021-11-19 17:13:23.280577 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-19 17:13:23.281291 (Thread-2): Began running node model.my_new_project.dim_issuer
2021-11-19 17:13:23.281452 (Thread-1): Began running node model.my_new_project.fct_emissions
2021-11-19 17:13:23.281683 (Thread-2): 18:13:23 | 4 of 5 START table model sa_dm.dim_issuer............................ [RUN]
2021-11-19 17:13:23.281895 (Thread-1): 18:13:23 | 5 of 5 START incremental model sa_dm.fct_emissions................... [RUN]
2021-11-19 17:13:23.282316 (Thread-2): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:13:23.282657 (Thread-1): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:13:23.282813 (Thread-2): Compiling model.my_new_project.dim_issuer
2021-11-19 17:13:23.282976 (Thread-1): Compiling model.my_new_project.fct_emissions
2021-11-19 17:13:23.285382 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_issuer"
2021-11-19 17:13:23.288440 (Thread-1): Writing injected SQL for node "model.my_new_project.fct_emissions"
2021-11-19 17:13:23.288988 (Thread-2): finished collecting timing info
2021-11-19 17:13:23.290518 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_issuer"
2021-11-19 17:13:23.290688 (Thread-1): finished collecting timing info
2021-11-19 17:13:23.293665 (Thread-1): Writing runtime SQL for node "model.my_new_project.fct_emissions"
2021-11-19 17:13:23.294005 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:13:23.294254 (Thread-2): On model.my_new_project.dim_issuer: BEGIN
2021-11-19 17:13:23.294444 (Thread-1): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:13:23.294622 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 17:13:23.294757 (Thread-1): On model.my_new_project.fct_emissions: BEGIN
2021-11-19 17:13:23.295040 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 17:13:23.301074 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:13:23.301323 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:13:23.301509 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:13:23.301650 (Thread-1): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:13:23.301784 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */


  create  table "demo_db"."sa_dm"."dim_issuer__dbt_tmp"
  as (
    

select distinct
     md5(iss.isin)              as dim_issuer_key
    ,iss.isin                   as isin
    ,iss.issuer_name            as issuer_name
    ,iss.gics_sector            as gics_sector
    ,iss.gics_industry_group    as gics_industry_group
from "demo_db"."sa_dwh"."iss_issuer" iss
  );
2021-11-19 17:13:23.301918 (Thread-1): On model.my_new_project.fct_emissions: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.fct_emissions"} */

      

  create  table "demo_db"."sa_dm"."fct_emissions"
  as (
    


with cte_fundamental_enterprise_value as (
    select
         iss.isin                                                    as isin
        ,'EnterpriseValue'                                           as fundamental
        ,climate_scope1_emissions / climate_scope1_emissions_int_usd as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

with cte_fundamental_revenue as (
    select
         iss.ISIN                                                    as isin
        ,'Revenue'                                                   as fundamental
        ,adjusted_enterprise_value / 1e6                             as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

with cte_fundamental_market_cap as (
    select
         iss.ISIN                                                    as isin
        ,iss.climate_emissions_fiscal_year
        ,'MarketCap'                                                 as fundamental
        ,market_cap_daily / 1e6                                      as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

with cte_union_tables as (
    select * from cte_fundamental_enterprise_value

    union

    select * from cte_fundamental_revenue

    union

    select * from cte_fundamental_market_cap
)

select
     md5(isin||)                            as fct_emissions_key
    ,md5(isin)                        as dim_issuer_key
    ,fundamental
    ,fundamental_value
    ,'2021-01-01'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from cte_union_tables
  );
  
2021-11-19 17:13:23.302400 (Thread-1): Postgres error: syntax error at or near "with"
LINE 18: with cte_fundamental_revenue as (
         ^

2021-11-19 17:13:23.302548 (Thread-1): On model.my_new_project.fct_emissions: ROLLBACK
2021-11-19 17:13:23.302900 (Thread-1): finished collecting timing info
2021-11-19 17:13:23.303042 (Thread-1): On model.my_new_project.fct_emissions: Close
2021-11-19 17:13:23.303346 (Thread-1): Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
  syntax error at or near "with"
  LINE 18: with cte_fundamental_revenue as (
           ^
  compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "with"
LINE 18: with cte_fundamental_revenue as (
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
  syntax error at or near "with"
  LINE 18: with cte_fundamental_revenue as (
           ^
  compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
2021-11-19 17:13:23.304351 (Thread-1): 18:13:23 | 5 of 5 ERROR creating incremental model sa_dm.fct_emissions.......... [ERROR in 0.02s]
2021-11-19 17:13:23.304540 (Thread-1): Finished running node model.my_new_project.fct_emissions
2021-11-19 17:13:23.367770 (Thread-2): SQL status: SELECT 28444 in 0.07 seconds
2021-11-19 17:13:23.372048 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:13:23.372168 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer" rename to "dim_issuer__dbt_backup"
2021-11-19 17:13:23.372719 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 17:13:23.374099 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:13:23.374202 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer__dbt_tmp" rename to "dim_issuer"
2021-11-19 17:13:23.374751 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 17:13:23.379520 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 17:13:23.379727 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:13:23.379818 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 17:13:23.381003 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:13:23.384272 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:13:23.384377 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
drop table if exists "demo_db"."sa_dm"."dim_issuer__dbt_backup" cascade
2021-11-19 17:13:23.386483 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-11-19 17:13:23.387232 (Thread-2): finished collecting timing info
2021-11-19 17:13:23.387356 (Thread-2): On model.my_new_project.dim_issuer: Close
2021-11-19 17:13:23.387699 (Thread-2): 18:13:23 | 4 of 5 OK created table model sa_dm.dim_issuer....................... [SELECT 28444 in 0.11s]
2021-11-19 17:13:23.387878 (Thread-2): Finished running node model.my_new_project.dim_issuer
2021-11-19 17:13:23.389513 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:13:23.389683 (MainThread): Using postgres connection "master".
2021-11-19 17:13:23.389795 (MainThread): On master: BEGIN
2021-11-19 17:13:23.389891 (MainThread): Opening a new connection, currently in state closed
2021-11-19 17:13:23.395428 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:13:23.395551 (MainThread): On master: COMMIT
2021-11-19 17:13:23.395642 (MainThread): Using postgres connection "master".
2021-11-19 17:13:23.395728 (MainThread): On master: COMMIT
2021-11-19 17:13:23.396129 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:13:23.396252 (MainThread): On master: Close
2021-11-19 17:13:23.396620 (MainThread): 18:13:23 | 
2021-11-19 17:13:23.396759 (MainThread): 18:13:23 | Finished running 2 table models, 1 view model, 2 incremental models in 0.53s.
2021-11-19 17:13:23.396970 (MainThread): Connection 'master' was properly closed.
2021-11-19 17:13:23.397125 (MainThread): Connection 'model.my_new_project.dim_issuer' was properly closed.
2021-11-19 17:13:23.397282 (MainThread): Connection 'model.my_new_project.fct_emissions' was properly closed.
2021-11-19 17:13:23.400200 (MainThread): 
2021-11-19 17:13:23.400341 (MainThread): Completed with 2 errors and 0 warnings:
2021-11-19 17:13:23.400537 (MainThread): 
2021-11-19 17:13:23.400745 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-11-19 17:13:23.400939 (MainThread):   syntax error at or near "with"
2021-11-19 17:13:23.401076 (MainThread):   LINE 23: with source_case as (
2021-11-19 17:13:23.401351 (MainThread):            ^
2021-11-19 17:13:23.401552 (MainThread):   compiled SQL at target/run/my_new_project/models/example/my_first_dbt_model.sql
2021-11-19 17:13:23.401749 (MainThread): 
2021-11-19 17:13:23.401971 (MainThread): Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
2021-11-19 17:13:23.402217 (MainThread):   syntax error at or near "with"
2021-11-19 17:13:23.402440 (MainThread):   LINE 18: with cte_fundamental_revenue as (
2021-11-19 17:13:23.402644 (MainThread):            ^
2021-11-19 17:13:23.402818 (MainThread):   compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
2021-11-19 17:13:23.402990 (MainThread): 
Done. PASS=2 WARN=0 ERROR=2 SKIP=1 TOTAL=5
2021-11-19 17:13:23.403209 (MainThread): Flushing usage events
2021-11-19 17:13:37.648631 (MainThread): Running with dbt=0.21.0
2021-11-19 17:13:37.704926 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 17:13:37.705529 (MainThread): Tracking: do not track
2021-11-19 17:13:37.715654 (MainThread): Partial parsing not enabled
2021-11-19 17:13:37.721938 (MainThread): Parsing macros/adapters.sql
2021-11-19 17:13:37.740141 (MainThread): Parsing macros/catalog.sql
2021-11-19 17:13:37.741923 (MainThread): Parsing macros/relations.sql
2021-11-19 17:13:37.742876 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 17:13:37.744143 (MainThread): Parsing macros/core.sql
2021-11-19 17:13:37.747117 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 17:13:37.788897 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 17:13:37.790947 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 17:13:37.792355 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 17:13:37.793570 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 17:13:37.800214 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 17:13:37.801325 (MainThread): Parsing macros/etc/query.sql
2021-11-19 17:13:37.802047 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 17:13:37.803143 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 17:13:37.810414 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 17:13:37.815829 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 17:13:37.832797 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 17:13:37.834040 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 17:13:37.856348 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 17:13:37.870543 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 17:13:37.886542 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 17:13:37.894604 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 17:13:37.896005 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 17:13:37.906199 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 17:13:37.909482 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 17:13:37.914691 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 17:13:37.920342 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 17:13:37.921401 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 17:13:37.922474 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 17:13:37.923709 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 17:13:38.084569 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:13:38.098093 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:13:38.101594 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:13:38.104185 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:13:38.104406 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:13:38.105388 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:13:38.108957 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:13:38.109189 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:13:38.110061 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:13:38.113312 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:13:38.113546 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:13:38.142712 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:13:38.144171 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:13:38.145519 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:13:38.146993 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:13:38.160950 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 17:13:38.161242 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-19 17:13:38.162514 (MainThread): 
2021-11-19 17:13:38.162795 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:13:38.163667 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:13:38.169193 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:13:38.173991 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 17:13:38.174243 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:13:38.176928 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 17:13:38.177152 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 17:13:38.177610 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:13:38.178082 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 17:13:38.184413 (ThreadPoolExecutor-0_0): SQL status: SELECT 19 in 0.01 seconds
2021-11-19 17:13:38.185589 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 17:13:38.185725 (ThreadPoolExecutor-0_1): SQL status: SELECT 19 in 0.01 seconds
2021-11-19 17:13:38.186657 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 17:13:38.187052 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:13:38.188410 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 17:13:38.188602 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:13:38.188714 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-11-19 17:13:38.194371 (ThreadPoolExecutor-0_0): SQL status: SELECT 19 in 0.01 seconds
2021-11-19 17:13:38.195346 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 17:13:38.196570 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:13:38.200947 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:13:38.201244 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 17:13:38.201384 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: BEGIN
2021-11-19 17:13:38.202424 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-19 17:13:38.202588 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 17:13:38.202736 (ThreadPoolExecutor-1_1): On list_demo_db_sa: BEGIN
2021-11-19 17:13:38.203002 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 17:13:38.209472 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:13:38.209751 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:13:38.209890 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 17:13:38.210128 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:13:38.210255 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-19 17:13:38.210351 (ThreadPoolExecutor-1_1): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 17:13:38.211626 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:13:38.212561 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 17:13:38.212724 (ThreadPoolExecutor-1_1): SQL status: SELECT 3 in 0.00 seconds
2021-11-19 17:13:38.213737 (ThreadPoolExecutor-1_1): On list_demo_db_sa: ROLLBACK
2021-11-19 17:13:38.213989 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: Close
2021-11-19 17:13:38.214146 (ThreadPoolExecutor-1_1): On list_demo_db_sa: Close
2021-11-19 17:13:38.214749 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 17:13:38.216133 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:13:38.216483 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: BEGIN
2021-11-19 17:13:38.216612 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 17:13:38.222194 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:13:38.222336 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:13:38.222482 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 17:13:38.224089 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:13:38.224943 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 17:13:38.225328 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: Close
2021-11-19 17:13:38.228740 (MainThread): Using postgres connection "master".
2021-11-19 17:13:38.228849 (MainThread): On master: BEGIN
2021-11-19 17:13:38.228946 (MainThread): Opening a new connection, currently in state init
2021-11-19 17:13:38.234398 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:13:38.234604 (MainThread): Using postgres connection "master".
2021-11-19 17:13:38.234692 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 17:13:38.238917 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:13:38.239828 (MainThread): On master: ROLLBACK
2021-11-19 17:13:38.240208 (MainThread): Using postgres connection "master".
2021-11-19 17:13:38.240311 (MainThread): On master: BEGIN
2021-11-19 17:13:38.241039 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 17:13:38.241185 (MainThread): On master: COMMIT
2021-11-19 17:13:38.241277 (MainThread): Using postgres connection "master".
2021-11-19 17:13:38.241360 (MainThread): On master: COMMIT
2021-11-19 17:13:38.241673 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:13:38.241793 (MainThread): On master: Close
2021-11-19 17:13:38.242053 (MainThread): 18:13:38 | Concurrency: 2 threads (target='dev')
2021-11-19 17:13:38.242224 (MainThread): 18:13:38 | 
2021-11-19 17:13:38.244776 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-19 17:13:38.244980 (Thread-2): Began running node model.my_new_project.my_first_dbt_model
2021-11-19 17:13:38.245334 (Thread-1): 18:13:38 | 1 of 5 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-19 17:13:38.245580 (Thread-2): 18:13:38 | 2 of 5 START table model sa.my_first_dbt_model....................... [RUN]
2021-11-19 17:13:38.246742 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:13:38.246992 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:13:38.247225 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-19 17:13:38.247370 (Thread-2): Compiling model.my_new_project.my_first_dbt_model
2021-11-19 17:13:38.249808 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-19 17:13:38.251259 (Thread-2): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 17:13:38.251668 (Thread-2): finished collecting timing info
2021-11-19 17:13:38.257058 (Thread-1): finished collecting timing info
2021-11-19 17:13:38.286649 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 17:13:38.287034 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:13:38.287164 (Thread-2): On model.my_new_project.my_first_dbt_model: BEGIN
2021-11-19 17:13:38.287292 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 17:13:38.300102 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:13:38.300260 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

    

  create temporary table "iss_issuer__dbt_tmp181338293933"
  as (
    

select
     iss.AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,iss.ISIN                             as isin
    ,iss.IssuerName                       as issuer_name
    ,iss.gicssector                       as gics_sector
    ,iss.gicsindustrygroup                as gics_industry_group
    ,iss.ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,iss.ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,iss.ClimateScope2Emissions           as climate_scope2_emissions
    ,iss.ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,iss.ClimateScope3Emissions           as climate_scope3_emissions
    ,iss.ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,iss.ClimateTotalEmissions            as climate_total_emissions
    ,iss.ClimateScope1Emissions           as climate_scope1_emissions
    ,iss.MarketCapDaily                   as market_cap_daily
    ,iss.ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,'2021-01-01'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-19 17:13:38.300397 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 17:13:38.300653 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:13:38.300777 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:13:38.300871 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table "demo_db"."sa"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)
;with source_case as (

    select 1 as id , 'a' as name
    union all
    select 1 as id , 'b' as name

)

select s.id,n.name
from source_data s
inner join source_case n on n.id = s.id

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-11-19 17:13:38.301400 (Thread-2): Postgres error: syntax error at or near ";"
LINE 23: ;with source_case as (
         ^

2021-11-19 17:13:38.301544 (Thread-2): On model.my_new_project.my_first_dbt_model: ROLLBACK
2021-11-19 17:13:38.301950 (Thread-2): finished collecting timing info
2021-11-19 17:13:38.302089 (Thread-2): On model.my_new_project.my_first_dbt_model: Close
2021-11-19 17:13:38.302402 (Thread-2): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  syntax error at or near ";"
  LINE 23: ;with source_case as (
           ^
  compiled SQL at target/run/my_new_project/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near ";"
LINE 23: ;with source_case as (
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 70, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  syntax error at or near ";"
  LINE 23: ;with source_case as (
           ^
  compiled SQL at target/run/my_new_project/models/example/my_first_dbt_model.sql
2021-11-19 17:13:38.303731 (Thread-2): 18:13:38 | 2 of 5 ERROR creating table model sa.my_first_dbt_model.............. [ERROR in 0.06s]
2021-11-19 17:13:38.303923 (Thread-2): Finished running node model.my_new_project.my_first_dbt_model
2021-11-19 17:13:38.304601 (Thread-2): Began running node model.my_new_project.my_second_dbt_model
2021-11-19 17:13:38.304802 (Thread-2): 18:13:38 | 3 of 5 SKIP relation sa.my_second_dbt_model.......................... [SKIP]
2021-11-19 17:13:38.304990 (Thread-2): Finished running node model.my_new_project.my_second_dbt_model
2021-11-19 17:13:38.415172 (Thread-1): SQL status: SELECT 28444 in 0.11 seconds
2021-11-19 17:13:38.420478 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:13:38.420594 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-19 17:13:38.421079 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-11-19 17:13:38.421249 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:13:38.421338 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer__dbt_tmp181338293933'
        
      order by ordinal_position

  
2021-11-19 17:13:38.425728 (Thread-1): SQL status: SELECT 18 in 0.00 seconds
2021-11-19 17:13:38.429346 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:13:38.429458 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-19 17:13:38.431999 (Thread-1): SQL status: SELECT 18 in 0.00 seconds
2021-11-19 17:13:38.439653 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:13:38.439773 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-19 17:13:38.441829 (Thread-1): SQL status: SELECT 18 in 0.00 seconds
2021-11-19 17:13:38.443157 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-19 17:13:38.443383 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:13:38.443477 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      delete
    from "demo_db"."sa_dwh"."iss_issuer"
    where (ISIN) in (
        select (ISIN)
        from "iss_issuer__dbt_tmp181338293933"
    );

    insert into "demo_db"."sa_dwh"."iss_issuer" ("adjusted_enterprise_value", "isin", "issuer_name", "gics_sector", "gics_industry_group", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_cap_daily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp")
    (
       select "adjusted_enterprise_value", "isin", "issuer_name", "gics_sector", "gics_industry_group", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_cap_daily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp"
       from "iss_issuer__dbt_tmp181338293933"
    );
  
2021-11-19 17:13:38.497347 (Thread-1): SQL status: INSERT 0 28444 in 0.05 seconds
2021-11-19 17:13:38.502084 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 17:13:38.502194 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:13:38.502281 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 17:13:38.516113 (Thread-1): SQL status: COMMIT in 0.01 seconds
2021-11-19 17:13:38.516601 (Thread-1): finished collecting timing info
2021-11-19 17:13:38.516749 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-19 17:13:38.517154 (Thread-1): 18:13:38 | 1 of 5 OK created incremental model sa_dwh.iss_issuer................ [INSERT 0 28444 in 0.27s]
2021-11-19 17:13:38.517314 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-19 17:13:38.518145 (Thread-2): Began running node model.my_new_project.dim_issuer
2021-11-19 17:13:38.518431 (Thread-2): 18:13:38 | 4 of 5 START table model sa_dm.dim_issuer............................ [RUN]
2021-11-19 17:13:38.518599 (Thread-1): Began running node model.my_new_project.fct_emissions
2021-11-19 17:13:38.518959 (Thread-2): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:13:38.519167 (Thread-1): 18:13:38 | 5 of 5 START incremental model sa_dm.fct_emissions................... [RUN]
2021-11-19 17:13:38.519337 (Thread-2): Compiling model.my_new_project.dim_issuer
2021-11-19 17:13:38.519641 (Thread-1): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:13:38.521975 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_issuer"
2021-11-19 17:13:38.522164 (Thread-1): Compiling model.my_new_project.fct_emissions
2021-11-19 17:13:38.525504 (Thread-1): Writing injected SQL for node "model.my_new_project.fct_emissions"
2021-11-19 17:13:38.526083 (Thread-2): finished collecting timing info
2021-11-19 17:13:38.528098 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_issuer"
2021-11-19 17:13:38.528477 (Thread-1): finished collecting timing info
2021-11-19 17:13:38.531200 (Thread-1): Writing runtime SQL for node "model.my_new_project.fct_emissions"
2021-11-19 17:13:38.531378 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:13:38.531611 (Thread-2): On model.my_new_project.dim_issuer: BEGIN
2021-11-19 17:13:38.531744 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 17:13:38.532067 (Thread-1): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:13:38.532169 (Thread-1): On model.my_new_project.fct_emissions: BEGIN
2021-11-19 17:13:38.532289 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 17:13:38.537430 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:13:38.537644 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:13:38.537795 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:13:38.537938 (Thread-1): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:13:38.538125 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */


  create  table "demo_db"."sa_dm"."dim_issuer__dbt_tmp"
  as (
    

select distinct
     md5(iss.isin)              as dim_issuer_key
    ,iss.isin                   as isin
    ,iss.issuer_name            as issuer_name
    ,iss.gics_sector            as gics_sector
    ,iss.gics_industry_group    as gics_industry_group
from "demo_db"."sa_dwh"."iss_issuer" iss
  );
2021-11-19 17:13:38.538267 (Thread-1): On model.my_new_project.fct_emissions: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.fct_emissions"} */

      

  create  table "demo_db"."sa_dm"."fct_emissions"
  as (
    


with cte_fundamental_enterprise_value as (
    select
         iss.isin                                                    as isin
        ,'EnterpriseValue'                                           as fundamental
        ,climate_scope1_emissions / climate_scope1_emissions_int_usd as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

with cte_fundamental_revenue as (
    select
         iss.ISIN                                                    as isin
        ,'Revenue'                                                   as fundamental
        ,adjusted_enterprise_value / 1e6                             as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

with cte_fundamental_market_cap as (
    select
         iss.ISIN                                                    as isin
        ,iss.climate_emissions_fiscal_year
        ,'MarketCap'                                                 as fundamental
        ,market_cap_daily / 1e6                                      as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

with cte_union_tables as (
    select * from cte_fundamental_enterprise_value

    union

    select * from cte_fundamental_revenue

    union

    select * from cte_fundamental_market_cap
)

select
     md5(isin||)                            as fct_emissions_key
    ,md5(isin)                        as dim_issuer_key
    ,fundamental
    ,fundamental_value
    ,'2021-01-01'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from cte_union_tables
  );
  
2021-11-19 17:13:38.538721 (Thread-1): Postgres error: syntax error at or near "with"
LINE 18: with cte_fundamental_revenue as (
         ^

2021-11-19 17:13:38.538850 (Thread-1): On model.my_new_project.fct_emissions: ROLLBACK
2021-11-19 17:13:38.539161 (Thread-1): finished collecting timing info
2021-11-19 17:13:38.539302 (Thread-1): On model.my_new_project.fct_emissions: Close
2021-11-19 17:13:38.539638 (Thread-1): Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
  syntax error at or near "with"
  LINE 18: with cte_fundamental_revenue as (
           ^
  compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "with"
LINE 18: with cte_fundamental_revenue as (
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
  syntax error at or near "with"
  LINE 18: with cte_fundamental_revenue as (
           ^
  compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
2021-11-19 17:13:38.540174 (Thread-1): 18:13:38 | 5 of 5 ERROR creating incremental model sa_dm.fct_emissions.......... [ERROR in 0.02s]
2021-11-19 17:13:38.540396 (Thread-1): Finished running node model.my_new_project.fct_emissions
2021-11-19 17:13:38.602472 (Thread-2): SQL status: SELECT 28444 in 0.06 seconds
2021-11-19 17:13:38.607002 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:13:38.607140 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer" rename to "dim_issuer__dbt_backup"
2021-11-19 17:13:38.607783 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 17:13:38.609304 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:13:38.609408 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer__dbt_tmp" rename to "dim_issuer"
2021-11-19 17:13:38.609960 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 17:13:38.613468 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 17:13:38.613573 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:13:38.613661 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 17:13:38.621095 (Thread-2): SQL status: COMMIT in 0.01 seconds
2021-11-19 17:13:38.624791 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:13:38.624923 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
drop table if exists "demo_db"."sa_dm"."dim_issuer__dbt_backup" cascade
2021-11-19 17:13:38.627284 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-11-19 17:13:38.628072 (Thread-2): finished collecting timing info
2021-11-19 17:13:38.628201 (Thread-2): On model.my_new_project.dim_issuer: Close
2021-11-19 17:13:38.628627 (Thread-2): 18:13:38 | 4 of 5 OK created table model sa_dm.dim_issuer....................... [SELECT 28444 in 0.11s]
2021-11-19 17:13:38.628770 (Thread-2): Finished running node model.my_new_project.dim_issuer
2021-11-19 17:13:38.630279 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:13:38.630489 (MainThread): Using postgres connection "master".
2021-11-19 17:13:38.630621 (MainThread): On master: BEGIN
2021-11-19 17:13:38.630716 (MainThread): Opening a new connection, currently in state closed
2021-11-19 17:13:38.636332 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:13:38.636547 (MainThread): On master: COMMIT
2021-11-19 17:13:38.636637 (MainThread): Using postgres connection "master".
2021-11-19 17:13:38.636720 (MainThread): On master: COMMIT
2021-11-19 17:13:38.637020 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:13:38.637141 (MainThread): On master: Close
2021-11-19 17:13:38.637467 (MainThread): 18:13:38 | 
2021-11-19 17:13:38.637605 (MainThread): 18:13:38 | Finished running 2 table models, 1 view model, 2 incremental models in 0.47s.
2021-11-19 17:13:38.637781 (MainThread): Connection 'master' was properly closed.
2021-11-19 17:13:38.637978 (MainThread): Connection 'model.my_new_project.fct_emissions' was properly closed.
2021-11-19 17:13:38.638140 (MainThread): Connection 'model.my_new_project.dim_issuer' was properly closed.
2021-11-19 17:13:38.642043 (MainThread): 
2021-11-19 17:13:38.642299 (MainThread): Completed with 2 errors and 0 warnings:
2021-11-19 17:13:38.642433 (MainThread): 
2021-11-19 17:13:38.642569 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-11-19 17:13:38.642700 (MainThread):   syntax error at or near ";"
2021-11-19 17:13:38.642823 (MainThread):   LINE 23: ;with source_case as (
2021-11-19 17:13:38.642945 (MainThread):            ^
2021-11-19 17:13:38.643067 (MainThread):   compiled SQL at target/run/my_new_project/models/example/my_first_dbt_model.sql
2021-11-19 17:13:38.643195 (MainThread): 
2021-11-19 17:13:38.643326 (MainThread): Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
2021-11-19 17:13:38.643451 (MainThread):   syntax error at or near "with"
2021-11-19 17:13:38.643571 (MainThread):   LINE 18: with cte_fundamental_revenue as (
2021-11-19 17:13:38.643690 (MainThread):            ^
2021-11-19 17:13:38.643810 (MainThread):   compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
2021-11-19 17:13:38.643942 (MainThread): 
Done. PASS=2 WARN=0 ERROR=2 SKIP=1 TOTAL=5
2021-11-19 17:13:38.644128 (MainThread): Flushing usage events
2021-11-19 17:14:09.450368 (MainThread): Running with dbt=0.21.0
2021-11-19 17:14:09.504540 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 17:14:09.504909 (MainThread): Tracking: do not track
2021-11-19 17:14:09.514770 (MainThread): Partial parsing not enabled
2021-11-19 17:14:09.521060 (MainThread): Parsing macros/adapters.sql
2021-11-19 17:14:09.539280 (MainThread): Parsing macros/catalog.sql
2021-11-19 17:14:09.541020 (MainThread): Parsing macros/relations.sql
2021-11-19 17:14:09.542035 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 17:14:09.543261 (MainThread): Parsing macros/core.sql
2021-11-19 17:14:09.546148 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 17:14:09.586553 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 17:14:09.588404 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 17:14:09.589776 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 17:14:09.591035 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 17:14:09.597409 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 17:14:09.598522 (MainThread): Parsing macros/etc/query.sql
2021-11-19 17:14:09.599248 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 17:14:09.600364 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 17:14:09.607882 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 17:14:09.612943 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 17:14:09.629732 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 17:14:09.630954 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 17:14:09.653337 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 17:14:09.666969 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 17:14:09.681601 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 17:14:09.689227 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 17:14:09.690600 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 17:14:09.700400 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 17:14:09.703320 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 17:14:09.708932 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 17:14:09.714275 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 17:14:09.715349 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 17:14:09.716249 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 17:14:09.717465 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 17:14:09.876207 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:14:09.885819 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:14:09.888468 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:09.891065 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:09.891277 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:09.892072 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:14:09.895290 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:09.895493 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:09.896280 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:09.899096 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:09.899330 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:09.925196 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:09.926628 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:09.928009 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:09.929478 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:09.943340 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 17:14:09.943630 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-19 17:14:09.945139 (MainThread): 
2021-11-19 17:14:09.945462 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:14:09.946390 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:14:09.953260 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 17:14:09.953383 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:14:09.953500 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 17:14:09.953983 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:14:09.955179 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 17:14:09.955435 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:14:09.955587 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 17:14:09.962330 (ThreadPoolExecutor-0_0): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 17:14:09.963418 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 17:14:09.964206 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:14:09.965516 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 17:14:09.965867 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:14:09.966353 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-11-19 17:14:09.966631 (ThreadPoolExecutor-0_1): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 17:14:09.967828 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 17:14:09.973142 (ThreadPoolExecutor-0_0): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 17:14:09.974013 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 17:14:09.975411 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:14:09.979595 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:14:09.979767 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: BEGIN
2021-11-19 17:14:09.979956 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 17:14:09.980777 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 17:14:09.981985 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:14:09.982379 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: BEGIN
2021-11-19 17:14:09.982511 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 17:14:09.986895 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:09.987083 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:14:09.987171 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 17:14:09.988746 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:09.988942 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:14:09.989124 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 17:14:09.989317 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:14:09.990420 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 17:14:09.990823 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: Close
2021-11-19 17:14:09.991526 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 17:14:09.991883 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:14:09.992961 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 17:14:09.993932 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 17:14:09.994147 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-19 17:14:09.994426 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 17:14:09.994711 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: Close
2021-11-19 17:14:09.999989 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:10.000131 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 17:14:10.000219 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 17:14:10.001691 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2021-11-19 17:14:10.002555 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-19 17:14:10.002877 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-19 17:14:10.006536 (MainThread): Using postgres connection "master".
2021-11-19 17:14:10.006658 (MainThread): On master: BEGIN
2021-11-19 17:14:10.006756 (MainThread): Opening a new connection, currently in state init
2021-11-19 17:14:10.012597 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:10.012729 (MainThread): Using postgres connection "master".
2021-11-19 17:14:10.012816 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 17:14:10.016842 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:14:10.017708 (MainThread): On master: ROLLBACK
2021-11-19 17:14:10.018164 (MainThread): Using postgres connection "master".
2021-11-19 17:14:10.018269 (MainThread): On master: BEGIN
2021-11-19 17:14:10.018970 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 17:14:10.019115 (MainThread): On master: COMMIT
2021-11-19 17:14:10.019207 (MainThread): Using postgres connection "master".
2021-11-19 17:14:10.019291 (MainThread): On master: COMMIT
2021-11-19 17:14:10.019607 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:14:10.019726 (MainThread): On master: Close
2021-11-19 17:14:10.020018 (MainThread): 18:14:10 | Concurrency: 2 threads (target='dev')
2021-11-19 17:14:10.020158 (MainThread): 18:14:10 | 
2021-11-19 17:14:10.023629 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-19 17:14:10.023893 (Thread-1): 18:14:10 | 1 of 5 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-19 17:14:10.024170 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:10.024316 (Thread-2): Began running node model.my_new_project.my_first_dbt_model
2021-11-19 17:14:10.024522 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-19 17:14:10.024725 (Thread-2): 18:14:10 | 2 of 5 START table model sa.my_first_dbt_model....................... [RUN]
2021-11-19 17:14:10.027448 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-19 17:14:10.027724 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:14:10.027994 (Thread-2): Compiling model.my_new_project.my_first_dbt_model
2021-11-19 17:14:10.029424 (Thread-2): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 17:14:10.029688 (Thread-1): finished collecting timing info
2021-11-19 17:14:10.040212 (Thread-2): finished collecting timing info
2021-11-19 17:14:10.076569 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 17:14:10.079923 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:10.080065 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

    

  create temporary table "iss_issuer__dbt_tmp181410068467"
  as (
    

select
     iss.AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,iss.ISIN                             as isin
    ,iss.IssuerName                       as issuer_name
    ,iss.gicssector                       as gics_sector
    ,iss.gicsindustrygroup                as gics_industry_group
    ,iss.ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,iss.ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,iss.ClimateScope2Emissions           as climate_scope2_emissions
    ,iss.ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,iss.ClimateScope3Emissions           as climate_scope3_emissions
    ,iss.ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,iss.ClimateTotalEmissions            as climate_total_emissions
    ,iss.ClimateScope1Emissions           as climate_scope1_emissions
    ,iss.MarketCapDaily                   as market_cap_daily
    ,iss.ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,'2021-01-01'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-19 17:14:10.080215 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 17:14:10.080516 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:14:10.080629 (Thread-2): On model.my_new_project.my_first_dbt_model: BEGIN
2021-11-19 17:14:10.080762 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 17:14:10.087017 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:10.087199 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:14:10.087304 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table "demo_db"."sa"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

);
with source_case as (

    select 1 as id , 'a' as name
    union all
    select 1 as id , 'b' as name

)

select s.id,n.name
from source_data s
inner join source_case n on n.id = s.id

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-11-19 17:14:10.087867 (Thread-2): Postgres error: syntax error at or near ";"
LINE 22: );
          ^

2021-11-19 17:14:10.088003 (Thread-2): On model.my_new_project.my_first_dbt_model: ROLLBACK
2021-11-19 17:14:10.088351 (Thread-2): finished collecting timing info
2021-11-19 17:14:10.088506 (Thread-2): On model.my_new_project.my_first_dbt_model: Close
2021-11-19 17:14:10.088936 (Thread-2): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  syntax error at or near ";"
  LINE 22: );
            ^
  compiled SQL at target/run/my_new_project/models/example/my_first_dbt_model.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near ";"
LINE 22: );
          ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 70, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  syntax error at or near ";"
  LINE 22: );
            ^
  compiled SQL at target/run/my_new_project/models/example/my_first_dbt_model.sql
2021-11-19 17:14:10.090471 (Thread-2): 18:14:10 | 2 of 5 ERROR creating table model sa.my_first_dbt_model.............. [ERROR in 0.06s]
2021-11-19 17:14:10.090687 (Thread-2): Finished running node model.my_new_project.my_first_dbt_model
2021-11-19 17:14:10.091218 (Thread-2): Began running node model.my_new_project.my_second_dbt_model
2021-11-19 17:14:10.091381 (Thread-2): 18:14:10 | 3 of 5 SKIP relation sa.my_second_dbt_model.......................... [SKIP]
2021-11-19 17:14:10.091576 (Thread-2): Finished running node model.my_new_project.my_second_dbt_model
2021-11-19 17:14:10.215845 (Thread-1): SQL status: SELECT 28444 in 0.14 seconds
2021-11-19 17:14:10.221262 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:10.221377 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-19 17:14:10.221892 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-11-19 17:14:10.222003 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:10.222097 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer__dbt_tmp181410068467'
        
      order by ordinal_position

  
2021-11-19 17:14:10.226772 (Thread-1): SQL status: SELECT 18 in 0.00 seconds
2021-11-19 17:14:10.230539 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:10.230651 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-19 17:14:10.233080 (Thread-1): SQL status: SELECT 18 in 0.00 seconds
2021-11-19 17:14:10.240217 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:10.240345 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-19 17:14:10.242472 (Thread-1): SQL status: SELECT 18 in 0.00 seconds
2021-11-19 17:14:10.243851 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-19 17:14:10.244084 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:10.244178 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      delete
    from "demo_db"."sa_dwh"."iss_issuer"
    where (ISIN) in (
        select (ISIN)
        from "iss_issuer__dbt_tmp181410068467"
    );

    insert into "demo_db"."sa_dwh"."iss_issuer" ("adjusted_enterprise_value", "isin", "issuer_name", "gics_sector", "gics_industry_group", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_cap_daily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp")
    (
       select "adjusted_enterprise_value", "isin", "issuer_name", "gics_sector", "gics_industry_group", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_cap_daily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp"
       from "iss_issuer__dbt_tmp181410068467"
    );
  
2021-11-19 17:14:10.297245 (Thread-1): SQL status: INSERT 0 28444 in 0.05 seconds
2021-11-19 17:14:10.302086 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 17:14:10.302200 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:10.302285 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 17:14:10.313187 (Thread-1): SQL status: COMMIT in 0.01 seconds
2021-11-19 17:14:10.313639 (Thread-1): finished collecting timing info
2021-11-19 17:14:10.313775 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-19 17:14:10.314335 (Thread-1): 18:14:10 | 1 of 5 OK created incremental model sa_dwh.iss_issuer................ [INSERT 0 28444 in 0.29s]
2021-11-19 17:14:10.314592 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-19 17:14:10.315482 (Thread-2): Began running node model.my_new_project.dim_issuer
2021-11-19 17:14:10.315665 (Thread-1): Began running node model.my_new_project.fct_emissions
2021-11-19 17:14:10.315911 (Thread-2): 18:14:10 | 4 of 5 START table model sa_dm.dim_issuer............................ [RUN]
2021-11-19 17:14:10.316132 (Thread-1): 18:14:10 | 5 of 5 START incremental model sa_dm.fct_emissions................... [RUN]
2021-11-19 17:14:10.316561 (Thread-2): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:10.316887 (Thread-1): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:14:10.317040 (Thread-2): Compiling model.my_new_project.dim_issuer
2021-11-19 17:14:10.317198 (Thread-1): Compiling model.my_new_project.fct_emissions
2021-11-19 17:14:10.319550 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_issuer"
2021-11-19 17:14:10.322487 (Thread-1): Writing injected SQL for node "model.my_new_project.fct_emissions"
2021-11-19 17:14:10.322960 (Thread-1): finished collecting timing info
2021-11-19 17:14:10.326092 (Thread-1): Writing runtime SQL for node "model.my_new_project.fct_emissions"
2021-11-19 17:14:10.326296 (Thread-2): finished collecting timing info
2021-11-19 17:14:10.327550 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_issuer"
2021-11-19 17:14:10.327815 (Thread-1): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:14:10.328028 (Thread-1): On model.my_new_project.fct_emissions: BEGIN
2021-11-19 17:14:10.328148 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 17:14:10.328465 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:10.328757 (Thread-2): On model.my_new_project.dim_issuer: BEGIN
2021-11-19 17:14:10.328976 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 17:14:10.335218 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:10.335536 (Thread-1): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:14:10.335652 (Thread-1): On model.my_new_project.fct_emissions: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.fct_emissions"} */

      

  create  table "demo_db"."sa_dm"."fct_emissions"
  as (
    


with cte_fundamental_enterprise_value as (
    select
         iss.isin                                                    as isin
        ,'EnterpriseValue'                                           as fundamental
        ,climate_scope1_emissions / climate_scope1_emissions_int_usd as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

with cte_fundamental_revenue as (
    select
         iss.ISIN                                                    as isin
        ,'Revenue'                                                   as fundamental
        ,adjusted_enterprise_value / 1e6                             as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

with cte_fundamental_market_cap as (
    select
         iss.ISIN                                                    as isin
        ,iss.climate_emissions_fiscal_year
        ,'MarketCap'                                                 as fundamental
        ,market_cap_daily / 1e6                                      as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

with cte_union_tables as (
    select * from cte_fundamental_enterprise_value

    union

    select * from cte_fundamental_revenue

    union

    select * from cte_fundamental_market_cap
)

select
     md5(isin||)                            as fct_emissions_key
    ,md5(isin)                        as dim_issuer_key
    ,fundamental
    ,fundamental_value
    ,'2021-01-01'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from cte_union_tables
  );
  
2021-11-19 17:14:10.336158 (Thread-1): Postgres error: syntax error at or near "with"
LINE 18: with cte_fundamental_revenue as (
         ^

2021-11-19 17:14:10.336329 (Thread-1): On model.my_new_project.fct_emissions: ROLLBACK
2021-11-19 17:14:10.336502 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:10.336686 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:10.336863 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */


  create  table "demo_db"."sa_dm"."dim_issuer__dbt_tmp"
  as (
    

select distinct
     md5(iss.isin)              as dim_issuer_key
    ,iss.isin                   as isin
    ,iss.issuer_name            as issuer_name
    ,iss.gics_sector            as gics_sector
    ,iss.gics_industry_group    as gics_industry_group
from "demo_db"."sa_dwh"."iss_issuer" iss
  );
2021-11-19 17:14:10.337163 (Thread-1): finished collecting timing info
2021-11-19 17:14:10.337311 (Thread-1): On model.my_new_project.fct_emissions: Close
2021-11-19 17:14:10.337644 (Thread-1): Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
  syntax error at or near "with"
  LINE 18: with cte_fundamental_revenue as (
           ^
  compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "with"
LINE 18: with cte_fundamental_revenue as (
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
  syntax error at or near "with"
  LINE 18: with cte_fundamental_revenue as (
           ^
  compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
2021-11-19 17:14:10.338086 (Thread-1): 18:14:10 | 5 of 5 ERROR creating incremental model sa_dm.fct_emissions.......... [ERROR in 0.02s]
2021-11-19 17:14:10.338251 (Thread-1): Finished running node model.my_new_project.fct_emissions
2021-11-19 17:14:10.408564 (Thread-2): SQL status: SELECT 28444 in 0.07 seconds
2021-11-19 17:14:10.413015 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:10.413133 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer" rename to "dim_issuer__dbt_backup"
2021-11-19 17:14:10.413704 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 17:14:10.415103 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:10.415208 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer__dbt_tmp" rename to "dim_issuer"
2021-11-19 17:14:10.415833 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 17:14:10.419500 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 17:14:10.419612 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:10.419704 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 17:14:10.426768 (Thread-2): SQL status: COMMIT in 0.01 seconds
2021-11-19 17:14:10.430374 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:10.430495 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
drop table if exists "demo_db"."sa_dm"."dim_issuer__dbt_backup" cascade
2021-11-19 17:14:10.432544 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-11-19 17:14:10.433346 (Thread-2): finished collecting timing info
2021-11-19 17:14:10.433481 (Thread-2): On model.my_new_project.dim_issuer: Close
2021-11-19 17:14:10.433849 (Thread-2): 18:14:10 | 4 of 5 OK created table model sa_dm.dim_issuer....................... [SELECT 28444 in 0.12s]
2021-11-19 17:14:10.434000 (Thread-2): Finished running node model.my_new_project.dim_issuer
2021-11-19 17:14:10.435476 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:14:10.435636 (MainThread): Using postgres connection "master".
2021-11-19 17:14:10.435736 (MainThread): On master: BEGIN
2021-11-19 17:14:10.435836 (MainThread): Opening a new connection, currently in state closed
2021-11-19 17:14:10.442026 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:10.442171 (MainThread): On master: COMMIT
2021-11-19 17:14:10.442268 (MainThread): Using postgres connection "master".
2021-11-19 17:14:10.442357 (MainThread): On master: COMMIT
2021-11-19 17:14:10.442732 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:14:10.442868 (MainThread): On master: Close
2021-11-19 17:14:10.443189 (MainThread): 18:14:10 | 
2021-11-19 17:14:10.443337 (MainThread): 18:14:10 | Finished running 2 table models, 1 view model, 2 incremental models in 0.50s.
2021-11-19 17:14:10.443505 (MainThread): Connection 'master' was properly closed.
2021-11-19 17:14:10.443637 (MainThread): Connection 'model.my_new_project.fct_emissions' was properly closed.
2021-11-19 17:14:10.443763 (MainThread): Connection 'model.my_new_project.dim_issuer' was properly closed.
2021-11-19 17:14:10.446933 (MainThread): 
2021-11-19 17:14:10.447083 (MainThread): Completed with 2 errors and 0 warnings:
2021-11-19 17:14:10.447248 (MainThread): 
2021-11-19 17:14:10.447501 (MainThread): Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
2021-11-19 17:14:10.447731 (MainThread):   syntax error at or near ";"
2021-11-19 17:14:10.447988 (MainThread):   LINE 22: );
2021-11-19 17:14:10.448188 (MainThread):             ^
2021-11-19 17:14:10.448347 (MainThread):   compiled SQL at target/run/my_new_project/models/example/my_first_dbt_model.sql
2021-11-19 17:14:10.448476 (MainThread): 
2021-11-19 17:14:10.448608 (MainThread): Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
2021-11-19 17:14:10.448733 (MainThread):   syntax error at or near "with"
2021-11-19 17:14:10.448865 (MainThread):   LINE 18: with cte_fundamental_revenue as (
2021-11-19 17:14:10.449022 (MainThread):            ^
2021-11-19 17:14:10.449188 (MainThread):   compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
2021-11-19 17:14:10.449361 (MainThread): 
Done. PASS=2 WARN=0 ERROR=2 SKIP=1 TOTAL=5
2021-11-19 17:14:10.449611 (MainThread): Flushing usage events
2021-11-19 17:14:38.714750 (MainThread): Running with dbt=0.21.0
2021-11-19 17:14:38.768633 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 17:14:38.769075 (MainThread): Tracking: do not track
2021-11-19 17:14:38.778929 (MainThread): Partial parsing not enabled
2021-11-19 17:14:38.785123 (MainThread): Parsing macros/adapters.sql
2021-11-19 17:14:38.802538 (MainThread): Parsing macros/catalog.sql
2021-11-19 17:14:38.804235 (MainThread): Parsing macros/relations.sql
2021-11-19 17:14:38.805175 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 17:14:38.806640 (MainThread): Parsing macros/core.sql
2021-11-19 17:14:38.809356 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 17:14:38.850604 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 17:14:38.852486 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 17:14:38.853838 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 17:14:38.855137 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 17:14:38.861696 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 17:14:38.862816 (MainThread): Parsing macros/etc/query.sql
2021-11-19 17:14:38.863598 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 17:14:38.864702 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 17:14:38.872586 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 17:14:38.877867 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 17:14:38.895095 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 17:14:38.896476 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 17:14:38.919041 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 17:14:38.932195 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 17:14:38.949829 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 17:14:38.958182 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 17:14:38.959503 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 17:14:38.969649 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 17:14:38.972766 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 17:14:38.978449 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 17:14:38.983754 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 17:14:38.984809 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 17:14:38.985771 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 17:14:38.987010 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 17:14:39.147048 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:14:39.157071 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:14:39.159868 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:39.162327 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:39.162536 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:39.163355 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:14:39.166549 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:39.166755 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:39.167564 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:39.170449 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:39.170654 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:39.197214 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:39.198628 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:39.200027 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:39.201500 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:39.215100 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 17:14:39.215469 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-19 17:14:39.216931 (MainThread): 
2021-11-19 17:14:39.217199 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:14:39.218069 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:14:39.224166 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:14:39.228105 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 17:14:39.229131 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 17:14:39.229440 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:14:39.229628 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:14:39.229828 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 17:14:39.230011 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 17:14:39.241014 (ThreadPoolExecutor-0_0): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 17:14:39.241400 (ThreadPoolExecutor-0_1): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 17:14:39.242960 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 17:14:39.244241 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 17:14:39.244985 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:14:39.246275 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 17:14:39.246605 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:14:39.246820 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-11-19 17:14:39.252359 (ThreadPoolExecutor-0_0): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 17:14:39.253239 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 17:14:39.254460 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 17:14:39.259211 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 17:14:39.259360 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-19 17:14:39.259483 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 17:14:39.259962 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:14:39.261101 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:14:39.261330 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-19 17:14:39.261565 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 17:14:39.266270 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:39.266406 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 17:14:39.266493 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 17:14:39.267677 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:39.267813 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:14:39.267906 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 17:14:39.268531 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2021-11-19 17:14:39.269447 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-19 17:14:39.269654 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:14:39.270517 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 17:14:39.270759 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-19 17:14:39.270939 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-19 17:14:39.271391 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 17:14:39.272793 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:14:39.273170 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: BEGIN
2021-11-19 17:14:39.273388 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 17:14:39.279007 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:39.279151 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:14:39.279245 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 17:14:39.280929 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:14:39.281863 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 17:14:39.282170 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: Close
2021-11-19 17:14:39.285717 (MainThread): Using postgres connection "master".
2021-11-19 17:14:39.285835 (MainThread): On master: BEGIN
2021-11-19 17:14:39.285937 (MainThread): Opening a new connection, currently in state init
2021-11-19 17:14:39.291508 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:39.291664 (MainThread): Using postgres connection "master".
2021-11-19 17:14:39.291759 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 17:14:39.295736 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:14:39.296692 (MainThread): On master: ROLLBACK
2021-11-19 17:14:39.297066 (MainThread): Using postgres connection "master".
2021-11-19 17:14:39.297181 (MainThread): On master: BEGIN
2021-11-19 17:14:39.297859 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 17:14:39.298012 (MainThread): On master: COMMIT
2021-11-19 17:14:39.298110 (MainThread): Using postgres connection "master".
2021-11-19 17:14:39.298201 (MainThread): On master: COMMIT
2021-11-19 17:14:39.298607 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:14:39.298738 (MainThread): On master: Close
2021-11-19 17:14:39.299018 (MainThread): 18:14:39 | Concurrency: 2 threads (target='dev')
2021-11-19 17:14:39.299167 (MainThread): 18:14:39 | 
2021-11-19 17:14:39.301374 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-19 17:14:39.301677 (Thread-1): 18:14:39 | 1 of 5 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-19 17:14:39.302749 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:39.302914 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-19 17:14:39.305543 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-19 17:14:39.305726 (Thread-2): Began running node model.my_new_project.my_first_dbt_model
2021-11-19 17:14:39.306043 (Thread-2): 18:14:39 | 2 of 5 START table model sa.my_first_dbt_model....................... [RUN]
2021-11-19 17:14:39.306323 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:14:39.306511 (Thread-1): finished collecting timing info
2021-11-19 17:14:39.306760 (Thread-2): Compiling model.my_new_project.my_first_dbt_model
2021-11-19 17:14:39.313538 (Thread-2): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 17:14:39.325397 (Thread-2): finished collecting timing info
2021-11-19 17:14:39.362348 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 17:14:39.363725 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:39.363869 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

    

  create temporary table "iss_issuer__dbt_tmp181439338106"
  as (
    

select
     iss.AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,iss.ISIN                             as isin
    ,iss.IssuerName                       as issuer_name
    ,iss.gicssector                       as gics_sector
    ,iss.gicsindustrygroup                as gics_industry_group
    ,iss.ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,iss.ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,iss.ClimateScope2Emissions           as climate_scope2_emissions
    ,iss.ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,iss.ClimateScope3Emissions           as climate_scope3_emissions
    ,iss.ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,iss.ClimateTotalEmissions            as climate_total_emissions
    ,iss.ClimateScope1Emissions           as climate_scope1_emissions
    ,iss.MarketCapDaily                   as market_cap_daily
    ,iss.ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,'2021-01-01'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-19 17:14:39.364013 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 17:14:39.364352 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:14:39.364468 (Thread-2): On model.my_new_project.my_first_dbt_model: BEGIN
2021-11-19 17:14:39.364634 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 17:14:39.371044 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:39.371211 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:14:39.371313 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table "demo_db"."sa"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)
,source_case as (

    select 1 as id , 'a' as name
    union all
    select 1 as id , 'b' as name

)

select s.id,n.name
from source_data s
inner join source_case n on n.id = s.id

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-11-19 17:14:39.375297 (Thread-2): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 17:14:39.380047 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:14:39.380176 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "demo_db"."sa"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2021-11-19 17:14:39.380605 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 17:14:39.382007 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:14:39.382110 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "demo_db"."sa"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2021-11-19 17:14:39.382599 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 17:14:39.390188 (Thread-2): On model.my_new_project.my_first_dbt_model: COMMIT
2021-11-19 17:14:39.390314 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:14:39.390403 (Thread-2): On model.my_new_project.my_first_dbt_model: COMMIT
2021-11-19 17:14:39.392036 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:14:39.395355 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:14:39.395502 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "demo_db"."sa"."my_first_dbt_model__dbt_backup" cascade
2021-11-19 17:14:39.397624 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-11-19 17:14:39.398679 (Thread-2): finished collecting timing info
2021-11-19 17:14:39.398813 (Thread-2): On model.my_new_project.my_first_dbt_model: Close
2021-11-19 17:14:39.399226 (Thread-2): 18:14:39 | 2 of 5 OK created table model sa.my_first_dbt_model.................. [SELECT 2 in 0.09s]
2021-11-19 17:14:39.399397 (Thread-2): Finished running node model.my_new_project.my_first_dbt_model
2021-11-19 17:14:39.400007 (Thread-2): Began running node model.my_new_project.my_second_dbt_model
2021-11-19 17:14:39.400258 (Thread-2): 18:14:39 | 3 of 5 START view model sa.my_second_dbt_model....................... [RUN]
2021-11-19 17:14:39.400647 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:14:39.400844 (Thread-2): Compiling model.my_new_project.my_second_dbt_model
2021-11-19 17:14:39.402640 (Thread-2): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-19 17:14:39.402850 (Thread-2): finished collecting timing info
2021-11-19 17:14:39.415663 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-19 17:14:39.415941 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:14:39.416043 (Thread-2): On model.my_new_project.my_second_dbt_model: BEGIN
2021-11-19 17:14:39.416138 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 17:14:39.422318 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:39.422538 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:14:39.422636 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */

  create view "demo_db"."sa"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."sa"."my_first_dbt_model"
where id = 1
  );

2021-11-19 17:14:39.424061 (Thread-2): SQL status: CREATE VIEW in 0.00 seconds
2021-11-19 17:14:39.426551 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:14:39.426662 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "demo_db"."sa"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2021-11-19 17:14:39.427278 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 17:14:39.428048 (Thread-2): On model.my_new_project.my_second_dbt_model: COMMIT
2021-11-19 17:14:39.428148 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:14:39.428235 (Thread-2): On model.my_new_project.my_second_dbt_model: COMMIT
2021-11-19 17:14:39.429799 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:14:39.430886 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:14:39.430995 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "demo_db"."sa"."my_second_dbt_model__dbt_backup" cascade
2021-11-19 17:14:39.431479 (Thread-2): SQL status: DROP VIEW in 0.00 seconds
2021-11-19 17:14:39.432271 (Thread-2): finished collecting timing info
2021-11-19 17:14:39.432403 (Thread-2): On model.my_new_project.my_second_dbt_model: Close
2021-11-19 17:14:39.432827 (Thread-2): 18:14:39 | 3 of 5 OK created view model sa.my_second_dbt_model.................. [CREATE VIEW in 0.03s]
2021-11-19 17:14:39.432999 (Thread-2): Finished running node model.my_new_project.my_second_dbt_model
2021-11-19 17:14:39.481671 (Thread-1): SQL status: SELECT 28444 in 0.12 seconds
2021-11-19 17:14:39.487580 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:39.487710 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-19 17:14:39.488166 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-11-19 17:14:39.488330 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:39.488420 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer__dbt_tmp181439338106'
        
      order by ordinal_position

  
2021-11-19 17:14:39.493516 (Thread-1): SQL status: SELECT 18 in 0.00 seconds
2021-11-19 17:14:39.497473 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:39.497587 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-19 17:14:39.499858 (Thread-1): SQL status: SELECT 18 in 0.00 seconds
2021-11-19 17:14:39.507716 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:39.507874 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-19 17:14:39.510330 (Thread-1): SQL status: SELECT 18 in 0.00 seconds
2021-11-19 17:14:39.511792 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-19 17:14:39.512034 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:39.512130 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      delete
    from "demo_db"."sa_dwh"."iss_issuer"
    where (ISIN) in (
        select (ISIN)
        from "iss_issuer__dbt_tmp181439338106"
    );

    insert into "demo_db"."sa_dwh"."iss_issuer" ("adjusted_enterprise_value", "isin", "issuer_name", "gics_sector", "gics_industry_group", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_cap_daily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp")
    (
       select "adjusted_enterprise_value", "isin", "issuer_name", "gics_sector", "gics_industry_group", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_cap_daily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp"
       from "iss_issuer__dbt_tmp181439338106"
    );
  
2021-11-19 17:14:39.599598 (Thread-1): SQL status: INSERT 0 28444 in 0.09 seconds
2021-11-19 17:14:39.600703 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 17:14:39.600816 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:39.600905 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 17:14:39.606496 (Thread-1): SQL status: COMMIT in 0.01 seconds
2021-11-19 17:14:39.606941 (Thread-1): finished collecting timing info
2021-11-19 17:14:39.607080 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-19 17:14:39.607462 (Thread-1): 18:14:39 | 1 of 5 OK created incremental model sa_dwh.iss_issuer................ [INSERT 0 28444 in 0.31s]
2021-11-19 17:14:39.607635 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-19 17:14:39.608663 (Thread-2): Began running node model.my_new_project.dim_issuer
2021-11-19 17:14:39.608850 (Thread-1): Began running node model.my_new_project.fct_emissions
2021-11-19 17:14:39.609073 (Thread-2): 18:14:39 | 4 of 5 START table model sa_dm.dim_issuer............................ [RUN]
2021-11-19 17:14:39.609283 (Thread-1): 18:14:39 | 5 of 5 START incremental model sa_dm.fct_emissions................... [RUN]
2021-11-19 17:14:39.609699 (Thread-2): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:39.610108 (Thread-1): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:14:39.610268 (Thread-2): Compiling model.my_new_project.dim_issuer
2021-11-19 17:14:39.610412 (Thread-1): Compiling model.my_new_project.fct_emissions
2021-11-19 17:14:39.612734 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_issuer"
2021-11-19 17:14:39.615595 (Thread-1): Writing injected SQL for node "model.my_new_project.fct_emissions"
2021-11-19 17:14:39.615982 (Thread-1): finished collecting timing info
2021-11-19 17:14:39.616205 (Thread-2): finished collecting timing info
2021-11-19 17:14:39.617997 (Thread-1): Writing runtime SQL for node "model.my_new_project.fct_emissions"
2021-11-19 17:14:39.619305 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_issuer"
2021-11-19 17:14:39.619709 (Thread-1): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:14:39.619906 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:39.620121 (Thread-1): On model.my_new_project.fct_emissions: BEGIN
2021-11-19 17:14:39.620262 (Thread-2): On model.my_new_project.dim_issuer: BEGIN
2021-11-19 17:14:39.620447 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 17:14:39.620585 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 17:14:39.627462 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:39.627773 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:39.627915 (Thread-1): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:14:39.628053 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:39.628186 (Thread-1): On model.my_new_project.fct_emissions: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.fct_emissions"} */

      

  create  table "demo_db"."sa_dm"."fct_emissions"
  as (
    


with cte_fundamental_enterprise_value as (
    select
         iss.isin                                                    as isin
        ,'EnterpriseValue'                                           as fundamental
        ,climate_scope1_emissions / climate_scope1_emissions_int_usd as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

, cte_fundamental_revenue as (
    select
         iss.ISIN                                                    as isin
        ,'Revenue'                                                   as fundamental
        ,adjusted_enterprise_value / 1e6                             as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

, cte_fundamental_market_cap as (
    select
         iss.ISIN                                                    as isin
        ,iss.climate_emissions_fiscal_year
        ,'MarketCap'                                                 as fundamental
        ,market_cap_daily / 1e6                                      as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

, cte_union_tables as (
    select * from cte_fundamental_enterprise_value

    union

    select * from cte_fundamental_revenue

    union

    select * from cte_fundamental_market_cap
)

select
     md5(isin||)                            as fct_emissions_key
    ,md5(isin)                        as dim_issuer_key
    ,fundamental
    ,fundamental_value
    ,'2021-01-01'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from cte_union_tables
  );
  
2021-11-19 17:14:39.628319 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */


  create  table "demo_db"."sa_dm"."dim_issuer__dbt_tmp"
  as (
    

select distinct
     md5(iss.isin)              as dim_issuer_key
    ,iss.isin                   as isin
    ,iss.issuer_name            as issuer_name
    ,iss.gics_sector            as gics_sector
    ,iss.gics_industry_group    as gics_industry_group
from "demo_db"."sa_dwh"."iss_issuer" iss
  );
2021-11-19 17:14:39.628812 (Thread-1): Postgres error: syntax error at or near ")"
LINE 48:      md5(isin||)                            as fct_emissions...
                        ^

2021-11-19 17:14:39.629002 (Thread-1): On model.my_new_project.fct_emissions: ROLLBACK
2021-11-19 17:14:39.629379 (Thread-1): finished collecting timing info
2021-11-19 17:14:39.629509 (Thread-1): On model.my_new_project.fct_emissions: Close
2021-11-19 17:14:39.629835 (Thread-1): Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
  syntax error at or near ")"
  LINE 48:      md5(isin||)                            as fct_emissions...
                          ^
  compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near ")"
LINE 48:      md5(isin||)                            as fct_emissions...
                        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
  syntax error at or near ")"
  LINE 48:      md5(isin||)                            as fct_emissions...
                          ^
  compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
2021-11-19 17:14:39.631116 (Thread-1): 18:14:39 | 5 of 5 ERROR creating incremental model sa_dm.fct_emissions.......... [ERROR in 0.02s]
2021-11-19 17:14:39.631310 (Thread-1): Finished running node model.my_new_project.fct_emissions
2021-11-19 17:14:39.693379 (Thread-2): SQL status: SELECT 28444 in 0.06 seconds
2021-11-19 17:14:39.695002 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:39.695115 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer" rename to "dim_issuer__dbt_backup"
2021-11-19 17:14:39.695708 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 17:14:39.697089 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:39.697191 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer__dbt_tmp" rename to "dim_issuer"
2021-11-19 17:14:39.697677 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 17:14:39.698489 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 17:14:39.698588 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:39.698675 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 17:14:39.705596 (Thread-2): SQL status: COMMIT in 0.01 seconds
2021-11-19 17:14:39.707005 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:39.707122 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
drop table if exists "demo_db"."sa_dm"."dim_issuer__dbt_backup" cascade
2021-11-19 17:14:39.709399 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-11-19 17:14:39.710201 (Thread-2): finished collecting timing info
2021-11-19 17:14:39.710328 (Thread-2): On model.my_new_project.dim_issuer: Close
2021-11-19 17:14:39.710723 (Thread-2): 18:14:39 | 4 of 5 OK created table model sa_dm.dim_issuer....................... [SELECT 28444 in 0.10s]
2021-11-19 17:14:39.710867 (Thread-2): Finished running node model.my_new_project.dim_issuer
2021-11-19 17:14:39.712299 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:14:39.712435 (MainThread): Using postgres connection "master".
2021-11-19 17:14:39.712526 (MainThread): On master: BEGIN
2021-11-19 17:14:39.712619 (MainThread): Opening a new connection, currently in state closed
2021-11-19 17:14:39.718121 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:39.718280 (MainThread): On master: COMMIT
2021-11-19 17:14:39.718370 (MainThread): Using postgres connection "master".
2021-11-19 17:14:39.718455 (MainThread): On master: COMMIT
2021-11-19 17:14:39.718691 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:14:39.718803 (MainThread): On master: Close
2021-11-19 17:14:39.719119 (MainThread): 18:14:39 | 
2021-11-19 17:14:39.719280 (MainThread): 18:14:39 | Finished running 2 table models, 1 view model, 2 incremental models in 0.50s.
2021-11-19 17:14:39.719493 (MainThread): Connection 'master' was properly closed.
2021-11-19 17:14:39.719649 (MainThread): Connection 'model.my_new_project.dim_issuer' was properly closed.
2021-11-19 17:14:39.719732 (MainThread): Connection 'model.my_new_project.fct_emissions' was properly closed.
2021-11-19 17:14:39.722920 (MainThread): 
2021-11-19 17:14:39.723102 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 17:14:39.723251 (MainThread): 
2021-11-19 17:14:39.723531 (MainThread): Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
2021-11-19 17:14:39.723716 (MainThread):   syntax error at or near ")"
2021-11-19 17:14:39.723891 (MainThread):   LINE 48:      md5(isin||)                            as fct_emissions...
2021-11-19 17:14:39.724085 (MainThread):                           ^
2021-11-19 17:14:39.724227 (MainThread):   compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
2021-11-19 17:14:39.724375 (MainThread): 
Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
2021-11-19 17:14:39.724629 (MainThread): Flushing usage events
2021-11-19 17:14:55.138867 (MainThread): Running with dbt=0.21.0
2021-11-19 17:14:55.196868 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 17:14:55.197280 (MainThread): Tracking: do not track
2021-11-19 17:14:55.207270 (MainThread): Partial parsing not enabled
2021-11-19 17:14:55.213237 (MainThread): Parsing macros/adapters.sql
2021-11-19 17:14:55.230653 (MainThread): Parsing macros/catalog.sql
2021-11-19 17:14:55.232263 (MainThread): Parsing macros/relations.sql
2021-11-19 17:14:55.233185 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 17:14:55.234408 (MainThread): Parsing macros/core.sql
2021-11-19 17:14:55.237638 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 17:14:55.280270 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 17:14:55.282215 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 17:14:55.283683 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 17:14:55.285120 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 17:14:55.291747 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 17:14:55.292920 (MainThread): Parsing macros/etc/query.sql
2021-11-19 17:14:55.293650 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 17:14:55.294757 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 17:14:55.302423 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 17:14:55.307590 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 17:14:55.324865 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 17:14:55.326134 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 17:14:55.348256 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 17:14:55.361309 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 17:14:55.375688 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 17:14:55.383535 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 17:14:55.384824 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 17:14:55.395194 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 17:14:55.398458 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 17:14:55.403798 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 17:14:55.409256 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 17:14:55.410314 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 17:14:55.411228 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 17:14:55.412498 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 17:14:55.569250 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:14:55.578948 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:14:55.581648 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:55.584046 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:55.584253 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:55.585196 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:14:55.588421 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:55.588624 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:55.589415 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:55.592244 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:55.592449 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:55.618999 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:55.620434 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:55.621815 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:55.623376 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:14:55.637028 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 17:14:55.637314 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-19 17:14:55.638660 (MainThread): 
2021-11-19 17:14:55.638914 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:14:55.639887 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:14:55.647003 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 17:14:55.647134 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:14:55.647255 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 17:14:55.647726 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:14:55.648937 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 17:14:55.649059 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:14:55.649175 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 17:14:55.654589 (ThreadPoolExecutor-0_0): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 17:14:55.655733 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 17:14:55.656388 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:14:55.657755 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 17:14:55.657917 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:14:55.658079 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-11-19 17:14:55.658447 (ThreadPoolExecutor-0_1): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 17:14:55.659531 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 17:14:55.664767 (ThreadPoolExecutor-0_0): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 17:14:55.665697 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 17:14:55.667046 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:14:55.671009 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:14:55.671131 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: BEGIN
2021-11-19 17:14:55.671330 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 17:14:55.672107 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 17:14:55.673229 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:14:55.673391 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: BEGIN
2021-11-19 17:14:55.673607 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 17:14:55.678579 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:55.678763 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:14:55.678900 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 17:14:55.680705 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:55.680890 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:14:55.680992 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 17:14:55.681365 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:14:55.682247 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 17:14:55.682520 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: Close
2021-11-19 17:14:55.682693 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:14:55.683597 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 17:14:55.684030 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 17:14:55.685101 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 17:14:55.685224 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: Close
2021-11-19 17:14:55.685412 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-19 17:14:55.685616 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 17:14:55.691453 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:55.691719 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 17:14:55.691819 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 17:14:55.693405 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2021-11-19 17:14:55.694317 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-19 17:14:55.694552 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-19 17:14:55.698404 (MainThread): Using postgres connection "master".
2021-11-19 17:14:55.698539 (MainThread): On master: BEGIN
2021-11-19 17:14:55.698645 (MainThread): Opening a new connection, currently in state init
2021-11-19 17:14:55.704238 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:55.704442 (MainThread): Using postgres connection "master".
2021-11-19 17:14:55.704534 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 17:14:55.708686 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:14:55.709591 (MainThread): On master: ROLLBACK
2021-11-19 17:14:55.709922 (MainThread): Using postgres connection "master".
2021-11-19 17:14:55.710029 (MainThread): On master: BEGIN
2021-11-19 17:14:55.710619 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 17:14:55.710786 (MainThread): On master: COMMIT
2021-11-19 17:14:55.710879 (MainThread): Using postgres connection "master".
2021-11-19 17:14:55.710963 (MainThread): On master: COMMIT
2021-11-19 17:14:55.711272 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:14:55.711475 (MainThread): On master: Close
2021-11-19 17:14:55.711813 (MainThread): 18:14:55 | Concurrency: 2 threads (target='dev')
2021-11-19 17:14:55.711984 (MainThread): 18:14:55 | 
2021-11-19 17:14:55.714120 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-19 17:14:55.714383 (Thread-1): 18:14:55 | 1 of 5 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-19 17:14:55.714733 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:55.715714 (Thread-2): Began running node model.my_new_project.my_first_dbt_model
2021-11-19 17:14:55.715919 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-19 17:14:55.716132 (Thread-2): 18:14:55 | 2 of 5 START table model sa.my_first_dbt_model....................... [RUN]
2021-11-19 17:14:55.718575 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-19 17:14:55.718848 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:14:55.719117 (Thread-2): Compiling model.my_new_project.my_first_dbt_model
2021-11-19 17:14:55.720996 (Thread-2): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 17:14:55.721268 (Thread-2): finished collecting timing info
2021-11-19 17:14:55.726683 (Thread-1): finished collecting timing info
2021-11-19 17:14:55.755777 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 17:14:55.756139 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:14:55.756292 (Thread-2): On model.my_new_project.my_first_dbt_model: BEGIN
2021-11-19 17:14:55.756471 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 17:14:55.774217 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:55.774472 (Thread-2): SQL status: BEGIN in 0.02 seconds
2021-11-19 17:14:55.774687 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

    

  create temporary table "iss_issuer__dbt_tmp181455767489"
  as (
    

select
     iss.AdjustedEnterpriseValue          as adjusted_enterprise_value
    ,iss.ISIN                             as isin
    ,iss.IssuerName                       as issuer_name
    ,iss.gicssector                       as gics_sector
    ,iss.gicsindustrygroup                as gics_industry_group
    ,iss.ClimateScope2EmissionsIntUSD     as climate_scope2_emissions_int_usd
    ,iss.ClimateScope1EmissionsIntUSD     as climate_scope1_emissions_int_usd
    ,iss.ClimateScope2Emissions           as climate_scope2_emissions
    ,iss.ClimateTotalEmissionsIntUSD      as climate_total_emissions_int_usd
    ,iss.ClimateScope3Emissions           as climate_scope3_emissions
    ,iss.ClimateCNIEmissionsSource        as climate_cni_emissions_source
    ,iss.ClimateTotalEmissions            as climate_total_emissions
    ,iss.ClimateScope1Emissions           as climate_scope1_emissions
    ,iss.MarketCapDaily                   as market_cap_daily
    ,iss.ClimateEmissionsFiscalYear::INT  as climate_emissions_fiscal_year
    ,'2021-01-01'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-19 17:14:55.774850 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:14:55.775051 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 17:14:55.775195 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table "demo_db"."sa"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)
,source_case as (

    select 1 as id , 'a' as name
    union all
    select 1 as id , 'b' as name

)

select s.id,n.name
from source_data s
inner join source_case n on n.id = s.id

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-11-19 17:14:55.779020 (Thread-2): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 17:14:55.783704 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:14:55.784024 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "demo_db"."sa"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2021-11-19 17:14:55.784495 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 17:14:55.786026 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:14:55.786140 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "demo_db"."sa"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2021-11-19 17:14:55.786505 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 17:14:55.794525 (Thread-2): On model.my_new_project.my_first_dbt_model: COMMIT
2021-11-19 17:14:55.794679 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:14:55.794780 (Thread-2): On model.my_new_project.my_first_dbt_model: COMMIT
2021-11-19 17:14:55.796369 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:14:55.799761 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:14:55.799880 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "demo_db"."sa"."my_first_dbt_model__dbt_backup" cascade
2021-11-19 17:14:55.802164 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-11-19 17:14:55.803097 (Thread-2): finished collecting timing info
2021-11-19 17:14:55.803241 (Thread-2): On model.my_new_project.my_first_dbt_model: Close
2021-11-19 17:14:55.803657 (Thread-2): 18:14:55 | 2 of 5 OK created table model sa.my_first_dbt_model.................. [SELECT 2 in 0.08s]
2021-11-19 17:14:55.803849 (Thread-2): Finished running node model.my_new_project.my_first_dbt_model
2021-11-19 17:14:55.804414 (Thread-2): Began running node model.my_new_project.my_second_dbt_model
2021-11-19 17:14:55.804621 (Thread-2): 18:14:55 | 3 of 5 START view model sa.my_second_dbt_model....................... [RUN]
2021-11-19 17:14:55.804967 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:14:55.805087 (Thread-2): Compiling model.my_new_project.my_second_dbt_model
2021-11-19 17:14:55.807203 (Thread-2): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-19 17:14:55.807430 (Thread-2): finished collecting timing info
2021-11-19 17:14:55.821466 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-19 17:14:55.821766 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:14:55.821877 (Thread-2): On model.my_new_project.my_second_dbt_model: BEGIN
2021-11-19 17:14:55.821979 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 17:14:55.828490 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:55.828733 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:14:55.828840 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */

  create view "demo_db"."sa"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."sa"."my_first_dbt_model"
where id = 1
  );

2021-11-19 17:14:55.829977 (Thread-2): SQL status: CREATE VIEW in 0.00 seconds
2021-11-19 17:14:55.832512 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:14:55.832636 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "demo_db"."sa"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2021-11-19 17:14:55.833194 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 17:14:55.834030 (Thread-2): On model.my_new_project.my_second_dbt_model: COMMIT
2021-11-19 17:14:55.834140 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:14:55.834235 (Thread-2): On model.my_new_project.my_second_dbt_model: COMMIT
2021-11-19 17:14:55.835482 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:14:55.836477 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:14:55.836586 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "demo_db"."sa"."my_second_dbt_model__dbt_backup" cascade
2021-11-19 17:14:55.837000 (Thread-2): SQL status: DROP VIEW in 0.00 seconds
2021-11-19 17:14:55.837773 (Thread-2): finished collecting timing info
2021-11-19 17:14:55.837907 (Thread-2): On model.my_new_project.my_second_dbt_model: Close
2021-11-19 17:14:55.838392 (Thread-2): 18:14:55 | 3 of 5 OK created view model sa.my_second_dbt_model.................. [CREATE VIEW in 0.03s]
2021-11-19 17:14:55.838630 (Thread-2): Finished running node model.my_new_project.my_second_dbt_model
2021-11-19 17:14:55.903564 (Thread-1): SQL status: SELECT 28444 in 0.13 seconds
2021-11-19 17:14:55.909416 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:55.909563 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-19 17:14:55.910236 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-11-19 17:14:55.910361 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:55.910456 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer__dbt_tmp181455767489'
        
      order by ordinal_position

  
2021-11-19 17:14:55.915041 (Thread-1): SQL status: SELECT 18 in 0.00 seconds
2021-11-19 17:14:55.919117 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:55.919233 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-19 17:14:55.921603 (Thread-1): SQL status: SELECT 18 in 0.00 seconds
2021-11-19 17:14:55.929365 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:55.929504 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-19 17:14:55.931763 (Thread-1): SQL status: SELECT 18 in 0.00 seconds
2021-11-19 17:14:55.933183 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-19 17:14:55.933424 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:55.933523 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      delete
    from "demo_db"."sa_dwh"."iss_issuer"
    where (ISIN) in (
        select (ISIN)
        from "iss_issuer__dbt_tmp181455767489"
    );

    insert into "demo_db"."sa_dwh"."iss_issuer" ("adjusted_enterprise_value", "isin", "issuer_name", "gics_sector", "gics_industry_group", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_cap_daily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp")
    (
       select "adjusted_enterprise_value", "isin", "issuer_name", "gics_sector", "gics_industry_group", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_cap_daily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp"
       from "iss_issuer__dbt_tmp181455767489"
    );
  
2021-11-19 17:14:56.016488 (Thread-1): SQL status: INSERT 0 28444 in 0.08 seconds
2021-11-19 17:14:56.017536 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 17:14:56.017659 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:14:56.017755 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 17:14:56.021118 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:14:56.021544 (Thread-1): finished collecting timing info
2021-11-19 17:14:56.021688 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-19 17:14:56.022079 (Thread-1): 18:14:56 | 1 of 5 OK created incremental model sa_dwh.iss_issuer................ [INSERT 0 28444 in 0.31s]
2021-11-19 17:14:56.022237 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-19 17:14:56.023006 (Thread-2): Began running node model.my_new_project.dim_issuer
2021-11-19 17:14:56.023212 (Thread-1): Began running node model.my_new_project.fct_emissions
2021-11-19 17:14:56.023475 (Thread-2): 18:14:56 | 4 of 5 START table model sa_dm.dim_issuer............................ [RUN]
2021-11-19 17:14:56.023729 (Thread-1): 18:14:56 | 5 of 5 START incremental model sa_dm.fct_emissions................... [RUN]
2021-11-19 17:14:56.024088 (Thread-2): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:56.024395 (Thread-1): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:14:56.024545 (Thread-2): Compiling model.my_new_project.dim_issuer
2021-11-19 17:14:56.024698 (Thread-1): Compiling model.my_new_project.fct_emissions
2021-11-19 17:14:56.027118 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_issuer"
2021-11-19 17:14:56.030168 (Thread-1): Writing injected SQL for node "model.my_new_project.fct_emissions"
2021-11-19 17:14:56.030672 (Thread-2): finished collecting timing info
2021-11-19 17:14:56.030842 (Thread-1): finished collecting timing info
2021-11-19 17:14:56.032367 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_issuer"
2021-11-19 17:14:56.034392 (Thread-1): Writing runtime SQL for node "model.my_new_project.fct_emissions"
2021-11-19 17:14:56.034935 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:56.035174 (Thread-1): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:14:56.035353 (Thread-2): On model.my_new_project.dim_issuer: BEGIN
2021-11-19 17:14:56.035522 (Thread-1): On model.my_new_project.fct_emissions: BEGIN
2021-11-19 17:14:56.035676 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 17:14:56.035820 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 17:14:56.041495 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:56.041739 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:56.041901 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:56.042158 (Thread-1): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:14:56.042303 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */


  create  table "demo_db"."sa_dm"."dim_issuer__dbt_tmp"
  as (
    

select distinct
     md5(iss.isin)              as dim_issuer_key
    ,iss.isin                   as isin
    ,iss.issuer_name            as issuer_name
    ,iss.gics_sector            as gics_sector
    ,iss.gics_industry_group    as gics_industry_group
from "demo_db"."sa_dwh"."iss_issuer" iss
  );
2021-11-19 17:14:56.042447 (Thread-1): On model.my_new_project.fct_emissions: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.fct_emissions"} */

      

  create  table "demo_db"."sa_dm"."fct_emissions"
  as (
    


with cte_fundamental_enterprise_value as (
    select
         iss.isin                                                    as isin
        ,'EnterpriseValue'                                           as fundamental
        ,climate_scope1_emissions / climate_scope1_emissions_int_usd as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

, cte_fundamental_revenue as (
    select
         iss.ISIN                                                    as isin
        ,'Revenue'                                                   as fundamental
        ,adjusted_enterprise_value / 1e6                             as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

, cte_fundamental_market_cap as (
    select
         iss.ISIN                                                    as isin
        ,iss.climate_emissions_fiscal_year
        ,'MarketCap'                                                 as fundamental
        ,market_cap_daily / 1e6                                      as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

, cte_union_tables as (
    select * from cte_fundamental_enterprise_value

    union

    select * from cte_fundamental_revenue

    union

    select * from cte_fundamental_market_cap
)

select
     md5(isin)                            as fct_emissions_key
    ,md5(isin)                        as dim_issuer_key
    ,fundamental
    ,fundamental_value
    ,'2021-01-01'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from cte_union_tables
  );
  
2021-11-19 17:14:56.043053 (Thread-1): Postgres error: operator does not exist: double precision / text
LINE 14:         ,climate_scope1_emissions / climate_scope1_emissions...
                                           ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.

2021-11-19 17:14:56.043187 (Thread-1): On model.my_new_project.fct_emissions: ROLLBACK
2021-11-19 17:14:56.043476 (Thread-1): finished collecting timing info
2021-11-19 17:14:56.043613 (Thread-1): On model.my_new_project.fct_emissions: Close
2021-11-19 17:14:56.043916 (Thread-1): Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
  operator does not exist: double precision / text
  LINE 14:         ,climate_scope1_emissions / climate_scope1_emissions...
                                             ^
  HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
  compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedFunction: operator does not exist: double precision / text
LINE 14:         ,climate_scope1_emissions / climate_scope1_emissions...
                                           ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
  operator does not exist: double precision / text
  LINE 14:         ,climate_scope1_emissions / climate_scope1_emissions...
                                             ^
  HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
  compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
2021-11-19 17:14:56.045207 (Thread-1): 18:14:56 | 5 of 5 ERROR creating incremental model sa_dm.fct_emissions.......... [ERROR in 0.02s]
2021-11-19 17:14:56.045419 (Thread-1): Finished running node model.my_new_project.fct_emissions
2021-11-19 17:14:56.119264 (Thread-2): SQL status: SELECT 28444 in 0.08 seconds
2021-11-19 17:14:56.122011 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:56.122235 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer" rename to "dim_issuer__dbt_backup"
2021-11-19 17:14:56.123024 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 17:14:56.125817 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:56.126066 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer__dbt_tmp" rename to "dim_issuer"
2021-11-19 17:14:56.126829 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 17:14:56.128422 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 17:14:56.128597 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:56.128742 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 17:14:56.142365 (Thread-2): SQL status: COMMIT in 0.01 seconds
2021-11-19 17:14:56.143657 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:14:56.143771 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
drop table if exists "demo_db"."sa_dm"."dim_issuer__dbt_backup" cascade
2021-11-19 17:14:56.146508 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-11-19 17:14:56.147469 (Thread-2): finished collecting timing info
2021-11-19 17:14:56.147612 (Thread-2): On model.my_new_project.dim_issuer: Close
2021-11-19 17:14:56.148113 (Thread-2): 18:14:56 | 4 of 5 OK created table model sa_dm.dim_issuer....................... [SELECT 28444 in 0.12s]
2021-11-19 17:14:56.148265 (Thread-2): Finished running node model.my_new_project.dim_issuer
2021-11-19 17:14:56.149800 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:14:56.150010 (MainThread): Using postgres connection "master".
2021-11-19 17:14:56.150124 (MainThread): On master: BEGIN
2021-11-19 17:14:56.150291 (MainThread): Opening a new connection, currently in state closed
2021-11-19 17:14:56.157149 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:14:56.157370 (MainThread): On master: COMMIT
2021-11-19 17:14:56.157495 (MainThread): Using postgres connection "master".
2021-11-19 17:14:56.157670 (MainThread): On master: COMMIT
2021-11-19 17:14:56.158085 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:14:56.158239 (MainThread): On master: Close
2021-11-19 17:14:56.158783 (MainThread): 18:14:56 | 
2021-11-19 17:14:56.158960 (MainThread): 18:14:56 | Finished running 2 table models, 1 view model, 2 incremental models in 0.52s.
2021-11-19 17:14:56.159167 (MainThread): Connection 'master' was properly closed.
2021-11-19 17:14:56.159311 (MainThread): Connection 'model.my_new_project.fct_emissions' was properly closed.
2021-11-19 17:14:56.159401 (MainThread): Connection 'model.my_new_project.dim_issuer' was properly closed.
2021-11-19 17:14:56.162578 (MainThread): 
2021-11-19 17:14:56.162754 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 17:14:56.162906 (MainThread): 
2021-11-19 17:14:56.163049 (MainThread): Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
2021-11-19 17:14:56.163181 (MainThread):   operator does not exist: double precision / text
2021-11-19 17:14:56.163306 (MainThread):   LINE 14:         ,climate_scope1_emissions / climate_scope1_emissions...
2021-11-19 17:14:56.163434 (MainThread):                                              ^
2021-11-19 17:14:56.163565 (MainThread):   HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
2021-11-19 17:14:56.163712 (MainThread):   compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
2021-11-19 17:14:56.163850 (MainThread): 
Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
2021-11-19 17:14:56.164039 (MainThread): Flushing usage events
2021-11-19 17:46:58.427952 (MainThread): Running with dbt=0.21.0
2021-11-19 17:46:58.484812 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 17:46:58.485328 (MainThread): Tracking: do not track
2021-11-19 17:46:58.495704 (MainThread): Partial parsing not enabled
2021-11-19 17:46:58.502210 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 17:46:58.502869 (MainThread): Parsing macros/adapters.sql
2021-11-19 17:46:58.520807 (MainThread): Parsing macros/catalog.sql
2021-11-19 17:46:58.522486 (MainThread): Parsing macros/relations.sql
2021-11-19 17:46:58.523426 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 17:46:58.524685 (MainThread): Parsing macros/core.sql
2021-11-19 17:46:58.527744 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 17:46:58.570814 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 17:46:58.572758 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 17:46:58.574129 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 17:46:58.575356 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 17:46:58.582579 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 17:46:58.583762 (MainThread): Parsing macros/etc/query.sql
2021-11-19 17:46:58.584515 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 17:46:58.585704 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 17:46:58.594020 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 17:46:58.599247 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 17:46:58.616636 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 17:46:58.618012 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 17:46:58.643086 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 17:46:58.656485 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 17:46:58.671007 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 17:46:58.678893 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 17:46:58.680242 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 17:46:58.690762 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 17:46:58.693777 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 17:46:58.699219 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 17:46:58.704600 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 17:46:58.705758 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 17:46:58.706680 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 17:46:58.707928 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 17:46:58.872266 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:46:58.883158 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:46:58.886332 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:46:58.889055 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:46:58.889293 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:46:58.890138 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:46:58.894056 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:46:58.894326 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:46:58.895184 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:46:58.901772 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:46:58.902000 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:46:58.929672 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:46:58.931116 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:46:58.932557 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:46:58.934058 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:46:58.950852 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 17:46:58.951173 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-19 17:46:58.952508 (MainThread): 
2021-11-19 17:46:58.952854 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:46:58.953692 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:46:58.959396 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:46:58.961638 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 17:46:58.962801 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 17:46:58.963132 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:46:58.963378 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:46:58.963636 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 17:46:58.963874 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 17:46:58.971295 (ThreadPoolExecutor-0_0): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 17:46:58.972298 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 17:46:58.972479 (ThreadPoolExecutor-0_1): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 17:46:58.973813 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 17:46:58.975279 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 17:46:58.975688 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:46:58.979924 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:46:58.980991 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:46:58.981180 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: BEGIN
2021-11-19 17:46:58.981369 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-19 17:46:58.981557 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 17:46:58.981738 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 17:46:58.988423 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:46:58.988744 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:46:58.989526 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:46:58.989669 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 17:46:58.989317 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:46:58.989881 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 17:46:58.991802 (ThreadPoolExecutor-1_1): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 17:46:58.992726 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 17:46:58.993078 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:46:58.993901 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 17:46:58.994051 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-19 17:46:58.994609 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 17:46:58.995877 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-19 17:46:58.995998 (ThreadPoolExecutor-1_1): On list_demo_db_sa: BEGIN
2021-11-19 17:46:58.996118 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 17:46:58.996357 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: Close
2021-11-19 17:46:59.002831 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:46:59.003082 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-19 17:46:59.003229 (ThreadPoolExecutor-1_1): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 17:46:59.005260 (ThreadPoolExecutor-1_1): SQL status: SELECT 3 in 0.00 seconds
2021-11-19 17:46:59.006199 (ThreadPoolExecutor-1_1): On list_demo_db_sa: ROLLBACK
2021-11-19 17:46:59.006565 (ThreadPoolExecutor-1_1): On list_demo_db_sa: Close
2021-11-19 17:46:59.010383 (MainThread): Using postgres connection "master".
2021-11-19 17:46:59.010512 (MainThread): On master: BEGIN
2021-11-19 17:46:59.010608 (MainThread): Opening a new connection, currently in state init
2021-11-19 17:46:59.016253 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:46:59.016430 (MainThread): Using postgres connection "master".
2021-11-19 17:46:59.016518 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 17:46:59.019604 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:46:59.020474 (MainThread): On master: ROLLBACK
2021-11-19 17:46:59.020756 (MainThread): Using postgres connection "master".
2021-11-19 17:46:59.020860 (MainThread): On master: BEGIN
2021-11-19 17:46:59.021345 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 17:46:59.021524 (MainThread): On master: COMMIT
2021-11-19 17:46:59.021617 (MainThread): Using postgres connection "master".
2021-11-19 17:46:59.021704 (MainThread): On master: COMMIT
2021-11-19 17:46:59.021984 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:46:59.022122 (MainThread): On master: Close
2021-11-19 17:46:59.022447 (MainThread): 18:46:59 | Concurrency: 2 threads (target='dev')
2021-11-19 17:46:59.022616 (MainThread): 18:46:59 | 
2021-11-19 17:46:59.024985 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-19 17:46:59.025334 (Thread-1): 18:46:59 | 1 of 3 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-19 17:46:59.025945 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:46:59.026120 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-19 17:46:59.032624 (Thread-1): finished collecting timing info
2021-11-19 17:46:59.032887 (Thread-1): Compilation Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  'iss' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 517, in catch_jinja
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 549, in render_template
    return template.render(ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 11, in top-level template code
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'iss' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 285, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/compile.py", line 33, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/compilation.py", line 543, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/compilation.py", line 383, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 598, in get_rendered
    return render_template(template, ctx, node)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 549, in render_template
    return template.render(ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 522, in catch_jinja
    raise UndefinedMacroException(str(e), node) from e
dbt.exceptions.UndefinedMacroException: Compilation Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  'iss' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
2021-11-19 17:46:59.036222 (Thread-1): 18:46:59 | 1 of 3 ERROR creating incremental model sa_dwh.iss_issuer............ [ERROR in 0.01s]
2021-11-19 17:46:59.036383 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-19 17:46:59.037016 (Thread-2): Began running node model.my_new_project.dim_issuer
2021-11-19 17:46:59.037177 (Thread-2): 18:46:59 | 2 of 3 SKIP relation sa_dm.dim_issuer................................ [SKIP]
2021-11-19 17:46:59.037328 (Thread-2): Finished running node model.my_new_project.dim_issuer
2021-11-19 17:46:59.037498 (Thread-2): Began running node model.my_new_project.fct_emissions
2021-11-19 17:46:59.037658 (Thread-2): 18:46:59 | 3 of 3 SKIP relation sa_dm.fct_emissions............................. [SKIP]
2021-11-19 17:46:59.037855 (Thread-2): Finished running node model.my_new_project.fct_emissions
2021-11-19 17:46:59.039439 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:46:59.039564 (MainThread): Using postgres connection "master".
2021-11-19 17:46:59.039651 (MainThread): On master: BEGIN
2021-11-19 17:46:59.039745 (MainThread): Opening a new connection, currently in state closed
2021-11-19 17:46:59.046085 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:46:59.046279 (MainThread): On master: COMMIT
2021-11-19 17:46:59.046372 (MainThread): Using postgres connection "master".
2021-11-19 17:46:59.046458 (MainThread): On master: COMMIT
2021-11-19 17:46:59.046799 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:46:59.046965 (MainThread): On master: Close
2021-11-19 17:46:59.047332 (MainThread): 18:46:59 | 
2021-11-19 17:46:59.047498 (MainThread): 18:46:59 | Finished running 2 incremental models, 1 table model in 0.09s.
2021-11-19 17:46:59.047704 (MainThread): Connection 'master' was properly closed.
2021-11-19 17:46:59.047836 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-19 17:46:59.047972 (MainThread): Connection 'list_demo_db_sa_dm' was properly closed.
2021-11-19 17:46:59.050911 (MainThread): 
2021-11-19 17:46:59.051073 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 17:46:59.051295 (MainThread): 
2021-11-19 17:46:59.051526 (MainThread): Compilation Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
2021-11-19 17:46:59.051740 (MainThread):   'iss' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
2021-11-19 17:46:59.051932 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=2 TOTAL=3
2021-11-19 17:46:59.052189 (MainThread): Flushing usage events
2021-11-19 17:51:01.886154 (MainThread): Running with dbt=0.21.0
2021-11-19 17:51:02.047002 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 17:51:02.047808 (MainThread): Tracking: do not track
2021-11-19 17:51:02.062909 (MainThread): Partial parsing not enabled
2021-11-19 17:51:02.076039 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 17:51:02.077331 (MainThread): Parsing macros/adapters.sql
2021-11-19 17:51:02.104619 (MainThread): Parsing macros/catalog.sql
2021-11-19 17:51:02.106597 (MainThread): Parsing macros/relations.sql
2021-11-19 17:51:02.107808 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 17:51:02.109269 (MainThread): Parsing macros/core.sql
2021-11-19 17:51:02.113217 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 17:51:02.162861 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 17:51:02.164964 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 17:51:02.166502 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 17:51:02.167802 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 17:51:02.174900 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 17:51:02.176212 (MainThread): Parsing macros/etc/query.sql
2021-11-19 17:51:02.177051 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 17:51:02.178272 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 17:51:02.186263 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 17:51:02.193334 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 17:51:02.215236 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 17:51:02.216882 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 17:51:02.243392 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 17:51:02.259322 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 17:51:02.277369 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 17:51:02.286092 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 17:51:02.287580 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 17:51:02.298735 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 17:51:02.302041 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 17:51:02.307808 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 17:51:02.313857 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 17:51:02.315075 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 17:51:02.316112 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 17:51:02.317535 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 17:51:02.498358 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:51:02.511386 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:51:02.514635 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:51:02.517823 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:51:02.518152 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:51:02.519093 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:51:02.522760 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:51:02.523001 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:51:02.523949 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:51:02.531323 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:51:02.531728 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:51:02.565741 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:51:02.567587 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:51:02.569287 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:51:02.571335 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:51:02.589705 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 17:51:02.590087 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-19 17:51:02.591271 (MainThread): 
2021-11-19 17:51:02.591726 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:51:02.592724 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:51:02.593242 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:51:02.602680 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 17:51:02.604547 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 17:51:02.604820 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:51:02.605091 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:51:02.605283 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 17:51:02.605463 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 17:51:02.612036 (ThreadPoolExecutor-0_1): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 17:51:02.613231 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 17:51:02.613435 (ThreadPoolExecutor-0_0): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 17:51:02.614770 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 17:51:02.617604 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 17:51:02.623334 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:51:02.624375 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:51:02.625649 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:51:02.625839 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: BEGIN
2021-11-19 17:51:02.626006 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-19 17:51:02.626179 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 17:51:02.626331 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 17:51:02.632932 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:51:02.633440 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:51:02.633715 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 17:51:02.635157 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:51:02.635351 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:51:02.635514 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 17:51:02.636583 (ThreadPoolExecutor-1_1): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 17:51:02.638008 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 17:51:02.638306 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:51:02.639688 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 17:51:02.639890 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-19 17:51:02.640650 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 17:51:02.642297 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-19 17:51:02.642469 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: Close
2021-11-19 17:51:02.642633 (ThreadPoolExecutor-1_1): On list_demo_db_sa: BEGIN
2021-11-19 17:51:02.642845 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 17:51:02.651005 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:51:02.651237 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-19 17:51:02.651437 (ThreadPoolExecutor-1_1): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 17:51:02.654728 (ThreadPoolExecutor-1_1): SQL status: SELECT 3 in 0.00 seconds
2021-11-19 17:51:02.656689 (ThreadPoolExecutor-1_1): On list_demo_db_sa: ROLLBACK
2021-11-19 17:51:02.657307 (ThreadPoolExecutor-1_1): On list_demo_db_sa: Close
2021-11-19 17:51:02.663946 (MainThread): Using postgres connection "master".
2021-11-19 17:51:02.664360 (MainThread): On master: BEGIN
2021-11-19 17:51:02.665000 (MainThread): Opening a new connection, currently in state init
2021-11-19 17:51:02.674414 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:51:02.674617 (MainThread): Using postgres connection "master".
2021-11-19 17:51:02.674728 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 17:51:02.682004 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-11-19 17:51:02.683202 (MainThread): On master: ROLLBACK
2021-11-19 17:51:02.683738 (MainThread): Using postgres connection "master".
2021-11-19 17:51:02.683925 (MainThread): On master: BEGIN
2021-11-19 17:51:02.684622 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 17:51:02.684805 (MainThread): On master: COMMIT
2021-11-19 17:51:02.684913 (MainThread): Using postgres connection "master".
2021-11-19 17:51:02.685010 (MainThread): On master: COMMIT
2021-11-19 17:51:02.685465 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:51:02.685634 (MainThread): On master: Close
2021-11-19 17:51:02.686004 (MainThread): 18:51:02 | Concurrency: 2 threads (target='dev')
2021-11-19 17:51:02.686246 (MainThread): 18:51:02 | 
2021-11-19 17:51:02.689775 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-19 17:51:02.690284 (Thread-1): 18:51:02 | 1 of 3 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-19 17:51:02.690868 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:51:02.691083 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-19 17:51:02.700432 (Thread-1): finished collecting timing info
2021-11-19 17:51:02.701195 (Thread-1): Compilation Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  'iss' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 517, in catch_jinja
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 549, in render_template
    return template.render(ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 11, in top-level template code
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'iss' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 285, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/compile.py", line 33, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/compilation.py", line 543, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/compilation.py", line 383, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 598, in get_rendered
    return render_template(template, ctx, node)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 549, in render_template
    return template.render(ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 522, in catch_jinja
    raise UndefinedMacroException(str(e), node) from e
dbt.exceptions.UndefinedMacroException: Compilation Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  'iss' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
2021-11-19 17:51:02.702693 (Thread-1): 18:51:02 | 1 of 3 ERROR creating incremental model sa_dwh.iss_issuer............ [ERROR in 0.01s]
2021-11-19 17:51:02.703015 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-19 17:51:02.704370 (Thread-2): Began running node model.my_new_project.dim_issuer
2021-11-19 17:51:02.704691 (Thread-1): Began running node model.my_new_project.fct_emissions
2021-11-19 17:51:02.704931 (Thread-2): 18:51:02 | 2 of 3 SKIP relation sa_dm.dim_issuer................................ [SKIP]
2021-11-19 17:51:02.705180 (Thread-1): 18:51:02 | 3 of 3 SKIP relation sa_dm.fct_emissions............................. [SKIP]
2021-11-19 17:51:02.705564 (Thread-2): Finished running node model.my_new_project.dim_issuer
2021-11-19 17:51:02.705981 (Thread-1): Finished running node model.my_new_project.fct_emissions
2021-11-19 17:51:02.707546 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:51:02.707718 (MainThread): Using postgres connection "master".
2021-11-19 17:51:02.707823 (MainThread): On master: BEGIN
2021-11-19 17:51:02.707926 (MainThread): Opening a new connection, currently in state closed
2021-11-19 17:51:02.714266 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:51:02.714589 (MainThread): On master: COMMIT
2021-11-19 17:51:02.714771 (MainThread): Using postgres connection "master".
2021-11-19 17:51:02.714938 (MainThread): On master: COMMIT
2021-11-19 17:51:02.715425 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:51:02.716037 (MainThread): On master: Close
2021-11-19 17:51:02.717233 (MainThread): 18:51:02 | 
2021-11-19 17:51:02.717735 (MainThread): 18:51:02 | Finished running 2 incremental models, 1 table model in 0.13s.
2021-11-19 17:51:02.718084 (MainThread): Connection 'master' was properly closed.
2021-11-19 17:51:02.718335 (MainThread): Connection 'list_demo_db_sa_dm' was properly closed.
2021-11-19 17:51:02.718495 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-19 17:51:02.723376 (MainThread): 
2021-11-19 17:51:02.723576 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 17:51:02.723787 (MainThread): 
2021-11-19 17:51:02.723962 (MainThread): Compilation Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
2021-11-19 17:51:02.724108 (MainThread):   'iss' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
2021-11-19 17:51:02.724284 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=2 TOTAL=3
2021-11-19 17:51:02.724504 (MainThread): Flushing usage events
2021-11-19 17:51:14.468432 (MainThread): Running with dbt=0.21.0
2021-11-19 17:51:14.523927 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, defer=None, state=None, cls=<class 'dbt.task.deps.DepsTask'>, which='deps', rpc_method='deps')
2021-11-19 17:51:14.524193 (MainThread): Tracking: do not track
2021-11-19 17:51:14.526701 (MainThread): Warning: No packages were found in packages.yml
2021-11-19 17:51:14.527009 (MainThread): Flushing usage events
2021-11-19 17:53:13.147222 (MainThread): Running with dbt=0.21.0
2021-11-19 17:53:13.203299 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 17:53:13.203707 (MainThread): Tracking: do not track
2021-11-19 17:53:13.213158 (MainThread): Partial parsing not enabled
2021-11-19 17:53:13.219293 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 17:53:13.219873 (MainThread): Parsing macros/adapters.sql
2021-11-19 17:53:13.237460 (MainThread): Parsing macros/catalog.sql
2021-11-19 17:53:13.239096 (MainThread): Parsing macros/relations.sql
2021-11-19 17:53:13.240021 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 17:53:13.241264 (MainThread): Parsing macros/core.sql
2021-11-19 17:53:13.244409 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 17:53:13.285544 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 17:53:13.287438 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 17:53:13.288752 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 17:53:13.289927 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 17:53:13.296286 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 17:53:13.297813 (MainThread): Parsing macros/etc/query.sql
2021-11-19 17:53:13.298872 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 17:53:13.300929 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 17:53:13.309494 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 17:53:13.314790 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 17:53:13.331832 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 17:53:13.333319 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 17:53:13.356327 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 17:53:13.369434 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 17:53:13.383782 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 17:53:13.391653 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 17:53:13.392936 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 17:53:13.403241 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 17:53:13.406261 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 17:53:13.411566 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 17:53:13.416960 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 17:53:13.418050 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 17:53:13.418956 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 17:53:13.420241 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 17:53:13.574080 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:53:13.583840 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:53:13.586617 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:53:13.589224 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:53:13.589434 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:53:13.590339 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:53:13.593561 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:53:13.593768 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:53:13.594542 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:53:13.600173 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:53:13.600386 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:53:13.629650 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:53:13.631106 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:53:13.632517 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:53:13.634235 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:53:13.648066 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 17:53:13.648362 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-19 17:53:13.649616 (MainThread): 
2021-11-19 17:53:13.650056 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:53:13.651149 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:53:13.656765 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:53:13.660473 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 17:53:13.660607 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:53:13.660840 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 17:53:13.663570 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 17:53:13.663784 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:53:13.663936 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 17:53:13.668610 (ThreadPoolExecutor-0_1): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 17:53:13.669719 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 17:53:13.670945 (ThreadPoolExecutor-0_0): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 17:53:13.671885 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 17:53:13.673148 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 17:53:13.673521 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:53:13.677623 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:53:13.678633 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:53:13.678820 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: BEGIN
2021-11-19 17:53:13.678999 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-19 17:53:13.679186 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 17:53:13.679368 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 17:53:13.686218 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:53:13.686414 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:53:13.686575 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:53:13.686766 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:53:13.686906 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 17:53:13.687086 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 17:53:13.688814 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:53:13.689726 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 17:53:13.689885 (ThreadPoolExecutor-1_1): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 17:53:13.690627 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 17:53:13.690743 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: Close
2021-11-19 17:53:13.691362 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 17:53:13.692335 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 17:53:13.692533 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-19 17:53:13.692658 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-19 17:53:13.693029 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 17:53:13.698852 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:53:13.698999 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 17:53:13.699088 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 17:53:13.700863 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2021-11-19 17:53:13.701818 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-19 17:53:13.702062 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-19 17:53:13.705681 (MainThread): Using postgres connection "master".
2021-11-19 17:53:13.705792 (MainThread): On master: BEGIN
2021-11-19 17:53:13.705887 (MainThread): Opening a new connection, currently in state init
2021-11-19 17:53:13.711426 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:53:13.711558 (MainThread): Using postgres connection "master".
2021-11-19 17:53:13.711646 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 17:53:13.714851 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:53:13.715792 (MainThread): On master: ROLLBACK
2021-11-19 17:53:13.716182 (MainThread): Using postgres connection "master".
2021-11-19 17:53:13.716322 (MainThread): On master: BEGIN
2021-11-19 17:53:13.717031 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 17:53:13.717258 (MainThread): On master: COMMIT
2021-11-19 17:53:13.717351 (MainThread): Using postgres connection "master".
2021-11-19 17:53:13.717437 (MainThread): On master: COMMIT
2021-11-19 17:53:13.717810 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:53:13.717933 (MainThread): On master: Close
2021-11-19 17:53:13.718226 (MainThread): 18:53:13 | Concurrency: 2 threads (target='dev')
2021-11-19 17:53:13.718371 (MainThread): 18:53:13 | 
2021-11-19 17:53:13.720784 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-19 17:53:13.721054 (Thread-1): 18:53:13 | 1 of 3 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-19 17:53:13.721490 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:53:13.721610 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-19 17:53:13.726639 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-19 17:53:13.726850 (Thread-1): finished collecting timing info
2021-11-19 17:53:13.760191 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-19 17:53:13.760478 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:53:13.760578 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-19 17:53:13.760674 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 17:53:13.767409 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:53:13.767572 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:53:13.767666 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer"
  as (
    

select
     CASE
        WHEN iss.AdjustedEnterpriseValue ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.AdjustedEnterpriseValue::numeric
    ELSE NULL
    END        as adjusted_enterprise_value
    ,iss.ISIN                                             as isin
    ,iss.IssuerName                                       as issuer_name
    ,iss.gicssector                                       as gics_sector
    ,iss.gicsindustrygroup                                as gics_industry_group
    ,CASE
        WHEN iss.ClimateScope2EmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope2EmissionsIntUSD::numeric
    ELSE NULL
    END   as climate_scope2_emissions_int_usd
    ,CASE
        WHEN iss.ClimateScope1EmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope1EmissionsIntUSD::numeric
    ELSE NULL
    END   as climate_scope1_emissions_int_usd
    ,CASE
        WHEN iss.ClimateScope2Emissions ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope2Emissions::numeric
    ELSE NULL
    END         as climate_scope2_emissions
    ,CASE
        WHEN iss.ClimateTotalEmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateTotalEmissionsIntUSD::numeric
    ELSE NULL
    END    as climate_total_emissions_int_usd
    ,CASE
        WHEN iss.ClimateScope3Emissions ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope3Emissions::numeric
    ELSE NULL
    END         as climate_scope3_emissions
    ,CASE
        WHEN iss.ClimateCNIEmissionsSource ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateCNIEmissionsSource::numeric
    ELSE NULL
    END      as climate_cni_emissions_source
    ,CASE
        WHEN iss.ClimateTotalEmissions ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateTotalEmissions::numeric
    ELSE NULL
    END          as climate_total_emissions
    ,CASE
        WHEN iss.ClimateScope1Emissions ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope1Emissions::numeric
    ELSE NULL
    END         as climate_scope1_emissions
    ,CASE
        WHEN iss.MarketCapDaily ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.MarketCapDaily::numeric
    ELSE NULL
    END                 as market_cap_daily
    ,iss.ClimateEmissionsFiscalYear::INT                  as climate_emissions_fiscal_year
    ,'2021-01-01'::DATE                          as meta_file_date
    ,'20211117T164451425627'                              as meta_run_id
    ,CURRENT_TIMESTAMP                                    as meta_insert_timestamp
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-19 17:53:13.768433 (Thread-1): Postgres error: operator does not exist: double precision ~ unknown
LINE 30:         WHEN iss.ClimateScope2Emissions ~ '[+-]?([0-9]*[.])?...
                                                 ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.

2021-11-19 17:53:13.768584 (Thread-1): On model.my_new_project.iss_issuer: ROLLBACK
2021-11-19 17:53:13.769110 (Thread-1): finished collecting timing info
2021-11-19 17:53:13.769241 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-19 17:53:13.769578 (Thread-1): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  operator does not exist: double precision ~ unknown
  LINE 30:         WHEN iss.ClimateScope2Emissions ~ '[+-]?([0-9]*[.])?...
                                                   ^
  HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedFunction: operator does not exist: double precision ~ unknown
LINE 30:         WHEN iss.ClimateScope2Emissions ~ '[+-]?([0-9]*[.])?...
                                                 ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  operator does not exist: double precision ~ unknown
  LINE 30:         WHEN iss.ClimateScope2Emissions ~ '[+-]?([0-9]*[.])?...
                                                   ^
  HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-19 17:53:13.770794 (Thread-1): 18:53:13 | 1 of 3 ERROR creating incremental model sa_dwh.iss_issuer............ [ERROR in 0.05s]
2021-11-19 17:53:13.770942 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-19 17:53:13.771766 (Thread-2): Began running node model.my_new_project.dim_issuer
2021-11-19 17:53:13.771972 (Thread-2): 18:53:13 | 2 of 3 SKIP relation sa_dm.dim_issuer................................ [SKIP]
2021-11-19 17:53:13.772147 (Thread-2): Finished running node model.my_new_project.dim_issuer
2021-11-19 17:53:13.772417 (Thread-2): Began running node model.my_new_project.fct_emissions
2021-11-19 17:53:13.772792 (Thread-2): 18:53:13 | 3 of 3 SKIP relation sa_dm.fct_emissions............................. [SKIP]
2021-11-19 17:53:13.773158 (Thread-2): Finished running node model.my_new_project.fct_emissions
2021-11-19 17:53:13.774471 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:53:13.774608 (MainThread): Using postgres connection "master".
2021-11-19 17:53:13.774700 (MainThread): On master: BEGIN
2021-11-19 17:53:13.774821 (MainThread): Opening a new connection, currently in state closed
2021-11-19 17:53:13.780330 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:53:13.780497 (MainThread): On master: COMMIT
2021-11-19 17:53:13.780588 (MainThread): Using postgres connection "master".
2021-11-19 17:53:13.780673 (MainThread): On master: COMMIT
2021-11-19 17:53:13.780886 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:53:13.780993 (MainThread): On master: Close
2021-11-19 17:53:13.781347 (MainThread): 18:53:13 | 
2021-11-19 17:53:13.781483 (MainThread): 18:53:13 | Finished running 2 incremental models, 1 table model in 0.13s.
2021-11-19 17:53:13.781673 (MainThread): Connection 'master' was properly closed.
2021-11-19 17:53:13.781833 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-19 17:53:13.781914 (MainThread): Connection 'list_demo_db_sa_dwh' was properly closed.
2021-11-19 17:53:13.785028 (MainThread): 
2021-11-19 17:53:13.785184 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 17:53:13.785472 (MainThread): 
2021-11-19 17:53:13.785719 (MainThread): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
2021-11-19 17:53:13.785913 (MainThread):   operator does not exist: double precision ~ unknown
2021-11-19 17:53:13.786065 (MainThread):   LINE 30:         WHEN iss.ClimateScope2Emissions ~ '[+-]?([0-9]*[.])?...
2021-11-19 17:53:13.786213 (MainThread):                                                    ^
2021-11-19 17:53:13.786363 (MainThread):   HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
2021-11-19 17:53:13.786511 (MainThread):   compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-19 17:53:13.786654 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=2 TOTAL=3
2021-11-19 17:53:13.786827 (MainThread): Flushing usage events
2021-11-19 17:54:00.905016 (MainThread): Running with dbt=0.21.0
2021-11-19 17:54:00.959093 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 17:54:00.959518 (MainThread): Tracking: do not track
2021-11-19 17:54:00.969170 (MainThread): Partial parsing not enabled
2021-11-19 17:54:00.975169 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 17:54:00.975853 (MainThread): Parsing macros/adapters.sql
2021-11-19 17:54:00.993215 (MainThread): Parsing macros/catalog.sql
2021-11-19 17:54:00.994819 (MainThread): Parsing macros/relations.sql
2021-11-19 17:54:00.995863 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 17:54:00.997255 (MainThread): Parsing macros/core.sql
2021-11-19 17:54:01.000179 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 17:54:01.040989 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 17:54:01.042924 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 17:54:01.044311 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 17:54:01.045553 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 17:54:01.051867 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 17:54:01.052988 (MainThread): Parsing macros/etc/query.sql
2021-11-19 17:54:01.053735 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 17:54:01.054842 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 17:54:01.062838 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 17:54:01.068488 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 17:54:01.087689 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 17:54:01.089193 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 17:54:01.112261 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 17:54:01.126149 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 17:54:01.140841 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 17:54:01.148505 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 17:54:01.149767 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 17:54:01.159965 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 17:54:01.163275 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 17:54:01.168542 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 17:54:01.173900 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 17:54:01.174923 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 17:54:01.175829 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 17:54:01.177085 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 17:54:01.333943 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:54:01.343542 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:54:01.346495 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:54:01.348932 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:54:01.349145 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:54:01.349999 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:54:01.353256 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:54:01.353463 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:54:01.354334 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:54:01.359783 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:54:01.359990 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:54:01.388382 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:54:01.389818 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:54:01.391206 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:54:01.392702 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:54:01.407062 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 17:54:01.407441 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-19 17:54:01.408673 (MainThread): 
2021-11-19 17:54:01.408997 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:54:01.409859 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:54:01.415479 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:54:01.419355 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 17:54:01.419509 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:54:01.419639 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 17:54:01.421596 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 17:54:01.421838 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:54:01.422079 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 17:54:01.428157 (ThreadPoolExecutor-0_1): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 17:54:01.429499 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 17:54:01.430888 (ThreadPoolExecutor-0_0): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 17:54:01.431797 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 17:54:01.433149 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:54:01.433556 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 17:54:01.438411 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:54:01.439588 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-19 17:54:01.439802 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: BEGIN
2021-11-19 17:54:01.440026 (ThreadPoolExecutor-1_1): On list_demo_db_sa: BEGIN
2021-11-19 17:54:01.440255 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 17:54:01.440476 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 17:54:01.447448 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:54:01.447609 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-19 17:54:01.447732 (ThreadPoolExecutor-1_1): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 17:54:01.447900 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:54:01.448020 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:54:01.448115 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 17:54:01.449563 (ThreadPoolExecutor-1_1): SQL status: SELECT 3 in 0.00 seconds
2021-11-19 17:54:01.450546 (ThreadPoolExecutor-1_1): On list_demo_db_sa: ROLLBACK
2021-11-19 17:54:01.450722 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 17:54:01.451541 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 17:54:01.451706 (ThreadPoolExecutor-1_1): On list_demo_db_sa: Close
2021-11-19 17:54:01.452135 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 17:54:01.453225 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:54:01.453351 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: BEGIN
2021-11-19 17:54:01.453477 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 17:54:01.453984 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: Close
2021-11-19 17:54:01.459851 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:54:01.460048 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:54:01.460135 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 17:54:01.461712 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:54:01.462621 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 17:54:01.463057 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: Close
2021-11-19 17:54:01.466510 (MainThread): Using postgres connection "master".
2021-11-19 17:54:01.466635 (MainThread): On master: BEGIN
2021-11-19 17:54:01.466735 (MainThread): Opening a new connection, currently in state init
2021-11-19 17:54:01.472580 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:54:01.472712 (MainThread): Using postgres connection "master".
2021-11-19 17:54:01.472804 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 17:54:01.476016 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:54:01.476871 (MainThread): On master: ROLLBACK
2021-11-19 17:54:01.477205 (MainThread): Using postgres connection "master".
2021-11-19 17:54:01.477304 (MainThread): On master: BEGIN
2021-11-19 17:54:01.478012 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 17:54:01.478164 (MainThread): On master: COMMIT
2021-11-19 17:54:01.478253 (MainThread): Using postgres connection "master".
2021-11-19 17:54:01.478337 (MainThread): On master: COMMIT
2021-11-19 17:54:01.478654 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:54:01.478764 (MainThread): On master: Close
2021-11-19 17:54:01.479120 (MainThread): 18:54:01 | Concurrency: 2 threads (target='dev')
2021-11-19 17:54:01.479259 (MainThread): 18:54:01 | 
2021-11-19 17:54:01.481631 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-19 17:54:01.481916 (Thread-1): 18:54:01 | 1 of 3 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-19 17:54:01.482329 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:54:01.482565 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-19 17:54:01.487931 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-19 17:54:01.488164 (Thread-1): finished collecting timing info
2021-11-19 17:54:01.524194 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-19 17:54:01.524490 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:54:01.524590 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-19 17:54:01.524686 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 17:54:01.530922 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:54:01.531100 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:54:01.531190 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer"
  as (
    

select
     CASE
        WHEN iss.AdjustedEnterpriseValue like '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.AdjustedEnterpriseValue::numeric
    ELSE NULL
    END        as adjusted_enterprise_value
    ,iss.ISIN                                               as isin
    ,iss.IssuerName                                         as issuer_name
    ,iss.gicssector                                         as gics_sector
    ,iss.gicsindustrygroup                                  as gics_industry_group
    ,CASE
        WHEN iss.ClimateScope2EmissionsIntUSD like '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope2EmissionsIntUSD::numeric
    ELSE NULL
    END   as climate_scope2_emissions_int_usd
    ,CASE
        WHEN iss.ClimateScope1EmissionsIntUSD like '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope1EmissionsIntUSD::numeric
    ELSE NULL
    END   as climate_scope1_emissions_int_usd
    ,CASE
        WHEN iss.ClimateScope2Emissions like '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope2Emissions::numeric
    ELSE NULL
    END         as climate_scope2_emissions
    ,CASE
        WHEN iss.ClimateTotalEmissionsIntUSD like '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateTotalEmissionsIntUSD::numeric
    ELSE NULL
    END    as climate_total_emissions_int_usd
    ,CASE
        WHEN iss.ClimateScope3Emissions like '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope3Emissions::numeric
    ELSE NULL
    END         as climate_scope3_emissions
    ,CASE
        WHEN iss.ClimateCNIEmissionsSource like '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateCNIEmissionsSource::numeric
    ELSE NULL
    END      as climate_cni_emissions_source
    ,CASE
        WHEN iss.ClimateTotalEmissions like '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateTotalEmissions::numeric
    ELSE NULL
    END          as climate_total_emissions
    ,CASE
        WHEN iss.ClimateScope1Emissions like '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope1Emissions::numeric
    ELSE NULL
    END         as climate_scope1_emissions
    ,CASE
        WHEN iss.MarketCapDaily like '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.MarketCapDaily::numeric
    ELSE NULL
    END                 as market_cap_daily
    ,iss.ClimateEmissionsFiscalYear::INT                    as climate_emissions_fiscal_year
    ,'2021-01-01'::DATE                            as meta_file_date
    ,'20211117T164451425627'                                as meta_run_id
    ,CURRENT_TIMESTAMP                                      as meta_insert_timestamp
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-19 17:54:01.532001 (Thread-1): Postgres error: operator does not exist: double precision ~~ unknown
LINE 30:         WHEN iss.ClimateScope2Emissions like '[+-]?([0-9]*[....
                                                 ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.

2021-11-19 17:54:01.532170 (Thread-1): On model.my_new_project.iss_issuer: ROLLBACK
2021-11-19 17:54:01.532599 (Thread-1): finished collecting timing info
2021-11-19 17:54:01.532730 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-19 17:54:01.532994 (Thread-1): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  operator does not exist: double precision ~~ unknown
  LINE 30:         WHEN iss.ClimateScope2Emissions like '[+-]?([0-9]*[....
                                                   ^
  HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedFunction: operator does not exist: double precision ~~ unknown
LINE 30:         WHEN iss.ClimateScope2Emissions like '[+-]?([0-9]*[....
                                                 ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  operator does not exist: double precision ~~ unknown
  LINE 30:         WHEN iss.ClimateScope2Emissions like '[+-]?([0-9]*[....
                                                   ^
  HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-19 17:54:01.534611 (Thread-1): 18:54:01 | 1 of 3 ERROR creating incremental model sa_dwh.iss_issuer............ [ERROR in 0.05s]
2021-11-19 17:54:01.534871 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-19 17:54:01.535786 (Thread-2): Began running node model.my_new_project.dim_issuer
2021-11-19 17:54:01.535959 (Thread-2): 18:54:01 | 2 of 3 SKIP relation sa_dm.dim_issuer................................ [SKIP]
2021-11-19 17:54:01.536115 (Thread-2): Finished running node model.my_new_project.dim_issuer
2021-11-19 17:54:01.536267 (Thread-2): Began running node model.my_new_project.fct_emissions
2021-11-19 17:54:01.536441 (Thread-2): 18:54:01 | 3 of 3 SKIP relation sa_dm.fct_emissions............................. [SKIP]
2021-11-19 17:54:01.536615 (Thread-2): Finished running node model.my_new_project.fct_emissions
2021-11-19 17:54:01.537975 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:54:01.538123 (MainThread): Using postgres connection "master".
2021-11-19 17:54:01.538221 (MainThread): On master: BEGIN
2021-11-19 17:54:01.538322 (MainThread): Opening a new connection, currently in state closed
2021-11-19 17:54:01.543941 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:54:01.544113 (MainThread): On master: COMMIT
2021-11-19 17:54:01.544204 (MainThread): Using postgres connection "master".
2021-11-19 17:54:01.544289 (MainThread): On master: COMMIT
2021-11-19 17:54:01.544646 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:54:01.544797 (MainThread): On master: Close
2021-11-19 17:54:01.545140 (MainThread): 18:54:01 | 
2021-11-19 17:54:01.545343 (MainThread): 18:54:01 | Finished running 2 incremental models, 1 table model in 0.14s.
2021-11-19 17:54:01.545550 (MainThread): Connection 'master' was properly closed.
2021-11-19 17:54:01.545721 (MainThread): Connection 'list_demo_db_sa_dwh' was properly closed.
2021-11-19 17:54:01.545822 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-19 17:54:01.548813 (MainThread): 
2021-11-19 17:54:01.548954 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 17:54:01.549202 (MainThread): 
2021-11-19 17:54:01.549479 (MainThread): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
2021-11-19 17:54:01.549665 (MainThread):   operator does not exist: double precision ~~ unknown
2021-11-19 17:54:01.549880 (MainThread):   LINE 30:         WHEN iss.ClimateScope2Emissions like '[+-]?([0-9]*[....
2021-11-19 17:54:01.550050 (MainThread):                                                    ^
2021-11-19 17:54:01.550235 (MainThread):   HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
2021-11-19 17:54:01.550399 (MainThread):   compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-19 17:54:01.550529 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=2 TOTAL=3
2021-11-19 17:54:01.550718 (MainThread): Flushing usage events
2021-11-19 17:54:34.645192 (MainThread): Running with dbt=0.21.0
2021-11-19 17:54:34.699032 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 17:54:34.699531 (MainThread): Tracking: do not track
2021-11-19 17:54:34.709177 (MainThread): Partial parsing not enabled
2021-11-19 17:54:34.715366 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 17:54:34.715947 (MainThread): Parsing macros/adapters.sql
2021-11-19 17:54:34.733144 (MainThread): Parsing macros/catalog.sql
2021-11-19 17:54:34.734831 (MainThread): Parsing macros/relations.sql
2021-11-19 17:54:34.735866 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 17:54:34.737093 (MainThread): Parsing macros/core.sql
2021-11-19 17:54:34.740000 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 17:54:34.782295 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 17:54:34.784308 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 17:54:34.785919 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 17:54:34.787117 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 17:54:34.793466 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 17:54:34.794581 (MainThread): Parsing macros/etc/query.sql
2021-11-19 17:54:34.795402 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 17:54:34.796536 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 17:54:34.804653 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 17:54:34.809713 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 17:54:34.827800 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 17:54:34.829140 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 17:54:34.853633 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 17:54:34.866967 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 17:54:34.882241 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 17:54:34.890444 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 17:54:34.892471 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 17:54:34.902903 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 17:54:34.905941 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 17:54:34.911120 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 17:54:34.916689 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 17:54:34.917760 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 17:54:34.918725 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 17:54:34.920029 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 17:54:35.085797 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 17:54:35.096848 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 17:54:35.100463 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 17:54:35.105471 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:54:35.105765 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:54:35.106799 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 17:54:35.111799 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:54:35.112200 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:54:35.113573 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:54:35.121047 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:54:35.121485 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:54:35.153754 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:54:35.155833 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:54:35.157483 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:54:35.159673 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 17:54:35.177986 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 17:54:35.178319 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-19 17:54:35.179955 (MainThread): 
2021-11-19 17:54:35.180361 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:54:35.181572 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:54:35.182344 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 17:54:35.197296 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 17:54:35.197451 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:54:35.197583 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 17:54:35.198950 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 17:54:35.199091 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 17:54:35.199187 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 17:54:35.204588 (ThreadPoolExecutor-0_1): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 17:54:35.205707 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 17:54:35.206716 (ThreadPoolExecutor-0_0): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 17:54:35.207581 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 17:54:35.208851 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 17:54:35.209205 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:54:35.213168 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:54:35.214234 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:54:35.214417 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: BEGIN
2021-11-19 17:54:35.214599 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-19 17:54:35.214786 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 17:54:35.214969 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 17:54:35.221915 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:54:35.222164 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:54:35.222386 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 17:54:35.222591 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 17:54:35.222770 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 17:54:35.222944 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 17:54:35.224709 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:54:35.224906 (ThreadPoolExecutor-1_1): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 17:54:35.225832 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 17:54:35.226634 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 17:54:35.226946 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: Close
2021-11-19 17:54:35.227075 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-19 17:54:35.227582 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 17:54:35.228643 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 17:54:35.229128 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-19 17:54:35.229247 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 17:54:35.234361 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:54:35.234527 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 17:54:35.234635 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 17:54:35.236298 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2021-11-19 17:54:35.237246 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-19 17:54:35.237630 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-19 17:54:35.241337 (MainThread): Using postgres connection "master".
2021-11-19 17:54:35.241469 (MainThread): On master: BEGIN
2021-11-19 17:54:35.241576 (MainThread): Opening a new connection, currently in state init
2021-11-19 17:54:35.247460 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:54:35.247623 (MainThread): Using postgres connection "master".
2021-11-19 17:54:35.247719 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 17:54:35.250910 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 17:54:35.252373 (MainThread): On master: ROLLBACK
2021-11-19 17:54:35.252798 (MainThread): Using postgres connection "master".
2021-11-19 17:54:35.252973 (MainThread): On master: BEGIN
2021-11-19 17:54:35.253449 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 17:54:35.253578 (MainThread): On master: COMMIT
2021-11-19 17:54:35.253678 (MainThread): Using postgres connection "master".
2021-11-19 17:54:35.253770 (MainThread): On master: COMMIT
2021-11-19 17:54:35.254021 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:54:35.254147 (MainThread): On master: Close
2021-11-19 17:54:35.254431 (MainThread): 18:54:35 | Concurrency: 2 threads (target='dev')
2021-11-19 17:54:35.254585 (MainThread): 18:54:35 | 
2021-11-19 17:54:35.256640 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-19 17:54:35.256971 (Thread-1): 18:54:35 | 1 of 3 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-19 17:54:35.257528 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:54:35.257660 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-19 17:54:35.263352 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-19 17:54:35.263593 (Thread-1): finished collecting timing info
2021-11-19 17:54:35.299484 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-19 17:54:35.299785 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:54:35.299891 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-19 17:54:35.299994 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 17:54:35.306481 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:54:35.306646 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 17:54:35.306745 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer"
  as (
    

select
     CASE
        WHEN iss.AdjustedEnterpriseValue ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.AdjustedEnterpriseValue::numeric
    ELSE NULL
    END        as adjusted_enterprise_value
    ,iss.ISIN                                               as isin
    ,iss.IssuerName                                         as issuer_name
    ,iss.gicssector                                         as gics_sector
    ,iss.gicsindustrygroup                                  as gics_industry_group
    ,CASE
        WHEN iss.ClimateScope2EmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope2EmissionsIntUSD::numeric
    ELSE NULL
    END   as climate_scope2_emissions_int_usd
    ,CASE
        WHEN iss.ClimateScope1EmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope1EmissionsIntUSD::numeric
    ELSE NULL
    END   as climate_scope1_emissions_int_usd
    ,CASE
        WHEN iss.ClimateScope2Emissions ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope2Emissions::numeric
    ELSE NULL
    END         as climate_scope2_emissions
    ,CASE
        WHEN iss.ClimateTotalEmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateTotalEmissionsIntUSD::numeric
    ELSE NULL
    END    as climate_total_emissions_int_usd
    ,CASE
        WHEN iss.ClimateScope3Emissions ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope3Emissions::numeric
    ELSE NULL
    END         as climate_scope3_emissions
    ,CASE
        WHEN iss.ClimateCNIEmissionsSource ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateCNIEmissionsSource::numeric
    ELSE NULL
    END      as climate_cni_emissions_source
    ,CASE
        WHEN iss.ClimateTotalEmissions ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateTotalEmissions::numeric
    ELSE NULL
    END          as climate_total_emissions
    ,CASE
        WHEN iss.ClimateScope1Emissions ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope1Emissions::numeric
    ELSE NULL
    END         as climate_scope1_emissions
    ,CASE
        WHEN iss.MarketCapDaily ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.MarketCapDaily::numeric
    ELSE NULL
    END                 as market_cap_daily
    ,iss.ClimateEmissionsFiscalYear::INT                    as climate_emissions_fiscal_year
    ,'2021-01-01'::DATE                            as meta_file_date
    ,'20211117T164451425627'                                as meta_run_id
    ,CURRENT_TIMESTAMP                                      as meta_insert_timestamp
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-19 17:54:35.307515 (Thread-1): Postgres error: operator does not exist: double precision ~ unknown
LINE 30:         WHEN iss.ClimateScope2Emissions ~ '[+-]?([0-9]*[.])?...
                                                 ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.

2021-11-19 17:54:35.307652 (Thread-1): On model.my_new_project.iss_issuer: ROLLBACK
2021-11-19 17:54:35.308077 (Thread-1): finished collecting timing info
2021-11-19 17:54:35.308220 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-19 17:54:35.308520 (Thread-1): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  operator does not exist: double precision ~ unknown
  LINE 30:         WHEN iss.ClimateScope2Emissions ~ '[+-]?([0-9]*[.])?...
                                                   ^
  HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedFunction: operator does not exist: double precision ~ unknown
LINE 30:         WHEN iss.ClimateScope2Emissions ~ '[+-]?([0-9]*[.])?...
                                                 ^
HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  operator does not exist: double precision ~ unknown
  LINE 30:         WHEN iss.ClimateScope2Emissions ~ '[+-]?([0-9]*[.])?...
                                                   ^
  HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-19 17:54:35.309930 (Thread-1): 18:54:35 | 1 of 3 ERROR creating incremental model sa_dwh.iss_issuer............ [ERROR in 0.05s]
2021-11-19 17:54:35.310095 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-19 17:54:35.310964 (Thread-2): Began running node model.my_new_project.dim_issuer
2021-11-19 17:54:35.311175 (Thread-1): Began running node model.my_new_project.fct_emissions
2021-11-19 17:54:35.311405 (Thread-2): 18:54:35 | 2 of 3 SKIP relation sa_dm.dim_issuer................................ [SKIP]
2021-11-19 17:54:35.311653 (Thread-1): 18:54:35 | 3 of 3 SKIP relation sa_dm.fct_emissions............................. [SKIP]
2021-11-19 17:54:35.311967 (Thread-2): Finished running node model.my_new_project.dim_issuer
2021-11-19 17:54:35.312224 (Thread-1): Finished running node model.my_new_project.fct_emissions
2021-11-19 17:54:35.313719 (MainThread): Acquiring new postgres connection "master".
2021-11-19 17:54:35.313860 (MainThread): Using postgres connection "master".
2021-11-19 17:54:35.313957 (MainThread): On master: BEGIN
2021-11-19 17:54:35.314057 (MainThread): Opening a new connection, currently in state closed
2021-11-19 17:54:35.320041 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 17:54:35.320224 (MainThread): On master: COMMIT
2021-11-19 17:54:35.320326 (MainThread): Using postgres connection "master".
2021-11-19 17:54:35.320422 (MainThread): On master: COMMIT
2021-11-19 17:54:35.320667 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 17:54:35.320789 (MainThread): On master: Close
2021-11-19 17:54:35.321116 (MainThread): 18:54:35 | 
2021-11-19 17:54:35.321276 (MainThread): 18:54:35 | Finished running 2 incremental models, 1 table model in 0.14s.
2021-11-19 17:54:35.321448 (MainThread): Connection 'master' was properly closed.
2021-11-19 17:54:35.321558 (MainThread): Connection 'list_demo_db_sa_dwh' was properly closed.
2021-11-19 17:54:35.321657 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-19 17:54:35.324683 (MainThread): 
2021-11-19 17:54:35.324850 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 17:54:35.325115 (MainThread): 
2021-11-19 17:54:35.325277 (MainThread): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
2021-11-19 17:54:35.325499 (MainThread):   operator does not exist: double precision ~ unknown
2021-11-19 17:54:35.325726 (MainThread):   LINE 30:         WHEN iss.ClimateScope2Emissions ~ '[+-]?([0-9]*[.])?...
2021-11-19 17:54:35.325925 (MainThread):                                                    ^
2021-11-19 17:54:35.326065 (MainThread):   HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
2021-11-19 17:54:35.326255 (MainThread):   compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-19 17:54:35.326421 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=2 TOTAL=3
2021-11-19 17:54:35.326628 (MainThread): Flushing usage events
2021-11-19 18:28:10.409512 (MainThread): Running with dbt=0.21.0
2021-11-19 18:28:10.464003 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 18:28:10.464424 (MainThread): Tracking: do not track
2021-11-19 18:28:10.474117 (MainThread): Partial parsing not enabled
2021-11-19 18:28:10.480719 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 18:28:10.481709 (MainThread): Parsing macros/adapters.sql
2021-11-19 18:28:10.499143 (MainThread): Parsing macros/catalog.sql
2021-11-19 18:28:10.500719 (MainThread): Parsing macros/relations.sql
2021-11-19 18:28:10.501624 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 18:28:10.502847 (MainThread): Parsing macros/core.sql
2021-11-19 18:28:10.505872 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 18:28:10.546116 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 18:28:10.548069 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 18:28:10.549410 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 18:28:10.550556 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 18:28:10.557235 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 18:28:10.558335 (MainThread): Parsing macros/etc/query.sql
2021-11-19 18:28:10.559046 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 18:28:10.560172 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 18:28:10.567502 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 18:28:10.572655 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 18:28:10.589432 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 18:28:10.590693 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 18:28:10.612699 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 18:28:10.626118 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 18:28:10.640574 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 18:28:10.648189 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 18:28:10.649609 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 18:28:10.659701 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 18:28:10.662612 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 18:28:10.667737 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 18:28:10.673314 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 18:28:10.674354 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 18:28:10.675260 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 18:28:10.676481 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 18:28:10.866427 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 18:28:10.879481 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 18:28:10.883316 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 18:28:10.886539 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 18:28:10.886832 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 18:28:10.887833 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 18:28:10.891984 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 18:28:10.892320 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 18:28:10.893486 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 18:28:10.899267 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 18:28:10.899536 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 18:28:10.929745 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 18:28:10.931395 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 18:28:10.932903 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 18:28:10.934557 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 18:28:10.949395 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 18:28:10.949694 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-19 18:28:10.950754 (MainThread): 
2021-11-19 18:28:10.951018 (MainThread): Acquiring new postgres connection "master".
2021-11-19 18:28:10.951827 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 18:28:10.952286 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 18:28:10.961820 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 18:28:10.961973 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 18:28:10.962097 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 18:28:10.964670 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 18:28:10.964785 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 18:28:10.964889 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 18:28:10.969719 (ThreadPoolExecutor-0_1): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 18:28:10.970800 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 18:28:10.971892 (ThreadPoolExecutor-0_0): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 18:28:10.973010 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 18:28:10.974280 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 18:28:10.978686 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 18:28:10.978818 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-19 18:28:10.978938 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 18:28:10.979359 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 18:28:10.980567 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 18:28:10.980733 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-19 18:28:10.980876 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 18:28:10.985009 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 18:28:10.985163 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 18:28:10.985320 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 18:28:10.987119 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 18:28:10.987247 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 18:28:10.987359 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 18:28:10.987532 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2021-11-19 18:28:10.988511 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-19 18:28:10.988782 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-19 18:28:10.989257 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 18:28:10.990602 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 18:28:10.990937 (ThreadPoolExecutor-1_1): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 18:28:10.991107 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: BEGIN
2021-11-19 18:28:10.992061 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 18:28:10.992253 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 18:28:10.992813 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-19 18:28:10.998524 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 18:28:10.998686 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 18:28:10.998778 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 18:28:11.000352 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 18:28:11.001202 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 18:28:11.001530 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: Close
2021-11-19 18:28:11.004700 (MainThread): Using postgres connection "master".
2021-11-19 18:28:11.004808 (MainThread): On master: BEGIN
2021-11-19 18:28:11.004903 (MainThread): Opening a new connection, currently in state init
2021-11-19 18:28:11.010990 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 18:28:11.011159 (MainThread): Using postgres connection "master".
2021-11-19 18:28:11.011249 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 18:28:11.014456 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 18:28:11.015503 (MainThread): On master: ROLLBACK
2021-11-19 18:28:11.015771 (MainThread): Using postgres connection "master".
2021-11-19 18:28:11.015909 (MainThread): On master: BEGIN
2021-11-19 18:28:11.016590 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 18:28:11.016737 (MainThread): On master: COMMIT
2021-11-19 18:28:11.016849 (MainThread): Using postgres connection "master".
2021-11-19 18:28:11.016933 (MainThread): On master: COMMIT
2021-11-19 18:28:11.017431 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 18:28:11.017567 (MainThread): On master: Close
2021-11-19 18:28:11.017923 (MainThread): 19:28:11 | Concurrency: 2 threads (target='dev')
2021-11-19 18:28:11.018129 (MainThread): 19:28:11 | 
2021-11-19 18:28:11.020751 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-19 18:28:11.021048 (Thread-1): 19:28:11 | 1 of 3 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-19 18:28:11.021375 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 18:28:11.021490 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-19 18:28:11.026391 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-19 18:28:11.026662 (Thread-1): finished collecting timing info
2021-11-19 18:28:11.061189 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-19 18:28:11.061518 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 18:28:11.061629 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-19 18:28:11.061733 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 18:28:11.068309 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 18:28:11.068463 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 18:28:11.068559 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer"
  as (
    

select
     CASE
        WHEN iss.AdjustedEnterpriseValue ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.AdjustedEnterpriseValue::numeric
    ELSE NULL
    END        as adjusted_enterprise_value
    ,iss.ISIN                                               as isin
    ,iss.IssuerName                                         as issuer_name
    ,iss.gicssector                                         as gics_sector
    ,iss.gicsindustrygroup                                  as gics_industry_group
    ,CASE
        WHEN iss.ClimateScope2EmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope2EmissionsIntUSD::numeric
    ELSE NULL
    END   as climate_scope2_emissions_int_usd
    ,CASE
        WHEN iss.ClimateScope1EmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope1EmissionsIntUSD::numeric
    ELSE NULL
    END   as climate_scope1_emissions_int_usd
    ,iss.ClimateScope2Emissions                             as climate_scope2_emissions
    ,CASE
        WHEN iss.ClimateTotalEmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateTotalEmissionsIntUSD::numeric
    ELSE NULL
    END    as climate_total_emissions_int_usd
    ,iss.ClimateScope3Emissions                             as climate_scope3_emissions
    ,CASE
        WHEN iss.ClimateCNIEmissionsSource ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateCNIEmissionsSource::numeric
    ELSE NULL
    END      as climate_cni_emissions_source
    ,iss.ClimateTotalEmissions                              as climate_total_emissions
    ,'iss.ClimateScope1Emissions'::numeric                  as climate_scope1_emissions
    ,CASE
        WHEN iss.MarketCapDaily ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.MarketCapDaily::numeric
    ELSE NULL
    END                 as market_cap_daily
    ,iss.ClimateEmissionsFiscalYear::INT                    as climate_emissions_fiscal_year
    ,'2021-01-01'::DATE                            as meta_file_date
    ,'20211117T164451425627'                                as meta_run_id
    ,CURRENT_TIMESTAMP                                      as meta_insert_timestamp
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-19 18:28:11.069335 (Thread-1): Postgres error: invalid input syntax for type numeric: "iss.ClimateScope1Emissions"
LINE 42:     ,'iss.ClimateScope1Emissions'::numeric                  ...
              ^

2021-11-19 18:28:11.069453 (Thread-1): On model.my_new_project.iss_issuer: ROLLBACK
2021-11-19 18:28:11.069885 (Thread-1): finished collecting timing info
2021-11-19 18:28:11.070024 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-19 18:28:11.070358 (Thread-1): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  invalid input syntax for type numeric: "iss.ClimateScope1Emissions"
  LINE 42:     ,'iss.ClimateScope1Emissions'::numeric                  ...
                ^
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type numeric: "iss.ClimateScope1Emissions"
LINE 42:     ,'iss.ClimateScope1Emissions'::numeric                  ...
              ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  invalid input syntax for type numeric: "iss.ClimateScope1Emissions"
  LINE 42:     ,'iss.ClimateScope1Emissions'::numeric                  ...
                ^
  compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-19 18:28:11.071592 (Thread-1): 19:28:11 | 1 of 3 ERROR creating incremental model sa_dwh.iss_issuer............ [ERROR in 0.05s]
2021-11-19 18:28:11.071749 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-19 18:28:11.073022 (Thread-2): Began running node model.my_new_project.dim_issuer
2021-11-19 18:28:11.073209 (Thread-2): 19:28:11 | 2 of 3 SKIP relation sa_dm.dim_issuer................................ [SKIP]
2021-11-19 18:28:11.073395 (Thread-1): Began running node model.my_new_project.fct_emissions
2021-11-19 18:28:11.073578 (Thread-2): Finished running node model.my_new_project.dim_issuer
2021-11-19 18:28:11.073788 (Thread-1): 19:28:11 | 3 of 3 SKIP relation sa_dm.fct_emissions............................. [SKIP]
2021-11-19 18:28:11.074096 (Thread-1): Finished running node model.my_new_project.fct_emissions
2021-11-19 18:28:11.075373 (MainThread): Acquiring new postgres connection "master".
2021-11-19 18:28:11.075517 (MainThread): Using postgres connection "master".
2021-11-19 18:28:11.075614 (MainThread): On master: BEGIN
2021-11-19 18:28:11.075715 (MainThread): Opening a new connection, currently in state closed
2021-11-19 18:28:11.081454 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 18:28:11.081597 (MainThread): On master: COMMIT
2021-11-19 18:28:11.081694 (MainThread): Using postgres connection "master".
2021-11-19 18:28:11.081783 (MainThread): On master: COMMIT
2021-11-19 18:28:11.082016 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 18:28:11.082130 (MainThread): On master: Close
2021-11-19 18:28:11.082427 (MainThread): 19:28:11 | 
2021-11-19 18:28:11.082568 (MainThread): 19:28:11 | Finished running 2 incremental models, 1 table model in 0.13s.
2021-11-19 18:28:11.082769 (MainThread): Connection 'master' was properly closed.
2021-11-19 18:28:11.082913 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-19 18:28:11.082999 (MainThread): Connection 'list_demo_db_sa_dwh' was properly closed.
2021-11-19 18:28:11.086074 (MainThread): 
2021-11-19 18:28:11.086222 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 18:28:11.086506 (MainThread): 
2021-11-19 18:28:11.086770 (MainThread): Database Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
2021-11-19 18:28:11.086989 (MainThread):   invalid input syntax for type numeric: "iss.ClimateScope1Emissions"
2021-11-19 18:28:11.087199 (MainThread):   LINE 42:     ,'iss.ClimateScope1Emissions'::numeric                  ...
2021-11-19 18:28:11.087452 (MainThread):                 ^
2021-11-19 18:28:11.087620 (MainThread):   compiled SQL at target/run/my_new_project/models/dwh_iss/iss_issuer.sql
2021-11-19 18:28:11.087733 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=2 TOTAL=3
2021-11-19 18:28:11.087884 (MainThread): Flushing usage events
2021-11-19 18:28:32.755989 (MainThread): Running with dbt=0.21.0
2021-11-19 18:28:32.821811 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['tag:dwh'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 18:28:32.822282 (MainThread): Tracking: do not track
2021-11-19 18:28:32.832091 (MainThread): Partial parsing not enabled
2021-11-19 18:28:32.838628 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 18:28:32.839293 (MainThread): Parsing macros/adapters.sql
2021-11-19 18:28:32.857993 (MainThread): Parsing macros/catalog.sql
2021-11-19 18:28:32.859861 (MainThread): Parsing macros/relations.sql
2021-11-19 18:28:32.860863 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 18:28:32.862219 (MainThread): Parsing macros/core.sql
2021-11-19 18:28:32.865310 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 18:28:32.911382 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 18:28:32.913411 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 18:28:32.915209 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 18:28:32.916645 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 18:28:32.923882 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 18:28:32.925229 (MainThread): Parsing macros/etc/query.sql
2021-11-19 18:28:32.926085 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 18:28:32.927390 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 18:28:32.935374 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 18:28:32.941049 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 18:28:32.959875 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 18:28:32.961268 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 18:28:32.985886 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 18:28:33.000172 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 18:28:33.015796 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 18:28:33.024301 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 18:28:33.025707 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 18:28:33.036766 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 18:28:33.040009 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 18:28:33.045668 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 18:28:33.051533 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 18:28:33.052615 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 18:28:33.053568 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 18:28:33.054860 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 18:28:33.229086 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 18:28:33.241396 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 18:28:33.244285 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 18:28:33.246927 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 18:28:33.247149 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 18:28:33.247993 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 18:28:33.251363 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 18:28:33.251580 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 18:28:33.252430 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 18:28:33.257366 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 18:28:33.257589 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 18:28:33.285153 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 18:28:33.286637 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 18:28:33.288055 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 18:28:33.289792 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 18:28:33.303696 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 18:28:33.304094 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 1 seed file, 0 sources, 0 exposures
2021-11-19 18:28:33.305420 (MainThread): 
2021-11-19 18:28:33.305688 (MainThread): Acquiring new postgres connection "master".
2021-11-19 18:28:33.306643 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 18:28:33.312344 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 18:28:33.316288 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 18:28:33.316425 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 18:28:33.316557 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 18:28:33.318517 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 18:28:33.318655 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 18:28:33.318900 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 18:28:33.323731 (ThreadPoolExecutor-0_1): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 18:28:33.325211 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 18:28:33.326882 (ThreadPoolExecutor-0_0): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 18:28:33.327954 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 18:28:33.329283 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 18:28:33.333313 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 18:28:33.333438 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: BEGIN
2021-11-19 18:28:33.333557 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 18:28:33.334248 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 18:28:33.335456 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-19 18:28:33.335781 (ThreadPoolExecutor-1_1): On list_demo_db_sa: BEGIN
2021-11-19 18:28:33.335900 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 18:28:33.340085 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 18:28:33.340284 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 18:28:33.340377 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 18:28:33.342089 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 18:28:33.342426 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-19 18:28:33.342609 (ThreadPoolExecutor-1_1): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 18:28:33.342904 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 18:28:33.343793 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 18:28:33.344176 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: Close
2021-11-19 18:28:33.344738 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 18:28:33.345125 (ThreadPoolExecutor-1_1): SQL status: SELECT 3 in 0.00 seconds
2021-11-19 18:28:33.346439 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 18:28:33.347391 (ThreadPoolExecutor-1_1): On list_demo_db_sa: ROLLBACK
2021-11-19 18:28:33.347604 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: BEGIN
2021-11-19 18:28:33.347871 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 18:28:33.348197 (ThreadPoolExecutor-1_1): On list_demo_db_sa: Close
2021-11-19 18:28:33.353160 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 18:28:33.353391 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 18:28:33.353488 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 18:28:33.355198 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 18:28:33.356233 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 18:28:33.356621 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: Close
2021-11-19 18:28:33.360315 (MainThread): Using postgres connection "master".
2021-11-19 18:28:33.360450 (MainThread): On master: BEGIN
2021-11-19 18:28:33.360552 (MainThread): Opening a new connection, currently in state init
2021-11-19 18:28:33.367097 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 18:28:33.367272 (MainThread): Using postgres connection "master".
2021-11-19 18:28:33.367364 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 18:28:33.370634 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 18:28:33.371514 (MainThread): On master: ROLLBACK
2021-11-19 18:28:33.371871 (MainThread): Using postgres connection "master".
2021-11-19 18:28:33.371977 (MainThread): On master: BEGIN
2021-11-19 18:28:33.372582 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 18:28:33.372768 (MainThread): On master: COMMIT
2021-11-19 18:28:33.372859 (MainThread): Using postgres connection "master".
2021-11-19 18:28:33.372943 (MainThread): On master: COMMIT
2021-11-19 18:28:33.373280 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 18:28:33.373402 (MainThread): On master: Close
2021-11-19 18:28:33.373673 (MainThread): 19:28:33 | Concurrency: 2 threads (target='dev')
2021-11-19 18:28:33.373817 (MainThread): 19:28:33 | 
2021-11-19 18:28:33.376347 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-19 18:28:33.376651 (Thread-1): 19:28:33 | 1 of 3 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-19 18:28:33.377035 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 18:28:33.377211 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-19 18:28:33.381482 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-19 18:28:33.381717 (Thread-1): finished collecting timing info
2021-11-19 18:28:33.417196 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-19 18:28:33.417496 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 18:28:33.417600 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-19 18:28:33.417698 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 18:28:33.424940 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 18:28:33.425169 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 18:28:33.425352 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer"
  as (
    

select
     CASE
        WHEN iss.AdjustedEnterpriseValue ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.AdjustedEnterpriseValue::numeric
    ELSE NULL
    END        as adjusted_enterprise_value
    ,iss.ISIN                                               as isin
    ,iss.IssuerName                                         as issuer_name
    ,iss.gicssector                                         as gics_sector
    ,iss.gicsindustrygroup                                  as gics_industry_group
    ,CASE
        WHEN iss.ClimateScope2EmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope2EmissionsIntUSD::numeric
    ELSE NULL
    END   as climate_scope2_emissions_int_usd
    ,CASE
        WHEN iss.ClimateScope1EmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope1EmissionsIntUSD::numeric
    ELSE NULL
    END   as climate_scope1_emissions_int_usd
    ,iss.ClimateScope2Emissions::numeric                             as climate_scope2_emissions
    ,CASE
        WHEN iss.ClimateTotalEmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateTotalEmissionsIntUSD::numeric
    ELSE NULL
    END    as climate_total_emissions_int_usd
    ,iss.ClimateScope3Emissions::numeric                             as climate_scope3_emissions
    ,CASE
        WHEN iss.ClimateCNIEmissionsSource ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateCNIEmissionsSource::numeric
    ELSE NULL
    END      as climate_cni_emissions_source
    ,iss.ClimateTotalEmissions                              as climate_total_emissions
    ,iss.ClimateScope1Emissions::numeric                   as climate_scope1_emissions
    ,CASE
        WHEN iss.MarketCapDaily ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.MarketCapDaily::numeric
    ELSE NULL
    END                 as market_cap_daily
    ,iss.ClimateEmissionsFiscalYear::INT                    as climate_emissions_fiscal_year
    ,'2021-01-01'::DATE                            as meta_file_date
    ,'20211117T164451425627'                                as meta_run_id
    ,CURRENT_TIMESTAMP                                      as meta_insert_timestamp
from "demo_db"."sa"."sa_iss_issuer" iss
  );
  
2021-11-19 18:28:33.703594 (Thread-1): SQL status: SELECT 28444 in 0.28 seconds
2021-11-19 18:28:33.711497 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 18:28:33.711630 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 18:28:33.711739 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 18:28:33.717097 (Thread-1): SQL status: COMMIT in 0.01 seconds
2021-11-19 18:28:33.717532 (Thread-1): finished collecting timing info
2021-11-19 18:28:33.717665 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-19 18:28:33.718145 (Thread-1): 19:28:33 | 1 of 3 OK created incremental model sa_dwh.iss_issuer................ [SELECT 28444 in 0.34s]
2021-11-19 18:28:33.718314 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-19 18:28:33.719389 (Thread-2): Began running node model.my_new_project.dim_issuer
2021-11-19 18:28:33.719536 (Thread-1): Began running node model.my_new_project.fct_emissions
2021-11-19 18:28:33.719776 (Thread-2): 19:28:33 | 2 of 3 START table model sa_dm.dim_issuer............................ [RUN]
2021-11-19 18:28:33.720152 (Thread-1): 19:28:33 | 3 of 3 START incremental model sa_dm.fct_emissions................... [RUN]
2021-11-19 18:28:33.720725 (Thread-2): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 18:28:33.721169 (Thread-1): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 18:28:33.721439 (Thread-2): Compiling model.my_new_project.dim_issuer
2021-11-19 18:28:33.721594 (Thread-1): Compiling model.my_new_project.fct_emissions
2021-11-19 18:28:33.723981 (Thread-2): Writing injected SQL for node "model.my_new_project.dim_issuer"
2021-11-19 18:28:33.726847 (Thread-1): Writing injected SQL for node "model.my_new_project.fct_emissions"
2021-11-19 18:28:33.727263 (Thread-2): finished collecting timing info
2021-11-19 18:28:33.727510 (Thread-1): finished collecting timing info
2021-11-19 18:28:33.740360 (Thread-1): Writing runtime SQL for node "model.my_new_project.fct_emissions"
2021-11-19 18:28:33.741297 (Thread-2): Writing runtime SQL for node "model.my_new_project.dim_issuer"
2021-11-19 18:28:33.741611 (Thread-1): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 18:28:33.741741 (Thread-1): On model.my_new_project.fct_emissions: BEGIN
2021-11-19 18:28:33.741866 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 18:28:33.742212 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 18:28:33.742366 (Thread-2): On model.my_new_project.dim_issuer: BEGIN
2021-11-19 18:28:33.742503 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 18:28:33.748459 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 18:28:33.748665 (Thread-1): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 18:28:33.748829 (Thread-1): On model.my_new_project.fct_emissions: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.fct_emissions"} */

      

  create  table "demo_db"."sa_dm"."fct_emissions"
  as (
    


with cte_fundamental_enterprise_value as (
    select
         iss.isin                                                    as isin
        ,'EnterpriseValue'                                           as fundamental
        ,climate_scope1_emissions / climate_scope1_emissions_int_usd as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

, cte_fundamental_revenue as (
    select
         iss.ISIN                                                    as isin
        ,'Revenue'                                                   as fundamental
        ,adjusted_enterprise_value / 1e6                             as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

, cte_fundamental_market_cap as (
    select
         iss.ISIN                                                    as isin
        ,iss.climate_emissions_fiscal_year
        ,'MarketCap'                                                 as fundamental
        ,market_cap_daily / 1e6                                      as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

, cte_union_tables as (
    select * from cte_fundamental_enterprise_value

    union

    select * from cte_fundamental_revenue

    union

    select * from cte_fundamental_market_cap
)

select
     md5(isin)                            as fct_emissions_key
    ,md5(isin)                        as dim_issuer_key
    ,fundamental
    ,fundamental_value
    ,'2021-01-01'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from cte_union_tables
  );
  
2021-11-19 18:28:33.749012 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 18:28:33.749243 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 18:28:33.749376 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */


  create  table "demo_db"."sa_dm"."dim_issuer__dbt_tmp"
  as (
    

select distinct
     md5(iss.isin)              as dim_issuer_key
    ,iss.isin                   as isin
    ,iss.issuer_name            as issuer_name
    ,iss.gics_sector            as gics_sector
    ,iss.gics_industry_group    as gics_industry_group
from "demo_db"."sa_dwh"."iss_issuer" iss
  );
2021-11-19 18:28:33.749956 (Thread-1): Postgres error: each UNION query must have the same number of columns
LINE 44:     select * from cte_fundamental_market_cap
                    ^

2021-11-19 18:28:33.750081 (Thread-1): On model.my_new_project.fct_emissions: ROLLBACK
2021-11-19 18:28:33.750385 (Thread-1): finished collecting timing info
2021-11-19 18:28:33.750524 (Thread-1): On model.my_new_project.fct_emissions: Close
2021-11-19 18:28:33.750830 (Thread-1): Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
  each UNION query must have the same number of columns
  LINE 44:     select * from cte_fundamental_market_cap
                      ^
  compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: each UNION query must have the same number of columns
LINE 44:     select * from cte_fundamental_market_cap
                    ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
  each UNION query must have the same number of columns
  LINE 44:     select * from cte_fundamental_market_cap
                      ^
  compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
2021-11-19 18:28:33.752110 (Thread-1): 19:28:33 | 3 of 3 ERROR creating incremental model sa_dm.fct_emissions.......... [ERROR in 0.03s]
2021-11-19 18:28:33.752277 (Thread-1): Finished running node model.my_new_project.fct_emissions
2021-11-19 18:28:33.800541 (Thread-2): SQL status: SELECT 28444 in 0.05 seconds
2021-11-19 18:28:33.805026 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 18:28:33.805145 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer" rename to "dim_issuer__dbt_backup"
2021-11-19 18:28:33.805770 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 18:28:33.807258 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 18:28:33.807363 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer__dbt_tmp" rename to "dim_issuer"
2021-11-19 18:28:33.807870 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 18:28:33.808753 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 18:28:33.808853 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 18:28:33.808939 (Thread-2): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 18:28:33.815943 (Thread-2): SQL status: COMMIT in 0.01 seconds
2021-11-19 18:28:33.819753 (Thread-2): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 18:28:33.819890 (Thread-2): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
drop table if exists "demo_db"."sa_dm"."dim_issuer__dbt_backup" cascade
2021-11-19 18:28:33.822129 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-11-19 18:28:33.823048 (Thread-2): finished collecting timing info
2021-11-19 18:28:33.823190 (Thread-2): On model.my_new_project.dim_issuer: Close
2021-11-19 18:28:33.823614 (Thread-2): 19:28:33 | 2 of 3 OK created table model sa_dm.dim_issuer....................... [SELECT 28444 in 0.10s]
2021-11-19 18:28:33.823787 (Thread-2): Finished running node model.my_new_project.dim_issuer
2021-11-19 18:28:33.825625 (MainThread): Acquiring new postgres connection "master".
2021-11-19 18:28:33.825784 (MainThread): Using postgres connection "master".
2021-11-19 18:28:33.825881 (MainThread): On master: BEGIN
2021-11-19 18:28:33.825977 (MainThread): Opening a new connection, currently in state closed
2021-11-19 18:28:33.831367 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 18:28:33.831526 (MainThread): On master: COMMIT
2021-11-19 18:28:33.831621 (MainThread): Using postgres connection "master".
2021-11-19 18:28:33.831710 (MainThread): On master: COMMIT
2021-11-19 18:28:33.831940 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 18:28:33.832054 (MainThread): On master: Close
2021-11-19 18:28:33.832351 (MainThread): 19:28:33 | 
2021-11-19 18:28:33.832519 (MainThread): 19:28:33 | Finished running 2 incremental models, 1 table model in 0.53s.
2021-11-19 18:28:33.832687 (MainThread): Connection 'master' was properly closed.
2021-11-19 18:28:33.832828 (MainThread): Connection 'model.my_new_project.dim_issuer' was properly closed.
2021-11-19 18:28:33.832929 (MainThread): Connection 'model.my_new_project.fct_emissions' was properly closed.
2021-11-19 18:28:33.836046 (MainThread): 
2021-11-19 18:28:33.836200 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 18:28:33.836444 (MainThread): 
2021-11-19 18:28:33.836653 (MainThread): Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
2021-11-19 18:28:33.836775 (MainThread):   each UNION query must have the same number of columns
2021-11-19 18:28:33.836922 (MainThread):   LINE 44:     select * from cte_fundamental_market_cap
2021-11-19 18:28:33.837038 (MainThread):                       ^
2021-11-19 18:28:33.837152 (MainThread):   compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
2021-11-19 18:28:33.837278 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
2021-11-19 18:28:33.837446 (MainThread): Flushing usage events
2021-11-19 19:04:06.921058 (MainThread): Running with dbt=0.21.0
2021-11-19 19:04:06.974477 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, full_refresh=False, show=False, threads=None, version_check=True, select=['dbt-sample/data/iss/2021-08-31/iss_file'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.seed.SeedTask'>, which='seed', rpc_method='seed')
2021-11-19 19:04:06.974857 (MainThread): Tracking: do not track
2021-11-19 19:04:06.984797 (MainThread): Partial parsing not enabled
2021-11-19 19:04:06.991057 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 19:04:06.991630 (MainThread): Parsing macros/adapters.sql
2021-11-19 19:04:07.009098 (MainThread): Parsing macros/catalog.sql
2021-11-19 19:04:07.010724 (MainThread): Parsing macros/relations.sql
2021-11-19 19:04:07.011653 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 19:04:07.012873 (MainThread): Parsing macros/core.sql
2021-11-19 19:04:07.016035 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 19:04:07.058994 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 19:04:07.061322 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 19:04:07.062825 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 19:04:07.064196 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 19:04:07.071417 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 19:04:07.072723 (MainThread): Parsing macros/etc/query.sql
2021-11-19 19:04:07.073476 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 19:04:07.074732 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 19:04:07.082435 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 19:04:07.088420 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 19:04:07.108852 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 19:04:07.110561 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 19:04:07.142244 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 19:04:07.157891 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 19:04:07.174922 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 19:04:07.183567 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 19:04:07.184981 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 19:04:07.195221 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 19:04:07.198327 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 19:04:07.203563 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 19:04:07.209052 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 19:04:07.210060 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 19:04:07.210944 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 19:04:07.212216 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 19:04:07.364671 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:04:07.376177 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:04:07.379003 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:04:07.381670 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:04:07.381893 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:04:07.382805 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:04:07.386257 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:04:07.386463 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:04:07.387428 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:04:07.392035 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:04:07.392236 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:04:07.401639 (MainThread): Flushing usage events
2021-11-19 19:04:07.401783 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-19 19:04:07.401885 (MainThread): Encountered an error:
2021-11-19 19:04:07.402014 (MainThread): Compilation Error
  dbt found two resources with the name "iss_file". Since these resources have the same name,
  dbt will be unable to find the correct resource when ref("iss_file") is used. To fix this,
  change the name of one of these resources:
  - seed.my_new_project.iss_file (data/iss/2021-10-31/iss_file.csv)
  - seed.my_new_project.iss_file (data/iss/2021-09-30/iss_file.csv)
2021-11-19 19:04:07.411131 (MainThread): Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 433, in run
    self._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 149, in _runtime_initialize
    super()._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 87, in _runtime_initialize
    self.load_manifest()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 74, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 182, in get_full_manifest
    manifest = loader.load()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 301, in load
    self.parse_project(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 410, in parse_project
    parser.parse_file(block)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/base.py", line 432, in parse_file
    self.parse_node(file_block)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/base.py", line 407, in parse_node
    self.add_result_node(block, result)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/base.py", line 389, in add_result_node
    self.manifest.add_node(block.file, node)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/contracts/graph/manifest.py", line 999, in add_node
    self.add_node_nofile(node)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/contracts/graph/manifest.py", line 995, in add_node_nofile
    _check_duplicates(node, self.nodes)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/contracts/graph/manifest.py", line 1124, in _check_duplicates
    raise_duplicate_resource_name(value, src[value.unique_id])
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/exceptions.py", line 788, in raise_duplicate_resource_name
    raise_compiler_error(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/exceptions.py", line 444, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error
  dbt found two resources with the name "iss_file". Since these resources have the same name,
  dbt will be unable to find the correct resource when ref("iss_file") is used. To fix this,
  change the name of one of these resources:
  - seed.my_new_project.iss_file (data/iss/2021-10-31/iss_file.csv)
  - seed.my_new_project.iss_file (data/iss/2021-09-30/iss_file.csv)

2021-11-19 19:09:09.001050 (MainThread): Running with dbt=0.21.0
2021-11-19 19:09:09.053656 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, full_refresh=False, show=False, threads=None, version_check=True, select=['dbt-sample/data/iss/iss_file_20210831'], exclude=None, selector_name='iss_file', state=None, defer=None, cls=<class 'dbt.task.seed.SeedTask'>, which='seed', rpc_method='seed')
2021-11-19 19:09:09.054085 (MainThread): Tracking: do not track
2021-11-19 19:09:09.063501 (MainThread): Partial parsing not enabled
2021-11-19 19:09:09.071295 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 19:09:09.071949 (MainThread): Parsing macros/adapters.sql
2021-11-19 19:09:09.090020 (MainThread): Parsing macros/catalog.sql
2021-11-19 19:09:09.092010 (MainThread): Parsing macros/relations.sql
2021-11-19 19:09:09.094143 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 19:09:09.096528 (MainThread): Parsing macros/core.sql
2021-11-19 19:09:09.101786 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 19:09:09.165129 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 19:09:09.167537 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 19:09:09.169231 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 19:09:09.170990 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 19:09:09.178998 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 19:09:09.180306 (MainThread): Parsing macros/etc/query.sql
2021-11-19 19:09:09.181314 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 19:09:09.182562 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 19:09:09.191276 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 19:09:09.200154 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 19:09:09.217963 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 19:09:09.219427 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 19:09:09.241888 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 19:09:09.254982 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 19:09:09.269573 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 19:09:09.277418 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 19:09:09.278764 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 19:09:09.288990 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 19:09:09.291863 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 19:09:09.297256 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 19:09:09.302658 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 19:09:09.303691 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 19:09:09.304599 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 19:09:09.305885 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 19:09:09.459665 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:09:09.469438 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:09:09.472167 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:09:09.474566 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:09:09.474775 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:09:09.475596 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:09:09.478805 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:09:09.479009 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:09:09.479831 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:09:09.484362 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:09:09.484565 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:09:09.518225 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:09:09.520090 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:09:09.521632 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:09:09.523162 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:09:09.523527 (MainThread): Flushing usage events
2021-11-19 19:09:09.523664 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-19 19:09:09.523770 (MainThread): Encountered an error:
2021-11-19 19:09:09.523914 (MainThread): Compilation Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  Model 'model.my_new_project.iss_issuer' (models/dwh_iss/iss_issuer.sql) depends on a node named 'sa_iss_issuer' which was not found
2021-11-19 19:09:09.524871 (MainThread): Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 433, in run
    self._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 149, in _runtime_initialize
    super()._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 87, in _runtime_initialize
    self.load_manifest()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 74, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 182, in get_full_manifest
    manifest = loader.load()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 355, in load
    self.process_refs(self.root_project.project_name)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 715, in process_refs
    _process_refs_for_node(self.manifest, current_project, node)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 1026, in _process_refs_for_node
    invalid_ref_fail_unless_test(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 799, in invalid_ref_fail_unless_test
    ref_target_not_found(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/exceptions.py", line 575, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/exceptions.py", line 444, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model iss_issuer (models/dwh_iss/iss_issuer.sql)
  Model 'model.my_new_project.iss_issuer' (models/dwh_iss/iss_issuer.sql) depends on a node named 'sa_iss_issuer' which was not found

2021-11-19 19:10:47.396848 (MainThread): Running with dbt=0.21.0
2021-11-19 19:10:47.450758 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, full_refresh=False, show=False, threads=None, version_check=True, select=['dbt-sample/data/iss/iss_file'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.seed.SeedTask'>, which='seed', rpc_method='seed')
2021-11-19 19:10:47.451156 (MainThread): Tracking: do not track
2021-11-19 19:10:47.460563 (MainThread): Partial parsing not enabled
2021-11-19 19:10:47.466707 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 19:10:47.467264 (MainThread): Parsing macros/adapters.sql
2021-11-19 19:10:47.484510 (MainThread): Parsing macros/catalog.sql
2021-11-19 19:10:47.486276 (MainThread): Parsing macros/relations.sql
2021-11-19 19:10:47.487206 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 19:10:47.488468 (MainThread): Parsing macros/core.sql
2021-11-19 19:10:47.491422 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 19:10:47.531803 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 19:10:47.533696 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 19:10:47.535059 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 19:10:47.536352 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 19:10:47.542873 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 19:10:47.544051 (MainThread): Parsing macros/etc/query.sql
2021-11-19 19:10:47.544783 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 19:10:47.546021 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 19:10:47.553349 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 19:10:47.558383 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 19:10:47.575288 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 19:10:47.576504 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 19:10:47.598715 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 19:10:47.611691 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 19:10:47.626179 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 19:10:47.633919 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 19:10:47.635255 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 19:10:47.645533 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 19:10:47.648379 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 19:10:47.654244 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 19:10:47.659624 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 19:10:47.660654 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 19:10:47.661539 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 19:10:47.662752 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 19:10:47.818825 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:10:47.828515 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:10:47.831203 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:10:47.833649 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:10:47.833855 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:10:47.834651 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:10:47.838241 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:10:47.838463 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:10:47.839282 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:10:47.843838 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:10:47.844041 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:10:47.873926 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:10:47.875404 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:10:47.876784 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:10:47.878298 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:10:47.892755 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 19:10:47.893058 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 19:10:47.893886 (MainThread): The selection criterion 'dbt-sample/data/iss/iss_file' does not match any nodes
2021-11-19 19:10:47.894751 (MainThread): 
WARNING: Nothing to do. Try checking your model configs and model specification args
2021-11-19 19:10:47.897307 (MainThread): 
2021-11-19 19:10:47.897448 (MainThread): Completed successfully
2021-11-19 19:10:47.897628 (MainThread): 
Done. PASS=0 WARN=0 ERROR=0 SKIP=0 TOTAL=0
2021-11-19 19:10:47.897927 (MainThread): Flushing usage events
2021-11-19 19:10:47.898230 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-19 19:17:21.266456 (MainThread): Running with dbt=0.21.0
2021-11-19 19:17:21.321579 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, full_refresh=False, show=False, threads=None, version_check=True, select=['dbt-sample/data/iss/iss_file'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.seed.SeedTask'>, which='seed', rpc_method='seed')
2021-11-19 19:17:21.322002 (MainThread): Tracking: do not track
2021-11-19 19:17:21.332277 (MainThread): Partial parsing not enabled
2021-11-19 19:17:21.338681 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 19:17:21.339266 (MainThread): Parsing macros/adapters.sql
2021-11-19 19:17:21.356464 (MainThread): Parsing macros/catalog.sql
2021-11-19 19:17:21.358046 (MainThread): Parsing macros/relations.sql
2021-11-19 19:17:21.358959 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 19:17:21.360178 (MainThread): Parsing macros/core.sql
2021-11-19 19:17:21.363148 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 19:17:21.403297 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 19:17:21.405215 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 19:17:21.406575 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 19:17:21.407726 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 19:17:21.414070 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 19:17:21.415215 (MainThread): Parsing macros/etc/query.sql
2021-11-19 19:17:21.415942 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 19:17:21.417035 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 19:17:21.424382 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 19:17:21.429466 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 19:17:21.446277 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 19:17:21.447493 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 19:17:21.469650 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 19:17:21.485966 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 19:17:21.500663 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 19:17:21.508462 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 19:17:21.509726 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 19:17:21.519943 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 19:17:21.522992 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 19:17:21.528541 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 19:17:21.533654 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 19:17:21.534654 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 19:17:21.535652 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 19:17:21.536953 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 19:17:21.690768 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:17:21.700354 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:17:21.703075 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:17:21.705589 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:21.705796 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:21.706577 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:17:21.709840 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:21.710062 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:21.710836 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:17:21.715614 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:21.715818 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:21.746119 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:21.747490 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:21.748924 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:21.750355 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:21.764555 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 19:17:21.764851 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 19:17:21.765696 (MainThread): The selection criterion 'dbt-sample/data/iss/iss_file' does not match any nodes
2021-11-19 19:17:21.766609 (MainThread): 
WARNING: Nothing to do. Try checking your model configs and model specification args
2021-11-19 19:17:21.769183 (MainThread): 
2021-11-19 19:17:21.769344 (MainThread): Completed successfully
2021-11-19 19:17:21.769564 (MainThread): 
Done. PASS=0 WARN=0 ERROR=0 SKIP=0 TOTAL=0
2021-11-19 19:17:21.769846 (MainThread): Flushing usage events
2021-11-19 19:17:21.770085 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-19 19:17:45.726599 (MainThread): Running with dbt=0.21.0
2021-11-19 19:17:45.781197 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, full_refresh=False, show=False, threads=None, version_check=True, select=['iss/iss_file'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.seed.SeedTask'>, which='seed', rpc_method='seed')
2021-11-19 19:17:45.781646 (MainThread): Tracking: do not track
2021-11-19 19:17:45.791009 (MainThread): Partial parsing not enabled
2021-11-19 19:17:45.797439 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 19:17:45.798040 (MainThread): Parsing macros/adapters.sql
2021-11-19 19:17:45.815177 (MainThread): Parsing macros/catalog.sql
2021-11-19 19:17:45.817239 (MainThread): Parsing macros/relations.sql
2021-11-19 19:17:45.818185 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 19:17:45.819431 (MainThread): Parsing macros/core.sql
2021-11-19 19:17:45.822228 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 19:17:45.862964 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 19:17:45.864845 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 19:17:45.866257 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 19:17:45.867469 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 19:17:45.873829 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 19:17:45.874950 (MainThread): Parsing macros/etc/query.sql
2021-11-19 19:17:45.875815 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 19:17:45.876953 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 19:17:45.884127 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 19:17:45.889178 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 19:17:45.906182 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 19:17:45.907502 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 19:17:45.930353 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 19:17:45.943429 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 19:17:45.957917 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 19:17:45.965917 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 19:17:45.967281 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 19:17:45.977486 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 19:17:45.980455 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 19:17:45.985690 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 19:17:45.991113 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 19:17:45.992123 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 19:17:45.993013 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 19:17:45.994239 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 19:17:46.153430 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:17:46.163051 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:17:46.165757 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:17:46.168196 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:46.168404 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:46.169194 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:17:46.172638 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:46.172845 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:46.173639 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:17:46.178173 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:46.178416 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:46.210937 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:46.213376 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:46.214762 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:46.216286 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:46.230707 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 19:17:46.231035 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 19:17:46.231980 (MainThread): The selection criterion 'iss/iss_file' does not match any nodes
2021-11-19 19:17:46.233151 (MainThread): 
WARNING: Nothing to do. Try checking your model configs and model specification args
2021-11-19 19:17:46.236105 (MainThread): 
2021-11-19 19:17:46.236247 (MainThread): Completed successfully
2021-11-19 19:17:46.236436 (MainThread): 
Done. PASS=0 WARN=0 ERROR=0 SKIP=0 TOTAL=0
2021-11-19 19:17:46.236768 (MainThread): Flushing usage events
2021-11-19 19:17:46.236913 (MainThread): Connection 'model.my_new_project.iss_issuer' was properly closed.
2021-11-19 19:17:53.784828 (MainThread): Running with dbt=0.21.0
2021-11-19 19:17:53.840911 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, full_refresh=False, show=False, threads=None, version_check=True, select=['iss_file'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.seed.SeedTask'>, which='seed', rpc_method='seed')
2021-11-19 19:17:53.841317 (MainThread): Tracking: do not track
2021-11-19 19:17:53.851096 (MainThread): Partial parsing not enabled
2021-11-19 19:17:53.857185 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 19:17:53.857822 (MainThread): Parsing macros/adapters.sql
2021-11-19 19:17:53.874966 (MainThread): Parsing macros/catalog.sql
2021-11-19 19:17:53.876700 (MainThread): Parsing macros/relations.sql
2021-11-19 19:17:53.877624 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 19:17:53.878928 (MainThread): Parsing macros/core.sql
2021-11-19 19:17:53.881844 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 19:17:53.924627 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 19:17:53.926767 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 19:17:53.928100 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 19:17:53.929539 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 19:17:53.935862 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 19:17:53.936974 (MainThread): Parsing macros/etc/query.sql
2021-11-19 19:17:53.937695 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 19:17:53.938799 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 19:17:53.946297 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 19:17:53.951293 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 19:17:53.968354 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 19:17:53.969581 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 19:17:53.991765 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 19:17:54.004954 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 19:17:54.019446 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 19:17:54.027355 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 19:17:54.028837 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 19:17:54.039147 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 19:17:54.042198 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 19:17:54.047694 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 19:17:54.053102 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 19:17:54.054142 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 19:17:54.055185 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 19:17:54.056962 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 19:17:54.216689 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:17:54.228850 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:17:54.231870 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:17:54.234449 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.234678 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.235567 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:17:54.238846 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.239049 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.239837 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:17:54.244411 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.244634 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.274972 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.276533 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.277890 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.279391 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.293697 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 19:17:54.294240 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 19:17:54.295720 (MainThread): 
2021-11-19 19:17:54.296161 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:17:54.296798 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 19:17:54.303646 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 19:17:54.303752 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 19:17:54.303849 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 19:17:54.310365 (ThreadPoolExecutor-0_0): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 19:17:54.311277 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 19:17:54.312767 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 19:17:54.317292 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 19:17:54.317477 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-19 19:17:54.317616 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 19:17:54.318344 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 19:17:54.319355 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 19:17:54.319508 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-19 19:17:54.319670 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-19 19:17:54.324226 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:17:54.324383 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 19:17:54.324473 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 19:17:54.325890 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:17:54.326116 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 19:17:54.326203 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 19:17:54.326453 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2021-11-19 19:17:54.327316 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-19 19:17:54.327710 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:17:54.328666 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 19:17:54.328843 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-19 19:17:54.329503 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 19:17:54.330912 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 19:17:54.331116 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-19 19:17:54.331387 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: BEGIN
2021-11-19 19:17:54.331584 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 19:17:54.337023 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:17:54.337187 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 19:17:54.337280 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 19:17:54.338752 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:17:54.339560 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 19:17:54.339822 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: Close
2021-11-19 19:17:54.343015 (MainThread): Using postgres connection "master".
2021-11-19 19:17:54.343128 (MainThread): On master: BEGIN
2021-11-19 19:17:54.343227 (MainThread): Opening a new connection, currently in state init
2021-11-19 19:17:54.348590 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:17:54.348769 (MainThread): Using postgres connection "master".
2021-11-19 19:17:54.348860 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 19:17:54.352554 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:17:54.353455 (MainThread): On master: ROLLBACK
2021-11-19 19:17:54.353721 (MainThread): Using postgres connection "master".
2021-11-19 19:17:54.353831 (MainThread): On master: BEGIN
2021-11-19 19:17:54.354389 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 19:17:54.354540 (MainThread): On master: COMMIT
2021-11-19 19:17:54.354634 (MainThread): Using postgres connection "master".
2021-11-19 19:17:54.354721 (MainThread): On master: COMMIT
2021-11-19 19:17:54.354994 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:17:54.355108 (MainThread): On master: Close
2021-11-19 19:17:54.355453 (MainThread): 20:17:54 | Concurrency: 2 threads (target='sa')
2021-11-19 19:17:54.355595 (MainThread): 20:17:54 | 
2021-11-19 19:17:54.358275 (Thread-1): Began running node seed.my_new_project.iss_file
2021-11-19 19:17:54.358539 (Thread-1): 20:17:54 | 1 of 1 START seed file sa.iss_file................................... [RUN]
2021-11-19 19:17:54.358885 (Thread-1): Acquiring new postgres connection "seed.my_new_project.iss_file".
2021-11-19 19:17:54.359067 (Thread-1): finished collecting timing info
2021-11-19 19:17:54.689241 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.689620 (Thread-1): * Deprecation Warning: The quote_columns parameter was not set for seeds, so the
default value of False was chosen. The default will change to True in a future
release.

For more information, see:
https://docs.getdbt.com/v0.15/docs/seeds#section-specify-column-quoting
2021-11-19 19:17:54.689833 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.690016 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.690225 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.690348 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.690463 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.692776 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.694864 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.697144 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.699426 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.699561 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.699678 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.699793 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.699906 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.700027 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.700137 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.702107 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.702234 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.702347 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.702458 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.702569 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.702679 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.702791 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.702902 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.703014 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.703126 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.703235 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.703372 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.703494 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.703604 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.703862 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.703978 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.704089 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.704199 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.704315 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.704424 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.704532 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.704639 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.704746 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.704854 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.704962 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.705070 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.705178 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.705314 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.705440 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.705548 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.705656 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.705764 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.705871 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.705978 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.706085 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.706218 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.706328 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.706438 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.706549 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.706658 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.706766 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.706874 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.706984 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.707092 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.707199 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.707308 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.707414 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.707520 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.707629 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.707742 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.707851 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.707961 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.708070 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.708180 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.708287 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.708394 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.708501 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.708609 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.708721 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.708829 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.708935 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.709042 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.709149 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.709258 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.709366 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.709475 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.709585 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.709695 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.709804 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.709913 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.710034 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.710138 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.710246 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.710373 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.710482 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.710587 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.710692 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.710798 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.710904 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.711010 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.711119 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.711228 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.711335 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.711441 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.711605 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.711716 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.711845 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.711989 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.712522 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.712636 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.712747 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.712857 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.712965 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.713072 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.713179 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.713286 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.713392 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.713498 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.713604 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.713709 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.713813 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.713918 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.714022 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.714127 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.714232 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.714336 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.714442 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.714567 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.714673 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.714778 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.714888 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.714993 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.715100 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.715207 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.715327 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.715433 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.715537 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.715642 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.715746 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.715851 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.715956 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.716060 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.716165 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.716420 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.716548 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.716741 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.716878 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.716983 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.719103 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.719225 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.719337 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.719446 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.719554 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.719661 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.719768 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.719874 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.719979 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.720117 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.720225 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.720332 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.720440 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.720550 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.720656 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.720763 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.720870 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.720975 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.721079 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.721184 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.721289 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.721396 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.721503 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.721609 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.721714 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.721820 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.721924 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.722028 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.722132 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.722237 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.722343 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.722451 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.722557 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.722665 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.722773 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.722903 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.723011 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.723116 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.723220 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.723329 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.723434 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.723658 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.723769 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.723881 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.723987 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.724092 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.724196 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.724300 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.724404 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.724508 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.724611 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.724714 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.724816 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.724918 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.725021 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.725123 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.725226 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.725341 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.725444 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.725547 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.725651 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.725755 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.725858 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.725961 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.726067 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.726172 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.726276 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.726381 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.726486 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.726591 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.726695 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.726799 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.726903 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.727007 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.727132 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.727239 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.727343 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.727447 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.727553 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:17:54.727759 (Thread-1): Using postgres connection "seed.my_new_project.iss_file".
2021-11-19 19:17:54.727851 (Thread-1): On seed.my_new_project.iss_file: BEGIN
2021-11-19 19:17:54.727944 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 19:17:54.734608 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:17:54.734804 (Thread-1): Using postgres connection "seed.my_new_project.iss_file".
2021-11-19 19:17:54.734896 (Thread-1): On seed.my_new_project.iss_file: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "seed.my_new_project.iss_file"} */

    create table "demo_db"."sa"."iss_file" (IssuerName text,ISIN text,GICSSector text,GICSIndustryGroup text,CountryOfIncorporation text,CountryOfOperations text,ClimateScope1Emissions float8,ClimateScope2Emissions float8,ClimateTotalEmissions float8,ClimateScope3Emissions float8,ClimateCNIEmissionsSource text,ClimateEmissionsReportedTrust text,ClimateEmissionsEstimatedTrust text,ClimateScope1EmissionsIntUSD text,ClimateScope2EmissionsIntUSD text,ClimateTotalEmissionsIntUSD text,ClimateAvePeerEmissionsIntUSD float8,MarketCapDaily text,AdjustedEnterpriseValue text,ClimateCarbonBudget2DegExcdYear text,ClimateCarbonBudget4DegExcdYear text,ClimateCarbonBudget6DegExcdYear text,ClimateEmissionsTrajectoryRatio text,ClimateCarbonBudget2DegRatioAve text,ClimateCarbonBudget4DegRatioAve text,ClimateCarbonBudget6DegRatioAve text,ClimateCarbonBudget2Deg text,ClimateCarbonBudget4Deg text,ClimateCarbonBudget6Deg text,ClimateCarbonBudget2Deg2020 text,ClimateCarbonBudget2Deg2021 text,ClimateCarbonBudget2Deg2022 text,ClimateCarbonBudget2Deg2023 text,ClimateCarbonBudget2Deg2024 text,ClimateCarbonBudget2Deg2025 text,ClimateCarbonBudget2Deg2026 text,ClimateCarbonBudget2Deg2027 text,ClimateCarbonBudget2Deg2028 text,ClimateCarbonBudget2Deg2029 text,ClimateCarbonBudget2Deg2030 text,ClimateCarbonBudget2Deg2031 text,ClimateCarbonBudget2Deg2032 text,ClimateCarbonBudget2Deg2033 text,ClimateCarbonBudget2Deg2034 text,ClimateCarbonBudget2Deg2035 text,ClimateCarbonBudget2Deg2036 text,ClimateCarbonBudget2Deg2037 text,ClimateCarbonBudget2Deg2038 text,ClimateCarbonBudget2Deg2039 text,ClimateCarbonBudget2Deg2040 text,ClimateCarbonBudget2Deg2041 text,ClimateCarbonBudget2Deg2042 text,ClimateCarbonBudget2Deg2043 text,ClimateCarbonBudget2Deg2044 text,ClimateCarbonBudget2Deg2045 text,ClimateCarbonBudget2Deg2046 text,ClimateCarbonBudget2Deg2047 text,ClimateCarbonBudget2Deg2048 text,ClimateCarbonBudget2Deg2049 text,ClimateCarbonBudget2Deg2050 text,ClimateCarbonBudget4Deg2020 text,ClimateCarbonBudget4Deg2021 text,ClimateCarbonBudget4Deg2022 text,ClimateCarbonBudget4Deg2023 text,ClimateCarbonBudget4Deg2024 text,ClimateCarbonBudget4Deg2025 text,ClimateCarbonBudget4Deg2026 text,ClimateCarbonBudget4Deg2027 text,ClimateCarbonBudget4Deg2028 text,ClimateCarbonBudget4Deg2029 text,ClimateCarbonBudget4Deg2030 text,ClimateCarbonBudget4Deg2031 text,ClimateCarbonBudget4Deg2032 text,ClimateCarbonBudget4Deg2033 text,ClimateCarbonBudget4Deg2034 text,ClimateCarbonBudget4Deg2035 text,ClimateCarbonBudget4Deg2036 text,ClimateCarbonBudget4Deg2037 text,ClimateCarbonBudget4Deg2038 text,ClimateCarbonBudget4Deg2039 text,ClimateCarbonBudget4Deg2040 text,ClimateCarbonBudget4Deg2041 text,ClimateCarbonBudget4Deg2042 text,ClimateCarbonBudget4Deg2043 text,ClimateCarbonBudget4Deg2044 text,ClimateCarbonBudget4Deg2045 text,ClimateCarbonBudget4Deg2046 text,ClimateCarbonBudget4Deg2047 text,ClimateCarbonBudget4Deg2048 text,ClimateCarbonBudget4Deg2049 text,ClimateCarbonBudget4Deg2050 text,ClimateCarbonBudget6Deg2020 text,ClimateCarbonBudget6Deg2021 text,ClimateCarbonBudget6Deg2022 text,ClimateCarbonBudget6Deg2023 text,ClimateCarbonBudget6Deg2024 text,ClimateCarbonBudget6Deg2025 text,ClimateCarbonBudget6Deg2026 text,ClimateCarbonBudget6Deg2027 text,ClimateCarbonBudget6Deg2028 text,ClimateCarbonBudget6Deg2029 text,ClimateCarbonBudget6Deg2030 text,ClimateCarbonBudget6Deg2031 text,ClimateCarbonBudget6Deg2032 text,ClimateCarbonBudget6Deg2033 text,ClimateCarbonBudget6Deg2034 text,ClimateCarbonBudget6Deg2035 text,ClimateCarbonBudget6Deg2036 text,ClimateCarbonBudget6Deg2037 text,ClimateCarbonBudget6Deg2038 text,ClimateCarbonBudget6Deg2039 text,ClimateCarbonBudget6Deg2040 text,ClimateCarbonBudget6Deg2041 text,ClimateCarbonBudget6Deg2042 text,ClimateCarbonBudget6Deg2043 text,ClimateCarbonBudget6Deg2044 text,ClimateCarbonBudget6Deg2045 text,ClimateCarbonBudget6Deg2046 text,ClimateCarbonBudget6Deg2047 text,ClimateCarbonBudget6Deg2048 text,ClimateCarbonBudget6Deg2049 text,ClimateCarbonBudget6Deg2050 text,PAETechTypes text,PAETotalPAEPerYear text,PAETotalSold text,PAEBiomassSold text,PAEBiomassPAEPerYear text,PAEBiomassPAGEPerYear text,PAEGeothermalSold text,PAEGeothermalPAEPerYear text,PAEGeothermalPAGEPerYear text,PAEHydroSold text,PAEHydroPAEPerYear text,PAEHydroPAGEPerYear text,PAESolarCSPSold text,PAESolarPVSold text,PAESolarPAEPerYear text,PAESolarCSPPAGEPerYear text,PAESolarPVPAGEPerYear text,PAEOnshoreWindSold text,PAEOffshoreWindSold text,PAEWindPAEPerYear text,PAEWindPAGEPerYear text,PAEWindSold text,ClimateEmissionsFiscalYear integer,ClimateScienceBasedTargets text,ClimateTemperatureScore text,ClimateGHGReductionTargets text,ClimateEmissionsTrajectoryRatioSDS text,ClimateCarbonBudgetSDSDegExcdYear text,ClimateCarbonBudgetSDSRatioAve text,ClimateCarbonBudgetSDS text,ClimateCarbonBudgetSDS2019 text,ClimateCarbonBudgetSDS2020 text,ClimateCarbonBudgetSDS2021 text,ClimateCarbonBudgetSDS2022 text,ClimateCarbonBudgetSDS2023 text,ClimateCarbonBudgetSDS2024 text,ClimateCarbonBudgetSDS2025 text,ClimateCarbonBudgetSDS2026 text,ClimateCarbonBudgetSDS2027 text,ClimateCarbonBudgetSDS2028 text,ClimateCarbonBudgetSDS2029 text,ClimateCarbonBudgetSDS2030 text,ClimateCarbonBudgetSDS2031 text,ClimateCarbonBudgetSDS2032 text,ClimateCarbonBudgetSDS2033 text,ClimateCarbonBudgetSDS2034 text,ClimateCarbonBudgetSDS2035 text,ClimateCarbonBudgetSDS2036 text,ClimateCarbonBudgetSDS2037 text,ClimateCarbonBudgetSDS2038 text,ClimateCarbonBudgetSDS2039 text,ClimateCarbonBudgetSDS2040 text,ClimateCarbonBudgetSDS2041 text,ClimateCarbonBudgetSDS2042 text,ClimateCarbonBudgetSDS2043 text,ClimateCarbonBudgetSDS2044 text,ClimateCarbonBudgetSDS2045 text,ClimateCarbonBudgetSDS2046 text,ClimateCarbonBudgetSDS2047 text,ClimateCarbonBudgetSDS2048 text,ClimateCarbonBudgetSDS2049 text,ClimateCarbonBudgetSDS2050 text,ClimateCarbonBudgetSDSPCT text,ClimateCarbonBudgetSDSPCT2019 text,ClimateCarbonBudgetSDSPCT2020 text,ClimateCarbonBudgetSDSPCT2021 text,ClimateCarbonBudgetSDSPCT2022 text,ClimateCarbonBudgetSDSPCT2023 text,ClimateCarbonBudgetSDSPCT2024 text,ClimateCarbonBudgetSDSPCT2025 text,ClimateCarbonBudgetSDSPCT2026 text,ClimateCarbonBudgetSDSPCT2027 text,ClimateCarbonBudgetSDSPCT2028 text,ClimateCarbonBudgetSDSPCT2029 text,ClimateCarbonBudgetSDSPCT2030 text,ClimateCarbonBudgetSDSPCT2031 text,ClimateCarbonBudgetSDSPCT2032 text,ClimateCarbonBudgetSDSPCT2033 text,ClimateCarbonBudgetSDSPCT2034 text,ClimateCarbonBudgetSDSPCT2035 text,ClimateCarbonBudgetSDSPCT2036 text,ClimateCarbonBudgetSDSPCT2037 text,ClimateCarbonBudgetSDSPCT2038 text,ClimateCarbonBudgetSDSPCT2039 text,ClimateCarbonBudgetSDSPCT2040 text,ClimateCarbonBudgetSDSPCT2041 text,ClimateCarbonBudgetSDSPCT2042 text,ClimateCarbonBudgetSDSPCT2043 text,ClimateCarbonBudgetSDSPCT2044 text,ClimateCarbonBudgetSDSPCT2045 text,ClimateCarbonBudgetSDSPCT2046 text,ClimateCarbonBudgetSDSPCT2047 text,ClimateCarbonBudgetSDSPCT2048 text,ClimateCarbonBudgetSDSPCT2049 text,ClimateCarbonBudgetSDSPCT2050 text,ClimateCarbonBudgetSDSModelType text,ClimateDSGovernanceAlignment text,ClimateDSMandTAlignment text,ClimateDSOverallAlignment text,ClimateDSRiskMgmtAlignment text,ClimateDSStrategyAlignment text)
  
2021-11-19 19:17:54.740691 (Thread-1): SQL status: CREATE TABLE in 0.01 seconds
2021-11-19 19:18:31.039567 (Thread-1): Using postgres connection "seed.my_new_project.iss_file".
2021-11-19 19:18:31.039785 (Thread-1): On seed.my_new_project.iss_file: 
          insert into "demo_db"."sa"."iss_file" (IssuerName, ISIN, GICSSector, GICSIndustryGroup, CountryOfIncorporation, CountryOfOperations, ClimateScope1Emissions, ClimateScope2Emissions, ClimateTotalEmissions, ClimateScope3Emissions, ClimateCNIEmissionsSource, ClimateEmissionsReportedTrust, ClimateEmissionsEstimatedTrust, ClimateScope1EmissionsIntUSD, ClimateScope2EmissionsIntUSD, ClimateTotalEmissionsIntUSD, ClimateAvePeerEmissionsIntUSD, MarketCapDaily, AdjustedEnterpriseValue, ClimateCarbonBudget2De...
2021-11-19 19:18:31.528028 (Thread-1): SQL status: INSERT 0 1594 in 0.49 seconds
2021-11-19 19:18:31.533790 (Thread-1): Writing runtime SQL for node "seed.my_new_project.iss_file"
2021-11-19 19:18:31.542318 (Thread-1): On seed.my_new_project.iss_file: COMMIT
2021-11-19 19:18:31.542445 (Thread-1): Using postgres connection "seed.my_new_project.iss_file".
2021-11-19 19:18:31.542542 (Thread-1): On seed.my_new_project.iss_file: COMMIT
2021-11-19 19:18:31.550046 (Thread-1): SQL status: COMMIT in 0.01 seconds
2021-11-19 19:18:31.550502 (Thread-1): finished collecting timing info
2021-11-19 19:18:31.550654 (Thread-1): On seed.my_new_project.iss_file: Close
2021-11-19 19:18:31.551018 (Thread-1): 20:18:31 | 1 of 1 OK loaded seed file sa.iss_file............................... [INSERT 1594 in 37.19s]
2021-11-19 19:18:31.551166 (Thread-1): Finished running node seed.my_new_project.iss_file
2021-11-19 19:18:31.552377 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:18:31.552526 (MainThread): Using postgres connection "master".
2021-11-19 19:18:31.552627 (MainThread): On master: BEGIN
2021-11-19 19:18:31.552730 (MainThread): Opening a new connection, currently in state closed
2021-11-19 19:18:31.557958 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:18:31.558088 (MainThread): On master: COMMIT
2021-11-19 19:18:31.558184 (MainThread): Using postgres connection "master".
2021-11-19 19:18:31.558272 (MainThread): On master: COMMIT
2021-11-19 19:18:31.558633 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:18:31.558793 (MainThread): On master: Close
2021-11-19 19:18:31.559125 (MainThread): 20:18:31 | 
2021-11-19 19:18:31.559308 (MainThread): 20:18:31 | Finished running 1 seed in 37.26s.
2021-11-19 19:18:31.559530 (MainThread): Connection 'master' was properly closed.
2021-11-19 19:18:31.559703 (MainThread): Connection 'seed.my_new_project.iss_file' was properly closed.
2021-11-19 19:18:31.559806 (MainThread): Connection 'list_demo_db_sa_dwh' was properly closed.
2021-11-19 19:18:31.563169 (MainThread): 
2021-11-19 19:18:31.563337 (MainThread): Completed successfully
2021-11-19 19:18:31.563569 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-11-19 19:18:31.563889 (MainThread): Flushing usage events
2021-11-19 19:19:15.149490 (MainThread): Running with dbt=0.21.0
2021-11-19 19:19:15.209706 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 19:19:15.210165 (MainThread): Tracking: do not track
2021-11-19 19:19:15.220597 (MainThread): Partial parsing not enabled
2021-11-19 19:19:15.227392 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 19:19:15.228027 (MainThread): Parsing macros/adapters.sql
2021-11-19 19:19:15.245761 (MainThread): Parsing macros/catalog.sql
2021-11-19 19:19:15.247633 (MainThread): Parsing macros/relations.sql
2021-11-19 19:19:15.248658 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 19:19:15.249959 (MainThread): Parsing macros/core.sql
2021-11-19 19:19:15.252734 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 19:19:15.293996 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 19:19:15.295976 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 19:19:15.297460 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 19:19:15.298688 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 19:19:15.305187 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 19:19:15.306427 (MainThread): Parsing macros/etc/query.sql
2021-11-19 19:19:15.307395 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 19:19:15.308566 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 19:19:15.316133 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 19:19:15.321436 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 19:19:15.339105 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 19:19:15.340410 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 19:19:15.363614 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 19:19:15.376947 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 19:19:15.392054 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 19:19:15.400234 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 19:19:15.401634 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 19:19:15.412393 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 19:19:15.415496 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 19:19:15.421060 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 19:19:15.426731 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 19:19:15.427780 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 19:19:15.428706 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 19:19:15.429990 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 19:19:15.590439 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:19:15.600060 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:19:15.602915 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:19:15.605510 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:19:15.605740 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:19:15.606569 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:19:15.610013 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:19:15.610226 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:19:15.611090 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:19:15.616000 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:19:15.616224 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:19:15.648081 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:19:15.649557 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:19:15.650969 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:19:15.652519 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:19:15.667518 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 19:19:15.667862 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 19:19:15.669093 (MainThread): 
2021-11-19 19:19:15.669349 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:19:15.670134 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 19:19:15.675763 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 19:19:15.679596 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 19:19:15.679808 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 19:19:15.679988 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 19:19:15.683020 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 19:19:15.683167 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 19:19:15.683293 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 19:19:15.687548 (ThreadPoolExecutor-0_1): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 19:19:15.688584 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 19:19:15.689119 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 19:19:15.690504 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 19:19:15.690770 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 19:19:15.690965 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state closed
2021-11-19 19:19:15.692451 (ThreadPoolExecutor-0_0): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 19:19:15.693518 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 19:19:15.698006 (ThreadPoolExecutor-0_1): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 19:19:15.698876 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 19:19:15.700381 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 19:19:15.704275 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 19:19:15.704398 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: BEGIN
2021-11-19 19:19:15.704516 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 19:19:15.705163 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 19:19:15.706958 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-19 19:19:15.707082 (ThreadPoolExecutor-1_1): On list_demo_db_sa: BEGIN
2021-11-19 19:19:15.707197 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 19:19:15.711677 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:19:15.711807 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 19:19:15.711901 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 19:19:15.714283 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:19:15.714508 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:19:15.715522 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 19:19:15.715670 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-19 19:19:15.715863 (ThreadPoolExecutor-1_1): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 19:19:15.716039 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: Close
2021-11-19 19:19:15.716547 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 19:19:15.717673 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 19:19:15.717831 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: BEGIN
2021-11-19 19:19:15.717985 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 19:19:15.718278 (ThreadPoolExecutor-1_1): SQL status: SELECT 4 in 0.00 seconds
2021-11-19 19:19:15.719342 (ThreadPoolExecutor-1_1): On list_demo_db_sa: ROLLBACK
2021-11-19 19:19:15.719681 (ThreadPoolExecutor-1_1): On list_demo_db_sa: Close
2021-11-19 19:19:15.723381 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:19:15.723587 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 19:19:15.723691 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 19:19:15.725163 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:19:15.725986 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 19:19:15.726304 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: Close
2021-11-19 19:19:15.729587 (MainThread): Using postgres connection "master".
2021-11-19 19:19:15.729718 (MainThread): On master: BEGIN
2021-11-19 19:19:15.729830 (MainThread): Opening a new connection, currently in state init
2021-11-19 19:19:15.735444 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:19:15.735658 (MainThread): Using postgres connection "master".
2021-11-19 19:19:15.735745 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 19:19:15.740700 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:19:15.741768 (MainThread): On master: ROLLBACK
2021-11-19 19:19:15.742194 (MainThread): Using postgres connection "master".
2021-11-19 19:19:15.742311 (MainThread): On master: BEGIN
2021-11-19 19:19:15.743021 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 19:19:15.743178 (MainThread): On master: COMMIT
2021-11-19 19:19:15.743266 (MainThread): Using postgres connection "master".
2021-11-19 19:19:15.743350 (MainThread): On master: COMMIT
2021-11-19 19:19:15.743821 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:19:15.743976 (MainThread): On master: Close
2021-11-19 19:19:15.744400 (MainThread): 20:19:15 | Concurrency: 2 threads (target='sa')
2021-11-19 19:19:15.744538 (MainThread): 20:19:15 | 
2021-11-19 19:19:15.747278 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-19 19:19:15.747487 (Thread-2): Began running node model.my_new_project.my_first_dbt_model
2021-11-19 19:19:15.747799 (Thread-1): 20:19:15 | 1 of 5 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-19 19:19:15.748011 (Thread-2): 20:19:15 | 2 of 5 START table model sa.my_first_dbt_model....................... [RUN]
2021-11-19 19:19:15.748373 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:19:15.748654 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:19:15.748888 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-19 19:19:15.749032 (Thread-2): Compiling model.my_new_project.my_first_dbt_model
2021-11-19 19:19:15.752760 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-19 19:19:15.754309 (Thread-2): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 19:19:15.754743 (Thread-2): finished collecting timing info
2021-11-19 19:19:15.765238 (Thread-1): finished collecting timing info
2021-11-19 19:19:15.783551 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 19:19:15.789100 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:19:15.789234 (Thread-2): On model.my_new_project.my_first_dbt_model: BEGIN
2021-11-19 19:19:15.789356 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 19:19:15.803843 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:19:15.804124 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.iss_issuer"} */

    

  create temporary table "iss_issuer__dbt_tmp201915796297"
  as (
    

select
     CASE
        WHEN iss.AdjustedEnterpriseValue ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.AdjustedEnterpriseValue::numeric
    ELSE NULL
    END        as adjusted_enterprise_value
    ,iss.ISIN                                               as isin
    ,iss.IssuerName                                         as issuer_name
    ,iss.gicssector                                         as gics_sector
    ,iss.gicsindustrygroup                                  as gics_industry_group
    ,CASE
        WHEN iss.ClimateScope2EmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope2EmissionsIntUSD::numeric
    ELSE NULL
    END   as climate_scope2_emissions_int_usd
    ,CASE
        WHEN iss.ClimateScope1EmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope1EmissionsIntUSD::numeric
    ELSE NULL
    END   as climate_scope1_emissions_int_usd
    ,iss.ClimateScope2Emissions::NUMERIC                    as climate_scope2_emissions
    ,CASE
        WHEN iss.ClimateTotalEmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateTotalEmissionsIntUSD::numeric
    ELSE NULL
    END    as climate_total_emissions_int_usd
    ,iss.ClimateScope3Emissions::NUMERIC                    as climate_scope3_emissions
    ,CASE
        WHEN iss.ClimateCNIEmissionsSource ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateCNIEmissionsSource::numeric
    ELSE NULL
    END      as climate_cni_emissions_source
    ,iss.ClimateTotalEmissions                              as climate_total_emissions
    ,iss.ClimateScope1Emissions::NUMERIC                    as climate_scope1_emissions
    ,CASE
        WHEN iss.MarketCapDaily ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.MarketCapDaily::numeric
    ELSE NULL
    END                 as market_cap_daily
    ,iss.ClimateEmissionsFiscalYear::INT                    as climate_emissions_fiscal_year
    ,'2021-01-01'::DATE                            as meta_file_date
    ,'20211117T164451425627'                                as meta_run_id
    ,CURRENT_TIMESTAMP                                      as meta_insert_timestamp
from "demo_db"."sa"."iss_file" iss
  );
  
2021-11-19 19:19:15.804318 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 19:19:15.804695 (Thread-2): SQL status: BEGIN in 0.02 seconds
2021-11-19 19:19:15.804900 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:19:15.805042 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table "demo_db"."sa"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)
,source_case as (

    select 1 as id , 'a' as name
    union all
    select 1 as id , 'b' as name

)

select s.id,n.name
from source_data s
inner join source_case n on n.id = s.id

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-11-19 19:19:15.809899 (Thread-2): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 19:19:15.814752 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:19:15.815013 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "demo_db"."sa"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2021-11-19 19:19:15.815494 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 19:19:15.817111 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:19:15.817258 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "demo_db"."sa"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2021-11-19 19:19:15.817686 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 19:19:15.825468 (Thread-2): On model.my_new_project.my_first_dbt_model: COMMIT
2021-11-19 19:19:15.825584 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:19:15.825676 (Thread-2): On model.my_new_project.my_first_dbt_model: COMMIT
2021-11-19 19:19:15.827232 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:19:15.830342 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:19:15.830583 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "demo_db"."sa"."my_first_dbt_model__dbt_backup" cascade
2021-11-19 19:19:15.831467 (Thread-1): SQL status: SELECT 1594 in 0.03 seconds
2021-11-19 19:19:15.837429 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:19:15.837570 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-19 19:19:15.837730 (Thread-2): SQL status: DROP TABLE in 0.01 seconds
2021-11-19 19:19:15.838676 (Thread-2): finished collecting timing info
2021-11-19 19:19:15.838828 (Thread-2): On model.my_new_project.my_first_dbt_model: Close
2021-11-19 19:19:15.838990 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-11-19 19:19:15.839148 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:19:15.839274 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer__dbt_tmp201915796297'
        
      order by ordinal_position

  
2021-11-19 19:19:15.839700 (Thread-2): 20:19:15 | 2 of 5 OK created table model sa.my_first_dbt_model.................. [SELECT 2 in 0.09s]
2021-11-19 19:19:15.839856 (Thread-2): Finished running node model.my_new_project.my_first_dbt_model
2021-11-19 19:19:15.840818 (Thread-2): Began running node model.my_new_project.my_second_dbt_model
2021-11-19 19:19:15.841081 (Thread-2): 20:19:15 | 3 of 5 START view model sa.my_second_dbt_model....................... [RUN]
2021-11-19 19:19:15.841319 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:19:15.841497 (Thread-2): Compiling model.my_new_project.my_second_dbt_model
2021-11-19 19:19:15.843709 (Thread-2): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-19 19:19:15.844070 (Thread-2): finished collecting timing info
2021-11-19 19:19:15.850258 (Thread-1): SQL status: SELECT 18 in 0.01 seconds
2021-11-19 19:19:15.854230 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:19:15.854370 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-19 19:19:15.862201 (Thread-1): SQL status: SELECT 18 in 0.01 seconds
2021-11-19 19:19:15.862933 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-19 19:19:15.871417 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:19:15.871570 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-19 19:19:15.871798 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:19:15.871915 (Thread-2): On model.my_new_project.my_second_dbt_model: BEGIN
2021-11-19 19:19:15.872034 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 19:19:15.873949 (Thread-1): SQL status: SELECT 18 in 0.00 seconds
2021-11-19 19:19:15.875504 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-19 19:19:15.875767 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:19:15.875871 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.iss_issuer"} */

      delete
    from "demo_db"."sa_dwh"."iss_issuer"
    where (ISIN) in (
        select (ISIN)
        from "iss_issuer__dbt_tmp201915796297"
    );

    insert into "demo_db"."sa_dwh"."iss_issuer" ("adjusted_enterprise_value", "isin", "issuer_name", "gics_sector", "gics_industry_group", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_cap_daily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp")
    (
       select "adjusted_enterprise_value", "isin", "issuer_name", "gics_sector", "gics_industry_group", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_cap_daily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp"
       from "iss_issuer__dbt_tmp201915796297"
    );
  
2021-11-19 19:19:15.878438 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:19:15.878583 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:19:15.878678 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.my_second_dbt_model"} */

  create view "demo_db"."sa"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."sa"."my_first_dbt_model"
where id = 1
  );

2021-11-19 19:19:15.879836 (Thread-2): SQL status: CREATE VIEW in 0.00 seconds
2021-11-19 19:19:15.881632 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:19:15.881767 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "demo_db"."sa"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2021-11-19 19:19:15.882404 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 19:19:15.883243 (Thread-2): On model.my_new_project.my_second_dbt_model: COMMIT
2021-11-19 19:19:15.883355 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:19:15.883449 (Thread-2): On model.my_new_project.my_second_dbt_model: COMMIT
2021-11-19 19:19:15.883617 (Thread-1): SQL status: INSERT 0 1594 in 0.01 seconds
2021-11-19 19:19:15.884641 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 19:19:15.884767 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:19:15.884861 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 19:19:15.886415 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:19:15.887580 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:19:15.887710 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "demo_db"."sa"."my_second_dbt_model__dbt_backup" cascade
2021-11-19 19:19:15.887873 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:19:15.888219 (Thread-1): finished collecting timing info
2021-11-19 19:19:15.888374 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-19 19:19:15.888560 (Thread-2): SQL status: DROP VIEW in 0.00 seconds
2021-11-19 19:19:15.889014 (Thread-1): 20:19:15 | 1 of 5 OK created incremental model sa_dwh.iss_issuer................ [INSERT 0 1594 in 0.14s]
2021-11-19 19:19:15.889876 (Thread-2): finished collecting timing info
2021-11-19 19:19:15.890084 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-19 19:19:15.890361 (Thread-2): On model.my_new_project.my_second_dbt_model: Close
2021-11-19 19:19:15.891276 (Thread-2): 20:19:15 | 3 of 5 OK created view model sa.my_second_dbt_model.................. [CREATE VIEW in 0.05s]
2021-11-19 19:19:15.891625 (Thread-2): Finished running node model.my_new_project.my_second_dbt_model
2021-11-19 19:19:15.891854 (Thread-1): Began running node model.my_new_project.dim_issuer
2021-11-19 19:19:15.892142 (Thread-2): Began running node model.my_new_project.fct_emissions
2021-11-19 19:19:15.892475 (Thread-1): 20:19:15 | 4 of 5 START table model sa_dm.dim_issuer............................ [RUN]
2021-11-19 19:19:15.892731 (Thread-2): 20:19:15 | 5 of 5 START incremental model sa_dm.fct_emissions................... [RUN]
2021-11-19 19:19:15.893065 (Thread-1): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:19:15.893350 (Thread-2): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:19:15.893519 (Thread-1): Compiling model.my_new_project.dim_issuer
2021-11-19 19:19:15.893671 (Thread-2): Compiling model.my_new_project.fct_emissions
2021-11-19 19:19:15.895946 (Thread-1): Writing injected SQL for node "model.my_new_project.dim_issuer"
2021-11-19 19:19:15.899025 (Thread-2): Writing injected SQL for node "model.my_new_project.fct_emissions"
2021-11-19 19:19:15.899444 (Thread-2): finished collecting timing info
2021-11-19 19:19:15.899594 (Thread-1): finished collecting timing info
2021-11-19 19:19:15.901440 (Thread-2): Writing runtime SQL for node "model.my_new_project.fct_emissions"
2021-11-19 19:19:15.903003 (Thread-1): Writing runtime SQL for node "model.my_new_project.dim_issuer"
2021-11-19 19:19:15.903387 (Thread-2): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:19:15.903514 (Thread-2): On model.my_new_project.fct_emissions: BEGIN
2021-11-19 19:19:15.903642 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 19:19:15.903959 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:19:15.904097 (Thread-1): On model.my_new_project.dim_issuer: BEGIN
2021-11-19 19:19:15.904243 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 19:19:15.910081 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:19:15.910285 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:19:15.910470 (Thread-2): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:19:15.910642 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:19:15.910828 (Thread-2): On model.my_new_project.fct_emissions: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.fct_emissions"} */

      

  create  table "demo_db"."sa_dm"."fct_emissions"
  as (
    


with cte_fundamental_enterprise_value as (
    select
         iss.isin                                                    as isin
        ,'EnterpriseValue'                                           as fundamental
        ,climate_scope1_emissions / climate_scope1_emissions_int_usd as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

, cte_fundamental_revenue as (
    select
         iss.ISIN                                                    as isin
        ,'Revenue'                                                   as fundamental
        ,adjusted_enterprise_value / 1e6                             as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

, cte_fundamental_market_cap as (
    select
         iss.ISIN                                                    as isin
        ,iss.climate_emissions_fiscal_year
        ,'MarketCap'                                                 as fundamental
        ,market_cap_daily / 1e6                                      as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

, cte_union_tables as (
    select * from cte_fundamental_enterprise_value

    union

    select * from cte_fundamental_revenue

    union

    select * from cte_fundamental_market_cap
)

select
     md5(isin)                            as fct_emissions_key
    ,md5(isin)                        as dim_issuer_key
    ,fundamental
    ,fundamental_value
    ,'2021-01-01'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from cte_union_tables
  );
  
2021-11-19 19:19:15.910979 (Thread-1): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.dim_issuer"} */


  create  table "demo_db"."sa_dm"."dim_issuer__dbt_tmp"
  as (
    

select distinct
     md5(iss.isin)              as dim_issuer_key
    ,iss.isin                   as isin
    ,iss.issuer_name            as issuer_name
    ,iss.gics_sector            as gics_sector
    ,iss.gics_industry_group    as gics_industry_group
from "demo_db"."sa_dwh"."iss_issuer" iss
  );
2021-11-19 19:19:15.911815 (Thread-2): Postgres error: each UNION query must have the same number of columns
LINE 44:     select * from cte_fundamental_market_cap
                    ^

2021-11-19 19:19:15.911948 (Thread-2): On model.my_new_project.fct_emissions: ROLLBACK
2021-11-19 19:19:15.912344 (Thread-2): finished collecting timing info
2021-11-19 19:19:15.912474 (Thread-2): On model.my_new_project.fct_emissions: Close
2021-11-19 19:19:15.912800 (Thread-2): Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
  each UNION query must have the same number of columns
  LINE 44:     select * from cte_fundamental_market_cap
                      ^
  compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: each UNION query must have the same number of columns
LINE 44:     select * from cte_fundamental_market_cap
                    ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
  each UNION query must have the same number of columns
  LINE 44:     select * from cte_fundamental_market_cap
                      ^
  compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
2021-11-19 19:19:15.914344 (Thread-2): 20:19:15 | 5 of 5 ERROR creating incremental model sa_dm.fct_emissions.......... [ERROR in 0.02s]
2021-11-19 19:19:15.914536 (Thread-2): Finished running node model.my_new_project.fct_emissions
2021-11-19 19:19:15.972538 (Thread-1): SQL status: SELECT 28447 in 0.06 seconds
2021-11-19 19:19:15.974322 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:19:15.974432 (Thread-1): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer" rename to "dim_issuer__dbt_backup"
2021-11-19 19:19:15.975043 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 19:19:15.976379 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:19:15.976482 (Thread-1): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer__dbt_tmp" rename to "dim_issuer"
2021-11-19 19:19:15.976944 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 19:19:15.977769 (Thread-1): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 19:19:15.977871 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:19:15.977959 (Thread-1): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 19:19:15.985427 (Thread-1): SQL status: COMMIT in 0.01 seconds
2021-11-19 19:19:15.986720 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:19:15.986834 (Thread-1): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.dim_issuer"} */
drop table if exists "demo_db"."sa_dm"."dim_issuer__dbt_backup" cascade
2021-11-19 19:19:15.989153 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-11-19 19:19:15.989951 (Thread-1): finished collecting timing info
2021-11-19 19:19:15.990079 (Thread-1): On model.my_new_project.dim_issuer: Close
2021-11-19 19:19:15.990492 (Thread-1): 20:19:15 | 4 of 5 OK created table model sa_dm.dim_issuer....................... [SELECT 28447 in 0.10s]
2021-11-19 19:19:15.990638 (Thread-1): Finished running node model.my_new_project.dim_issuer
2021-11-19 19:19:15.992211 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:19:15.992358 (MainThread): Using postgres connection "master".
2021-11-19 19:19:15.992452 (MainThread): On master: BEGIN
2021-11-19 19:19:15.992549 (MainThread): Opening a new connection, currently in state closed
2021-11-19 19:19:15.999126 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:19:15.999351 (MainThread): On master: COMMIT
2021-11-19 19:19:15.999452 (MainThread): Using postgres connection "master".
2021-11-19 19:19:15.999537 (MainThread): On master: COMMIT
2021-11-19 19:19:15.999895 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:19:16.000012 (MainThread): On master: Close
2021-11-19 19:19:16.000376 (MainThread): 20:19:15 | 
2021-11-19 19:19:16.000540 (MainThread): 20:19:15 | Finished running 2 table models, 2 incremental models, 1 view model in 0.33s.
2021-11-19 19:19:16.000743 (MainThread): Connection 'master' was properly closed.
2021-11-19 19:19:16.000890 (MainThread): Connection 'model.my_new_project.fct_emissions' was properly closed.
2021-11-19 19:19:16.001029 (MainThread): Connection 'model.my_new_project.dim_issuer' was properly closed.
2021-11-19 19:19:16.004855 (MainThread): 
2021-11-19 19:19:16.005112 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 19:19:16.005380 (MainThread): 
2021-11-19 19:19:16.005593 (MainThread): Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
2021-11-19 19:19:16.005779 (MainThread):   each UNION query must have the same number of columns
2021-11-19 19:19:16.005918 (MainThread):   LINE 44:     select * from cte_fundamental_market_cap
2021-11-19 19:19:16.006096 (MainThread):                       ^
2021-11-19 19:19:16.006279 (MainThread):   compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
2021-11-19 19:19:16.006498 (MainThread): 
Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
2021-11-19 19:19:16.006729 (MainThread): Flushing usage events
2021-11-19 19:20:07.023651 (MainThread): Running with dbt=0.21.0
2021-11-19 19:20:07.080407 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 19:20:07.080938 (MainThread): Tracking: do not track
2021-11-19 19:20:07.092936 (MainThread): Partial parsing not enabled
2021-11-19 19:20:07.099625 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 19:20:07.100284 (MainThread): Parsing macros/adapters.sql
2021-11-19 19:20:07.118212 (MainThread): Parsing macros/catalog.sql
2021-11-19 19:20:07.120250 (MainThread): Parsing macros/relations.sql
2021-11-19 19:20:07.121264 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 19:20:07.122504 (MainThread): Parsing macros/core.sql
2021-11-19 19:20:07.125705 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 19:20:07.178320 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 19:20:07.180267 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 19:20:07.181829 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 19:20:07.183067 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 19:20:07.190832 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 19:20:07.192143 (MainThread): Parsing macros/etc/query.sql
2021-11-19 19:20:07.192948 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 19:20:07.194112 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 19:20:07.201677 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 19:20:07.206790 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 19:20:07.223780 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 19:20:07.225031 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 19:20:07.247175 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 19:20:07.260212 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 19:20:07.274612 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 19:20:07.282726 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 19:20:07.284063 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 19:20:07.294208 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 19:20:07.297137 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 19:20:07.304347 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 19:20:07.309913 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 19:20:07.311003 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 19:20:07.311932 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 19:20:07.313227 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 19:20:07.468318 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:20:07.477962 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:20:07.480888 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:20:07.483412 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:20:07.483627 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:20:07.484481 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:20:07.487758 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:20:07.487962 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:20:07.488757 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:20:07.493344 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:20:07.493559 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:20:07.524492 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:20:07.526021 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:20:07.527417 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:20:07.528918 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:20:07.543557 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 19:20:07.543987 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 19:20:07.545221 (MainThread): 
2021-11-19 19:20:07.545507 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:20:07.546289 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 19:20:07.553620 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 19:20:07.553813 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 19:20:07.553940 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 19:20:07.554453 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 19:20:07.556051 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 19:20:07.556160 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 19:20:07.556307 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 19:20:07.561647 (ThreadPoolExecutor-0_0): SQL status: SELECT 19 in 0.01 seconds
2021-11-19 19:20:07.562684 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 19:20:07.563311 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 19:20:07.564557 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 19:20:07.564785 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 19:20:07.565331 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-11-19 19:20:07.565631 (ThreadPoolExecutor-0_1): SQL status: SELECT 19 in 0.01 seconds
2021-11-19 19:20:07.566838 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 19:20:07.572141 (ThreadPoolExecutor-0_0): SQL status: SELECT 19 in 0.01 seconds
2021-11-19 19:20:07.572923 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 19:20:07.573554 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "create_demo_db_sa_dm".
2021-11-19 19:20:07.573801 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_demo_db_sa_dwh".
2021-11-19 19:20:07.574219 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "create_demo_db_sa_dm".
2021-11-19 19:20:07.574483 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_demo_db_sa_dwh".
2021-11-19 19:20:07.574698 (ThreadPoolExecutor-0_1): Creating schema ""demo_db"."sa_dm""
2021-11-19 19:20:07.574914 (ThreadPoolExecutor-0_0): Creating schema ""demo_db"."sa_dwh""
2021-11-19 19:20:07.578677 (ThreadPoolExecutor-0_1): Using postgres connection "create_demo_db_sa_dm".
2021-11-19 19:20:07.580025 (ThreadPoolExecutor-0_0): Using postgres connection "create_demo_db_sa_dwh".
2021-11-19 19:20:07.580205 (ThreadPoolExecutor-0_1): On create_demo_db_sa_dm: BEGIN
2021-11-19 19:20:07.580356 (ThreadPoolExecutor-0_0): On create_demo_db_sa_dwh: BEGIN
2021-11-19 19:20:07.580728 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state closed
2021-11-19 19:20:07.581078 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-11-19 19:20:07.588350 (ThreadPoolExecutor-0_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:20:07.588509 (ThreadPoolExecutor-0_1): Using postgres connection "create_demo_db_sa_dm".
2021-11-19 19:20:07.588623 (ThreadPoolExecutor-0_1): On create_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "create_demo_db_sa_dm"} */
create schema if not exists "sa_dm"
2021-11-19 19:20:07.588784 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:20:07.588936 (ThreadPoolExecutor-0_0): Using postgres connection "create_demo_db_sa_dwh".
2021-11-19 19:20:07.589058 (ThreadPoolExecutor-0_0): On create_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "create_demo_db_sa_dwh"} */
create schema if not exists "sa_dwh"
2021-11-19 19:20:07.589270 (ThreadPoolExecutor-0_1): SQL status: CREATE SCHEMA in 0.00 seconds
2021-11-19 19:20:07.589947 (ThreadPoolExecutor-0_1): On create_demo_db_sa_dm: COMMIT
2021-11-19 19:20:07.590068 (ThreadPoolExecutor-0_1): Using postgres connection "create_demo_db_sa_dm".
2021-11-19 19:20:07.590176 (ThreadPoolExecutor-0_1): On create_demo_db_sa_dm: COMMIT
2021-11-19 19:20:07.590329 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.00 seconds
2021-11-19 19:20:07.590884 (ThreadPoolExecutor-0_0): On create_demo_db_sa_dwh: COMMIT
2021-11-19 19:20:07.590981 (ThreadPoolExecutor-0_0): Using postgres connection "create_demo_db_sa_dwh".
2021-11-19 19:20:07.591064 (ThreadPoolExecutor-0_0): On create_demo_db_sa_dwh: COMMIT
2021-11-19 19:20:07.591943 (ThreadPoolExecutor-0_1): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:20:07.592131 (ThreadPoolExecutor-0_1): On create_demo_db_sa_dm: Close
2021-11-19 19:20:07.592908 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:20:07.593079 (ThreadPoolExecutor-0_0): On create_demo_db_sa_dwh: Close
2021-11-19 19:20:07.594450 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 19:20:07.598986 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 19:20:07.599294 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 19:20:07.599463 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: BEGIN
2021-11-19 19:20:07.600528 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 19:20:07.600720 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 19:20:07.600900 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-19 19:20:07.601194 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 19:20:07.607564 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:20:07.607772 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:20:07.607901 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 19:20:07.608032 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 19:20:07.608160 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 19:20:07.608289 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 19:20:07.610078 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 19:20:07.610260 (ThreadPoolExecutor-1_1): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 19:20:07.611048 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 19:20:07.611959 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 19:20:07.612547 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-19 19:20:07.612777 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: Close
2021-11-19 19:20:07.613497 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 19:20:07.615824 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-19 19:20:07.616206 (ThreadPoolExecutor-1_1): On list_demo_db_sa: BEGIN
2021-11-19 19:20:07.616477 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 19:20:07.622419 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:20:07.622575 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-19 19:20:07.622669 (ThreadPoolExecutor-1_1): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 19:20:07.624208 (ThreadPoolExecutor-1_1): SQL status: SELECT 3 in 0.00 seconds
2021-11-19 19:20:07.625157 (ThreadPoolExecutor-1_1): On list_demo_db_sa: ROLLBACK
2021-11-19 19:20:07.625493 (ThreadPoolExecutor-1_1): On list_demo_db_sa: Close
2021-11-19 19:20:07.629113 (MainThread): Using postgres connection "master".
2021-11-19 19:20:07.629224 (MainThread): On master: BEGIN
2021-11-19 19:20:07.629320 (MainThread): Opening a new connection, currently in state init
2021-11-19 19:20:07.634886 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:20:07.635083 (MainThread): Using postgres connection "master".
2021-11-19 19:20:07.635172 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 19:20:07.638006 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:20:07.638895 (MainThread): On master: ROLLBACK
2021-11-19 19:20:07.639303 (MainThread): Using postgres connection "master".
2021-11-19 19:20:07.639420 (MainThread): On master: BEGIN
2021-11-19 19:20:07.640251 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 19:20:07.640426 (MainThread): On master: COMMIT
2021-11-19 19:20:07.640512 (MainThread): Using postgres connection "master".
2021-11-19 19:20:07.640594 (MainThread): On master: COMMIT
2021-11-19 19:20:07.640964 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:20:07.641101 (MainThread): On master: Close
2021-11-19 19:20:07.641418 (MainThread): 20:20:07 | Concurrency: 2 threads (target='sa')
2021-11-19 19:20:07.641580 (MainThread): 20:20:07 | 
2021-11-19 19:20:07.644221 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-19 19:20:07.644468 (Thread-2): Began running node model.my_new_project.my_first_dbt_model
2021-11-19 19:20:07.644983 (Thread-1): 20:20:07 | 1 of 5 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-19 19:20:07.645334 (Thread-2): 20:20:07 | 2 of 5 START table model sa.my_first_dbt_model....................... [RUN]
2021-11-19 19:20:07.645776 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:20:07.646199 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:20:07.646362 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-19 19:20:07.646562 (Thread-2): Compiling model.my_new_project.my_first_dbt_model
2021-11-19 19:20:07.650503 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-19 19:20:07.652093 (Thread-2): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 19:20:07.652515 (Thread-1): finished collecting timing info
2021-11-19 19:20:07.657886 (Thread-2): finished collecting timing info
2021-11-19 19:20:07.692822 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 19:20:07.699895 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-19 19:20:07.700245 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:20:07.700383 (Thread-2): On model.my_new_project.my_first_dbt_model: BEGIN
2021-11-19 19:20:07.700514 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 19:20:07.700833 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:20:07.700970 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-19 19:20:07.701160 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 19:20:07.707058 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:20:07.707206 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:20:07.707326 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."sa_dwh"."iss_issuer"
  as (
    

select
     CASE
        WHEN iss.AdjustedEnterpriseValue ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.AdjustedEnterpriseValue::numeric
    ELSE NULL
    END        as adjusted_enterprise_value
    ,iss.ISIN                                               as isin
    ,iss.IssuerName                                         as issuer_name
    ,iss.gicssector                                         as gics_sector
    ,iss.gicsindustrygroup                                  as gics_industry_group
    ,CASE
        WHEN iss.ClimateScope2EmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope2EmissionsIntUSD::numeric
    ELSE NULL
    END   as climate_scope2_emissions_int_usd
    ,CASE
        WHEN iss.ClimateScope1EmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope1EmissionsIntUSD::numeric
    ELSE NULL
    END   as climate_scope1_emissions_int_usd
    ,iss.ClimateScope2Emissions::NUMERIC                    as climate_scope2_emissions
    ,CASE
        WHEN iss.ClimateTotalEmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateTotalEmissionsIntUSD::numeric
    ELSE NULL
    END    as climate_total_emissions_int_usd
    ,iss.ClimateScope3Emissions::NUMERIC                    as climate_scope3_emissions
    ,CASE
        WHEN iss.ClimateCNIEmissionsSource ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateCNIEmissionsSource::numeric
    ELSE NULL
    END      as climate_cni_emissions_source
    ,iss.ClimateTotalEmissions                              as climate_total_emissions
    ,iss.ClimateScope1Emissions::NUMERIC                    as climate_scope1_emissions
    ,CASE
        WHEN iss.MarketCapDaily ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.MarketCapDaily::numeric
    ELSE NULL
    END                 as market_cap_daily
    ,iss.ClimateEmissionsFiscalYear::INT                    as climate_emissions_fiscal_year
    ,'2021-01-01'::DATE                            as meta_file_date
    ,'20211117T164451425627'                                as meta_run_id
    ,CURRENT_TIMESTAMP                                      as meta_insert_timestamp
from "demo_db"."sa"."iss_file" iss
  );
  
2021-11-19 19:20:07.707498 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:20:07.707625 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:20:07.707738 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table "demo_db"."sa"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)
,source_case as (

    select 1 as id , 'a' as name
    union all
    select 1 as id , 'b' as name

)

select s.id,n.name
from source_data s
inner join source_case n on n.id = s.id

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-11-19 19:20:07.711474 (Thread-2): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 19:20:07.716420 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:20:07.716550 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "demo_db"."sa"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2021-11-19 19:20:07.717128 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 19:20:07.718509 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:20:07.718617 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "demo_db"."sa"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2021-11-19 19:20:07.719095 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 19:20:07.727800 (Thread-2): On model.my_new_project.my_first_dbt_model: COMMIT
2021-11-19 19:20:07.727945 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:20:07.728064 (Thread-2): On model.my_new_project.my_first_dbt_model: COMMIT
2021-11-19 19:20:07.728228 (Thread-1): SQL status: SELECT 1594 in 0.02 seconds
2021-11-19 19:20:07.729176 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 19:20:07.729285 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:20:07.729377 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 19:20:07.729870 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:20:07.733394 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:20:07.733556 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:20:07.733747 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "demo_db"."sa"."my_first_dbt_model__dbt_backup" cascade
2021-11-19 19:20:07.734126 (Thread-1): finished collecting timing info
2021-11-19 19:20:07.734392 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-19 19:20:07.734872 (Thread-1): 20:20:07 | 1 of 5 OK created incremental model sa_dwh.iss_issuer................ [SELECT 1594 in 0.09s]
2021-11-19 19:20:07.735026 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-19 19:20:07.735606 (Thread-1): Began running node model.my_new_project.dim_issuer
2021-11-19 19:20:07.735891 (Thread-1): 20:20:07 | 3 of 5 START table model sa_dm.dim_issuer............................ [RUN]
2021-11-19 19:20:07.736293 (Thread-1): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:20:07.736415 (Thread-1): Compiling model.my_new_project.dim_issuer
2021-11-19 19:20:07.738713 (Thread-1): Writing injected SQL for node "model.my_new_project.dim_issuer"
2021-11-19 19:20:07.738906 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-11-19 19:20:07.739859 (Thread-2): finished collecting timing info
2021-11-19 19:20:07.740017 (Thread-1): finished collecting timing info
2021-11-19 19:20:07.740233 (Thread-2): On model.my_new_project.my_first_dbt_model: Close
2021-11-19 19:20:07.741683 (Thread-1): Writing runtime SQL for node "model.my_new_project.dim_issuer"
2021-11-19 19:20:07.742320 (Thread-2): 20:20:07 | 2 of 5 OK created table model sa.my_first_dbt_model.................. [SELECT 2 in 0.10s]
2021-11-19 19:20:07.742529 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:20:07.742783 (Thread-1): On model.my_new_project.dim_issuer: BEGIN
2021-11-19 19:20:07.742913 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 19:20:07.743204 (Thread-2): Finished running node model.my_new_project.my_first_dbt_model
2021-11-19 19:20:07.743404 (Thread-2): Began running node model.my_new_project.fct_emissions
2021-11-19 19:20:07.743759 (Thread-2): 20:20:07 | 4 of 5 START incremental model sa_dm.fct_emissions................... [RUN]
2021-11-19 19:20:07.744139 (Thread-2): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:20:07.744279 (Thread-2): Compiling model.my_new_project.fct_emissions
2021-11-19 19:20:07.747434 (Thread-2): Writing injected SQL for node "model.my_new_project.fct_emissions"
2021-11-19 19:20:07.747943 (Thread-2): finished collecting timing info
2021-11-19 19:20:07.749937 (Thread-2): Writing runtime SQL for node "model.my_new_project.fct_emissions"
2021-11-19 19:20:07.750375 (Thread-2): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:20:07.750591 (Thread-2): On model.my_new_project.fct_emissions: BEGIN
2021-11-19 19:20:07.750870 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 19:20:07.751140 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:20:07.751279 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:20:07.751422 (Thread-1): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.dim_issuer"} */


  create  table "demo_db"."sa_dm"."dim_issuer__dbt_tmp"
  as (
    

select distinct
     md5(iss.isin)              as dim_issuer_key
    ,iss.isin                   as isin
    ,iss.issuer_name            as issuer_name
    ,iss.gics_sector            as gics_sector
    ,iss.gics_industry_group    as gics_industry_group
from "demo_db"."sa_dwh"."iss_issuer" iss
  );
2021-11-19 19:20:07.757026 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:20:07.757197 (Thread-2): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:20:07.757291 (Thread-2): On model.my_new_project.fct_emissions: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.fct_emissions"} */

      

  create  table "demo_db"."sa_dm"."fct_emissions"
  as (
    


with cte_fundamental_enterprise_value as (
    select
         iss.isin                                                    as isin
        ,'EnterpriseValue'                                           as fundamental
        ,climate_scope1_emissions / climate_scope1_emissions_int_usd as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

, cte_fundamental_revenue as (
    select
         iss.ISIN                                                    as isin
        ,'Revenue'                                                   as fundamental
        ,adjusted_enterprise_value / 1e6                             as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

, cte_fundamental_market_cap as (
    select
         iss.ISIN                                                    as isin
        ,iss.climate_emissions_fiscal_year
        ,'MarketCap'                                                 as fundamental
        ,market_cap_daily / 1e6                                      as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

, cte_union_tables as (
    select * from cte_fundamental_enterprise_value

    union

    select * from cte_fundamental_revenue

    union

    select * from cte_fundamental_market_cap
)

select
     md5(isin)                            as fct_emissions_key
    ,md5(isin)                        as dim_issuer_key
    ,fundamental
    ,fundamental_value
    ,'2021-01-01'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from cte_union_tables
  );
  
2021-11-19 19:20:07.758126 (Thread-2): Postgres error: each UNION query must have the same number of columns
LINE 44:     select * from cte_fundamental_market_cap
                    ^

2021-11-19 19:20:07.758288 (Thread-2): On model.my_new_project.fct_emissions: ROLLBACK
2021-11-19 19:20:07.758721 (Thread-2): finished collecting timing info
2021-11-19 19:20:07.758884 (Thread-2): On model.my_new_project.fct_emissions: Close
2021-11-19 19:20:07.759089 (Thread-1): SQL status: SELECT 1594 in 0.01 seconds
2021-11-19 19:20:07.761367 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:20:07.761763 (Thread-1): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer__dbt_tmp" rename to "dim_issuer"
2021-11-19 19:20:07.762915 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 19:20:07.763836 (Thread-1): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 19:20:07.764009 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:20:07.764145 (Thread-1): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 19:20:07.759439 (Thread-2): Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
  each UNION query must have the same number of columns
  LINE 44:     select * from cte_fundamental_market_cap
                      ^
  compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: each UNION query must have the same number of columns
LINE 44:     select * from cte_fundamental_market_cap
                    ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
  each UNION query must have the same number of columns
  LINE 44:     select * from cte_fundamental_market_cap
                      ^
  compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
2021-11-19 19:20:07.764937 (Thread-2): 20:20:07 | 4 of 5 ERROR creating incremental model sa_dm.fct_emissions.......... [ERROR in 0.02s]
2021-11-19 19:20:07.765115 (Thread-2): Finished running node model.my_new_project.fct_emissions
2021-11-19 19:20:07.765325 (Thread-2): Began running node model.my_new_project.my_second_dbt_model
2021-11-19 19:20:07.765735 (Thread-2): 20:20:07 | 5 of 5 START view model sa.my_second_dbt_model....................... [RUN]
2021-11-19 19:20:07.765875 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:20:07.766258 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:20:07.767433 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:20:07.767598 (Thread-2): Compiling model.my_new_project.my_second_dbt_model
2021-11-19 19:20:07.767736 (Thread-1): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.dim_issuer"} */
drop table if exists "demo_db"."sa_dm"."dim_issuer__dbt_backup" cascade
2021-11-19 19:20:07.769359 (Thread-2): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-19 19:20:07.769685 (Thread-2): finished collecting timing info
2021-11-19 19:20:07.769949 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-11-19 19:20:07.775953 (Thread-1): finished collecting timing info
2021-11-19 19:20:07.776099 (Thread-1): On model.my_new_project.dim_issuer: Close
2021-11-19 19:20:07.781769 (Thread-1): 20:20:07 | 3 of 5 OK created table model sa_dm.dim_issuer....................... [SELECT 1594 in 0.05s]
2021-11-19 19:20:07.784397 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-19 19:20:07.784703 (Thread-1): Finished running node model.my_new_project.dim_issuer
2021-11-19 19:20:07.785095 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:20:07.785199 (Thread-2): On model.my_new_project.my_second_dbt_model: BEGIN
2021-11-19 19:20:07.785437 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 19:20:07.791460 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:20:07.791631 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:20:07.791723 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.my_second_dbt_model"} */

  create view "demo_db"."sa"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."sa"."my_first_dbt_model"
where id = 1
  );

2021-11-19 19:20:07.792817 (Thread-2): SQL status: CREATE VIEW in 0.00 seconds
2021-11-19 19:20:07.794350 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:20:07.794452 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "demo_db"."sa"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2021-11-19 19:20:07.794952 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 19:20:07.795783 (Thread-2): On model.my_new_project.my_second_dbt_model: COMMIT
2021-11-19 19:20:07.795887 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:20:07.795976 (Thread-2): On model.my_new_project.my_second_dbt_model: COMMIT
2021-11-19 19:20:07.797707 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:20:07.798941 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:20:07.799049 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "sa", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "demo_db"."sa"."my_second_dbt_model__dbt_backup" cascade
2021-11-19 19:20:07.799533 (Thread-2): SQL status: DROP VIEW in 0.00 seconds
2021-11-19 19:20:07.800331 (Thread-2): finished collecting timing info
2021-11-19 19:20:07.800459 (Thread-2): On model.my_new_project.my_second_dbt_model: Close
2021-11-19 19:20:07.800856 (Thread-2): 20:20:07 | 5 of 5 OK created view model sa.my_second_dbt_model.................. [CREATE VIEW in 0.03s]
2021-11-19 19:20:07.800997 (Thread-2): Finished running node model.my_new_project.my_second_dbt_model
2021-11-19 19:20:07.802390 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:20:07.802516 (MainThread): Using postgres connection "master".
2021-11-19 19:20:07.802606 (MainThread): On master: BEGIN
2021-11-19 19:20:07.802698 (MainThread): Opening a new connection, currently in state closed
2021-11-19 19:20:07.807875 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:20:07.808077 (MainThread): On master: COMMIT
2021-11-19 19:20:07.808166 (MainThread): Using postgres connection "master".
2021-11-19 19:20:07.808252 (MainThread): On master: COMMIT
2021-11-19 19:20:07.808512 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:20:07.808643 (MainThread): On master: Close
2021-11-19 19:20:07.808969 (MainThread): 20:20:07 | 
2021-11-19 19:20:07.809107 (MainThread): 20:20:07 | Finished running 2 incremental models, 2 table models, 1 view model in 0.26s.
2021-11-19 19:20:07.809287 (MainThread): Connection 'master' was properly closed.
2021-11-19 19:20:07.809465 (MainThread): Connection 'model.my_new_project.my_second_dbt_model' was properly closed.
2021-11-19 19:20:07.809562 (MainThread): Connection 'model.my_new_project.dim_issuer' was properly closed.
2021-11-19 19:20:07.812673 (MainThread): 
2021-11-19 19:20:07.812815 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 19:20:07.813026 (MainThread): 
2021-11-19 19:20:07.813251 (MainThread): Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
2021-11-19 19:20:07.813481 (MainThread):   each UNION query must have the same number of columns
2021-11-19 19:20:07.813665 (MainThread):   LINE 44:     select * from cte_fundamental_market_cap
2021-11-19 19:20:07.813853 (MainThread):                       ^
2021-11-19 19:20:07.814061 (MainThread):   compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
2021-11-19 19:20:07.814256 (MainThread): 
Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
2021-11-19 19:20:07.814555 (MainThread): Flushing usage events
2021-11-19 19:30:00.537620 (MainThread): Running with dbt=0.21.0
2021-11-19 19:30:00.594920 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 19:30:00.595401 (MainThread): Tracking: do not track
2021-11-19 19:30:00.605408 (MainThread): Partial parsing not enabled
2021-11-19 19:30:00.612405 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 19:30:00.613032 (MainThread): Parsing macros/dbt/generate_schema_name.sql
2021-11-19 19:30:00.614777 (MainThread): Flushing usage events
2021-11-19 19:30:00.614957 (MainThread): Encountered an error:
2021-11-19 19:30:00.615103 (MainThread): Compilation Error
  dbt found two macros named "generate_schema_name" in the project
  "my_new_project".
   To fix this error, rename or remove one of the following macros:
      - macros/dbt/generate_schema_name.sql
      - macros/dbt/generate_schema_name.sql
2021-11-19 19:30:00.618330 (MainThread): Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 433, in run
    self._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 149, in _runtime_initialize
    super()._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 87, in _runtime_initialize
    self.load_manifest()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 74, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 182, in get_full_manifest
    manifest = loader.load()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 283, in load
    parser.parse_file(block)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/macros.py", line 112, in parse_file
    self.manifest.add_macro(block.file, node)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/contracts/graph/manifest.py", line 971, in add_macro
    raise_compiler_error(msg)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/exceptions.py", line 444, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error
  dbt found two macros named "generate_schema_name" in the project
  "my_new_project".
   To fix this error, rename or remove one of the following macros:
      - macros/dbt/generate_schema_name.sql
      - macros/dbt/generate_schema_name.sql

2021-11-19 19:30:43.165683 (MainThread): Running with dbt=0.21.0
2021-11-19 19:30:43.219263 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 19:30:43.219686 (MainThread): Tracking: do not track
2021-11-19 19:30:43.229146 (MainThread): Partial parsing not enabled
2021-11-19 19:30:43.235617 (MainThread): Parsing macros/generate_schema_name.sql
2021-11-19 19:30:43.237525 (MainThread): Flushing usage events
2021-11-19 19:30:43.237699 (MainThread): Encountered an error:
2021-11-19 19:30:43.237844 (MainThread): Compilation Error
  dbt found two macros named "generate_schema_name" in the project
  "my_new_project".
   To fix this error, rename or remove one of the following macros:
      - macros/generate_schema_name.sql
      - macros/generate_schema_name.sql
2021-11-19 19:30:43.238980 (MainThread): Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 433, in run
    self._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 149, in _runtime_initialize
    super()._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 87, in _runtime_initialize
    self.load_manifest()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 74, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 182, in get_full_manifest
    manifest = loader.load()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 283, in load
    parser.parse_file(block)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/macros.py", line 112, in parse_file
    self.manifest.add_macro(block.file, node)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/contracts/graph/manifest.py", line 971, in add_macro
    raise_compiler_error(msg)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/exceptions.py", line 444, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error
  dbt found two macros named "generate_schema_name" in the project
  "my_new_project".
   To fix this error, rename or remove one of the following macros:
      - macros/generate_schema_name.sql
      - macros/generate_schema_name.sql

2021-11-19 19:31:55.419383 (MainThread): Running with dbt=0.21.0
2021-11-19 19:31:55.473542 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 19:31:55.473936 (MainThread): Tracking: do not track
2021-11-19 19:31:55.483669 (MainThread): Partial parsing not enabled
2021-11-19 19:31:55.490148 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 19:31:55.490729 (MainThread): Parsing macros/adapters.sql
2021-11-19 19:31:55.507910 (MainThread): Parsing macros/catalog.sql
2021-11-19 19:31:55.509512 (MainThread): Parsing macros/relations.sql
2021-11-19 19:31:55.510434 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 19:31:55.511734 (MainThread): Parsing macros/core.sql
2021-11-19 19:31:55.514567 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 19:31:55.554930 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 19:31:55.556936 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 19:31:55.558285 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 19:31:55.559489 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 19:31:55.565987 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 19:31:55.567157 (MainThread): Parsing macros/etc/query.sql
2021-11-19 19:31:55.567880 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 19:31:55.569042 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 19:31:55.576153 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 19:31:55.581294 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 19:31:55.598223 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 19:31:55.599653 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 19:31:55.621884 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 19:31:55.635226 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 19:31:55.651849 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 19:31:55.659959 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 19:31:55.661440 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 19:31:55.671625 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 19:31:55.674516 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 19:31:55.679938 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 19:31:55.685133 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 19:31:55.686198 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 19:31:55.687110 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 19:31:55.688324 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 19:31:55.843087 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:31:55.852856 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:31:55.855691 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:31:55.858175 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:31:55.858384 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:31:55.859199 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:31:55.862686 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:31:55.862898 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:31:55.863752 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:31:55.868415 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:31:55.868705 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:31:55.903729 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:31:55.905315 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:31:55.906780 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:31:55.908281 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:31:55.922548 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 19:31:55.923021 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 19:31:55.924858 (MainThread): 
2021-11-19 19:31:55.925230 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:31:55.926113 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 19:31:55.932013 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 19:31:55.935808 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 19:31:55.935950 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 19:31:55.936084 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 19:31:55.938847 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 19:31:55.938977 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 19:31:55.939236 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 19:31:55.943665 (ThreadPoolExecutor-0_1): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 19:31:55.944934 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 19:31:55.945763 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 19:31:55.948328 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 19:31:55.948637 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 19:31:55.948951 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state closed
2021-11-19 19:31:55.949193 (ThreadPoolExecutor-0_0): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 19:31:55.950775 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 19:31:55.956483 (ThreadPoolExecutor-0_1): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 19:31:55.957388 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 19:31:55.958746 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 19:31:55.959087 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 19:31:55.963280 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 19:31:55.964704 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 19:31:55.964854 (ThreadPoolExecutor-1_0): On list_demo_db_sa: BEGIN
2021-11-19 19:31:55.964994 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: BEGIN
2021-11-19 19:31:55.965139 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 19:31:55.965470 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 19:31:55.971971 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:31:55.972231 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:31:55.972368 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa".
2021-11-19 19:31:55.972501 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 19:31:55.972632 (ThreadPoolExecutor-1_0): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 19:31:55.972763 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 19:31:55.974494 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:31:55.975513 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 19:31:55.975678 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2021-11-19 19:31:55.976464 (ThreadPoolExecutor-1_0): On list_demo_db_sa: ROLLBACK
2021-11-19 19:31:55.976622 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dm: Close
2021-11-19 19:31:55.976781 (ThreadPoolExecutor-1_0): On list_demo_db_sa: Close
2021-11-19 19:31:55.977437 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 19:31:55.978837 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 19:31:55.979167 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: BEGIN
2021-11-19 19:31:55.979278 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 19:31:55.985208 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:31:55.985396 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 19:31:55.985484 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 19:31:55.987079 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:31:55.987908 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 19:31:55.988222 (ThreadPoolExecutor-1_1): On list_demo_db_sa_dwh: Close
2021-11-19 19:31:55.991676 (MainThread): Using postgres connection "master".
2021-11-19 19:31:55.991786 (MainThread): On master: BEGIN
2021-11-19 19:31:55.991882 (MainThread): Opening a new connection, currently in state init
2021-11-19 19:31:55.998243 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:31:55.998480 (MainThread): Using postgres connection "master".
2021-11-19 19:31:55.998569 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 19:31:56.002551 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:31:56.003460 (MainThread): On master: ROLLBACK
2021-11-19 19:31:56.003872 (MainThread): Using postgres connection "master".
2021-11-19 19:31:56.003975 (MainThread): On master: BEGIN
2021-11-19 19:31:56.004665 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 19:31:56.004810 (MainThread): On master: COMMIT
2021-11-19 19:31:56.004901 (MainThread): Using postgres connection "master".
2021-11-19 19:31:56.004986 (MainThread): On master: COMMIT
2021-11-19 19:31:56.005314 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:31:56.005458 (MainThread): On master: Close
2021-11-19 19:31:56.005809 (MainThread): 20:31:55 | Concurrency: 2 threads (target='dev')
2021-11-19 19:31:56.005970 (MainThread): 20:31:55 | 
2021-11-19 19:31:56.008107 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-19 19:31:56.008363 (Thread-1): 20:31:55 | 1 of 5 START incremental model sa_dwh.iss_issuer..................... [RUN]
2021-11-19 19:31:56.008574 (Thread-2): Began running node model.my_new_project.my_first_dbt_model
2021-11-19 19:31:56.008937 (Thread-2): 20:31:55 | 2 of 5 START table model sa.my_first_dbt_model....................... [RUN]
2021-11-19 19:31:56.009471 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:31:56.009825 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:31:56.010060 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-19 19:31:56.010204 (Thread-2): Compiling model.my_new_project.my_first_dbt_model
2021-11-19 19:31:56.014110 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-19 19:31:56.015634 (Thread-2): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 19:31:56.016098 (Thread-1): finished collecting timing info
2021-11-19 19:31:56.021500 (Thread-2): finished collecting timing info
2021-11-19 19:31:56.060557 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 19:31:56.060956 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:31:56.061089 (Thread-2): On model.my_new_project.my_first_dbt_model: BEGIN
2021-11-19 19:31:56.064172 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:31:56.064369 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 19:31:56.064561 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

    

  create temporary table "iss_issuer__dbt_tmp203156054923"
  as (
    

select
     CASE
        WHEN iss.AdjustedEnterpriseValue ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.AdjustedEnterpriseValue::numeric
    ELSE NULL
    END        as adjusted_enterprise_value
    ,iss.ISIN                                               as isin
    ,iss.IssuerName                                         as issuer_name
    ,iss.gicssector                                         as gics_sector
    ,iss.gicsindustrygroup                                  as gics_industry_group
    ,CASE
        WHEN iss.ClimateScope2EmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope2EmissionsIntUSD::numeric
    ELSE NULL
    END   as climate_scope2_emissions_int_usd
    ,CASE
        WHEN iss.ClimateScope1EmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope1EmissionsIntUSD::numeric
    ELSE NULL
    END   as climate_scope1_emissions_int_usd
    ,iss.ClimateScope2Emissions::NUMERIC                    as climate_scope2_emissions
    ,CASE
        WHEN iss.ClimateTotalEmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateTotalEmissionsIntUSD::numeric
    ELSE NULL
    END    as climate_total_emissions_int_usd
    ,iss.ClimateScope3Emissions::NUMERIC                    as climate_scope3_emissions
    ,CASE
        WHEN iss.ClimateCNIEmissionsSource ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateCNIEmissionsSource::numeric
    ELSE NULL
    END      as climate_cni_emissions_source
    ,iss.ClimateTotalEmissions                              as climate_total_emissions
    ,iss.ClimateScope1Emissions::NUMERIC                    as climate_scope1_emissions
    ,CASE
        WHEN iss.MarketCapDaily ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.MarketCapDaily::numeric
    ELSE NULL
    END                 as market_cap_daily
    ,iss.ClimateEmissionsFiscalYear::INT                    as climate_emissions_fiscal_year
    ,'2021-01-01'::DATE                            as meta_file_date
    ,'20211117T164451425627'                                as meta_run_id
    ,CURRENT_TIMESTAMP                                      as meta_insert_timestamp
from "demo_db"."sa"."iss_file" iss
  );
  
2021-11-19 19:31:56.064931 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 19:31:56.072068 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:31:56.072270 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:31:56.072373 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table "demo_db"."sa"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)
,source_case as (

    select 1 as id , 'a' as name
    union all
    select 1 as id , 'b' as name

)

select s.id,n.name
from source_data s
inner join source_case n on n.id = s.id

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-11-19 19:31:56.076697 (Thread-2): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 19:31:56.082235 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:31:56.082463 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "demo_db"."sa"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2021-11-19 19:31:56.083106 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 19:31:56.084873 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:31:56.085003 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "demo_db"."sa"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2021-11-19 19:31:56.085555 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 19:31:56.093334 (Thread-2): On model.my_new_project.my_first_dbt_model: COMMIT
2021-11-19 19:31:56.093486 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:31:56.093618 (Thread-2): On model.my_new_project.my_first_dbt_model: COMMIT
2021-11-19 19:31:56.093793 (Thread-1): SQL status: SELECT 1594 in 0.03 seconds
2021-11-19 19:31:56.100265 (Thread-2): SQL status: COMMIT in 0.01 seconds
2021-11-19 19:31:56.104403 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:31:56.104546 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "demo_db"."sa"."my_first_dbt_model__dbt_backup" cascade
2021-11-19 19:31:56.100097 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:31:56.104731 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-19 19:31:56.105365 (Thread-1): SQL status: BEGIN in 0.00 seconds
2021-11-19 19:31:56.105486 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:31:56.105582 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer__dbt_tmp203156054923'
        
      order by ordinal_position

  
2021-11-19 19:31:56.106915 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-11-19 19:31:56.107838 (Thread-2): finished collecting timing info
2021-11-19 19:31:56.107984 (Thread-2): On model.my_new_project.my_first_dbt_model: Close
2021-11-19 19:31:56.108481 (Thread-2): 20:31:56 | 2 of 5 OK created table model sa.my_first_dbt_model.................. [SELECT 2 in 0.10s]
2021-11-19 19:31:56.108651 (Thread-2): Finished running node model.my_new_project.my_first_dbt_model
2021-11-19 19:31:56.109441 (Thread-2): Began running node model.my_new_project.my_second_dbt_model
2021-11-19 19:31:56.109666 (Thread-2): 20:31:56 | 3 of 5 START view model sa.my_second_dbt_model....................... [RUN]
2021-11-19 19:31:56.110033 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:31:56.110159 (Thread-2): Compiling model.my_new_project.my_second_dbt_model
2021-11-19 19:31:56.112318 (Thread-2): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-19 19:31:56.112682 (Thread-1): SQL status: SELECT 18 in 0.01 seconds
2021-11-19 19:31:56.116748 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:31:56.116894 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-19 19:31:56.117072 (Thread-2): finished collecting timing info
2021-11-19 19:31:56.124591 (Thread-1): SQL status: SELECT 18 in 0.01 seconds
2021-11-19 19:31:56.138564 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:31:56.138747 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "demo_db".INFORMATION_SCHEMA.columns
      where table_name = 'iss_issuer'
        
        and table_schema = 'sa_dwh'
        
      order by ordinal_position

  
2021-11-19 19:31:56.139461 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-19 19:31:56.139719 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:31:56.139819 (Thread-2): On model.my_new_project.my_second_dbt_model: BEGIN
2021-11-19 19:31:56.139919 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 19:31:56.141154 (Thread-1): SQL status: SELECT 18 in 0.00 seconds
2021-11-19 19:31:56.142661 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-19 19:31:56.142887 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:31:56.142988 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      delete
    from "demo_db"."sa_dwh"."iss_issuer"
    where (ISIN) in (
        select (ISIN)
        from "iss_issuer__dbt_tmp203156054923"
    );

    insert into "demo_db"."sa_dwh"."iss_issuer" ("adjusted_enterprise_value", "isin", "issuer_name", "gics_sector", "gics_industry_group", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_cap_daily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp")
    (
       select "adjusted_enterprise_value", "isin", "issuer_name", "gics_sector", "gics_industry_group", "climate_scope2_emissions_int_usd", "climate_scope1_emissions_int_usd", "climate_scope2_emissions", "climate_total_emissions_int_usd", "climate_scope3_emissions", "climate_cni_emissions_source", "climate_total_emissions", "climate_scope1_emissions", "market_cap_daily", "climate_emissions_fiscal_year", "meta_file_date", "meta_run_id", "meta_insert_timestamp"
       from "iss_issuer__dbt_tmp203156054923"
    );
  
2021-11-19 19:31:56.146570 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:31:56.146736 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:31:56.146858 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */

  create view "demo_db"."sa"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."sa"."my_first_dbt_model"
where id = 1
  );

2021-11-19 19:31:56.147022 (Thread-1): SQL status: INSERT 0 1594 in 0.00 seconds
2021-11-19 19:31:56.147966 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 19:31:56.148185 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:31:56.148362 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 19:31:56.148575 (Thread-2): SQL status: CREATE VIEW in 0.00 seconds
2021-11-19 19:31:56.150356 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:31:56.150473 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "demo_db"."sa"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2021-11-19 19:31:56.150933 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 19:31:56.151734 (Thread-2): On model.my_new_project.my_second_dbt_model: COMMIT
2021-11-19 19:31:56.151862 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:31:56.151979 (Thread-2): On model.my_new_project.my_second_dbt_model: COMMIT
2021-11-19 19:31:56.152136 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:31:56.152473 (Thread-1): finished collecting timing info
2021-11-19 19:31:56.152604 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-19 19:31:56.153104 (Thread-1): 20:31:56 | 1 of 5 OK created incremental model sa_dwh.iss_issuer................ [INSERT 0 1594 in 0.14s]
2021-11-19 19:31:56.153265 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:31:56.154411 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:31:56.154544 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "demo_db"."sa"."my_second_dbt_model__dbt_backup" cascade
2021-11-19 19:31:56.154772 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-19 19:31:56.155202 (Thread-2): SQL status: DROP VIEW in 0.00 seconds
2021-11-19 19:31:56.156387 (Thread-2): finished collecting timing info
2021-11-19 19:31:56.156600 (Thread-1): Began running node model.my_new_project.dim_issuer
2021-11-19 19:31:56.156812 (Thread-2): On model.my_new_project.my_second_dbt_model: Close
2021-11-19 19:31:56.157044 (Thread-1): 20:31:56 | 4 of 5 START table model sa_dm.dim_issuer............................ [RUN]
2021-11-19 19:31:56.157532 (Thread-2): 20:31:56 | 3 of 5 OK created view model sa.my_second_dbt_model.................. [CREATE VIEW in 0.05s]
2021-11-19 19:31:56.157853 (Thread-1): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:31:56.158091 (Thread-2): Finished running node model.my_new_project.my_second_dbt_model
2021-11-19 19:31:56.158285 (Thread-1): Compiling model.my_new_project.dim_issuer
2021-11-19 19:31:56.158526 (Thread-2): Began running node model.my_new_project.fct_emissions
2021-11-19 19:31:56.161069 (Thread-1): Writing injected SQL for node "model.my_new_project.dim_issuer"
2021-11-19 19:31:56.161305 (Thread-2): 20:31:56 | 5 of 5 START incremental model sa_dm.fct_emissions................... [RUN]
2021-11-19 19:31:56.161809 (Thread-1): finished collecting timing info
2021-11-19 19:31:56.162168 (Thread-2): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:31:56.163689 (Thread-1): Writing runtime SQL for node "model.my_new_project.dim_issuer"
2021-11-19 19:31:56.163899 (Thread-2): Compiling model.my_new_project.fct_emissions
2021-11-19 19:31:56.167162 (Thread-2): Writing injected SQL for node "model.my_new_project.fct_emissions"
2021-11-19 19:31:56.167399 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:31:56.167680 (Thread-1): On model.my_new_project.dim_issuer: BEGIN
2021-11-19 19:31:56.167811 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 19:31:56.168130 (Thread-2): finished collecting timing info
2021-11-19 19:31:56.170123 (Thread-2): Writing runtime SQL for node "model.my_new_project.fct_emissions"
2021-11-19 19:31:56.170346 (Thread-2): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:31:56.170446 (Thread-2): On model.my_new_project.fct_emissions: BEGIN
2021-11-19 19:31:56.170543 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 19:31:56.173822 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:31:56.173964 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:31:56.174059 (Thread-1): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */


  create  table "demo_db"."sa_dm"."dim_issuer__dbt_tmp"
  as (
    

select distinct
     md5(iss.isin)              as dim_issuer_key
    ,iss.isin                   as isin
    ,iss.issuer_name            as issuer_name
    ,iss.gics_sector            as gics_sector
    ,iss.gics_industry_group    as gics_industry_group
from "demo_db"."sa_dwh"."iss_issuer" iss
  );
2021-11-19 19:31:56.176500 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:31:56.176646 (Thread-2): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:31:56.176801 (Thread-2): On model.my_new_project.fct_emissions: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.fct_emissions"} */

      

  create  table "demo_db"."sa_dm"."fct_emissions"
  as (
    


with cte_fundamental_enterprise_value as (
    select
         iss.isin                                                    as isin
        ,'EnterpriseValue'                                           as fundamental
        ,climate_scope1_emissions / climate_scope1_emissions_int_usd as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

, cte_fundamental_revenue as (
    select
         iss.ISIN                                                    as isin
        ,'Revenue'                                                   as fundamental
        ,adjusted_enterprise_value / 1e6                             as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

, cte_fundamental_market_cap as (
    select
         iss.ISIN                                                    as isin
        ,iss.climate_emissions_fiscal_year
        ,'MarketCap'                                                 as fundamental
        ,market_cap_daily / 1e6                                      as fundamental_value
    from "demo_db"."sa_dwh"."iss_issuer" iss
)

, cte_union_tables as (
    select * from cte_fundamental_enterprise_value

    union

    select * from cte_fundamental_revenue

    union

    select * from cte_fundamental_market_cap
)

select
     md5(isin)                            as fct_emissions_key
    ,md5(isin)                        as dim_issuer_key
    ,fundamental
    ,fundamental_value
    ,'2021-01-01'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from cte_union_tables
  );
  
2021-11-19 19:31:56.177729 (Thread-2): Postgres error: each UNION query must have the same number of columns
LINE 44:     select * from cte_fundamental_market_cap
                    ^

2021-11-19 19:31:56.177860 (Thread-2): On model.my_new_project.fct_emissions: ROLLBACK
2021-11-19 19:31:56.178178 (Thread-2): finished collecting timing info
2021-11-19 19:31:56.178328 (Thread-2): On model.my_new_project.fct_emissions: Close
2021-11-19 19:31:56.178646 (Thread-2): Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
  each UNION query must have the same number of columns
  LINE 44:     select * from cte_fundamental_market_cap
                      ^
  compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: each UNION query must have the same number of columns
LINE 44:     select * from cte_fundamental_market_cap
                    ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/run.py", line 249, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 169, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
  each UNION query must have the same number of columns
  LINE 44:     select * from cte_fundamental_market_cap
                      ^
  compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
2021-11-19 19:31:56.179911 (Thread-2): 20:31:56 | 5 of 5 ERROR creating incremental model sa_dm.fct_emissions.......... [ERROR in 0.02s]
2021-11-19 19:31:56.180072 (Thread-2): Finished running node model.my_new_project.fct_emissions
2021-11-19 19:31:56.180640 (Thread-1): SQL status: SELECT 1594 in 0.01 seconds
2021-11-19 19:31:56.182249 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:31:56.182362 (Thread-1): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer" rename to "dim_issuer__dbt_backup"
2021-11-19 19:31:56.182773 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 19:31:56.184248 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:31:56.184357 (Thread-1): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."sa_dm"."dim_issuer__dbt_tmp" rename to "dim_issuer"
2021-11-19 19:31:56.184686 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 19:31:56.185576 (Thread-1): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 19:31:56.185684 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:31:56.185778 (Thread-1): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 19:31:56.187066 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:31:56.188118 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:31:56.188247 (Thread-1): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
drop table if exists "demo_db"."sa_dm"."dim_issuer__dbt_backup" cascade
2021-11-19 19:31:56.190057 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-11-19 19:31:56.190806 (Thread-1): finished collecting timing info
2021-11-19 19:31:56.190936 (Thread-1): On model.my_new_project.dim_issuer: Close
2021-11-19 19:31:56.191338 (Thread-1): 20:31:56 | 4 of 5 OK created table model sa_dm.dim_issuer....................... [SELECT 1594 in 0.03s]
2021-11-19 19:31:56.191488 (Thread-1): Finished running node model.my_new_project.dim_issuer
2021-11-19 19:31:56.193115 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:31:56.193267 (MainThread): Using postgres connection "master".
2021-11-19 19:31:56.193373 (MainThread): On master: BEGIN
2021-11-19 19:31:56.193473 (MainThread): Opening a new connection, currently in state closed
2021-11-19 19:31:56.199337 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:31:56.199507 (MainThread): On master: COMMIT
2021-11-19 19:31:56.199606 (MainThread): Using postgres connection "master".
2021-11-19 19:31:56.199697 (MainThread): On master: COMMIT
2021-11-19 19:31:56.199927 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:31:56.200041 (MainThread): On master: Close
2021-11-19 19:31:56.200392 (MainThread): 20:31:56 | 
2021-11-19 19:31:56.200539 (MainThread): 20:31:56 | Finished running 2 table models, 2 incremental models, 1 view model in 0.28s.
2021-11-19 19:31:56.200746 (MainThread): Connection 'master' was properly closed.
2021-11-19 19:31:56.200886 (MainThread): Connection 'model.my_new_project.fct_emissions' was properly closed.
2021-11-19 19:31:56.200971 (MainThread): Connection 'model.my_new_project.dim_issuer' was properly closed.
2021-11-19 19:31:56.205062 (MainThread): 
2021-11-19 19:31:56.205211 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 19:31:56.205416 (MainThread): 
2021-11-19 19:31:56.205701 (MainThread): Database Error in model fct_emissions (models/dm_emissions/fct_emissions.sql)
2021-11-19 19:31:56.205827 (MainThread):   each UNION query must have the same number of columns
2021-11-19 19:31:56.205994 (MainThread):   LINE 44:     select * from cte_fundamental_market_cap
2021-11-19 19:31:56.206112 (MainThread):                       ^
2021-11-19 19:31:56.206269 (MainThread):   compiled SQL at target/run/my_new_project/models/dm_emissions/fct_emissions.sql
2021-11-19 19:31:56.206443 (MainThread): 
Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
2021-11-19 19:31:56.206620 (MainThread): Flushing usage events
2021-11-19 19:32:19.921767 (MainThread): Running with dbt=0.21.0
2021-11-19 19:32:19.979614 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 19:32:19.980027 (MainThread): Tracking: do not track
2021-11-19 19:32:19.989787 (MainThread): Partial parsing not enabled
2021-11-19 19:32:19.998089 (MainThread): Parsing macros/generate_schema_name.sql
2021-11-19 19:32:20.000164 (MainThread): Flushing usage events
2021-11-19 19:32:20.000345 (MainThread): Encountered an error:
2021-11-19 19:32:20.000485 (MainThread): Compilation Error
  dbt found two macros named "generate_schema_name" in the project
  "my_new_project".
   To fix this error, rename or remove one of the following macros:
      - macros/generate_schema_name.sql
      - macros/generate_schema_name.sql
2021-11-19 19:32:20.001547 (MainThread): Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 433, in run
    self._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 149, in _runtime_initialize
    super()._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 87, in _runtime_initialize
    self.load_manifest()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 74, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 182, in get_full_manifest
    manifest = loader.load()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 283, in load
    parser.parse_file(block)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/macros.py", line 112, in parse_file
    self.manifest.add_macro(block.file, node)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/contracts/graph/manifest.py", line 971, in add_macro
    raise_compiler_error(msg)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/exceptions.py", line 444, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error
  dbt found two macros named "generate_schema_name" in the project
  "my_new_project".
   To fix this error, rename or remove one of the following macros:
      - macros/generate_schema_name.sql
      - macros/generate_schema_name.sql

2021-11-19 19:37:18.161015 (MainThread): Running with dbt=0.21.0
2021-11-19 19:37:18.214944 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 19:37:18.215350 (MainThread): Tracking: do not track
2021-11-19 19:37:18.229174 (MainThread): Partial parsing not enabled
2021-11-19 19:37:18.236445 (MainThread): Parsing macros/get_custom_schema.sql
2021-11-19 19:37:18.238495 (MainThread): Flushing usage events
2021-11-19 19:37:18.238682 (MainThread): Encountered an error:
2021-11-19 19:37:18.238826 (MainThread): Compilation Error
  dbt found two macros named "generate_schema_name" in the project
  "my_new_project".
   To fix this error, rename or remove one of the following macros:
      - macros/get_custom_schema.sql
      - macros/get_custom_schema.sql
2021-11-19 19:37:18.240003 (MainThread): Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 433, in run
    self._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 149, in _runtime_initialize
    super()._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 87, in _runtime_initialize
    self.load_manifest()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 74, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 182, in get_full_manifest
    manifest = loader.load()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 283, in load
    parser.parse_file(block)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/macros.py", line 112, in parse_file
    self.manifest.add_macro(block.file, node)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/contracts/graph/manifest.py", line 971, in add_macro
    raise_compiler_error(msg)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/exceptions.py", line 444, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error
  dbt found two macros named "generate_schema_name" in the project
  "my_new_project".
   To fix this error, rename or remove one of the following macros:
      - macros/get_custom_schema.sql
      - macros/get_custom_schema.sql

2021-11-19 19:38:13.161092 (MainThread): Running with dbt=0.21.0
2021-11-19 19:38:13.218121 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 19:38:13.218638 (MainThread): Tracking: do not track
2021-11-19 19:38:13.228185 (MainThread): Partial parsing not enabled
2021-11-19 19:38:13.234648 (MainThread): Parsing macros/get_custom_schema.sql
2021-11-19 19:38:13.236922 (MainThread): Flushing usage events
2021-11-19 19:38:13.237129 (MainThread): Encountered an error:
2021-11-19 19:38:13.237271 (MainThread): Compilation Error
  dbt found two macros named "generate_schema_name" in the project
  "my_new_project".
   To fix this error, rename or remove one of the following macros:
      - macros/get_custom_schema.sql
      - macros/get_custom_schema.sql
2021-11-19 19:38:13.238345 (MainThread): Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 433, in run
    self._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 149, in _runtime_initialize
    super()._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 87, in _runtime_initialize
    self.load_manifest()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 74, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 182, in get_full_manifest
    manifest = loader.load()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 283, in load
    parser.parse_file(block)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/macros.py", line 112, in parse_file
    self.manifest.add_macro(block.file, node)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/contracts/graph/manifest.py", line 971, in add_macro
    raise_compiler_error(msg)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/exceptions.py", line 444, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error
  dbt found two macros named "generate_schema_name" in the project
  "my_new_project".
   To fix this error, rename or remove one of the following macros:
      - macros/get_custom_schema.sql
      - macros/get_custom_schema.sql

2021-11-19 19:38:29.864768 (MainThread): Running with dbt=0.21.0
2021-11-19 19:38:29.919237 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 19:38:29.919962 (MainThread): Tracking: do not track
2021-11-19 19:38:29.929643 (MainThread): Partial parsing not enabled
2021-11-19 19:38:29.936258 (MainThread): Parsing macros/get_custom_schema.sql
2021-11-19 19:38:29.936900 (MainThread): Parsing macros/generate_schema_name.sql
2021-11-19 19:38:29.938078 (MainThread): Flushing usage events
2021-11-19 19:38:29.938249 (MainThread): Encountered an error:
2021-11-19 19:38:29.938392 (MainThread): Compilation Error
  dbt found two macros named "generate_schema_name" in the project
  "my_new_project".
   To fix this error, rename or remove one of the following macros:
      - macros/generate_schema_name.sql
      - macros/get_custom_schema.sql
2021-11-19 19:38:29.939573 (MainThread): Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 433, in run
    self._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 149, in _runtime_initialize
    super()._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 87, in _runtime_initialize
    self.load_manifest()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 74, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 182, in get_full_manifest
    manifest = loader.load()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 283, in load
    parser.parse_file(block)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/macros.py", line 112, in parse_file
    self.manifest.add_macro(block.file, node)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/contracts/graph/manifest.py", line 971, in add_macro
    raise_compiler_error(msg)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/exceptions.py", line 444, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error
  dbt found two macros named "generate_schema_name" in the project
  "my_new_project".
   To fix this error, rename or remove one of the following macros:
      - macros/generate_schema_name.sql
      - macros/get_custom_schema.sql

2021-11-19 19:41:09.485875 (MainThread): Running with dbt=0.21.0
2021-11-19 19:41:09.541243 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, full_refresh=False, show=False, threads=None, version_check=True, select=['iss_file'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.seed.SeedTask'>, which='seed', rpc_method='seed')
2021-11-19 19:41:09.541673 (MainThread): Tracking: do not track
2021-11-19 19:41:09.551194 (MainThread): Partial parsing not enabled
2021-11-19 19:41:09.557701 (MainThread): Parsing macros/generate_schema_name.sql
2021-11-19 19:41:09.559722 (MainThread): Flushing usage events
2021-11-19 19:41:09.559895 (MainThread): Encountered an error:
2021-11-19 19:41:09.560036 (MainThread): Compilation Error
  dbt found two macros named "generate_schema_name" in the project
  "my_new_project".
   To fix this error, rename or remove one of the following macros:
      - macros/generate_schema_name.sql
      - macros/generate_schema_name.sql
2021-11-19 19:41:09.561131 (MainThread): Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 433, in run
    self._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 149, in _runtime_initialize
    super()._runtime_initialize()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 87, in _runtime_initialize
    self.load_manifest()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 74, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 182, in get_full_manifest
    manifest = loader.load()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/manifest.py", line 283, in load
    parser.parse_file(block)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/parser/macros.py", line 112, in parse_file
    self.manifest.add_macro(block.file, node)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/contracts/graph/manifest.py", line 971, in add_macro
    raise_compiler_error(msg)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/exceptions.py", line 444, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error
  dbt found two macros named "generate_schema_name" in the project
  "my_new_project".
   To fix this error, rename or remove one of the following macros:
      - macros/generate_schema_name.sql
      - macros/generate_schema_name.sql

2021-11-19 19:41:18.041509 (MainThread): Running with dbt=0.21.0
2021-11-19 19:41:18.099885 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, full_refresh=False, show=False, threads=None, version_check=True, select=['iss_file'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.seed.SeedTask'>, which='seed', rpc_method='seed')
2021-11-19 19:41:18.100308 (MainThread): Tracking: do not track
2021-11-19 19:41:18.110653 (MainThread): Partial parsing not enabled
2021-11-19 19:41:18.117601 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 19:41:18.118318 (MainThread): Parsing macros/adapters.sql
2021-11-19 19:41:18.135574 (MainThread): Parsing macros/catalog.sql
2021-11-19 19:41:18.137236 (MainThread): Parsing macros/relations.sql
2021-11-19 19:41:18.138171 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 19:41:18.139477 (MainThread): Parsing macros/core.sql
2021-11-19 19:41:18.142252 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 19:41:18.182385 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 19:41:18.184244 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 19:41:18.185744 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 19:41:18.186964 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 19:41:18.193501 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 19:41:18.194628 (MainThread): Parsing macros/etc/query.sql
2021-11-19 19:41:18.195417 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 19:41:18.196534 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 19:41:18.203834 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 19:41:18.209113 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 19:41:18.226059 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 19:41:18.227299 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 19:41:18.249148 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 19:41:18.262089 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 19:41:18.276213 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 19:41:18.283891 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 19:41:18.285165 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 19:41:18.295848 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 19:41:18.298838 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 19:41:18.304053 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 19:41:18.309524 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 19:41:18.310593 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 19:41:18.311491 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 19:41:18.312691 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 19:41:18.464504 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:41:18.474600 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:41:18.477319 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:41:18.479751 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.479971 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.480755 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:41:18.484114 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.484333 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.485117 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:41:18.490143 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.490362 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.498172 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.499605 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.501087 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.503374 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.522733 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.524124 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.525477 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.527034 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.541116 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 19:41:18.541417 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 19:41:18.543055 (MainThread): 
2021-11-19 19:41:18.543462 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:41:18.544143 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 19:41:18.551124 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 19:41:18.551232 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 19:41:18.551332 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 19:41:18.558344 (ThreadPoolExecutor-0_0): SQL status: SELECT 21 in 0.01 seconds
2021-11-19 19:41:18.559300 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 19:41:18.559951 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_demo_db_sa_sa".
2021-11-19 19:41:18.560134 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_demo_db_sa_sa".
2021-11-19 19:41:18.560263 (ThreadPoolExecutor-0_0): Creating schema ""demo_db"."sa_sa""
2021-11-19 19:41:18.564182 (ThreadPoolExecutor-0_0): Using postgres connection "create_demo_db_sa_sa".
2021-11-19 19:41:18.564285 (ThreadPoolExecutor-0_0): On create_demo_db_sa_sa: BEGIN
2021-11-19 19:41:18.564377 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-11-19 19:41:18.570618 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:41:18.570772 (ThreadPoolExecutor-0_0): Using postgres connection "create_demo_db_sa_sa".
2021-11-19 19:41:18.570860 (ThreadPoolExecutor-0_0): On create_demo_db_sa_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "create_demo_db_sa_sa"} */
create schema if not exists "sa_sa"
2021-11-19 19:41:18.571478 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.00 seconds
2021-11-19 19:41:18.572184 (ThreadPoolExecutor-0_0): On create_demo_db_sa_sa: COMMIT
2021-11-19 19:41:18.572287 (ThreadPoolExecutor-0_0): Using postgres connection "create_demo_db_sa_sa".
2021-11-19 19:41:18.572376 (ThreadPoolExecutor-0_0): On create_demo_db_sa_sa: COMMIT
2021-11-19 19:41:18.574042 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:41:18.574167 (ThreadPoolExecutor-0_0): On create_demo_db_sa_sa: Close
2021-11-19 19:41:18.575728 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dwh".
2021-11-19 19:41:18.579708 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 19:41:18.579833 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: BEGIN
2021-11-19 19:41:18.579951 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 19:41:18.580631 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa".
2021-11-19 19:41:18.581910 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-19 19:41:18.582238 (ThreadPoolExecutor-1_1): On list_demo_db_sa: BEGIN
2021-11-19 19:41:18.582485 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-19 19:41:18.587682 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:41:18.587853 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dwh".
2021-11-19 19:41:18.587997 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dwh'
  
2021-11-19 19:41:18.589750 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:41:18.589878 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa".
2021-11-19 19:41:18.589968 (ThreadPoolExecutor-1_1): On list_demo_db_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa'
  
2021-11-19 19:41:18.590303 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:41:18.591177 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: ROLLBACK
2021-11-19 19:41:18.591705 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dwh: Close
2021-11-19 19:41:18.591895 (ThreadPoolExecutor-1_1): SQL status: SELECT 3 in 0.00 seconds
2021-11-19 19:41:18.592930 (ThreadPoolExecutor-1_1): On list_demo_db_sa: ROLLBACK
2021-11-19 19:41:18.593572 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_sa_dm".
2021-11-19 19:41:18.593714 (ThreadPoolExecutor-1_1): On list_demo_db_sa: Close
2021-11-19 19:41:18.595433 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 19:41:18.595904 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_sa_sa".
2021-11-19 19:41:18.596109 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: BEGIN
2021-11-19 19:41:18.597316 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_sa".
2021-11-19 19:41:18.597501 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 19:41:18.597673 (ThreadPoolExecutor-1_1): On list_demo_db_sa_sa: BEGIN
2021-11-19 19:41:18.598055 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 19:41:18.604538 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:41:18.604808 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_sa_sa".
2021-11-19 19:41:18.604952 (ThreadPoolExecutor-1_1): On list_demo_db_sa_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_sa'
  
2021-11-19 19:41:18.605156 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:41:18.605330 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_sa_dm".
2021-11-19 19:41:18.605422 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_sa_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'sa_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'sa_dm'
  
2021-11-19 19:41:18.606790 (ThreadPoolExecutor-1_1): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 19:41:18.607690 (ThreadPoolExecutor-1_1): On list_demo_db_sa_sa: ROLLBACK
2021-11-19 19:41:18.607847 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:41:18.608941 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: ROLLBACK
2021-11-19 19:41:18.609186 (ThreadPoolExecutor-1_1): On list_demo_db_sa_sa: Close
2021-11-19 19:41:18.609376 (ThreadPoolExecutor-1_0): On list_demo_db_sa_dm: Close
2021-11-19 19:41:18.612903 (MainThread): Using postgres connection "master".
2021-11-19 19:41:18.613012 (MainThread): On master: BEGIN
2021-11-19 19:41:18.613107 (MainThread): Opening a new connection, currently in state init
2021-11-19 19:41:18.619011 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:41:18.619171 (MainThread): Using postgres connection "master".
2021-11-19 19:41:18.619259 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 19:41:18.623489 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:41:18.624385 (MainThread): On master: ROLLBACK
2021-11-19 19:41:18.624757 (MainThread): Using postgres connection "master".
2021-11-19 19:41:18.624884 (MainThread): On master: BEGIN
2021-11-19 19:41:18.625763 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 19:41:18.625893 (MainThread): On master: COMMIT
2021-11-19 19:41:18.625980 (MainThread): Using postgres connection "master".
2021-11-19 19:41:18.626062 (MainThread): On master: COMMIT
2021-11-19 19:41:18.626469 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:41:18.626582 (MainThread): On master: Close
2021-11-19 19:41:18.626900 (MainThread): 20:41:18 | Concurrency: 2 threads (target='dev')
2021-11-19 19:41:18.627053 (MainThread): 20:41:18 | 
2021-11-19 19:41:18.629669 (Thread-1): Began running node seed.my_new_project.iss_file
2021-11-19 19:41:18.629951 (Thread-1): 20:41:18 | 1 of 1 START seed file sa_sa.iss_file................................ [RUN]
2021-11-19 19:41:18.630298 (Thread-1): Acquiring new postgres connection "seed.my_new_project.iss_file".
2021-11-19 19:41:18.630431 (Thread-1): finished collecting timing info
2021-11-19 19:41:18.949003 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.949310 (Thread-1): * Deprecation Warning: The quote_columns parameter was not set for seeds, so the
default value of False was chosen. The default will change to True in a future
release.

For more information, see:
https://docs.getdbt.com/v0.15/docs/seeds#section-specify-column-quoting
2021-11-19 19:41:18.949642 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.949776 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.949971 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.950097 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.950206 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.952591 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.954684 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.956780 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.959044 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.959194 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.959314 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.959429 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.959546 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.959666 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.959793 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.961846 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.961971 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.962082 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.962196 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.962307 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.962417 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.962527 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.962636 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.962746 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.962856 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.962964 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.963073 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.963182 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.963306 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.963562 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.963674 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.963782 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.963890 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.963998 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.964105 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.964211 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.964317 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.964423 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.964529 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.964635 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.964740 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.964846 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.964952 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.965065 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.965172 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.965286 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.965393 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.965500 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.965606 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.965734 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.965840 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.965946 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.966051 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.966157 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.966261 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.966367 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.966472 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.966576 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.966684 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.966792 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.966900 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.967006 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.967114 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.967219 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.967326 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.967433 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.967539 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.967645 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.967754 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.967896 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.968007 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.968112 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.968220 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.968329 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.968436 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.968543 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.968650 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.968758 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.968866 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.968974 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.969081 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.969186 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.969291 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.969399 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.969506 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.969612 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.969720 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.969826 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.969958 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.970069 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.970174 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.970281 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.970402 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.970512 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.970618 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.970723 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.970831 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.970937 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.971045 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.971151 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.971257 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.971362 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.971508 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.971720 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.971832 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.971939 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.972044 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.972149 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.972254 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.972358 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.972463 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.972568 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.972673 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.972779 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.972884 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.972989 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.973094 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.973200 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.973306 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.973411 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.973515 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.973620 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.973724 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.973829 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.973934 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.974039 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.974144 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.974249 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.974354 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.974459 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.974565 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.974670 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.974774 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.974878 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.974985 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.975090 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.975211 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.975327 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.975432 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.975537 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.975642 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.975747 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.975851 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.978085 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.978225 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.978344 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.978459 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.978572 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.978684 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.978796 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.978907 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.979019 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.979129 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.979239 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.979366 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.979474 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.979583 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.979691 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.979800 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.979926 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.980055 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.980185 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.980296 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.980405 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.980512 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.980626 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.980735 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.980843 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.980951 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.981057 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.981163 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.981283 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.981386 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.981490 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.981596 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.981700 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.981805 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.981910 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.982013 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.982117 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.982224 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.982346 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.982455 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.982560 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.982787 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.982899 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.983007 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.983114 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.983220 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.983339 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.983444 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.983547 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.983650 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.983755 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.983858 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.983962 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.984069 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.984173 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.984278 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.984398 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.984504 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.984629 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.984741 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.984848 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.984954 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.985060 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.985165 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.985281 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.985388 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.985494 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.985600 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.985705 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.985811 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.985916 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.986020 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.986124 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.986229 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.986334 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.986439 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.986544 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.986648 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.986752 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:18.986974 (Thread-1): Using postgres connection "seed.my_new_project.iss_file".
2021-11-19 19:41:18.987068 (Thread-1): On seed.my_new_project.iss_file: BEGIN
2021-11-19 19:41:18.987164 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 19:41:18.993588 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:41:18.993756 (Thread-1): Using postgres connection "seed.my_new_project.iss_file".
2021-11-19 19:41:18.993844 (Thread-1): On seed.my_new_project.iss_file: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "seed.my_new_project.iss_file"} */

    create table "demo_db"."sa_sa"."iss_file" (IssuerName text,ISIN text,GICSSector text,GICSIndustryGroup text,CountryOfIncorporation text,CountryOfOperations text,ClimateScope1Emissions float8,ClimateScope2Emissions float8,ClimateTotalEmissions float8,ClimateScope3Emissions float8,ClimateCNIEmissionsSource text,ClimateEmissionsReportedTrust text,ClimateEmissionsEstimatedTrust text,ClimateScope1EmissionsIntUSD text,ClimateScope2EmissionsIntUSD text,ClimateTotalEmissionsIntUSD text,ClimateAvePeerEmissionsIntUSD float8,MarketCapDaily text,AdjustedEnterpriseValue text,ClimateCarbonBudget2DegExcdYear text,ClimateCarbonBudget4DegExcdYear text,ClimateCarbonBudget6DegExcdYear text,ClimateEmissionsTrajectoryRatio text,ClimateCarbonBudget2DegRatioAve text,ClimateCarbonBudget4DegRatioAve text,ClimateCarbonBudget6DegRatioAve text,ClimateCarbonBudget2Deg text,ClimateCarbonBudget4Deg text,ClimateCarbonBudget6Deg text,ClimateCarbonBudget2Deg2020 text,ClimateCarbonBudget2Deg2021 text,ClimateCarbonBudget2Deg2022 text,ClimateCarbonBudget2Deg2023 text,ClimateCarbonBudget2Deg2024 text,ClimateCarbonBudget2Deg2025 text,ClimateCarbonBudget2Deg2026 text,ClimateCarbonBudget2Deg2027 text,ClimateCarbonBudget2Deg2028 text,ClimateCarbonBudget2Deg2029 text,ClimateCarbonBudget2Deg2030 text,ClimateCarbonBudget2Deg2031 text,ClimateCarbonBudget2Deg2032 text,ClimateCarbonBudget2Deg2033 text,ClimateCarbonBudget2Deg2034 text,ClimateCarbonBudget2Deg2035 text,ClimateCarbonBudget2Deg2036 text,ClimateCarbonBudget2Deg2037 text,ClimateCarbonBudget2Deg2038 text,ClimateCarbonBudget2Deg2039 text,ClimateCarbonBudget2Deg2040 text,ClimateCarbonBudget2Deg2041 text,ClimateCarbonBudget2Deg2042 text,ClimateCarbonBudget2Deg2043 text,ClimateCarbonBudget2Deg2044 text,ClimateCarbonBudget2Deg2045 text,ClimateCarbonBudget2Deg2046 text,ClimateCarbonBudget2Deg2047 text,ClimateCarbonBudget2Deg2048 text,ClimateCarbonBudget2Deg2049 text,ClimateCarbonBudget2Deg2050 text,ClimateCarbonBudget4Deg2020 text,ClimateCarbonBudget4Deg2021 text,ClimateCarbonBudget4Deg2022 text,ClimateCarbonBudget4Deg2023 text,ClimateCarbonBudget4Deg2024 text,ClimateCarbonBudget4Deg2025 text,ClimateCarbonBudget4Deg2026 text,ClimateCarbonBudget4Deg2027 text,ClimateCarbonBudget4Deg2028 text,ClimateCarbonBudget4Deg2029 text,ClimateCarbonBudget4Deg2030 text,ClimateCarbonBudget4Deg2031 text,ClimateCarbonBudget4Deg2032 text,ClimateCarbonBudget4Deg2033 text,ClimateCarbonBudget4Deg2034 text,ClimateCarbonBudget4Deg2035 text,ClimateCarbonBudget4Deg2036 text,ClimateCarbonBudget4Deg2037 text,ClimateCarbonBudget4Deg2038 text,ClimateCarbonBudget4Deg2039 text,ClimateCarbonBudget4Deg2040 text,ClimateCarbonBudget4Deg2041 text,ClimateCarbonBudget4Deg2042 text,ClimateCarbonBudget4Deg2043 text,ClimateCarbonBudget4Deg2044 text,ClimateCarbonBudget4Deg2045 text,ClimateCarbonBudget4Deg2046 text,ClimateCarbonBudget4Deg2047 text,ClimateCarbonBudget4Deg2048 text,ClimateCarbonBudget4Deg2049 text,ClimateCarbonBudget4Deg2050 text,ClimateCarbonBudget6Deg2020 text,ClimateCarbonBudget6Deg2021 text,ClimateCarbonBudget6Deg2022 text,ClimateCarbonBudget6Deg2023 text,ClimateCarbonBudget6Deg2024 text,ClimateCarbonBudget6Deg2025 text,ClimateCarbonBudget6Deg2026 text,ClimateCarbonBudget6Deg2027 text,ClimateCarbonBudget6Deg2028 text,ClimateCarbonBudget6Deg2029 text,ClimateCarbonBudget6Deg2030 text,ClimateCarbonBudget6Deg2031 text,ClimateCarbonBudget6Deg2032 text,ClimateCarbonBudget6Deg2033 text,ClimateCarbonBudget6Deg2034 text,ClimateCarbonBudget6Deg2035 text,ClimateCarbonBudget6Deg2036 text,ClimateCarbonBudget6Deg2037 text,ClimateCarbonBudget6Deg2038 text,ClimateCarbonBudget6Deg2039 text,ClimateCarbonBudget6Deg2040 text,ClimateCarbonBudget6Deg2041 text,ClimateCarbonBudget6Deg2042 text,ClimateCarbonBudget6Deg2043 text,ClimateCarbonBudget6Deg2044 text,ClimateCarbonBudget6Deg2045 text,ClimateCarbonBudget6Deg2046 text,ClimateCarbonBudget6Deg2047 text,ClimateCarbonBudget6Deg2048 text,ClimateCarbonBudget6Deg2049 text,ClimateCarbonBudget6Deg2050 text,PAETechTypes text,PAETotalPAEPerYear text,PAETotalSold text,PAEBiomassSold text,PAEBiomassPAEPerYear text,PAEBiomassPAGEPerYear text,PAEGeothermalSold text,PAEGeothermalPAEPerYear text,PAEGeothermalPAGEPerYear text,PAEHydroSold text,PAEHydroPAEPerYear text,PAEHydroPAGEPerYear text,PAESolarCSPSold text,PAESolarPVSold text,PAESolarPAEPerYear text,PAESolarCSPPAGEPerYear text,PAESolarPVPAGEPerYear text,PAEOnshoreWindSold text,PAEOffshoreWindSold text,PAEWindPAEPerYear text,PAEWindPAGEPerYear text,PAEWindSold text,ClimateEmissionsFiscalYear integer,ClimateScienceBasedTargets text,ClimateTemperatureScore text,ClimateGHGReductionTargets text,ClimateEmissionsTrajectoryRatioSDS text,ClimateCarbonBudgetSDSDegExcdYear text,ClimateCarbonBudgetSDSRatioAve text,ClimateCarbonBudgetSDS text,ClimateCarbonBudgetSDS2019 text,ClimateCarbonBudgetSDS2020 text,ClimateCarbonBudgetSDS2021 text,ClimateCarbonBudgetSDS2022 text,ClimateCarbonBudgetSDS2023 text,ClimateCarbonBudgetSDS2024 text,ClimateCarbonBudgetSDS2025 text,ClimateCarbonBudgetSDS2026 text,ClimateCarbonBudgetSDS2027 text,ClimateCarbonBudgetSDS2028 text,ClimateCarbonBudgetSDS2029 text,ClimateCarbonBudgetSDS2030 text,ClimateCarbonBudgetSDS2031 text,ClimateCarbonBudgetSDS2032 text,ClimateCarbonBudgetSDS2033 text,ClimateCarbonBudgetSDS2034 text,ClimateCarbonBudgetSDS2035 text,ClimateCarbonBudgetSDS2036 text,ClimateCarbonBudgetSDS2037 text,ClimateCarbonBudgetSDS2038 text,ClimateCarbonBudgetSDS2039 text,ClimateCarbonBudgetSDS2040 text,ClimateCarbonBudgetSDS2041 text,ClimateCarbonBudgetSDS2042 text,ClimateCarbonBudgetSDS2043 text,ClimateCarbonBudgetSDS2044 text,ClimateCarbonBudgetSDS2045 text,ClimateCarbonBudgetSDS2046 text,ClimateCarbonBudgetSDS2047 text,ClimateCarbonBudgetSDS2048 text,ClimateCarbonBudgetSDS2049 text,ClimateCarbonBudgetSDS2050 text,ClimateCarbonBudgetSDSPCT text,ClimateCarbonBudgetSDSPCT2019 text,ClimateCarbonBudgetSDSPCT2020 text,ClimateCarbonBudgetSDSPCT2021 text,ClimateCarbonBudgetSDSPCT2022 text,ClimateCarbonBudgetSDSPCT2023 text,ClimateCarbonBudgetSDSPCT2024 text,ClimateCarbonBudgetSDSPCT2025 text,ClimateCarbonBudgetSDSPCT2026 text,ClimateCarbonBudgetSDSPCT2027 text,ClimateCarbonBudgetSDSPCT2028 text,ClimateCarbonBudgetSDSPCT2029 text,ClimateCarbonBudgetSDSPCT2030 text,ClimateCarbonBudgetSDSPCT2031 text,ClimateCarbonBudgetSDSPCT2032 text,ClimateCarbonBudgetSDSPCT2033 text,ClimateCarbonBudgetSDSPCT2034 text,ClimateCarbonBudgetSDSPCT2035 text,ClimateCarbonBudgetSDSPCT2036 text,ClimateCarbonBudgetSDSPCT2037 text,ClimateCarbonBudgetSDSPCT2038 text,ClimateCarbonBudgetSDSPCT2039 text,ClimateCarbonBudgetSDSPCT2040 text,ClimateCarbonBudgetSDSPCT2041 text,ClimateCarbonBudgetSDSPCT2042 text,ClimateCarbonBudgetSDSPCT2043 text,ClimateCarbonBudgetSDSPCT2044 text,ClimateCarbonBudgetSDSPCT2045 text,ClimateCarbonBudgetSDSPCT2046 text,ClimateCarbonBudgetSDSPCT2047 text,ClimateCarbonBudgetSDSPCT2048 text,ClimateCarbonBudgetSDSPCT2049 text,ClimateCarbonBudgetSDSPCT2050 text,ClimateCarbonBudgetSDSModelType text,ClimateDSGovernanceAlignment text,ClimateDSMandTAlignment text,ClimateDSOverallAlignment text,ClimateDSRiskMgmtAlignment text,ClimateDSStrategyAlignment text)
  
2021-11-19 19:41:19.003325 (Thread-1): SQL status: CREATE TABLE in 0.01 seconds
2021-11-19 19:41:40.976939 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:41:40.977152 (MainThread): Cancelling query 'seed.my_new_project.iss_file' (1118)
2021-11-19 19:41:40.977304 (MainThread): Using postgres connection "master".
2021-11-19 19:41:40.977465 (MainThread): On master: BEGIN
2021-11-19 19:41:40.977583 (MainThread): Opening a new connection, currently in state closed
2021-11-19 19:41:40.999592 (MainThread): SQL status: BEGIN in 0.02 seconds
2021-11-19 19:41:40.999756 (MainThread): Using postgres connection "master".
2021-11-19 19:41:40.999868 (MainThread): On master: select pg_terminate_backend(1118)
2021-11-19 19:41:41.007945 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-11-19 19:41:41.008109 (MainThread): Cancel query 'seed.my_new_project.iss_file': (True,)
2021-11-19 19:41:41.008260 (MainThread): 20:41:40 | CANCEL query seed.my_new_project.iss_file............................ [CANCEL]
2021-11-19 19:41:41.008408 (MainThread): 20:41:40 | CANCEL query list_demo_db_sa_sa...................................... [CANCEL]
2021-11-19 19:41:41.008616 (MainThread): On master: ROLLBACK
2021-11-19 19:41:41.014580 (MainThread): On master: Close
2021-11-19 19:41:42.824784 (MainThread): Connection 'master' was properly closed.
2021-11-19 19:41:42.824989 (MainThread): Connection 'seed.my_new_project.iss_file' was left open.
2021-11-19 19:41:42.825115 (MainThread): On seed.my_new_project.iss_file: ROLLBACK
2021-11-19 19:41:42.835630 (MainThread): Failed to rollback seed.my_new_project.iss_file
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 366, in execute_nodes
    self.run_queue(pool)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 291, in run_queue
    self.job_queue.join()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/graph/queue.py", line 197, in join
    self.inner.join()
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/queue.py", line 90, in join
    self.all_tasks_done.wait()
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/threading.py", line 312, in wait
    waiter.acquire()
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 411, in execute_with_hooks
    res = self.execute_nodes()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 374, in execute_nodes
    self._cancel_connections(pool)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/runnable.py", line 351, in _cancel_connections
    pool.join()
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/multiprocessing/pool.py", line 666, in join
    p.join()
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/threading.py", line 1033, in join
    self._wait_for_tstate_lock()
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/threading.py", line 1049, in _wait_for_tstate_lock
    elif lock.acquire(block, timeout):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/connections.py", line 221, in _rollback_handle
    connection.handle.rollback()
psycopg2.OperationalError: terminating connection due to administrator command
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.
2021-11-19 19:41:42.903479 (MainThread): On seed.my_new_project.iss_file: Close
2021-11-19 19:41:42.903634 (MainThread): Connection 'list_demo_db_sa_sa' was properly closed.
2021-11-19 19:41:42.903764 (MainThread): Flushing usage events
2021-11-19 19:41:42.903921 (MainThread): ctrl-c
2021-11-19 19:41:45.841744 (MainThread): Running with dbt=0.21.0
2021-11-19 19:41:45.899428 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, full_refresh=False, show=False, threads=None, version_check=True, select=['iss_file'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.seed.SeedTask'>, which='seed', rpc_method='seed')
2021-11-19 19:41:45.899876 (MainThread): Tracking: do not track
2021-11-19 19:41:45.909852 (MainThread): Partial parsing not enabled
2021-11-19 19:41:45.916425 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 19:41:45.917080 (MainThread): Parsing macros/adapters.sql
2021-11-19 19:41:45.935652 (MainThread): Parsing macros/catalog.sql
2021-11-19 19:41:45.937442 (MainThread): Parsing macros/relations.sql
2021-11-19 19:41:45.938449 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 19:41:45.939782 (MainThread): Parsing macros/core.sql
2021-11-19 19:41:45.943021 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 19:41:45.987050 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 19:41:45.989178 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 19:41:45.990609 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 19:41:45.991951 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 19:41:45.998871 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 19:41:46.000061 (MainThread): Parsing macros/etc/query.sql
2021-11-19 19:41:46.000844 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 19:41:46.002020 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 19:41:46.010061 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 19:41:46.015641 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 19:41:46.034065 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 19:41:46.035488 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 19:41:46.061431 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 19:41:46.075859 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 19:41:46.091695 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 19:41:46.100083 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 19:41:46.101531 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 19:41:46.113035 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 19:41:46.116639 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 19:41:46.122991 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 19:41:46.129254 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 19:41:46.130426 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 19:41:46.131538 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 19:41:46.133085 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 19:41:46.302071 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:41:46.313072 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:41:46.315916 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:41:46.318670 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.318886 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.319842 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:41:46.323282 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.323497 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.324344 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:41:46.329272 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.329490 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.338194 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.339838 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.341458 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.343850 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.363711 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.365275 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.366819 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.368423 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.383651 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 19:41:46.384061 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 19:41:46.385278 (MainThread): 
2021-11-19 19:41:46.385544 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:41:46.386127 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 19:41:46.393839 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 19:41:46.393988 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 19:41:46.394097 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 19:41:46.400983 (ThreadPoolExecutor-0_0): SQL status: SELECT 22 in 0.01 seconds
2021-11-19 19:41:46.401934 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 19:41:46.402731 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_demo_db_dev_sa".
2021-11-19 19:41:46.402993 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_demo_db_dev_sa".
2021-11-19 19:41:46.403143 (ThreadPoolExecutor-0_0): Creating schema ""demo_db"."dev_sa""
2021-11-19 19:41:46.407457 (ThreadPoolExecutor-0_0): Using postgres connection "create_demo_db_dev_sa".
2021-11-19 19:41:46.407599 (ThreadPoolExecutor-0_0): On create_demo_db_dev_sa: BEGIN
2021-11-19 19:41:46.407698 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-11-19 19:41:46.414104 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:41:46.414387 (ThreadPoolExecutor-0_0): Using postgres connection "create_demo_db_dev_sa".
2021-11-19 19:41:46.414552 (ThreadPoolExecutor-0_0): On create_demo_db_dev_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "create_demo_db_dev_sa"} */
create schema if not exists "dev_sa"
2021-11-19 19:41:46.415064 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.00 seconds
2021-11-19 19:41:46.415735 (ThreadPoolExecutor-0_0): On create_demo_db_dev_sa: COMMIT
2021-11-19 19:41:46.415837 (ThreadPoolExecutor-0_0): Using postgres connection "create_demo_db_dev_sa".
2021-11-19 19:41:46.415923 (ThreadPoolExecutor-0_0): On create_demo_db_dev_sa: COMMIT
2021-11-19 19:41:46.417414 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:41:46.417555 (ThreadPoolExecutor-0_0): On create_demo_db_dev_sa: Close
2021-11-19 19:41:46.418847 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev_sa".
2021-11-19 19:41:46.419242 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:41:46.424043 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 19:41:46.425193 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:41:46.425501 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: BEGIN
2021-11-19 19:41:46.425682 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: BEGIN
2021-11-19 19:41:46.425895 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 19:41:46.426070 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-19 19:41:46.432370 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:41:46.432613 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:41:46.432768 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dwh'
  
2021-11-19 19:41:46.433036 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:41:46.433157 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 19:41:46.433250 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_sa'
  
2021-11-19 19:41:46.434326 (ThreadPoolExecutor-1_1): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 19:41:46.435371 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: ROLLBACK
2021-11-19 19:41:46.435569 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 19:41:46.436431 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: ROLLBACK
2021-11-19 19:41:46.436578 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: Close
2021-11-19 19:41:46.437143 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev_dm".
2021-11-19 19:41:46.437350 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: Close
2021-11-19 19:41:46.438974 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 19:41:46.439247 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: BEGIN
2021-11-19 19:41:46.439635 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev".
2021-11-19 19:41:46.439803 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 19:41:46.440867 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev".
2021-11-19 19:41:46.441254 (ThreadPoolExecutor-1_0): On list_demo_db_dev: BEGIN
2021-11-19 19:41:46.441370 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 19:41:46.446885 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:41:46.447114 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 19:41:46.447251 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dm'
  
2021-11-19 19:41:46.447414 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:41:46.447610 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev".
2021-11-19 19:41:46.447710 (ThreadPoolExecutor-1_0): On list_demo_db_dev: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev'
  
2021-11-19 19:41:46.448996 (ThreadPoolExecutor-1_1): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 19:41:46.449983 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: ROLLBACK
2021-11-19 19:41:46.450170 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 19:41:46.451009 (ThreadPoolExecutor-1_0): On list_demo_db_dev: ROLLBACK
2021-11-19 19:41:46.451161 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: Close
2021-11-19 19:41:46.451542 (ThreadPoolExecutor-1_0): On list_demo_db_dev: Close
2021-11-19 19:41:46.454959 (MainThread): Using postgres connection "master".
2021-11-19 19:41:46.455092 (MainThread): On master: BEGIN
2021-11-19 19:41:46.455199 (MainThread): Opening a new connection, currently in state init
2021-11-19 19:41:46.460611 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:41:46.460745 (MainThread): Using postgres connection "master".
2021-11-19 19:41:46.460842 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 19:41:46.465005 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:41:46.465921 (MainThread): On master: ROLLBACK
2021-11-19 19:41:46.466305 (MainThread): Using postgres connection "master".
2021-11-19 19:41:46.466437 (MainThread): On master: BEGIN
2021-11-19 19:41:46.466864 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 19:41:46.466994 (MainThread): On master: COMMIT
2021-11-19 19:41:46.467088 (MainThread): Using postgres connection "master".
2021-11-19 19:41:46.467177 (MainThread): On master: COMMIT
2021-11-19 19:41:46.467413 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:41:46.467525 (MainThread): On master: Close
2021-11-19 19:41:46.467799 (MainThread): 20:41:46 | Concurrency: 2 threads (target='dev')
2021-11-19 19:41:46.467950 (MainThread): 20:41:46 | 
2021-11-19 19:41:46.469712 (Thread-1): Began running node seed.my_new_project.iss_file
2021-11-19 19:41:46.469997 (Thread-1): 20:41:46 | 1 of 1 START seed file dev_sa.iss_file............................... [RUN]
2021-11-19 19:41:46.470286 (Thread-1): Acquiring new postgres connection "seed.my_new_project.iss_file".
2021-11-19 19:41:46.470418 (Thread-1): finished collecting timing info
2021-11-19 19:41:46.812152 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.812468 (Thread-1): * Deprecation Warning: The quote_columns parameter was not set for seeds, so the
default value of False was chosen. The default will change to True in a future
release.

For more information, see:
https://docs.getdbt.com/v0.15/docs/seeds#section-specify-column-quoting
2021-11-19 19:41:46.812657 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.812788 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.812908 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.813027 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.813144 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.815746 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.817978 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.820234 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.822601 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.822744 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.822875 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.823003 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.823128 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.823265 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.823383 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.825666 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.825803 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.825927 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.826047 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.826169 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.826298 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.826419 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.826538 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.826655 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.826774 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.826892 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.827009 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.827128 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.827246 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.827529 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.827651 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.827773 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.827892 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.828009 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.828127 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.828243 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.828360 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.828475 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.828591 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.828730 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.828849 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.828967 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.829108 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.829241 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.829353 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.829464 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.829576 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.829687 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.829797 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.829908 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.830025 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.830139 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.830252 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.830364 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.830501 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.830618 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.830731 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.830842 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.830953 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.831063 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.831176 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.831306 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.831420 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.831532 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.831830 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.832007 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.832151 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.832294 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.832409 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.832521 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.832634 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.832748 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.832860 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.832974 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.833088 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.833236 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.833355 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.833473 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.833589 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.833704 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.833817 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.833943 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.834058 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.834171 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.834301 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.834415 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.834526 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.834636 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.834747 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.834858 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.834968 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.835081 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.835194 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.835338 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.835454 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.835567 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.835680 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.835796 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.835910 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.836025 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.836142 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.836260 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.836375 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.836615 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.836732 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.836848 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.836963 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.837076 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.837189 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.837302 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.837415 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.837530 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.837647 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.837762 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.837875 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.837987 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.838100 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.838212 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.838325 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.838438 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.838550 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.838662 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.838776 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.838891 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.839004 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.839117 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.839232 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.839347 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.839460 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.839573 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.839686 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.839839 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.839958 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.840072 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.840188 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.840301 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.840416 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.840531 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.840646 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.840759 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.840897 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.841011 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.841128 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.843447 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.843583 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.843705 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.843824 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.843942 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.844059 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.844175 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.844303 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.844417 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.844530 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.844643 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.844758 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.844874 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.844988 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.845102 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.845217 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.845371 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.845487 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.845600 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.845714 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.845828 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.845942 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.846058 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.846171 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.846284 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.846398 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.846511 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.846623 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.846735 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.846848 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.846965 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.847078 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.847192 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.847305 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.847416 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.847529 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.847643 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.847757 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.847870 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.847985 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.848099 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.848339 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.848476 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.848594 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.848709 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.848821 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.849025 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.849143 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.849257 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.849371 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.849484 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.849596 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.849707 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.849819 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.849964 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.850103 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.850219 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.850332 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.850445 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.850557 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.850674 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.850787 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.850901 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.851013 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.851125 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.851237 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.851349 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.851461 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.851573 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.851685 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.851797 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.851907 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.852019 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.852172 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.852290 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.852404 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.852515 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.852626 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.852736 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:41:46.852974 (Thread-1): Using postgres connection "seed.my_new_project.iss_file".
2021-11-19 19:41:46.853074 (Thread-1): On seed.my_new_project.iss_file: BEGIN
2021-11-19 19:41:46.853175 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 19:41:46.859471 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:41:46.859721 (Thread-1): Using postgres connection "seed.my_new_project.iss_file".
2021-11-19 19:41:46.859808 (Thread-1): On seed.my_new_project.iss_file: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "seed.my_new_project.iss_file"} */

    create table "demo_db"."dev_sa"."iss_file" (IssuerName text,ISIN text,GICSSector text,GICSIndustryGroup text,CountryOfIncorporation text,CountryOfOperations text,ClimateScope1Emissions float8,ClimateScope2Emissions float8,ClimateTotalEmissions float8,ClimateScope3Emissions float8,ClimateCNIEmissionsSource text,ClimateEmissionsReportedTrust text,ClimateEmissionsEstimatedTrust text,ClimateScope1EmissionsIntUSD text,ClimateScope2EmissionsIntUSD text,ClimateTotalEmissionsIntUSD text,ClimateAvePeerEmissionsIntUSD float8,MarketCapDaily text,AdjustedEnterpriseValue text,ClimateCarbonBudget2DegExcdYear text,ClimateCarbonBudget4DegExcdYear text,ClimateCarbonBudget6DegExcdYear text,ClimateEmissionsTrajectoryRatio text,ClimateCarbonBudget2DegRatioAve text,ClimateCarbonBudget4DegRatioAve text,ClimateCarbonBudget6DegRatioAve text,ClimateCarbonBudget2Deg text,ClimateCarbonBudget4Deg text,ClimateCarbonBudget6Deg text,ClimateCarbonBudget2Deg2020 text,ClimateCarbonBudget2Deg2021 text,ClimateCarbonBudget2Deg2022 text,ClimateCarbonBudget2Deg2023 text,ClimateCarbonBudget2Deg2024 text,ClimateCarbonBudget2Deg2025 text,ClimateCarbonBudget2Deg2026 text,ClimateCarbonBudget2Deg2027 text,ClimateCarbonBudget2Deg2028 text,ClimateCarbonBudget2Deg2029 text,ClimateCarbonBudget2Deg2030 text,ClimateCarbonBudget2Deg2031 text,ClimateCarbonBudget2Deg2032 text,ClimateCarbonBudget2Deg2033 text,ClimateCarbonBudget2Deg2034 text,ClimateCarbonBudget2Deg2035 text,ClimateCarbonBudget2Deg2036 text,ClimateCarbonBudget2Deg2037 text,ClimateCarbonBudget2Deg2038 text,ClimateCarbonBudget2Deg2039 text,ClimateCarbonBudget2Deg2040 text,ClimateCarbonBudget2Deg2041 text,ClimateCarbonBudget2Deg2042 text,ClimateCarbonBudget2Deg2043 text,ClimateCarbonBudget2Deg2044 text,ClimateCarbonBudget2Deg2045 text,ClimateCarbonBudget2Deg2046 text,ClimateCarbonBudget2Deg2047 text,ClimateCarbonBudget2Deg2048 text,ClimateCarbonBudget2Deg2049 text,ClimateCarbonBudget2Deg2050 text,ClimateCarbonBudget4Deg2020 text,ClimateCarbonBudget4Deg2021 text,ClimateCarbonBudget4Deg2022 text,ClimateCarbonBudget4Deg2023 text,ClimateCarbonBudget4Deg2024 text,ClimateCarbonBudget4Deg2025 text,ClimateCarbonBudget4Deg2026 text,ClimateCarbonBudget4Deg2027 text,ClimateCarbonBudget4Deg2028 text,ClimateCarbonBudget4Deg2029 text,ClimateCarbonBudget4Deg2030 text,ClimateCarbonBudget4Deg2031 text,ClimateCarbonBudget4Deg2032 text,ClimateCarbonBudget4Deg2033 text,ClimateCarbonBudget4Deg2034 text,ClimateCarbonBudget4Deg2035 text,ClimateCarbonBudget4Deg2036 text,ClimateCarbonBudget4Deg2037 text,ClimateCarbonBudget4Deg2038 text,ClimateCarbonBudget4Deg2039 text,ClimateCarbonBudget4Deg2040 text,ClimateCarbonBudget4Deg2041 text,ClimateCarbonBudget4Deg2042 text,ClimateCarbonBudget4Deg2043 text,ClimateCarbonBudget4Deg2044 text,ClimateCarbonBudget4Deg2045 text,ClimateCarbonBudget4Deg2046 text,ClimateCarbonBudget4Deg2047 text,ClimateCarbonBudget4Deg2048 text,ClimateCarbonBudget4Deg2049 text,ClimateCarbonBudget4Deg2050 text,ClimateCarbonBudget6Deg2020 text,ClimateCarbonBudget6Deg2021 text,ClimateCarbonBudget6Deg2022 text,ClimateCarbonBudget6Deg2023 text,ClimateCarbonBudget6Deg2024 text,ClimateCarbonBudget6Deg2025 text,ClimateCarbonBudget6Deg2026 text,ClimateCarbonBudget6Deg2027 text,ClimateCarbonBudget6Deg2028 text,ClimateCarbonBudget6Deg2029 text,ClimateCarbonBudget6Deg2030 text,ClimateCarbonBudget6Deg2031 text,ClimateCarbonBudget6Deg2032 text,ClimateCarbonBudget6Deg2033 text,ClimateCarbonBudget6Deg2034 text,ClimateCarbonBudget6Deg2035 text,ClimateCarbonBudget6Deg2036 text,ClimateCarbonBudget6Deg2037 text,ClimateCarbonBudget6Deg2038 text,ClimateCarbonBudget6Deg2039 text,ClimateCarbonBudget6Deg2040 text,ClimateCarbonBudget6Deg2041 text,ClimateCarbonBudget6Deg2042 text,ClimateCarbonBudget6Deg2043 text,ClimateCarbonBudget6Deg2044 text,ClimateCarbonBudget6Deg2045 text,ClimateCarbonBudget6Deg2046 text,ClimateCarbonBudget6Deg2047 text,ClimateCarbonBudget6Deg2048 text,ClimateCarbonBudget6Deg2049 text,ClimateCarbonBudget6Deg2050 text,PAETechTypes text,PAETotalPAEPerYear text,PAETotalSold text,PAEBiomassSold text,PAEBiomassPAEPerYear text,PAEBiomassPAGEPerYear text,PAEGeothermalSold text,PAEGeothermalPAEPerYear text,PAEGeothermalPAGEPerYear text,PAEHydroSold text,PAEHydroPAEPerYear text,PAEHydroPAGEPerYear text,PAESolarCSPSold text,PAESolarPVSold text,PAESolarPAEPerYear text,PAESolarCSPPAGEPerYear text,PAESolarPVPAGEPerYear text,PAEOnshoreWindSold text,PAEOffshoreWindSold text,PAEWindPAEPerYear text,PAEWindPAGEPerYear text,PAEWindSold text,ClimateEmissionsFiscalYear integer,ClimateScienceBasedTargets text,ClimateTemperatureScore text,ClimateGHGReductionTargets text,ClimateEmissionsTrajectoryRatioSDS text,ClimateCarbonBudgetSDSDegExcdYear text,ClimateCarbonBudgetSDSRatioAve text,ClimateCarbonBudgetSDS text,ClimateCarbonBudgetSDS2019 text,ClimateCarbonBudgetSDS2020 text,ClimateCarbonBudgetSDS2021 text,ClimateCarbonBudgetSDS2022 text,ClimateCarbonBudgetSDS2023 text,ClimateCarbonBudgetSDS2024 text,ClimateCarbonBudgetSDS2025 text,ClimateCarbonBudgetSDS2026 text,ClimateCarbonBudgetSDS2027 text,ClimateCarbonBudgetSDS2028 text,ClimateCarbonBudgetSDS2029 text,ClimateCarbonBudgetSDS2030 text,ClimateCarbonBudgetSDS2031 text,ClimateCarbonBudgetSDS2032 text,ClimateCarbonBudgetSDS2033 text,ClimateCarbonBudgetSDS2034 text,ClimateCarbonBudgetSDS2035 text,ClimateCarbonBudgetSDS2036 text,ClimateCarbonBudgetSDS2037 text,ClimateCarbonBudgetSDS2038 text,ClimateCarbonBudgetSDS2039 text,ClimateCarbonBudgetSDS2040 text,ClimateCarbonBudgetSDS2041 text,ClimateCarbonBudgetSDS2042 text,ClimateCarbonBudgetSDS2043 text,ClimateCarbonBudgetSDS2044 text,ClimateCarbonBudgetSDS2045 text,ClimateCarbonBudgetSDS2046 text,ClimateCarbonBudgetSDS2047 text,ClimateCarbonBudgetSDS2048 text,ClimateCarbonBudgetSDS2049 text,ClimateCarbonBudgetSDS2050 text,ClimateCarbonBudgetSDSPCT text,ClimateCarbonBudgetSDSPCT2019 text,ClimateCarbonBudgetSDSPCT2020 text,ClimateCarbonBudgetSDSPCT2021 text,ClimateCarbonBudgetSDSPCT2022 text,ClimateCarbonBudgetSDSPCT2023 text,ClimateCarbonBudgetSDSPCT2024 text,ClimateCarbonBudgetSDSPCT2025 text,ClimateCarbonBudgetSDSPCT2026 text,ClimateCarbonBudgetSDSPCT2027 text,ClimateCarbonBudgetSDSPCT2028 text,ClimateCarbonBudgetSDSPCT2029 text,ClimateCarbonBudgetSDSPCT2030 text,ClimateCarbonBudgetSDSPCT2031 text,ClimateCarbonBudgetSDSPCT2032 text,ClimateCarbonBudgetSDSPCT2033 text,ClimateCarbonBudgetSDSPCT2034 text,ClimateCarbonBudgetSDSPCT2035 text,ClimateCarbonBudgetSDSPCT2036 text,ClimateCarbonBudgetSDSPCT2037 text,ClimateCarbonBudgetSDSPCT2038 text,ClimateCarbonBudgetSDSPCT2039 text,ClimateCarbonBudgetSDSPCT2040 text,ClimateCarbonBudgetSDSPCT2041 text,ClimateCarbonBudgetSDSPCT2042 text,ClimateCarbonBudgetSDSPCT2043 text,ClimateCarbonBudgetSDSPCT2044 text,ClimateCarbonBudgetSDSPCT2045 text,ClimateCarbonBudgetSDSPCT2046 text,ClimateCarbonBudgetSDSPCT2047 text,ClimateCarbonBudgetSDSPCT2048 text,ClimateCarbonBudgetSDSPCT2049 text,ClimateCarbonBudgetSDSPCT2050 text,ClimateCarbonBudgetSDSModelType text,ClimateDSGovernanceAlignment text,ClimateDSMandTAlignment text,ClimateDSOverallAlignment text,ClimateDSRiskMgmtAlignment text,ClimateDSStrategyAlignment text)
  
2021-11-19 19:41:46.866491 (Thread-1): SQL status: CREATE TABLE in 0.01 seconds
2021-11-19 19:42:24.695714 (Thread-1): Using postgres connection "seed.my_new_project.iss_file".
2021-11-19 19:42:24.695911 (Thread-1): On seed.my_new_project.iss_file: 
          insert into "demo_db"."dev_sa"."iss_file" (IssuerName, ISIN, GICSSector, GICSIndustryGroup, CountryOfIncorporation, CountryOfOperations, ClimateScope1Emissions, ClimateScope2Emissions, ClimateTotalEmissions, ClimateScope3Emissions, ClimateCNIEmissionsSource, ClimateEmissionsReportedTrust, ClimateEmissionsEstimatedTrust, ClimateScope1EmissionsIntUSD, ClimateScope2EmissionsIntUSD, ClimateTotalEmissionsIntUSD, ClimateAvePeerEmissionsIntUSD, MarketCapDaily, AdjustedEnterpriseValue, ClimateCarbonBudge...
2021-11-19 19:42:25.153218 (Thread-1): SQL status: INSERT 0 1594 in 0.46 seconds
2021-11-19 19:42:25.159358 (Thread-1): Writing runtime SQL for node "seed.my_new_project.iss_file"
2021-11-19 19:42:25.167826 (Thread-1): On seed.my_new_project.iss_file: COMMIT
2021-11-19 19:42:25.167957 (Thread-1): Using postgres connection "seed.my_new_project.iss_file".
2021-11-19 19:42:25.168048 (Thread-1): On seed.my_new_project.iss_file: COMMIT
2021-11-19 19:42:25.176113 (Thread-1): SQL status: COMMIT in 0.01 seconds
2021-11-19 19:42:25.176577 (Thread-1): finished collecting timing info
2021-11-19 19:42:25.176723 (Thread-1): On seed.my_new_project.iss_file: Close
2021-11-19 19:42:25.177079 (Thread-1): 20:42:25 | 1 of 1 OK loaded seed file dev_sa.iss_file........................... [INSERT 1594 in 38.71s]
2021-11-19 19:42:25.177255 (Thread-1): Finished running node seed.my_new_project.iss_file
2021-11-19 19:42:25.178662 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:42:25.178801 (MainThread): Using postgres connection "master".
2021-11-19 19:42:25.178890 (MainThread): On master: BEGIN
2021-11-19 19:42:25.178983 (MainThread): Opening a new connection, currently in state closed
2021-11-19 19:42:25.185616 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:42:25.185806 (MainThread): On master: COMMIT
2021-11-19 19:42:25.185895 (MainThread): Using postgres connection "master".
2021-11-19 19:42:25.185979 (MainThread): On master: COMMIT
2021-11-19 19:42:25.186194 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:42:25.186299 (MainThread): On master: Close
2021-11-19 19:42:25.186630 (MainThread): 20:42:25 | 
2021-11-19 19:42:25.186767 (MainThread): 20:42:25 | Finished running 1 seed in 38.80s.
2021-11-19 19:42:25.186987 (MainThread): Connection 'master' was properly closed.
2021-11-19 19:42:25.187138 (MainThread): Connection 'seed.my_new_project.iss_file' was properly closed.
2021-11-19 19:42:25.187273 (MainThread): Connection 'list_demo_db_dev_dm' was properly closed.
2021-11-19 19:42:25.191261 (MainThread): 
2021-11-19 19:42:25.191444 (MainThread): Completed successfully
2021-11-19 19:42:25.191585 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-11-19 19:42:25.191771 (MainThread): Flushing usage events
2021-11-19 19:42:30.360986 (MainThread): Running with dbt=0.21.0
2021-11-19 19:42:30.420577 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2021-11-19 19:42:30.421030 (MainThread): Tracking: do not track
2021-11-19 19:42:30.430800 (MainThread): Partial parsing not enabled
2021-11-19 19:42:30.437463 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 19:42:30.438098 (MainThread): Parsing macros/adapters.sql
2021-11-19 19:42:30.457558 (MainThread): Parsing macros/catalog.sql
2021-11-19 19:42:30.459530 (MainThread): Parsing macros/relations.sql
2021-11-19 19:42:30.460597 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 19:42:30.462069 (MainThread): Parsing macros/core.sql
2021-11-19 19:42:30.465356 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 19:42:30.511236 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 19:42:30.513351 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 19:42:30.514842 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 19:42:30.516173 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 19:42:30.523373 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 19:42:30.524656 (MainThread): Parsing macros/etc/query.sql
2021-11-19 19:42:30.525476 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 19:42:30.526711 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 19:42:30.534872 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 19:42:30.540660 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 19:42:30.559675 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 19:42:30.561044 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 19:42:30.586195 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 19:42:30.600598 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 19:42:30.616680 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 19:42:30.625374 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 19:42:30.626819 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 19:42:30.638265 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 19:42:30.641483 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 19:42:30.647443 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 19:42:30.653457 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 19:42:30.654588 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 19:42:30.655642 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 19:42:30.657001 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 19:42:30.822855 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:42:30.833171 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:42:30.836030 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:42:30.838788 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:42:30.839014 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:42:30.839919 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:42:30.843603 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:42:30.843829 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:42:30.844730 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:42:30.849874 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:42:30.850125 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:42:30.858949 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:42:30.860656 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:42:30.862338 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:42:30.864827 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:42:30.884884 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:42:30.886486 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:42:30.887963 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:42:30.889615 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:42:30.905118 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 19:42:30.905479 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 19:42:30.906856 (MainThread): 
2021-11-19 19:42:30.907165 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:42:30.908044 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_demo_db".
2021-11-19 19:42:30.913674 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 19:42:30.917748 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 19:42:30.917916 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 19:42:30.918061 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state init
2021-11-19 19:42:30.920419 (ThreadPoolExecutor-0_0): Using postgres connection "list_demo_db".
2021-11-19 19:42:30.920752 (ThreadPoolExecutor-0_0): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 19:42:30.920861 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-11-19 19:42:30.926229 (ThreadPoolExecutor-0_1): SQL status: SELECT 20 in 0.01 seconds
2021-11-19 19:42:30.927511 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 19:42:30.928217 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "list_demo_db".
2021-11-19 19:42:30.929308 (ThreadPoolExecutor-0_1): Using postgres connection "list_demo_db".
2021-11-19 19:42:30.929546 (ThreadPoolExecutor-0_0): SQL status: SELECT 20 in 0.01 seconds
2021-11-19 19:42:30.929877 (ThreadPoolExecutor-0_1): On list_demo_db: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db"} */

    select distinct nspname from pg_namespace
  
2021-11-19 19:42:30.930700 (ThreadPoolExecutor-0_0): On list_demo_db: Close
2021-11-19 19:42:30.930891 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state closed
2021-11-19 19:42:30.937403 (ThreadPoolExecutor-0_1): SQL status: SELECT 20 in 0.01 seconds
2021-11-19 19:42:30.938205 (ThreadPoolExecutor-0_1): On list_demo_db: Close
2021-11-19 19:42:30.938946 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_demo_db_dev".
2021-11-19 19:42:30.939140 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "create_demo_db_dev_dwh".
2021-11-19 19:42:30.939653 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_demo_db_dev".
2021-11-19 19:42:30.939941 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "create_demo_db_dev_dwh".
2021-11-19 19:42:30.940198 (ThreadPoolExecutor-0_0): Creating schema ""demo_db"."dev""
2021-11-19 19:42:30.940513 (ThreadPoolExecutor-0_1): Creating schema ""demo_db"."dev_dwh""
2021-11-19 19:42:30.944351 (ThreadPoolExecutor-0_0): Using postgres connection "create_demo_db_dev".
2021-11-19 19:42:30.946138 (ThreadPoolExecutor-0_1): Using postgres connection "create_demo_db_dev_dwh".
2021-11-19 19:42:30.946345 (ThreadPoolExecutor-0_0): On create_demo_db_dev: BEGIN
2021-11-19 19:42:30.946527 (ThreadPoolExecutor-0_1): On create_demo_db_dev_dwh: BEGIN
2021-11-19 19:42:30.946720 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-11-19 19:42:30.946904 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state closed
2021-11-19 19:42:30.953392 (ThreadPoolExecutor-0_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:42:30.953574 (ThreadPoolExecutor-0_1): Using postgres connection "create_demo_db_dev_dwh".
2021-11-19 19:42:30.953686 (ThreadPoolExecutor-0_1): On create_demo_db_dev_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "create_demo_db_dev_dwh"} */
create schema if not exists "dev_dwh"
2021-11-19 19:42:30.953859 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:42:30.953986 (ThreadPoolExecutor-0_0): Using postgres connection "create_demo_db_dev".
2021-11-19 19:42:30.954075 (ThreadPoolExecutor-0_0): On create_demo_db_dev: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "create_demo_db_dev"} */
create schema if not exists "dev"
2021-11-19 19:42:30.954251 (ThreadPoolExecutor-0_1): SQL status: CREATE SCHEMA in 0.00 seconds
2021-11-19 19:42:30.954965 (ThreadPoolExecutor-0_1): On create_demo_db_dev_dwh: COMMIT
2021-11-19 19:42:30.955091 (ThreadPoolExecutor-0_1): Using postgres connection "create_demo_db_dev_dwh".
2021-11-19 19:42:30.955214 (ThreadPoolExecutor-0_1): On create_demo_db_dev_dwh: COMMIT
2021-11-19 19:42:30.955518 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.00 seconds
2021-11-19 19:42:30.956214 (ThreadPoolExecutor-0_0): On create_demo_db_dev: COMMIT
2021-11-19 19:42:30.956337 (ThreadPoolExecutor-0_0): Using postgres connection "create_demo_db_dev".
2021-11-19 19:42:30.956514 (ThreadPoolExecutor-0_0): On create_demo_db_dev: COMMIT
2021-11-19 19:42:30.956768 (ThreadPoolExecutor-0_1): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:42:30.956953 (ThreadPoolExecutor-0_1): On create_demo_db_dev_dwh: Close
2021-11-19 19:42:30.957630 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "create_demo_db_dev_dm".
2021-11-19 19:42:30.957928 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:42:30.958225 (ThreadPoolExecutor-0_1): Acquiring new postgres connection "create_demo_db_dev_dm".
2021-11-19 19:42:30.958563 (ThreadPoolExecutor-0_0): On create_demo_db_dev: Close
2021-11-19 19:42:30.958798 (ThreadPoolExecutor-0_1): Creating schema ""demo_db"."dev_dm""
2021-11-19 19:42:30.959901 (ThreadPoolExecutor-0_1): Using postgres connection "create_demo_db_dev_dm".
2021-11-19 19:42:30.960354 (ThreadPoolExecutor-0_1): On create_demo_db_dev_dm: BEGIN
2021-11-19 19:42:30.960517 (ThreadPoolExecutor-0_1): Opening a new connection, currently in state closed
2021-11-19 19:42:30.966138 (ThreadPoolExecutor-0_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:42:30.966285 (ThreadPoolExecutor-0_1): Using postgres connection "create_demo_db_dev_dm".
2021-11-19 19:42:30.966382 (ThreadPoolExecutor-0_1): On create_demo_db_dev_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "create_demo_db_dev_dm"} */
create schema if not exists "dev_dm"
2021-11-19 19:42:30.966792 (ThreadPoolExecutor-0_1): SQL status: CREATE SCHEMA in 0.00 seconds
2021-11-19 19:42:30.967398 (ThreadPoolExecutor-0_1): On create_demo_db_dev_dm: COMMIT
2021-11-19 19:42:30.967508 (ThreadPoolExecutor-0_1): Using postgres connection "create_demo_db_dev_dm".
2021-11-19 19:42:30.967602 (ThreadPoolExecutor-0_1): On create_demo_db_dev_dm: COMMIT
2021-11-19 19:42:30.968528 (ThreadPoolExecutor-0_1): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:42:30.968649 (ThreadPoolExecutor-0_1): On create_demo_db_dev_dm: Close
2021-11-19 19:42:30.969926 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev_sa".
2021-11-19 19:42:30.970303 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev".
2021-11-19 19:42:30.974668 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 19:42:30.975764 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev".
2021-11-19 19:42:30.975961 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: BEGIN
2021-11-19 19:42:30.976152 (ThreadPoolExecutor-1_1): On list_demo_db_dev: BEGIN
2021-11-19 19:42:30.976362 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 19:42:30.976548 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 19:42:30.982237 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:42:30.982423 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:42:30.982562 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 19:42:30.982694 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev".
2021-11-19 19:42:30.982822 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_sa'
  
2021-11-19 19:42:30.982952 (ThreadPoolExecutor-1_1): On list_demo_db_dev: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev'
  
2021-11-19 19:42:30.984749 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:42:30.984940 (ThreadPoolExecutor-1_1): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 19:42:30.985890 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: ROLLBACK
2021-11-19 19:42:30.986635 (ThreadPoolExecutor-1_1): On list_demo_db_dev: ROLLBACK
2021-11-19 19:42:30.987007 (ThreadPoolExecutor-1_1): On list_demo_db_dev: Close
2021-11-19 19:42:30.987148 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: Close
2021-11-19 19:42:30.987668 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:42:30.988822 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:42:30.989078 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: BEGIN
2021-11-19 19:42:30.989235 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 19:42:30.989795 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev_dm".
2021-11-19 19:42:30.991141 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 19:42:30.991254 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dm: BEGIN
2021-11-19 19:42:30.991352 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 19:42:30.994937 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:42:30.995076 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:42:30.995167 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dwh'
  
2021-11-19 19:42:30.997121 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:42:30.997319 (ThreadPoolExecutor-1_1): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 19:42:30.997474 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 19:42:30.998505 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: ROLLBACK
2021-11-19 19:42:30.998668 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dm'
  
2021-11-19 19:42:30.999000 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: Close
2021-11-19 19:42:31.000386 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 19:42:31.001180 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dm: ROLLBACK
2021-11-19 19:42:31.001437 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dm: Close
2021-11-19 19:42:31.004667 (MainThread): Using postgres connection "master".
2021-11-19 19:42:31.004776 (MainThread): On master: BEGIN
2021-11-19 19:42:31.004872 (MainThread): Opening a new connection, currently in state init
2021-11-19 19:42:31.010748 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:42:31.010914 (MainThread): Using postgres connection "master".
2021-11-19 19:42:31.011009 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 19:42:31.013709 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 19:42:31.014553 (MainThread): On master: ROLLBACK
2021-11-19 19:42:31.014817 (MainThread): Using postgres connection "master".
2021-11-19 19:42:31.014928 (MainThread): On master: BEGIN
2021-11-19 19:42:31.015441 (MainThread): SQL status: BEGIN in 0.00 seconds
2021-11-19 19:42:31.015548 (MainThread): On master: COMMIT
2021-11-19 19:42:31.015635 (MainThread): Using postgres connection "master".
2021-11-19 19:42:31.015718 (MainThread): On master: COMMIT
2021-11-19 19:42:31.016045 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:42:31.016152 (MainThread): On master: Close
2021-11-19 19:42:31.016475 (MainThread): 20:42:31 | Concurrency: 2 threads (target='dev')
2021-11-19 19:42:31.016651 (MainThread): 20:42:31 | 
2021-11-19 19:42:31.020588 (Thread-1): Began running node model.my_new_project.iss_issuer
2021-11-19 19:42:31.020772 (Thread-2): Began running node model.my_new_project.my_first_dbt_model
2021-11-19 19:42:31.021079 (Thread-1): 20:42:31 | 1 of 5 START incremental model dev_dwh.iss_issuer.................... [RUN]
2021-11-19 19:42:31.021384 (Thread-2): 20:42:31 | 2 of 5 START table model dev.my_first_dbt_model...................... [RUN]
2021-11-19 19:42:31.021849 (Thread-1): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:42:31.022298 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:42:31.022541 (Thread-1): Compiling model.my_new_project.iss_issuer
2021-11-19 19:42:31.022756 (Thread-2): Compiling model.my_new_project.my_first_dbt_model
2021-11-19 19:42:31.026856 (Thread-1): Writing injected SQL for node "model.my_new_project.iss_issuer"
2021-11-19 19:42:31.028433 (Thread-2): Writing injected SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 19:42:31.028995 (Thread-1): finished collecting timing info
2021-11-19 19:42:31.034505 (Thread-2): finished collecting timing info
2021-11-19 19:42:31.070563 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_first_dbt_model"
2021-11-19 19:42:31.076146 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:42:31.076303 (Thread-2): On model.my_new_project.my_first_dbt_model: BEGIN
2021-11-19 19:42:31.076436 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 19:42:31.078520 (Thread-1): Writing runtime SQL for node "model.my_new_project.iss_issuer"
2021-11-19 19:42:31.078782 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:42:31.078883 (Thread-1): On model.my_new_project.iss_issuer: BEGIN
2021-11-19 19:42:31.078983 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 19:42:31.083954 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:42:31.084136 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:42:31.084242 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */


  create  table "demo_db"."dev"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)
,source_case as (

    select 1 as id , 'a' as name
    union all
    select 1 as id , 'b' as name

)

select s.id,n.name
from source_data s
inner join source_case n on n.id = s.id

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2021-11-19 19:42:31.086569 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:42:31.086744 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:42:31.086850 (Thread-1): On model.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.iss_issuer"} */

      

  create  table "demo_db"."dev_dwh"."iss_issuer"
  as (
    

select
     CASE
        WHEN iss.AdjustedEnterpriseValue ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.AdjustedEnterpriseValue::numeric
    ELSE NULL
    END        as adjusted_enterprise_value
    ,iss.ISIN                                               as isin
    ,iss.IssuerName                                         as issuer_name
    ,iss.gicssector                                         as gics_sector
    ,iss.gicsindustrygroup                                  as gics_industry_group
    ,CASE
        WHEN iss.ClimateScope2EmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope2EmissionsIntUSD::numeric
    ELSE NULL
    END   as climate_scope2_emissions_int_usd
    ,CASE
        WHEN iss.ClimateScope1EmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateScope1EmissionsIntUSD::numeric
    ELSE NULL
    END   as climate_scope1_emissions_int_usd
    ,iss.ClimateScope2Emissions::NUMERIC                    as climate_scope2_emissions
    ,CASE
        WHEN iss.ClimateTotalEmissionsIntUSD ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateTotalEmissionsIntUSD::numeric
    ELSE NULL
    END    as climate_total_emissions_int_usd
    ,iss.ClimateScope3Emissions::NUMERIC                    as climate_scope3_emissions
    ,CASE
        WHEN iss.ClimateCNIEmissionsSource ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.ClimateCNIEmissionsSource::numeric
    ELSE NULL
    END      as climate_cni_emissions_source
    ,iss.ClimateTotalEmissions                              as climate_total_emissions
    ,iss.ClimateScope1Emissions::NUMERIC                    as climate_scope1_emissions
    ,CASE
        WHEN iss.MarketCapDaily ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN iss.MarketCapDaily::numeric
    ELSE NULL
    END                 as market_cap_daily
    ,iss.ClimateEmissionsFiscalYear::INT                    as climate_emissions_fiscal_year
    ,'2021-01-01'::DATE                            as meta_file_date
    ,'20211117T164451425627'                                as meta_run_id
    ,CURRENT_TIMESTAMP                                      as meta_insert_timestamp
from "demo_db"."dev_sa"."iss_file" iss
  );
  
2021-11-19 19:42:31.089232 (Thread-2): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 19:42:31.094873 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:42:31.095023 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
alter table "demo_db"."dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2021-11-19 19:42:31.095602 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 19:42:31.103420 (Thread-2): On model.my_new_project.my_first_dbt_model: COMMIT
2021-11-19 19:42:31.103566 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:42:31.103663 (Thread-2): On model.my_new_project.my_first_dbt_model: COMMIT
2021-11-19 19:42:31.105542 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:42:31.109217 (Thread-2): Using postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:42:31.109380 (Thread-2): On model.my_new_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_first_dbt_model"} */
drop table if exists "demo_db"."dev"."my_first_dbt_model__dbt_backup" cascade
2021-11-19 19:42:31.109680 (Thread-1): SQL status: SELECT 1594 in 0.02 seconds
2021-11-19 19:42:31.110628 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 19:42:31.110760 (Thread-1): Using postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:42:31.110877 (Thread-1): On model.my_new_project.iss_issuer: COMMIT
2021-11-19 19:42:31.111039 (Thread-2): SQL status: DROP TABLE in 0.00 seconds
2021-11-19 19:42:31.111842 (Thread-2): finished collecting timing info
2021-11-19 19:42:31.111980 (Thread-2): On model.my_new_project.my_first_dbt_model: Close
2021-11-19 19:42:31.112426 (Thread-2): 20:42:31 | 2 of 5 OK created table model dev.my_first_dbt_model................. [SELECT 2 in 0.09s]
2021-11-19 19:42:31.112589 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:42:31.113025 (Thread-1): finished collecting timing info
2021-11-19 19:42:31.113199 (Thread-2): Finished running node model.my_new_project.my_first_dbt_model
2021-11-19 19:42:31.113440 (Thread-1): On model.my_new_project.iss_issuer: Close
2021-11-19 19:42:31.114142 (Thread-1): 20:42:31 | 1 of 5 OK created incremental model dev_dwh.iss_issuer............... [SELECT 1594 in 0.09s]
2021-11-19 19:42:31.114659 (Thread-1): Finished running node model.my_new_project.iss_issuer
2021-11-19 19:42:31.115261 (Thread-2): Began running node model.my_new_project.my_second_dbt_model
2021-11-19 19:42:31.115677 (Thread-2): 20:42:31 | 3 of 5 START view model dev.my_second_dbt_model...................... [RUN]
2021-11-19 19:42:31.115830 (Thread-1): Began running node model.my_new_project.dim_issuer
2021-11-19 19:42:31.116240 (Thread-2): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:42:31.116503 (Thread-1): 20:42:31 | 4 of 5 START table model dev_dm.dim_issuer........................... [RUN]
2021-11-19 19:42:31.116685 (Thread-2): Compiling model.my_new_project.my_second_dbt_model
2021-11-19 19:42:31.117081 (Thread-1): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:42:31.119314 (Thread-2): Writing injected SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-19 19:42:31.119635 (Thread-1): Compiling model.my_new_project.dim_issuer
2021-11-19 19:42:31.123788 (Thread-1): Writing injected SQL for node "model.my_new_project.dim_issuer"
2021-11-19 19:42:31.124344 (Thread-2): finished collecting timing info
2021-11-19 19:42:31.140323 (Thread-1): finished collecting timing info
2021-11-19 19:42:31.148526 (Thread-1): Writing runtime SQL for node "model.my_new_project.dim_issuer"
2021-11-19 19:42:31.153157 (Thread-2): Writing runtime SQL for node "model.my_new_project.my_second_dbt_model"
2021-11-19 19:42:31.153712 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:42:31.154051 (Thread-1): On model.my_new_project.dim_issuer: BEGIN
2021-11-19 19:42:31.154232 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 19:42:31.154526 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:42:31.154652 (Thread-2): On model.my_new_project.my_second_dbt_model: BEGIN
2021-11-19 19:42:31.154800 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 19:42:31.161225 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:42:31.161443 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:42:31.161576 (Thread-1): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */


  create  table "demo_db"."dev_dm"."dim_issuer__dbt_tmp"
  as (
    

select distinct
     md5(iss.isin)              as dim_issuer_key
    ,iss.isin                   as isin
    ,iss.issuer_name            as issuer_name
    ,iss.gics_sector            as gics_sector
    ,iss.gics_industry_group    as gics_industry_group
from "demo_db"."dev_dwh"."iss_issuer" iss
  );
2021-11-19 19:42:31.161729 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:42:31.161954 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:42:31.162070 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */

  create view "demo_db"."dev"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."dev"."my_first_dbt_model"
where id = 1
  );

2021-11-19 19:42:31.163124 (Thread-2): SQL status: CREATE VIEW in 0.00 seconds
2021-11-19 19:42:31.165327 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:42:31.165475 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */
alter table "demo_db"."dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2021-11-19 19:42:31.166056 (Thread-2): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 19:42:31.166945 (Thread-2): On model.my_new_project.my_second_dbt_model: COMMIT
2021-11-19 19:42:31.167064 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:42:31.167161 (Thread-2): On model.my_new_project.my_second_dbt_model: COMMIT
2021-11-19 19:42:31.168023 (Thread-1): SQL status: SELECT 1594 in 0.01 seconds
2021-11-19 19:42:31.169621 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:42:31.169816 (Thread-1): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
alter table "demo_db"."dev_dm"."dim_issuer__dbt_tmp" rename to "dim_issuer"
2021-11-19 19:42:31.170108 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:42:31.171381 (Thread-2): Using postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:42:31.171541 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2021-11-19 19:42:31.171700 (Thread-2): On model.my_new_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.my_second_dbt_model"} */
drop view if exists "demo_db"."dev"."my_second_dbt_model__dbt_backup" cascade
2021-11-19 19:42:31.172712 (Thread-1): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 19:42:31.172928 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:42:31.173039 (Thread-1): On model.my_new_project.dim_issuer: COMMIT
2021-11-19 19:42:31.173201 (Thread-2): SQL status: DROP VIEW in 0.00 seconds
2021-11-19 19:42:31.174200 (Thread-2): finished collecting timing info
2021-11-19 19:42:31.174407 (Thread-2): On model.my_new_project.my_second_dbt_model: Close
2021-11-19 19:42:31.174608 (Thread-1): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:42:31.175231 (Thread-2): 20:42:31 | 3 of 5 OK created view model dev.my_second_dbt_model................. [CREATE VIEW in 0.06s]
2021-11-19 19:42:31.176568 (Thread-1): Using postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:42:31.176890 (Thread-2): Finished running node model.my_new_project.my_second_dbt_model
2021-11-19 19:42:31.177078 (Thread-1): On model.my_new_project.dim_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.dim_issuer"} */
drop table if exists "demo_db"."dev_dm"."dim_issuer__dbt_backup" cascade
2021-11-19 19:42:31.177369 (Thread-2): Began running node model.my_new_project.fct_emissions
2021-11-19 19:42:31.177855 (Thread-2): 20:42:31 | 5 of 5 START incremental model dev_dm.fct_emissions.................. [RUN]
2021-11-19 19:42:31.178078 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2021-11-19 19:42:31.178413 (Thread-2): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:42:31.179390 (Thread-1): finished collecting timing info
2021-11-19 19:42:31.179584 (Thread-2): Compiling model.my_new_project.fct_emissions
2021-11-19 19:42:31.179755 (Thread-1): On model.my_new_project.dim_issuer: Close
2021-11-19 19:42:31.183434 (Thread-2): Writing injected SQL for node "model.my_new_project.fct_emissions"
2021-11-19 19:42:31.183971 (Thread-1): 20:42:31 | 4 of 5 OK created table model dev_dm.dim_issuer...................... [SELECT 1594 in 0.07s]
2021-11-19 19:42:31.184220 (Thread-1): Finished running node model.my_new_project.dim_issuer
2021-11-19 19:42:31.184620 (Thread-2): finished collecting timing info
2021-11-19 19:42:31.186779 (Thread-2): Writing runtime SQL for node "model.my_new_project.fct_emissions"
2021-11-19 19:42:31.187014 (Thread-2): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:42:31.187137 (Thread-2): On model.my_new_project.fct_emissions: BEGIN
2021-11-19 19:42:31.187245 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 19:42:31.193516 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:42:31.193680 (Thread-2): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:42:31.193780 (Thread-2): On model.my_new_project.fct_emissions: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "model.my_new_project.fct_emissions"} */

      

  create  table "demo_db"."dev_dm"."fct_emissions"
  as (
    


with cte_fundamental_enterprise_value as (
    select
         iss.isin                                                    as isin
        ,'EnterpriseValue'                                           as fundamental
        ,climate_scope1_emissions / climate_scope1_emissions_int_usd as fundamental_value
    from "demo_db"."dev_dwh"."iss_issuer" iss
)

, cte_fundamental_revenue as (
    select
         iss.ISIN                                                    as isin
        ,'Revenue'                                                   as fundamental
        ,adjusted_enterprise_value / 1e6                             as fundamental_value
    from "demo_db"."dev_dwh"."iss_issuer" iss
)

, cte_fundamental_market_cap as (
    select
         iss.ISIN                                                    as isin
        ,'MarketCap'                                                 as fundamental
        ,market_cap_daily / 1e6                                      as fundamental_value
    from "demo_db"."dev_dwh"."iss_issuer" iss
)

, cte_union_tables as (
    select * from cte_fundamental_enterprise_value

    union

    select * from cte_fundamental_revenue

    union

    select * from cte_fundamental_market_cap
)

select
     md5(isin)                            as fct_emissions_key
    ,md5(isin)                            as dim_issuer_key
    ,fundamental
    ,fundamental_value
    ,'2021-01-01'                as meta_file_date
    ,'20211117T164451425627'              as meta_run_id
    ,CURRENT_TIMESTAMP                    as meta_insert_timestamp
from cte_union_tables
  );
  
2021-11-19 19:42:31.207180 (Thread-2): SQL status: SELECT 4782 in 0.01 seconds
2021-11-19 19:42:31.208342 (Thread-2): On model.my_new_project.fct_emissions: COMMIT
2021-11-19 19:42:31.208542 (Thread-2): Using postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:42:31.208637 (Thread-2): On model.my_new_project.fct_emissions: COMMIT
2021-11-19 19:42:31.210854 (Thread-2): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:42:31.211212 (Thread-2): finished collecting timing info
2021-11-19 19:42:31.211345 (Thread-2): On model.my_new_project.fct_emissions: Close
2021-11-19 19:42:31.211738 (Thread-2): 20:42:31 | 5 of 5 OK created incremental model dev_dm.fct_emissions............. [SELECT 4782 in 0.03s]
2021-11-19 19:42:31.211894 (Thread-2): Finished running node model.my_new_project.fct_emissions
2021-11-19 19:42:31.213079 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:42:31.213229 (MainThread): Using postgres connection "master".
2021-11-19 19:42:31.213325 (MainThread): On master: BEGIN
2021-11-19 19:42:31.213423 (MainThread): Opening a new connection, currently in state closed
2021-11-19 19:42:31.219520 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:42:31.219682 (MainThread): On master: COMMIT
2021-11-19 19:42:31.219782 (MainThread): Using postgres connection "master".
2021-11-19 19:42:31.219872 (MainThread): On master: COMMIT
2021-11-19 19:42:31.220298 (MainThread): SQL status: COMMIT in 0.00 seconds
2021-11-19 19:42:31.220428 (MainThread): On master: Close
2021-11-19 19:42:31.220763 (MainThread): 20:42:31 | 
2021-11-19 19:42:31.220912 (MainThread): 20:42:31 | Finished running 2 table models, 2 incremental models, 1 view model in 0.31s.
2021-11-19 19:42:31.221041 (MainThread): Connection 'master' was properly closed.
2021-11-19 19:42:31.221136 (MainThread): Connection 'model.my_new_project.fct_emissions' was properly closed.
2021-11-19 19:42:31.221222 (MainThread): Connection 'model.my_new_project.dim_issuer' was properly closed.
2021-11-19 19:42:31.224665 (MainThread): 
2021-11-19 19:42:31.224836 (MainThread): Completed successfully
2021-11-19 19:42:31.224982 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-11-19 19:42:31.225190 (MainThread): Flushing usage events
2021-11-19 19:46:06.617364 (MainThread): Running with dbt=0.21.0
2021-11-19 19:46:06.670654 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2021-11-19 19:46:06.671097 (MainThread): Tracking: do not track
2021-11-19 19:46:06.680978 (MainThread): Partial parsing not enabled
2021-11-19 19:46:06.687290 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 19:46:06.687853 (MainThread): Parsing macros/adapters.sql
2021-11-19 19:46:06.707196 (MainThread): Parsing macros/catalog.sql
2021-11-19 19:46:06.708937 (MainThread): Parsing macros/relations.sql
2021-11-19 19:46:06.709902 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 19:46:06.711319 (MainThread): Parsing macros/core.sql
2021-11-19 19:46:06.714157 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 19:46:06.754970 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 19:46:06.756965 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 19:46:06.758339 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 19:46:06.759532 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 19:46:06.766169 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 19:46:06.767284 (MainThread): Parsing macros/etc/query.sql
2021-11-19 19:46:06.768050 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 19:46:06.769150 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 19:46:06.776426 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 19:46:06.781625 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 19:46:06.798894 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 19:46:06.800153 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 19:46:06.822552 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 19:46:06.835381 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 19:46:06.850228 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 19:46:06.857982 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 19:46:06.859298 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 19:46:06.869611 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 19:46:06.872702 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 19:46:06.878016 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 19:46:06.883442 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 19:46:06.884472 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 19:46:06.885394 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 19:46:06.886605 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 19:46:07.043009 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:46:07.052789 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:46:07.056320 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:46:07.059023 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:07.059256 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:07.060124 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:46:07.063897 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:07.064132 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:07.065065 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:46:07.070524 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:07.070761 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:07.078303 (MainThread): Acquiring new postgres connection "test.my_new_project.iss_issuer".
2021-11-19 19:46:07.081703 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:07.082788 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:07.091652 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:07.093268 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:07.095062 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:07.096704 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:07.116338 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:07.117791 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:07.119223 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:07.120563 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:07.134786 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 19:46:07.135098 (MainThread): Found 5 models, 5 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 19:46:07.136601 (MainThread): 
2021-11-19 19:46:07.136971 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:46:07.138071 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev".
2021-11-19 19:46:07.138468 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev_dm".
2021-11-19 19:46:07.145860 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev".
2021-11-19 19:46:07.147014 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 19:46:07.147203 (ThreadPoolExecutor-1_0): On list_demo_db_dev: BEGIN
2021-11-19 19:46:07.147388 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: BEGIN
2021-11-19 19:46:07.147583 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-11-19 19:46:07.147767 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-19 19:46:07.154243 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:46:07.154626 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:46:07.154847 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev".
2021-11-19 19:46:07.155030 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 19:46:07.155191 (ThreadPoolExecutor-1_0): On list_demo_db_dev: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev'
  
2021-11-19 19:46:07.155442 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dm'
  
2021-11-19 19:46:07.157464 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 19:46:07.158453 (ThreadPoolExecutor-1_0): On list_demo_db_dev: ROLLBACK
2021-11-19 19:46:07.158614 (ThreadPoolExecutor-1_1): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 19:46:07.159545 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: ROLLBACK
2021-11-19 19:46:07.159697 (ThreadPoolExecutor-1_0): On list_demo_db_dev: Close
2021-11-19 19:46:07.160209 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev_sa".
2021-11-19 19:46:07.161580 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 19:46:07.161827 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: Close
2021-11-19 19:46:07.162003 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: BEGIN
2021-11-19 19:46:07.162606 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:46:07.162811 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 19:46:07.163805 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:46:07.164218 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: BEGIN
2021-11-19 19:46:07.164316 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 19:46:07.169980 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:46:07.170150 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 19:46:07.170312 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:46:07.170444 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_sa'
  
2021-11-19 19:46:07.170586 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:46:07.170758 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dwh'
  
2021-11-19 19:46:07.172388 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:46:07.172585 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:46:07.173450 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: ROLLBACK
2021-11-19 19:46:07.174231 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: ROLLBACK
2021-11-19 19:46:07.174811 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: Close
2021-11-19 19:46:07.175014 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: Close
2021-11-19 19:46:07.178947 (MainThread): Using postgres connection "master".
2021-11-19 19:46:07.179090 (MainThread): On master: BEGIN
2021-11-19 19:46:07.179189 (MainThread): Opening a new connection, currently in state init
2021-11-19 19:46:07.184751 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:46:07.184977 (MainThread): Using postgres connection "master".
2021-11-19 19:46:07.185067 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 19:46:07.192214 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-11-19 19:46:07.193077 (MainThread): On master: ROLLBACK
2021-11-19 19:46:07.193506 (MainThread): On master: Close
2021-11-19 19:46:07.194002 (MainThread): 20:46:07 | Concurrency: 2 threads (target='dev')
2021-11-19 19:46:07.194249 (MainThread): 20:46:07 | 
2021-11-19 19:46:07.196896 (Thread-1): Began running node test.my_new_project.iss_issuer
2021-11-19 19:46:07.197093 (Thread-2): Began running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2021-11-19 19:46:07.197256 (Thread-1): 20:46:07 | 1 of 5 START test iss_issuer......................................... [RUN]
2021-11-19 19:46:07.197409 (Thread-2): 20:46:07 | 2 of 5 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-11-19 19:46:07.197749 (Thread-1): Acquiring new postgres connection "test.my_new_project.iss_issuer".
2021-11-19 19:46:07.198062 (Thread-2): Acquiring new postgres connection "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710".
2021-11-19 19:46:07.198252 (Thread-1): Compiling test.my_new_project.iss_issuer
2021-11-19 19:46:07.198402 (Thread-2): Compiling test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2021-11-19 19:46:07.200481 (Thread-1): Writing injected SQL for node "test.my_new_project.iss_issuer"
2021-11-19 19:46:07.207614 (Thread-2): Writing injected SQL for node "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"
2021-11-19 19:46:07.207842 (Thread-2): finished collecting timing info
2021-11-19 19:46:07.220211 (Thread-2): Writing runtime SQL for node "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"
2021-11-19 19:46:07.220487 (Thread-1): finished collecting timing info
2021-11-19 19:46:07.230323 (Thread-1): On "test.my_new_project.iss_issuer": cache miss for schema "demo_db.dev_dbt_test__audit", this is inefficient
2021-11-19 19:46:07.231251 (Thread-1): Using postgres connection "test.my_new_project.iss_issuer".
2021-11-19 19:46:07.231383 (Thread-1): On test.my_new_project.iss_issuer: BEGIN
2021-11-19 19:46:07.231502 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 19:46:07.231822 (Thread-2): Using postgres connection "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710".
2021-11-19 19:46:07.231966 (Thread-2): On test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
2021-11-19 19:46:07.232080 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 19:46:07.238325 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:46:07.238546 (Thread-2): Using postgres connection "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710".
2021-11-19 19:46:07.238699 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:46:07.238882 (Thread-2): On test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from "demo_db"."dev"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
2021-11-19 19:46:07.239073 (Thread-1): Using postgres connection "test.my_new_project.iss_issuer".
2021-11-19 19:46:07.239307 (Thread-1): On test.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.iss_issuer"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dbt_test__audit'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dbt_test__audit'
  
2021-11-19 19:46:07.239899 (Thread-2): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:46:07.241445 (Thread-2): finished collecting timing info
2021-11-19 19:46:07.241599 (Thread-2): On test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
2021-11-19 19:46:07.241754 (Thread-1): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 19:46:07.242578 (Thread-1): with database=demo_db, schema=dev_dbt_test__audit, relations=[]
2021-11-19 19:46:07.242718 (Thread-2): On test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710: Close
2021-11-19 19:46:07.242979 (Thread-1): On "test.my_new_project.iss_issuer": cache miss for schema "demo_db.dev_dbt_test__audit", this is inefficient
2021-11-19 19:46:07.244406 (Thread-1): Using postgres connection "test.my_new_project.iss_issuer".
2021-11-19 19:46:07.244556 (Thread-1): On test.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.iss_issuer"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dbt_test__audit'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dbt_test__audit'
  
2021-11-19 19:46:07.245065 (Thread-2): 20:46:07 | 2 of 5 PASS not_null_my_first_dbt_model_id........................... [PASS in 0.05s]
2021-11-19 19:46:07.245244 (Thread-2): Finished running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2021-11-19 19:46:07.245495 (Thread-2): Began running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2021-11-19 19:46:07.245740 (Thread-1): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 19:46:07.246095 (Thread-2): 20:46:07 | 3 of 5 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-11-19 19:46:07.246977 (Thread-1): with database=demo_db, schema=dev_dbt_test__audit, relations=[]
2021-11-19 19:46:07.247438 (Thread-2): Acquiring new postgres connection "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778".
2021-11-19 19:46:07.247697 (Thread-1): On "test.my_new_project.iss_issuer": cache miss for schema "demo_db.dev_dbt_test__audit", this is inefficient
2021-11-19 19:46:07.247911 (Thread-2): Compiling test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2021-11-19 19:46:07.249066 (Thread-1): Using postgres connection "test.my_new_project.iss_issuer".
2021-11-19 19:46:07.251452 (Thread-2): Writing injected SQL for node "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"
2021-11-19 19:46:07.251633 (Thread-1): On test.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.iss_issuer"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dbt_test__audit'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dbt_test__audit'
  
2021-11-19 19:46:07.252157 (Thread-2): finished collecting timing info
2021-11-19 19:46:07.254087 (Thread-2): Writing runtime SQL for node "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"
2021-11-19 19:46:07.254353 (Thread-1): SQL status: SELECT 0 in 0.00 seconds
2021-11-19 19:46:07.255131 (Thread-1): with database=demo_db, schema=dev_dbt_test__audit, relations=[]
2021-11-19 19:46:07.263417 (Thread-1): Writing runtime SQL for node "test.my_new_project.iss_issuer"
2021-11-19 19:46:07.263723 (Thread-2): Using postgres connection "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778".
2021-11-19 19:46:07.263853 (Thread-2): On test.my_new_project.not_null_my_second_dbt_model_id.151b76d778: BEGIN
2021-11-19 19:46:07.263977 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 19:46:07.264360 (Thread-1): Using postgres connection "test.my_new_project.iss_issuer".
2021-11-19 19:46:07.264492 (Thread-1): On test.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.iss_issuer"} */


  create  table "demo_db"."dev_dbt_test__audit"."iss_issuer__dbt_tmp"
  as (
    

select 1 from "demo_db"."dev_dwh"."iss_issuer" iss where isin is null
  );
2021-11-19 19:46:07.265370 (Thread-1): Postgres error: schema "dev_dbt_test__audit" does not exist

2021-11-19 19:46:07.265581 (Thread-1): On test.my_new_project.iss_issuer: ROLLBACK
2021-11-19 19:46:07.266037 (Thread-1): finished collecting timing info
2021-11-19 19:46:07.266272 (Thread-1): On test.my_new_project.iss_issuer: Close
2021-11-19 19:46:07.266606 (Thread-1): Database Error in test iss_issuer (tests/dwh_iss/iss_issuer.sql)
  schema "dev_dbt_test__audit" does not exist
  compiled SQL at target/run/my_new_project/tests/dwh_iss/iss_issuer.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InvalidSchemaName: schema "dev_dbt_test__audit" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/test.py", line 112, in execute
    result = self.execute_test(test, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/test.py", line 82, in execute_test
    macro_func()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 70, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in test iss_issuer (tests/dwh_iss/iss_issuer.sql)
  schema "dev_dbt_test__audit" does not exist
  compiled SQL at target/run/my_new_project/tests/dwh_iss/iss_issuer.sql
2021-11-19 19:46:07.268253 (Thread-1): 20:46:07 | 1 of 5 ERROR iss_issuer.............................................. [ERROR in 0.07s]
2021-11-19 19:46:07.268405 (Thread-1): Finished running node test.my_new_project.iss_issuer
2021-11-19 19:46:07.268597 (Thread-1): Began running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2021-11-19 19:46:07.268796 (Thread-1): 20:46:07 | 4 of 5 START test unique_my_first_dbt_model_id....................... [RUN]
2021-11-19 19:46:07.269064 (Thread-1): Acquiring new postgres connection "test.my_new_project.unique_my_first_dbt_model_id.16e066b321".
2021-11-19 19:46:07.269240 (Thread-1): Compiling test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2021-11-19 19:46:07.273855 (Thread-1): Writing injected SQL for node "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"
2021-11-19 19:46:07.274446 (Thread-1): finished collecting timing info
2021-11-19 19:46:07.275920 (Thread-1): Writing runtime SQL for node "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"
2021-11-19 19:46:07.276107 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:46:07.276236 (Thread-2): Using postgres connection "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778".
2021-11-19 19:46:07.276343 (Thread-2): On test.my_new_project.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from "demo_db"."dev"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
2021-11-19 19:46:07.276618 (Thread-1): Using postgres connection "test.my_new_project.unique_my_first_dbt_model_id.16e066b321".
2021-11-19 19:46:07.276798 (Thread-1): On test.my_new_project.unique_my_first_dbt_model_id.16e066b321: BEGIN
2021-11-19 19:46:07.276897 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 19:46:07.277339 (Thread-2): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:46:07.278696 (Thread-2): finished collecting timing info
2021-11-19 19:46:07.278899 (Thread-2): On test.my_new_project.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
2021-11-19 19:46:07.279468 (Thread-2): On test.my_new_project.not_null_my_second_dbt_model_id.151b76d778: Close
2021-11-19 19:46:07.279839 (Thread-2): 20:46:07 | 3 of 5 PASS not_null_my_second_dbt_model_id.......................... [PASS in 0.03s]
2021-11-19 19:46:07.280033 (Thread-2): Finished running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2021-11-19 19:46:07.280273 (Thread-2): Began running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2021-11-19 19:46:07.280502 (Thread-2): 20:46:07 | 5 of 5 START test unique_my_second_dbt_model_id...................... [RUN]
2021-11-19 19:46:07.280882 (Thread-2): Acquiring new postgres connection "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493".
2021-11-19 19:46:07.281100 (Thread-2): Compiling test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2021-11-19 19:46:07.284038 (Thread-2): Writing injected SQL for node "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"
2021-11-19 19:46:07.284417 (Thread-2): finished collecting timing info
2021-11-19 19:46:07.285708 (Thread-2): Writing runtime SQL for node "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"
2021-11-19 19:46:07.285857 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:46:07.286160 (Thread-1): Using postgres connection "test.my_new_project.unique_my_first_dbt_model_id.16e066b321".
2021-11-19 19:46:07.286274 (Thread-1): On test.my_new_project.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "demo_db"."dev"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
2021-11-19 19:46:07.286506 (Thread-2): Using postgres connection "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493".
2021-11-19 19:46:07.286631 (Thread-2): On test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
2021-11-19 19:46:07.286729 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 19:46:07.287302 (Thread-1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:46:07.288440 (Thread-1): finished collecting timing info
2021-11-19 19:46:07.288641 (Thread-1): On test.my_new_project.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
2021-11-19 19:46:07.289042 (Thread-1): On test.my_new_project.unique_my_first_dbt_model_id.16e066b321: Close
2021-11-19 19:46:07.289406 (Thread-1): 20:46:07 | 4 of 5 FAIL 1 unique_my_first_dbt_model_id........................... [FAIL 1 in 0.02s]
2021-11-19 19:46:07.289575 (Thread-1): Finished running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2021-11-19 19:46:07.292719 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:46:07.292905 (Thread-2): Using postgres connection "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493".
2021-11-19 19:46:07.292996 (Thread-2): On test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "demo_db"."dev"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
2021-11-19 19:46:07.293781 (Thread-2): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:46:07.294967 (Thread-2): finished collecting timing info
2021-11-19 19:46:07.295107 (Thread-2): On test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
2021-11-19 19:46:07.295509 (Thread-2): On test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493: Close
2021-11-19 19:46:07.295865 (Thread-2): 20:46:07 | 5 of 5 FAIL 1 unique_my_second_dbt_model_id.......................... [FAIL 1 in 0.02s]
2021-11-19 19:46:07.296012 (Thread-2): Finished running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2021-11-19 19:46:07.297607 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:46:07.297846 (MainThread): 20:46:07 | 
2021-11-19 19:46:07.297983 (MainThread): 20:46:07 | Finished running 5 tests in 0.16s.
2021-11-19 19:46:07.298138 (MainThread): Connection 'master' was properly closed.
2021-11-19 19:46:07.298237 (MainThread): Connection 'test.my_new_project.unique_my_first_dbt_model_id.16e066b321' was properly closed.
2021-11-19 19:46:07.298326 (MainThread): Connection 'test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
2021-11-19 19:46:07.301686 (MainThread): 
2021-11-19 19:46:07.301865 (MainThread): Completed with 3 errors and 0 warnings:
2021-11-19 19:46:07.302120 (MainThread): 
2021-11-19 19:46:07.302404 (MainThread): Database Error in test iss_issuer (tests/dwh_iss/iss_issuer.sql)
2021-11-19 19:46:07.302586 (MainThread):   schema "dev_dbt_test__audit" does not exist
2021-11-19 19:46:07.302746 (MainThread):   compiled SQL at target/run/my_new_project/tests/dwh_iss/iss_issuer.sql
2021-11-19 19:46:07.302919 (MainThread): 
2021-11-19 19:46:07.303062 (MainThread): Failure in test unique_my_first_dbt_model_id (models/example/schema.yml)
2021-11-19 19:46:07.303193 (MainThread):   Got 1 result, configured to fail if != 0
2021-11-19 19:46:07.303323 (MainThread): 
2021-11-19 19:46:07.303454 (MainThread):   compiled SQL at target/compiled/my_new_project/models/example/schema.yml/schema_test/unique_my_first_dbt_model_id.sql
2021-11-19 19:46:07.303588 (MainThread): 
2021-11-19 19:46:07.303726 (MainThread): Failure in test unique_my_second_dbt_model_id (models/example/schema.yml)
2021-11-19 19:46:07.303854 (MainThread):   Got 1 result, configured to fail if != 0
2021-11-19 19:46:07.303981 (MainThread): 
2021-11-19 19:46:07.304110 (MainThread):   compiled SQL at target/compiled/my_new_project/models/example/schema.yml/schema_test/unique_my_second_dbt_model_id.sql
2021-11-19 19:46:07.304248 (MainThread): 
Done. PASS=2 WARN=0 ERROR=3 SKIP=0 TOTAL=5
2021-11-19 19:46:07.304429 (MainThread): Flushing usage events
2021-11-19 19:46:41.885909 (MainThread): Running with dbt=0.21.0
2021-11-19 19:46:41.943982 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2021-11-19 19:46:41.944518 (MainThread): Tracking: do not track
2021-11-19 19:46:41.954122 (MainThread): Partial parsing not enabled
2021-11-19 19:46:41.960587 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 19:46:41.961291 (MainThread): Parsing macros/adapters.sql
2021-11-19 19:46:41.978515 (MainThread): Parsing macros/catalog.sql
2021-11-19 19:46:41.980140 (MainThread): Parsing macros/relations.sql
2021-11-19 19:46:41.981071 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 19:46:41.982297 (MainThread): Parsing macros/core.sql
2021-11-19 19:46:41.985150 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 19:46:42.025510 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 19:46:42.027399 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 19:46:42.028816 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 19:46:42.029984 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 19:46:42.036215 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 19:46:42.037462 (MainThread): Parsing macros/etc/query.sql
2021-11-19 19:46:42.038189 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 19:46:42.039354 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 19:46:42.046593 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 19:46:42.051654 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 19:46:42.070614 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 19:46:42.071941 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 19:46:42.096037 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 19:46:42.109613 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 19:46:42.124985 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 19:46:42.133556 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 19:46:42.134902 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 19:46:42.145619 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 19:46:42.148684 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 19:46:42.154012 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 19:46:42.159383 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 19:46:42.160478 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 19:46:42.161647 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 19:46:42.162884 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 19:46:42.323170 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:46:42.333005 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:46:42.335737 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:46:42.338214 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:42.338425 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:42.339231 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:46:42.342609 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:42.342814 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:42.343655 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:46:42.348260 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:42.348468 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:42.355592 (MainThread): Acquiring new postgres connection "test.my_new_project.iss_issuer".
2021-11-19 19:46:42.357622 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:42.366424 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:42.368155 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:42.369943 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:42.371412 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:42.389335 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:42.390803 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:42.392221 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:42.393535 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:46:42.407771 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 19:46:42.408076 (MainThread): Found 5 models, 5 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 19:46:42.409598 (MainThread): 
2021-11-19 19:46:42.409864 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:46:42.410894 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev_dm".
2021-11-19 19:46:42.416492 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev".
2021-11-19 19:46:42.420391 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev".
2021-11-19 19:46:42.420530 (ThreadPoolExecutor-1_1): On list_demo_db_dev: BEGIN
2021-11-19 19:46:42.420738 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-19 19:46:42.423720 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 19:46:42.424146 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dm: BEGIN
2021-11-19 19:46:42.424285 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-11-19 19:46:42.428971 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:46:42.429160 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev".
2021-11-19 19:46:42.429250 (ThreadPoolExecutor-1_1): On list_demo_db_dev: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev'
  
2021-11-19 19:46:42.431144 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:46:42.431296 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 19:46:42.431496 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dm'
  
2021-11-19 19:46:42.431812 (ThreadPoolExecutor-1_1): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 19:46:42.432830 (ThreadPoolExecutor-1_1): On list_demo_db_dev: ROLLBACK
2021-11-19 19:46:42.433351 (ThreadPoolExecutor-1_1): On list_demo_db_dev: Close
2021-11-19 19:46:42.433568 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 19:46:42.434453 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dm: ROLLBACK
2021-11-19 19:46:42.435120 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:46:42.436596 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:46:42.436738 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: BEGIN
2021-11-19 19:46:42.436925 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 19:46:42.437197 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dm: Close
2021-11-19 19:46:42.437670 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev_sa".
2021-11-19 19:46:42.439118 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 19:46:42.439220 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: BEGIN
2021-11-19 19:46:42.439311 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 19:46:42.443213 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:46:42.443350 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:46:42.443442 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dwh'
  
2021-11-19 19:46:42.445398 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:46:42.445622 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:46:42.446500 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: ROLLBACK
2021-11-19 19:46:42.446643 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 19:46:42.446813 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_sa'
  
2021-11-19 19:46:42.446982 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: Close
2021-11-19 19:46:42.448627 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:46:42.449386 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: ROLLBACK
2021-11-19 19:46:42.449670 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: Close
2021-11-19 19:46:42.453118 (MainThread): Using postgres connection "master".
2021-11-19 19:46:42.453240 (MainThread): On master: BEGIN
2021-11-19 19:46:42.453337 (MainThread): Opening a new connection, currently in state init
2021-11-19 19:46:42.459274 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:46:42.459421 (MainThread): Using postgres connection "master".
2021-11-19 19:46:42.459508 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 19:46:42.466938 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-11-19 19:46:42.467896 (MainThread): On master: ROLLBACK
2021-11-19 19:46:42.468341 (MainThread): On master: Close
2021-11-19 19:46:42.468624 (MainThread): 20:46:42 | Concurrency: 2 threads (target='dev')
2021-11-19 19:46:42.468785 (MainThread): 20:46:42 | 
2021-11-19 19:46:42.471457 (Thread-1): Began running node test.my_new_project.iss_issuer
2021-11-19 19:46:42.471652 (Thread-1): 20:46:42 | 1 of 5 START test iss_issuer......................................... [RUN]
2021-11-19 19:46:42.471818 (Thread-2): Began running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2021-11-19 19:46:42.471972 (Thread-2): 20:46:42 | 2 of 5 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-11-19 19:46:42.472275 (Thread-1): Acquiring new postgres connection "test.my_new_project.iss_issuer".
2021-11-19 19:46:42.472713 (Thread-2): Acquiring new postgres connection "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710".
2021-11-19 19:46:42.472944 (Thread-1): Compiling test.my_new_project.iss_issuer
2021-11-19 19:46:42.473093 (Thread-2): Compiling test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2021-11-19 19:46:42.475196 (Thread-1): Writing injected SQL for node "test.my_new_project.iss_issuer"
2021-11-19 19:46:42.482171 (Thread-2): Writing injected SQL for node "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"
2021-11-19 19:46:42.482634 (Thread-1): finished collecting timing info
2021-11-19 19:46:42.487951 (Thread-2): finished collecting timing info
2021-11-19 19:46:42.504442 (Thread-1): Writing runtime SQL for node "test.my_new_project.iss_issuer"
2021-11-19 19:46:42.503417 (Thread-2): Writing runtime SQL for node "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"
2021-11-19 19:46:42.504937 (Thread-1): Using postgres connection "test.my_new_project.iss_issuer".
2021-11-19 19:46:42.505062 (Thread-1): On test.my_new_project.iss_issuer: BEGIN
2021-11-19 19:46:42.505229 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 19:46:42.505600 (Thread-2): Using postgres connection "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710".
2021-11-19 19:46:42.505750 (Thread-2): On test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
2021-11-19 19:46:42.505918 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 19:46:42.514141 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:46:42.514425 (Thread-1): Using postgres connection "test.my_new_project.iss_issuer".
2021-11-19 19:46:42.514675 (Thread-1): On test.my_new_project.iss_issuer: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.iss_issuer"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      

select 1 from "demo_db"."dev_dwh"."iss_issuer" iss where isin is null
      
    ) dbt_internal_test
2021-11-19 19:46:42.515007 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:46:42.515157 (Thread-2): Using postgres connection "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710".
2021-11-19 19:46:42.515284 (Thread-2): On test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from "demo_db"."dev"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
2021-11-19 19:46:42.515691 (Thread-1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:46:42.517206 (Thread-1): finished collecting timing info
2021-11-19 19:46:42.517394 (Thread-2): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:46:42.517559 (Thread-1): On test.my_new_project.iss_issuer: ROLLBACK
2021-11-19 19:46:42.518503 (Thread-2): finished collecting timing info
2021-11-19 19:46:42.518718 (Thread-2): On test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
2021-11-19 19:46:42.518852 (Thread-1): On test.my_new_project.iss_issuer: Close
2021-11-19 19:46:42.518973 (Thread-2): On test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710: Close
2021-11-19 19:46:42.519266 (Thread-1): 20:46:42 | 1 of 5 PASS iss_issuer............................................... [PASS in 0.05s]
2021-11-19 19:46:42.519580 (Thread-2): 20:46:42 | 2 of 5 PASS not_null_my_first_dbt_model_id........................... [PASS in 0.05s]
2021-11-19 19:46:42.519751 (Thread-1): Finished running node test.my_new_project.iss_issuer
2021-11-19 19:46:42.520010 (Thread-1): Began running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2021-11-19 19:46:42.520297 (Thread-2): Finished running node test.my_new_project.not_null_my_first_dbt_model_id.5fb22c2710
2021-11-19 19:46:42.520461 (Thread-1): 20:46:42 | 3 of 5 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-11-19 19:46:42.520652 (Thread-2): Began running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2021-11-19 19:46:42.521082 (Thread-1): Acquiring new postgres connection "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778".
2021-11-19 19:46:42.521229 (Thread-2): 20:46:42 | 4 of 5 START test unique_my_first_dbt_model_id....................... [RUN]
2021-11-19 19:46:42.521398 (Thread-1): Compiling test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2021-11-19 19:46:42.521716 (Thread-2): Acquiring new postgres connection "test.my_new_project.unique_my_first_dbt_model_id.16e066b321".
2021-11-19 19:46:42.524425 (Thread-1): Writing injected SQL for node "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"
2021-11-19 19:46:42.524603 (Thread-2): Compiling test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2021-11-19 19:46:42.529538 (Thread-2): Writing injected SQL for node "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"
2021-11-19 19:46:42.529994 (Thread-1): finished collecting timing info
2021-11-19 19:46:42.531482 (Thread-1): Writing runtime SQL for node "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"
2021-11-19 19:46:42.531827 (Thread-2): finished collecting timing info
2021-11-19 19:46:42.532120 (Thread-1): Using postgres connection "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778".
2021-11-19 19:46:42.533227 (Thread-2): Writing runtime SQL for node "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"
2021-11-19 19:46:42.533378 (Thread-1): On test.my_new_project.not_null_my_second_dbt_model_id.151b76d778: BEGIN
2021-11-19 19:46:42.533626 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 19:46:42.533988 (Thread-2): Using postgres connection "test.my_new_project.unique_my_first_dbt_model_id.16e066b321".
2021-11-19 19:46:42.534093 (Thread-2): On test.my_new_project.unique_my_first_dbt_model_id.16e066b321: BEGIN
2021-11-19 19:46:42.534192 (Thread-2): Opening a new connection, currently in state closed
2021-11-19 19:46:42.539717 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:46:42.539961 (Thread-2): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:46:42.540130 (Thread-1): Using postgres connection "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778".
2021-11-19 19:46:42.540309 (Thread-2): Using postgres connection "test.my_new_project.unique_my_first_dbt_model_id.16e066b321".
2021-11-19 19:46:42.540447 (Thread-1): On test.my_new_project.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from "demo_db"."dev"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
2021-11-19 19:46:42.540585 (Thread-2): On test.my_new_project.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "demo_db"."dev"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
2021-11-19 19:46:42.541379 (Thread-1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:46:42.541640 (Thread-2): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:46:42.542674 (Thread-1): finished collecting timing info
2021-11-19 19:46:42.544905 (Thread-2): finished collecting timing info
2021-11-19 19:46:42.545132 (Thread-1): On test.my_new_project.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
2021-11-19 19:46:42.545331 (Thread-2): On test.my_new_project.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
2021-11-19 19:46:42.545695 (Thread-1): On test.my_new_project.not_null_my_second_dbt_model_id.151b76d778: Close
2021-11-19 19:46:42.545845 (Thread-2): On test.my_new_project.unique_my_first_dbt_model_id.16e066b321: Close
2021-11-19 19:46:42.546224 (Thread-1): 20:46:42 | 3 of 5 PASS not_null_my_second_dbt_model_id.......................... [PASS in 0.03s]
2021-11-19 19:46:42.546511 (Thread-2): 20:46:42 | 4 of 5 FAIL 1 unique_my_first_dbt_model_id........................... [FAIL 1 in 0.02s]
2021-11-19 19:46:42.546729 (Thread-1): Finished running node test.my_new_project.not_null_my_second_dbt_model_id.151b76d778
2021-11-19 19:46:42.547046 (Thread-2): Finished running node test.my_new_project.unique_my_first_dbt_model_id.16e066b321
2021-11-19 19:46:42.547326 (Thread-1): Began running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2021-11-19 19:46:42.547740 (Thread-1): 20:46:42 | 5 of 5 START test unique_my_second_dbt_model_id...................... [RUN]
2021-11-19 19:46:42.548023 (Thread-1): Acquiring new postgres connection "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493".
2021-11-19 19:46:42.548139 (Thread-1): Compiling test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2021-11-19 19:46:42.551326 (Thread-1): Writing injected SQL for node "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"
2021-11-19 19:46:42.551600 (Thread-1): finished collecting timing info
2021-11-19 19:46:42.553027 (Thread-1): Writing runtime SQL for node "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"
2021-11-19 19:46:42.553248 (Thread-1): Using postgres connection "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493".
2021-11-19 19:46:42.553373 (Thread-1): On test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
2021-11-19 19:46:42.553474 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 19:46:42.559289 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:46:42.559473 (Thread-1): Using postgres connection "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493".
2021-11-19 19:46:42.559567 (Thread-1): On test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "demo_db"."dev"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
2021-11-19 19:46:42.560412 (Thread-1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:46:42.561480 (Thread-1): finished collecting timing info
2021-11-19 19:46:42.561642 (Thread-1): On test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
2021-11-19 19:46:42.562016 (Thread-1): On test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493: Close
2021-11-19 19:46:42.562409 (Thread-1): 20:46:42 | 5 of 5 FAIL 1 unique_my_second_dbt_model_id.......................... [FAIL 1 in 0.01s]
2021-11-19 19:46:42.562591 (Thread-1): Finished running node test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493
2021-11-19 19:46:42.564131 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:46:42.564377 (MainThread): 20:46:42 | 
2021-11-19 19:46:42.564520 (MainThread): 20:46:42 | Finished running 5 tests in 0.15s.
2021-11-19 19:46:42.564651 (MainThread): Connection 'master' was properly closed.
2021-11-19 19:46:42.564746 (MainThread): Connection 'test.my_new_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
2021-11-19 19:46:42.564833 (MainThread): Connection 'test.my_new_project.unique_my_first_dbt_model_id.16e066b321' was properly closed.
2021-11-19 19:46:42.568027 (MainThread): 
2021-11-19 19:46:42.568178 (MainThread): Completed with 2 errors and 0 warnings:
2021-11-19 19:46:42.568358 (MainThread): 
2021-11-19 19:46:42.568561 (MainThread): Failure in test unique_my_first_dbt_model_id (models/example/schema.yml)
2021-11-19 19:46:42.568711 (MainThread):   Got 1 result, configured to fail if != 0
2021-11-19 19:46:42.568878 (MainThread): 
2021-11-19 19:46:42.569080 (MainThread):   compiled SQL at target/compiled/my_new_project/models/example/schema.yml/schema_test/unique_my_first_dbt_model_id.sql
2021-11-19 19:46:42.569260 (MainThread): 
2021-11-19 19:46:42.569452 (MainThread): Failure in test unique_my_second_dbt_model_id (models/example/schema.yml)
2021-11-19 19:46:42.569577 (MainThread):   Got 1 result, configured to fail if != 0
2021-11-19 19:46:42.569714 (MainThread): 
2021-11-19 19:46:42.569841 (MainThread):   compiled SQL at target/compiled/my_new_project/models/example/schema.yml/schema_test/unique_my_second_dbt_model_id.sql
2021-11-19 19:46:42.569981 (MainThread): 
Done. PASS=3 WARN=0 ERROR=2 SKIP=0 TOTAL=5
2021-11-19 19:46:42.570164 (MainThread): Flushing usage events
2021-11-19 19:53:47.105331 (MainThread): Running with dbt=0.21.0
2021-11-19 19:53:47.159303 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['tag:cast_numeric'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2021-11-19 19:53:47.159748 (MainThread): Tracking: do not track
2021-11-19 19:53:47.169726 (MainThread): Partial parsing not enabled
2021-11-19 19:53:47.176253 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 19:53:47.176850 (MainThread): Parsing macros/adapters.sql
2021-11-19 19:53:47.193800 (MainThread): Parsing macros/catalog.sql
2021-11-19 19:53:47.195510 (MainThread): Parsing macros/relations.sql
2021-11-19 19:53:47.196423 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 19:53:47.197648 (MainThread): Parsing macros/core.sql
2021-11-19 19:53:47.201167 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 19:53:47.242442 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 19:53:47.244284 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 19:53:47.245716 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 19:53:47.246872 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 19:53:47.253252 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 19:53:47.254377 (MainThread): Parsing macros/etc/query.sql
2021-11-19 19:53:47.255099 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 19:53:47.256280 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 19:53:47.263594 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 19:53:47.268634 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 19:53:47.285481 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 19:53:47.286909 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 19:53:47.311464 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 19:53:47.324789 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 19:53:47.339348 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 19:53:47.347080 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 19:53:47.348396 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 19:53:47.358683 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 19:53:47.361627 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 19:53:47.366881 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 19:53:47.372401 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 19:53:47.373465 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 19:53:47.374417 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 19:53:47.375731 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 19:53:47.527322 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:53:47.536810 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:53:47.539680 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:53:47.542144 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:53:47.542357 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:53:47.543244 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:53:47.546581 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:53:47.546787 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:53:47.547634 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:53:47.552157 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:53:47.552434 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:53:47.559746 (MainThread): Acquiring new postgres connection "test.my_new_project.cast_numeric".
2021-11-19 19:53:47.564034 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:53:47.564819 (MainThread): Acquiring new postgres connection "test.my_new_project.iss_issuer".
2021-11-19 19:53:47.566849 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:53:47.575061 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:53:47.576712 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:53:47.578256 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:53:47.579692 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:53:47.597263 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:53:47.598696 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:53:47.600126 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:53:47.601449 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:53:47.619029 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 19:53:47.619455 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 19:53:47.620888 (MainThread): 
2021-11-19 19:53:47.621335 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:53:47.622355 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:53:47.628128 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev_dm".
2021-11-19 19:53:47.631288 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:53:47.632665 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 19:53:47.632900 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: BEGIN
2021-11-19 19:53:47.633129 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: BEGIN
2021-11-19 19:53:47.633340 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-11-19 19:53:47.633583 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-19 19:53:47.641264 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:53:47.641570 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:53:47.641800 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 19:53:47.642033 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:53:47.642250 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dm'
  
2021-11-19 19:53:47.642479 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dwh'
  
2021-11-19 19:53:47.644642 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:53:47.644846 (ThreadPoolExecutor-1_1): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 19:53:47.645979 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: ROLLBACK
2021-11-19 19:53:47.646852 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: ROLLBACK
2021-11-19 19:53:47.647668 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: Close
2021-11-19 19:53:47.647833 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: Close
2021-11-19 19:53:47.648538 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev_sa".
2021-11-19 19:53:47.648949 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev".
2021-11-19 19:53:47.650413 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 19:53:47.651504 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev".
2021-11-19 19:53:47.651687 (ThreadPoolExecutor-1_1): On list_demo_db_dev_sa: BEGIN
2021-11-19 19:53:47.651877 (ThreadPoolExecutor-1_0): On list_demo_db_dev: BEGIN
2021-11-19 19:53:47.652101 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 19:53:47.652285 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 19:53:47.660780 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:53:47.661032 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 19:53:47.661192 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:53:47.661427 (ThreadPoolExecutor-1_1): On list_demo_db_dev_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_sa'
  
2021-11-19 19:53:47.661572 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev".
2021-11-19 19:53:47.661810 (ThreadPoolExecutor-1_0): On list_demo_db_dev: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev'
  
2021-11-19 19:53:47.663708 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:53:47.664726 (ThreadPoolExecutor-1_1): On list_demo_db_dev_sa: ROLLBACK
2021-11-19 19:53:47.664888 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 19:53:47.666134 (ThreadPoolExecutor-1_0): On list_demo_db_dev: ROLLBACK
2021-11-19 19:53:47.666259 (ThreadPoolExecutor-1_1): On list_demo_db_dev_sa: Close
2021-11-19 19:53:47.666956 (ThreadPoolExecutor-1_0): On list_demo_db_dev: Close
2021-11-19 19:53:47.670883 (MainThread): Using postgres connection "master".
2021-11-19 19:53:47.671022 (MainThread): On master: BEGIN
2021-11-19 19:53:47.671121 (MainThread): Opening a new connection, currently in state init
2021-11-19 19:53:47.677796 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:53:47.677973 (MainThread): Using postgres connection "master".
2021-11-19 19:53:47.678079 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 19:53:47.686036 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-11-19 19:53:47.686990 (MainThread): On master: ROLLBACK
2021-11-19 19:53:47.687465 (MainThread): On master: Close
2021-11-19 19:53:47.687826 (MainThread): 20:53:47 | Concurrency: 2 threads (target='dev')
2021-11-19 19:53:47.687972 (MainThread): 20:53:47 | 
2021-11-19 19:53:47.690626 (Thread-1): Began running node test.my_new_project.cast_numeric
2021-11-19 19:53:47.690913 (Thread-1): 20:53:47 | 1 of 1 START test cast_numeric....................................... [RUN]
2021-11-19 19:53:47.691311 (Thread-1): Acquiring new postgres connection "test.my_new_project.cast_numeric".
2021-11-19 19:53:47.691439 (Thread-1): Compiling test.my_new_project.cast_numeric
2021-11-19 19:53:47.695140 (Thread-1): Writing injected SQL for node "test.my_new_project.cast_numeric"
2021-11-19 19:53:47.695527 (Thread-1): finished collecting timing info
2021-11-19 19:53:47.708003 (Thread-1): Writing runtime SQL for node "test.my_new_project.cast_numeric"
2021-11-19 19:53:47.708348 (Thread-1): Using postgres connection "test.my_new_project.cast_numeric".
2021-11-19 19:53:47.708453 (Thread-1): On test.my_new_project.cast_numeric: BEGIN
2021-11-19 19:53:47.708552 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 19:53:47.715416 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:53:47.715595 (Thread-1): Using postgres connection "test.my_new_project.cast_numeric".
2021-11-19 19:53:47.715690 (Thread-1): On test.my_new_project.cast_numeric: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.cast_numeric"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      

with test as (
    select case CASE
        WHEN a ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN a::numeric
    ELSE NULL
    END = NULL then 'ok' else 'nok' end as result
    select case CASE
        WHEN 0 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN 0::numeric
    ELSE NULL
    END = NULL then 'ok' else 'nok' end as result
    select case CASE
        WHEN 100 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN 100::numeric
    ELSE NULL
    END = 100 then 'ok' else 'nok' end as result
    select case CASE
        WHEN -100 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN -100::numeric
    ELSE NULL
    END = -100 then 'ok' else 'nok' end as result
    select case CASE
        WHEN 1.0 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN 1.0::numeric
    ELSE NULL
    END = 1 then 'ok' else 'nok' end as result
    select case CASE
        WHEN -1.0 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN -1.0::numeric
    ELSE NULL
    END = -1 then 'ok' else 'nok' end as result
    select case CASE
        WHEN -1.5 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN -1.5::numeric
    ELSE NULL
    END = 1.5 then 'ok' else 'nok' end as result
    select case CASE
        WHEN -1.5 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN -1.5::numeric
    ELSE NULL
    END = -1.5 then 'ok' else 'nok' end as result
    select case CASE
        WHEN -00.5 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN -00.5::numeric
    ELSE NULL
    END = 0.5 then 'ok' else 'nok' end as result
    select case CASE
        WHEN -0.5 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN -0.5::numeric
    ELSE NULL
    END = -0.5 then 'ok' else 'nok' end as result

)

select 1 from test where result = 'nok'
      
    ) dbt_internal_test
2021-11-19 19:53:47.716114 (Thread-1): Postgres error: syntax error at or near "then"
LINE 14:     END = NULL then 'ok' else 'nok' end as result
                        ^

2021-11-19 19:53:47.716273 (Thread-1): On test.my_new_project.cast_numeric: ROLLBACK
2021-11-19 19:53:47.716661 (Thread-1): finished collecting timing info
2021-11-19 19:53:47.716873 (Thread-1): On test.my_new_project.cast_numeric: Close
2021-11-19 19:53:47.717261 (Thread-1): Database Error in test cast_numeric (tests/macro/cast_numeric.sql)
  syntax error at or near "then"
  LINE 14:     END = NULL then 'ok' else 'nok' end as result
                          ^
  compiled SQL at target/run/my_new_project/tests/macro/cast_numeric.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "then"
LINE 14:     END = NULL then 'ok' else 'nok' end as result
                        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/test.py", line 112, in execute
    result = self.execute_test(test, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/test.py", line 82, in execute_test
    macro_func()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 132, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in test cast_numeric (tests/macro/cast_numeric.sql)
  syntax error at or near "then"
  LINE 14:     END = NULL then 'ok' else 'nok' end as result
                          ^
  compiled SQL at target/run/my_new_project/tests/macro/cast_numeric.sql
2021-11-19 19:53:47.718417 (Thread-1): 20:53:47 | 1 of 1 ERROR cast_numeric............................................ [ERROR in 0.03s]
2021-11-19 19:53:47.718593 (Thread-1): Finished running node test.my_new_project.cast_numeric
2021-11-19 19:53:47.719997 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:53:47.720264 (MainThread): 20:53:47 | 
2021-11-19 19:53:47.720423 (MainThread): 20:53:47 | Finished running 1 test in 0.10s.
2021-11-19 19:53:47.720558 (MainThread): Connection 'master' was properly closed.
2021-11-19 19:53:47.720656 (MainThread): Connection 'test.my_new_project.cast_numeric' was properly closed.
2021-11-19 19:53:47.720744 (MainThread): Connection 'list_demo_db_dev_sa' was properly closed.
2021-11-19 19:53:47.724006 (MainThread): 
2021-11-19 19:53:47.724190 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 19:53:47.724333 (MainThread): 
2021-11-19 19:53:47.724471 (MainThread): Database Error in test cast_numeric (tests/macro/cast_numeric.sql)
2021-11-19 19:53:47.724600 (MainThread):   syntax error at or near "then"
2021-11-19 19:53:47.724722 (MainThread):   LINE 14:     END = NULL then 'ok' else 'nok' end as result
2021-11-19 19:53:47.724842 (MainThread):                           ^
2021-11-19 19:53:47.724962 (MainThread):   compiled SQL at target/run/my_new_project/tests/macro/cast_numeric.sql
2021-11-19 19:53:47.725091 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-11-19 19:53:47.725298 (MainThread): Flushing usage events
2021-11-19 19:54:25.134861 (MainThread): Running with dbt=0.21.0
2021-11-19 19:54:25.189254 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['tag:cast_numeric'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2021-11-19 19:54:25.189684 (MainThread): Tracking: do not track
2021-11-19 19:54:25.199090 (MainThread): Partial parsing not enabled
2021-11-19 19:54:25.205782 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 19:54:25.206389 (MainThread): Parsing macros/adapters.sql
2021-11-19 19:54:25.223806 (MainThread): Parsing macros/catalog.sql
2021-11-19 19:54:25.225717 (MainThread): Parsing macros/relations.sql
2021-11-19 19:54:25.226661 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 19:54:25.227871 (MainThread): Parsing macros/core.sql
2021-11-19 19:54:25.230672 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 19:54:25.270449 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 19:54:25.272291 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 19:54:25.273632 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 19:54:25.274846 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 19:54:25.281117 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 19:54:25.282216 (MainThread): Parsing macros/etc/query.sql
2021-11-19 19:54:25.283058 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 19:54:25.284158 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 19:54:25.291465 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 19:54:25.296518 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 19:54:25.313897 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 19:54:25.315199 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 19:54:25.337472 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 19:54:25.350370 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 19:54:25.364412 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 19:54:25.372229 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 19:54:25.373520 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 19:54:25.383448 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 19:54:25.388978 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 19:54:25.395379 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 19:54:25.401095 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 19:54:25.402103 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 19:54:25.403062 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 19:54:25.404401 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 19:54:25.557456 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:54:25.566830 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:54:25.569572 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:54:25.572251 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:54:25.572464 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:54:25.573274 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:54:25.576485 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:54:25.576689 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:54:25.577496 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:54:25.582047 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:54:25.582251 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:54:25.589359 (MainThread): Acquiring new postgres connection "test.my_new_project.cast_numeric".
2021-11-19 19:54:25.593668 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:54:25.594448 (MainThread): Acquiring new postgres connection "test.my_new_project.iss_issuer".
2021-11-19 19:54:25.596473 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:54:25.604530 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:54:25.606064 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:54:25.607494 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:54:25.608887 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:54:25.626290 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:54:25.627660 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:54:25.629124 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:54:25.631052 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:54:25.646096 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 19:54:25.646404 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 19:54:25.648090 (MainThread): 
2021-11-19 19:54:25.648516 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:54:25.649568 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev".
2021-11-19 19:54:25.655218 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev_sa".
2021-11-19 19:54:25.659048 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 19:54:25.659188 (ThreadPoolExecutor-1_1): On list_demo_db_dev_sa: BEGIN
2021-11-19 19:54:25.659321 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-19 19:54:25.661980 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev".
2021-11-19 19:54:25.662105 (ThreadPoolExecutor-1_0): On list_demo_db_dev: BEGIN
2021-11-19 19:54:25.662221 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-11-19 19:54:25.666911 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:54:25.667056 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 19:54:25.667142 (ThreadPoolExecutor-1_1): On list_demo_db_dev_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_sa'
  
2021-11-19 19:54:25.668983 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:54:25.669201 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev".
2021-11-19 19:54:25.669311 (ThreadPoolExecutor-1_0): On list_demo_db_dev: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev'
  
2021-11-19 19:54:25.669600 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:54:25.670707 (ThreadPoolExecutor-1_1): On list_demo_db_dev_sa: ROLLBACK
2021-11-19 19:54:25.671002 (ThreadPoolExecutor-1_1): On list_demo_db_dev_sa: Close
2021-11-19 19:54:25.671205 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 19:54:25.671687 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev_dm".
2021-11-19 19:54:25.672582 (ThreadPoolExecutor-1_0): On list_demo_db_dev: ROLLBACK
2021-11-19 19:54:25.673789 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 19:54:25.674051 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: BEGIN
2021-11-19 19:54:25.674268 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 19:54:25.674571 (ThreadPoolExecutor-1_0): On list_demo_db_dev: Close
2021-11-19 19:54:25.674973 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:54:25.676503 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:54:25.676617 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: BEGIN
2021-11-19 19:54:25.676714 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 19:54:25.680741 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:54:25.680945 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 19:54:25.681036 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dm'
  
2021-11-19 19:54:25.682932 (ThreadPoolExecutor-1_1): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 19:54:25.683864 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: ROLLBACK
2021-11-19 19:54:25.684028 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:54:25.684144 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: Close
2021-11-19 19:54:25.684323 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:54:25.684797 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dwh'
  
2021-11-19 19:54:25.686589 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:54:25.687527 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: ROLLBACK
2021-11-19 19:54:25.687883 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: Close
2021-11-19 19:54:25.691482 (MainThread): Using postgres connection "master".
2021-11-19 19:54:25.691597 (MainThread): On master: BEGIN
2021-11-19 19:54:25.691694 (MainThread): Opening a new connection, currently in state init
2021-11-19 19:54:25.699182 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:54:25.699361 (MainThread): Using postgres connection "master".
2021-11-19 19:54:25.699464 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 19:54:25.707433 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-11-19 19:54:25.708410 (MainThread): On master: ROLLBACK
2021-11-19 19:54:25.708743 (MainThread): On master: Close
2021-11-19 19:54:25.709055 (MainThread): 20:54:25 | Concurrency: 2 threads (target='dev')
2021-11-19 19:54:25.709209 (MainThread): 20:54:25 | 
2021-11-19 19:54:25.711334 (Thread-1): Began running node test.my_new_project.cast_numeric
2021-11-19 19:54:25.711554 (Thread-1): 20:54:25 | 1 of 1 START test cast_numeric....................................... [RUN]
2021-11-19 19:54:25.711836 (Thread-1): Acquiring new postgres connection "test.my_new_project.cast_numeric".
2021-11-19 19:54:25.711956 (Thread-1): Compiling test.my_new_project.cast_numeric
2021-11-19 19:54:25.715577 (Thread-1): Writing injected SQL for node "test.my_new_project.cast_numeric"
2021-11-19 19:54:25.715789 (Thread-1): finished collecting timing info
2021-11-19 19:54:25.728195 (Thread-1): Writing runtime SQL for node "test.my_new_project.cast_numeric"
2021-11-19 19:54:25.728465 (Thread-1): Using postgres connection "test.my_new_project.cast_numeric".
2021-11-19 19:54:25.728564 (Thread-1): On test.my_new_project.cast_numeric: BEGIN
2021-11-19 19:54:25.728660 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 19:54:25.734966 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:54:25.735121 (Thread-1): Using postgres connection "test.my_new_project.cast_numeric".
2021-11-19 19:54:25.735208 (Thread-1): On test.my_new_project.cast_numeric: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.cast_numeric"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      

with test as (
    select case when CASE
        WHEN a ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN a::numeric
    ELSE NULL
    END = NULL then 'ok' else 'nok' end as result
    select case when CASE
        WHEN 0 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN 0::numeric
    ELSE NULL
    END = NULL then 'ok' else 'nok' end as result
    select case when CASE
        WHEN 100 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN 100::numeric
    ELSE NULL
    END = 100 then 'ok' else 'nok' end as result
    select case when CASE
        WHEN -100 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN -100::numeric
    ELSE NULL
    END = -100 then 'ok' else 'nok' end as result
    select case when CASE
        WHEN 1.0 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN 1.0::numeric
    ELSE NULL
    END = 1 then 'ok' else 'nok' end as result
    select case when CASE
        WHEN -1.0 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN -1.0::numeric
    ELSE NULL
    END = -1 then 'ok' else 'nok' end as result
    select case when CASE
        WHEN -1.5 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN -1.5::numeric
    ELSE NULL
    END = 1.5 then 'ok' else 'nok' end as result
    select case when CASE
        WHEN -1.5 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN -1.5::numeric
    ELSE NULL
    END = -1.5 then 'ok' else 'nok' end as result
    select case when CASE
        WHEN -00.5 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN -00.5::numeric
    ELSE NULL
    END = 0.5 then 'ok' else 'nok' end as result
    select case when CASE
        WHEN -0.5 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN -0.5::numeric
    ELSE NULL
    END = -0.5 then 'ok' else 'nok' end as result

)

select 1 from test where result = 'nok'
      
    ) dbt_internal_test
2021-11-19 19:54:25.735996 (Thread-1): Postgres error: syntax error at or near "select"
LINE 15:     select case when CASE
             ^

2021-11-19 19:54:25.736224 (Thread-1): On test.my_new_project.cast_numeric: ROLLBACK
2021-11-19 19:54:25.736768 (Thread-1): finished collecting timing info
2021-11-19 19:54:25.736904 (Thread-1): On test.my_new_project.cast_numeric: Close
2021-11-19 19:54:25.737425 (Thread-1): Database Error in test cast_numeric (tests/macro/cast_numeric.sql)
  syntax error at or near "select"
  LINE 15:     select case when CASE
               ^
  compiled SQL at target/run/my_new_project/tests/macro/cast_numeric.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "select"
LINE 15:     select case when CASE
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/test.py", line 112, in execute
    result = self.execute_test(test, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/test.py", line 82, in execute_test
    macro_func()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 132, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in test cast_numeric (tests/macro/cast_numeric.sql)
  syntax error at or near "select"
  LINE 15:     select case when CASE
               ^
  compiled SQL at target/run/my_new_project/tests/macro/cast_numeric.sql
2021-11-19 19:54:25.738638 (Thread-1): 20:54:25 | 1 of 1 ERROR cast_numeric............................................ [ERROR in 0.03s]
2021-11-19 19:54:25.738790 (Thread-1): Finished running node test.my_new_project.cast_numeric
2021-11-19 19:54:25.739998 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:54:25.740230 (MainThread): 20:54:25 | 
2021-11-19 19:54:25.740372 (MainThread): 20:54:25 | Finished running 1 test in 0.09s.
2021-11-19 19:54:25.740500 (MainThread): Connection 'master' was properly closed.
2021-11-19 19:54:25.740597 (MainThread): Connection 'test.my_new_project.cast_numeric' was properly closed.
2021-11-19 19:54:25.740683 (MainThread): Connection 'list_demo_db_dev_dm' was properly closed.
2021-11-19 19:54:25.743743 (MainThread): 
2021-11-19 19:54:25.743891 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 19:54:25.744026 (MainThread): 
2021-11-19 19:54:25.744215 (MainThread): Database Error in test cast_numeric (tests/macro/cast_numeric.sql)
2021-11-19 19:54:25.744325 (MainThread):   syntax error at or near "select"
2021-11-19 19:54:25.744441 (MainThread):   LINE 15:     select case when CASE
2021-11-19 19:54:25.744562 (MainThread):                ^
2021-11-19 19:54:25.744906 (MainThread):   compiled SQL at target/run/my_new_project/tests/macro/cast_numeric.sql
2021-11-19 19:54:25.745099 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-11-19 19:54:25.745463 (MainThread): Flushing usage events
2021-11-19 19:55:00.177886 (MainThread): Running with dbt=0.21.0
2021-11-19 19:55:00.232646 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['tag:cast_numeric'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2021-11-19 19:55:00.233121 (MainThread): Tracking: do not track
2021-11-19 19:55:00.242757 (MainThread): Partial parsing not enabled
2021-11-19 19:55:00.249458 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 19:55:00.250131 (MainThread): Parsing macros/adapters.sql
2021-11-19 19:55:00.267368 (MainThread): Parsing macros/catalog.sql
2021-11-19 19:55:00.269054 (MainThread): Parsing macros/relations.sql
2021-11-19 19:55:00.269992 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 19:55:00.271318 (MainThread): Parsing macros/core.sql
2021-11-19 19:55:00.274183 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 19:55:00.317696 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 19:55:00.319680 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 19:55:00.321279 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 19:55:00.322483 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 19:55:00.328849 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 19:55:00.330054 (MainThread): Parsing macros/etc/query.sql
2021-11-19 19:55:00.330778 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 19:55:00.331911 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 19:55:00.339197 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 19:55:00.344451 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 19:55:00.361513 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 19:55:00.362781 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 19:55:00.385017 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 19:55:00.398227 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 19:55:00.412455 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 19:55:00.420342 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 19:55:00.421832 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 19:55:00.431856 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 19:55:00.434823 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 19:55:00.440096 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 19:55:00.445396 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 19:55:00.446414 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 19:55:00.447335 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 19:55:00.448562 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 19:55:00.603624 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:55:00.613531 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:55:00.616478 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:55:00.618950 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:55:00.619159 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:55:00.619956 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:55:00.623398 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:55:00.623612 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:55:00.624420 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:55:00.629192 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:55:00.629396 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:55:00.636691 (MainThread): Acquiring new postgres connection "test.my_new_project.cast_numeric".
2021-11-19 19:55:00.641117 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:55:00.641920 (MainThread): Acquiring new postgres connection "test.my_new_project.iss_issuer".
2021-11-19 19:55:00.643916 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:55:00.652227 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:55:00.653854 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:55:00.655377 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:55:00.656885 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:55:00.674252 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:55:00.675614 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:55:00.677086 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:55:00.678465 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:55:00.692381 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 19:55:00.692689 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 19:55:00.693907 (MainThread): 
2021-11-19 19:55:00.694168 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:55:00.695112 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev_sa".
2021-11-19 19:55:00.700915 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev_dm".
2021-11-19 19:55:00.704972 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 19:55:00.705117 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: BEGIN
2021-11-19 19:55:00.705284 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-19 19:55:00.708949 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 19:55:00.709348 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: BEGIN
2021-11-19 19:55:00.709472 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-11-19 19:55:00.713442 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:55:00.713653 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 19:55:00.713749 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dm'
  
2021-11-19 19:55:00.715878 (ThreadPoolExecutor-1_1): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 19:55:00.717173 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: ROLLBACK
2021-11-19 19:55:00.717361 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:55:00.717618 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 19:55:00.717764 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_sa'
  
2021-11-19 19:55:00.717957 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: Close
2021-11-19 19:55:00.718994 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev".
2021-11-19 19:55:00.720564 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev".
2021-11-19 19:55:00.720905 (ThreadPoolExecutor-1_1): On list_demo_db_dev: BEGIN
2021-11-19 19:55:00.721146 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 19:55:00.721359 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:55:00.722600 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: ROLLBACK
2021-11-19 19:55:00.722933 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: Close
2021-11-19 19:55:00.723385 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:55:00.724955 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:55:00.725075 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: BEGIN
2021-11-19 19:55:00.725200 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 19:55:00.727492 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:55:00.727659 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev".
2021-11-19 19:55:00.727766 (ThreadPoolExecutor-1_1): On list_demo_db_dev: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev'
  
2021-11-19 19:55:00.729519 (ThreadPoolExecutor-1_1): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 19:55:00.730500 (ThreadPoolExecutor-1_1): On list_demo_db_dev: ROLLBACK
2021-11-19 19:55:00.730909 (ThreadPoolExecutor-1_1): On list_demo_db_dev: Close
2021-11-19 19:55:00.731110 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:55:00.731555 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:55:00.731822 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dwh'
  
2021-11-19 19:55:00.733565 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:55:00.734506 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: ROLLBACK
2021-11-19 19:55:00.734800 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: Close
2021-11-19 19:55:00.738381 (MainThread): Using postgres connection "master".
2021-11-19 19:55:00.738537 (MainThread): On master: BEGIN
2021-11-19 19:55:00.738647 (MainThread): Opening a new connection, currently in state init
2021-11-19 19:55:00.744200 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:55:00.744373 (MainThread): Using postgres connection "master".
2021-11-19 19:55:00.744476 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 19:55:00.752276 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-11-19 19:55:00.753430 (MainThread): On master: ROLLBACK
2021-11-19 19:55:00.753783 (MainThread): On master: Close
2021-11-19 19:55:00.754167 (MainThread): 20:55:00 | Concurrency: 2 threads (target='dev')
2021-11-19 19:55:00.754419 (MainThread): 20:55:00 | 
2021-11-19 19:55:00.756830 (Thread-1): Began running node test.my_new_project.cast_numeric
2021-11-19 19:55:00.757171 (Thread-1): 20:55:00 | 1 of 1 START test cast_numeric....................................... [RUN]
2021-11-19 19:55:00.757593 (Thread-1): Acquiring new postgres connection "test.my_new_project.cast_numeric".
2021-11-19 19:55:00.757754 (Thread-1): Compiling test.my_new_project.cast_numeric
2021-11-19 19:55:00.761627 (Thread-1): Writing injected SQL for node "test.my_new_project.cast_numeric"
2021-11-19 19:55:00.761886 (Thread-1): finished collecting timing info
2021-11-19 19:55:00.774672 (Thread-1): Writing runtime SQL for node "test.my_new_project.cast_numeric"
2021-11-19 19:55:00.775013 (Thread-1): Using postgres connection "test.my_new_project.cast_numeric".
2021-11-19 19:55:00.775117 (Thread-1): On test.my_new_project.cast_numeric: BEGIN
2021-11-19 19:55:00.775216 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 19:55:00.781686 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:55:00.781873 (Thread-1): Using postgres connection "test.my_new_project.cast_numeric".
2021-11-19 19:55:00.781965 (Thread-1): On test.my_new_project.cast_numeric: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.cast_numeric"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      

with test as (
    select case when CASE
        WHEN a ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN a::numeric
    ELSE NULL
    END = NULL       then 'ok' else 'nok' end as result union
    select case when CASE
        WHEN 0 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN 0::numeric
    ELSE NULL
    END = NULL       then 'ok' else 'nok' end as result union
    select case when CASE
        WHEN 100 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN 100::numeric
    ELSE NULL
    END = 100      then 'ok' else 'nok' end as result union
    select case when CASE
        WHEN -100 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN -100::numeric
    ELSE NULL
    END = -100    then 'ok' else 'nok' end as result union
    select case when CASE
        WHEN 1.0 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN 1.0::numeric
    ELSE NULL
    END = 1        then 'ok' else 'nok' end as result union
    select case when CASE
        WHEN -1.0 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN -1.0::numeric
    ELSE NULL
    END = -1      then 'ok' else 'nok' end as result union
    select case when CASE
        WHEN -1.5 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN -1.5::numeric
    ELSE NULL
    END = 1.5     then 'ok' else 'nok' end as result union
    select case when CASE
        WHEN -1.5 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN -1.5::numeric
    ELSE NULL
    END = -1.5    then 'ok' else 'nok' end as result union
    select case when CASE
        WHEN -00.5 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN -00.5::numeric
    ELSE NULL
    END = 0.5    then 'ok' else 'nok' end as result union
    select case when CASE
        WHEN -0.5 ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN -0.5::numeric
    ELSE NULL
    END = -0.5    then 'ok' else 'nok' end as result

)

select 1 from test where result = 'nok'
      
    ) dbt_internal_test
2021-11-19 19:55:00.782613 (Thread-1): Postgres error: column "a" does not exist
LINE 11:         WHEN a ~ '[+-]?([0-9]*[.])?[0-9]+'
                      ^

2021-11-19 19:55:00.782781 (Thread-1): On test.my_new_project.cast_numeric: ROLLBACK
2021-11-19 19:55:00.783204 (Thread-1): finished collecting timing info
2021-11-19 19:55:00.783341 (Thread-1): On test.my_new_project.cast_numeric: Close
2021-11-19 19:55:00.783704 (Thread-1): Database Error in test cast_numeric (tests/macro/cast_numeric.sql)
  column "a" does not exist
  LINE 11:         WHEN a ~ '[+-]?([0-9]*[.])?[0-9]+'
                        ^
  compiled SQL at target/run/my_new_project/tests/macro/cast_numeric.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedColumn: column "a" does not exist
LINE 11:         WHEN a ~ '[+-]?([0-9]*[.])?[0-9]+'
                      ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/test.py", line 112, in execute
    result = self.execute_test(test, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/test.py", line 82, in execute_test
    macro_func()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 132, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in test cast_numeric (tests/macro/cast_numeric.sql)
  column "a" does not exist
  LINE 11:         WHEN a ~ '[+-]?([0-9]*[.])?[0-9]+'
                        ^
  compiled SQL at target/run/my_new_project/tests/macro/cast_numeric.sql
2021-11-19 19:55:00.784793 (Thread-1): 20:55:00 | 1 of 1 ERROR cast_numeric............................................ [ERROR in 0.03s]
2021-11-19 19:55:00.784966 (Thread-1): Finished running node test.my_new_project.cast_numeric
2021-11-19 19:55:00.786502 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:55:00.786753 (MainThread): 20:55:00 | 
2021-11-19 19:55:00.786912 (MainThread): 20:55:00 | Finished running 1 test in 0.09s.
2021-11-19 19:55:00.787097 (MainThread): Connection 'master' was properly closed.
2021-11-19 19:55:00.787251 (MainThread): Connection 'list_demo_db_dev_dwh' was properly closed.
2021-11-19 19:55:00.787378 (MainThread): Connection 'test.my_new_project.cast_numeric' was properly closed.
2021-11-19 19:55:00.790802 (MainThread): 
2021-11-19 19:55:00.790978 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 19:55:00.791224 (MainThread): 
2021-11-19 19:55:00.791496 (MainThread): Database Error in test cast_numeric (tests/macro/cast_numeric.sql)
2021-11-19 19:55:00.791691 (MainThread):   column "a" does not exist
2021-11-19 19:55:00.791887 (MainThread):   LINE 11:         WHEN a ~ '[+-]?([0-9]*[.])?[0-9]+'
2021-11-19 19:55:00.792093 (MainThread):                         ^
2021-11-19 19:55:00.792285 (MainThread):   compiled SQL at target/run/my_new_project/tests/macro/cast_numeric.sql
2021-11-19 19:55:00.792499 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-11-19 19:55:00.792804 (MainThread): Flushing usage events
2021-11-19 19:59:56.668487 (MainThread): Running with dbt=0.21.0
2021-11-19 19:59:56.723212 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['tag:cast_numeric'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2021-11-19 19:59:56.723592 (MainThread): Tracking: do not track
2021-11-19 19:59:56.734806 (MainThread): Partial parsing not enabled
2021-11-19 19:59:56.746258 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 19:59:56.747210 (MainThread): Parsing macros/adapters.sql
2021-11-19 19:59:56.769251 (MainThread): Parsing macros/catalog.sql
2021-11-19 19:59:56.770868 (MainThread): Parsing macros/relations.sql
2021-11-19 19:59:56.771776 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 19:59:56.773000 (MainThread): Parsing macros/core.sql
2021-11-19 19:59:56.775891 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 19:59:56.815556 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 19:59:56.817366 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 19:59:56.818670 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 19:59:56.819927 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 19:59:56.826243 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 19:59:56.827343 (MainThread): Parsing macros/etc/query.sql
2021-11-19 19:59:56.828054 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 19:59:56.829182 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 19:59:56.836362 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 19:59:56.841646 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 19:59:56.858590 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 19:59:56.860091 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 19:59:56.881974 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 19:59:56.898373 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 19:59:56.913356 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 19:59:56.921116 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 19:59:56.922408 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 19:59:56.932815 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 19:59:56.935772 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 19:59:56.940851 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 19:59:56.946360 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 19:59:56.947390 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 19:59:56.948381 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 19:59:56.949597 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 19:59:57.101869 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 19:59:57.111778 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 19:59:57.114501 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 19:59:57.117295 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:59:57.117509 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:59:57.118314 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 19:59:57.121584 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:59:57.121791 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:59:57.122582 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 19:59:57.127297 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:59:57.127512 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:59:57.134421 (MainThread): Acquiring new postgres connection "test.my_new_project.cast_numeric".
2021-11-19 19:59:57.136505 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:59:57.137990 (MainThread): Acquiring new postgres connection "test.my_new_project.iss_issuer".
2021-11-19 19:59:57.139972 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:59:57.148189 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:59:57.149696 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:59:57.151222 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:59:57.152651 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:59:57.170164 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:59:57.171563 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:59:57.173038 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:59:57.174600 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 19:59:57.188883 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 19:59:57.189193 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 19:59:57.190555 (MainThread): 
2021-11-19 19:59:57.190816 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:59:57.192403 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev".
2021-11-19 19:59:57.200070 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev".
2021-11-19 19:59:57.200220 (ThreadPoolExecutor-1_0): On list_demo_db_dev: BEGIN
2021-11-19 19:59:57.200343 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-11-19 19:59:57.200908 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev_sa".
2021-11-19 19:59:57.202430 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 19:59:57.202673 (ThreadPoolExecutor-1_1): On list_demo_db_dev_sa: BEGIN
2021-11-19 19:59:57.202814 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-19 19:59:57.209055 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:59:57.209423 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev".
2021-11-19 19:59:57.209616 (ThreadPoolExecutor-1_0): On list_demo_db_dev: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev'
  
2021-11-19 19:59:57.211028 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:59:57.211277 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 19:59:57.211480 (ThreadPoolExecutor-1_1): On list_demo_db_dev_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_sa'
  
2021-11-19 19:59:57.212327 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 19:59:57.213764 (ThreadPoolExecutor-1_0): On list_demo_db_dev: ROLLBACK
2021-11-19 19:59:57.214069 (ThreadPoolExecutor-1_0): On list_demo_db_dev: Close
2021-11-19 19:59:57.214536 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev_dm".
2021-11-19 19:59:57.214868 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:59:57.215941 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 19:59:57.216829 (ThreadPoolExecutor-1_1): On list_demo_db_dev_sa: ROLLBACK
2021-11-19 19:59:57.216997 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dm: BEGIN
2021-11-19 19:59:57.217238 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 19:59:57.217464 (ThreadPoolExecutor-1_1): On list_demo_db_dev_sa: Close
2021-11-19 19:59:57.217878 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:59:57.218933 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:59:57.219043 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: BEGIN
2021-11-19 19:59:57.219142 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 19:59:57.222523 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:59:57.222652 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 19:59:57.222750 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dm'
  
2021-11-19 19:59:57.224242 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:59:57.224370 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 19:59:57.224504 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dwh'
  
2021-11-19 19:59:57.224681 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 19:59:57.225733 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dm: ROLLBACK
2021-11-19 19:59:57.226017 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dm: Close
2021-11-19 19:59:57.226470 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 19:59:57.227506 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: ROLLBACK
2021-11-19 19:59:57.227774 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: Close
2021-11-19 19:59:57.231135 (MainThread): Using postgres connection "master".
2021-11-19 19:59:57.231254 (MainThread): On master: BEGIN
2021-11-19 19:59:57.231358 (MainThread): Opening a new connection, currently in state init
2021-11-19 19:59:57.236739 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:59:57.236872 (MainThread): Using postgres connection "master".
2021-11-19 19:59:57.236961 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 19:59:57.244218 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-11-19 19:59:57.245123 (MainThread): On master: ROLLBACK
2021-11-19 19:59:57.245639 (MainThread): On master: Close
2021-11-19 19:59:57.245924 (MainThread): 20:59:57 | Concurrency: 2 threads (target='dev')
2021-11-19 19:59:57.246104 (MainThread): 20:59:57 | 
2021-11-19 19:59:57.248352 (Thread-1): Began running node test.my_new_project.cast_numeric
2021-11-19 19:59:57.248544 (Thread-1): 20:59:57 | 1 of 1 START test cast_numeric....................................... [RUN]
2021-11-19 19:59:57.248832 (Thread-1): Acquiring new postgres connection "test.my_new_project.cast_numeric".
2021-11-19 19:59:57.248978 (Thread-1): Compiling test.my_new_project.cast_numeric
2021-11-19 19:59:57.250809 (Thread-1): Writing injected SQL for node "test.my_new_project.cast_numeric"
2021-11-19 19:59:57.251053 (Thread-1): finished collecting timing info
2021-11-19 19:59:57.262948 (Thread-1): Writing runtime SQL for node "test.my_new_project.cast_numeric"
2021-11-19 19:59:57.263207 (Thread-1): Using postgres connection "test.my_new_project.cast_numeric".
2021-11-19 19:59:57.263312 (Thread-1): On test.my_new_project.cast_numeric: BEGIN
2021-11-19 19:59:57.263411 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 19:59:57.269961 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 19:59:57.270190 (Thread-1): Using postgres connection "test.my_new_project.cast_numeric".
2021-11-19 19:59:57.270283 (Thread-1): On test.my_new_project.cast_numeric: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.cast_numeric"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      

with cases as (
    select 'a'  as the_case union
    select '0'  as the_case union
    select '1'  as the_case union
    select '-1' as the_case union
)

, test as (
    select
        case when CASE
        WHEN the_case ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN the_case::numeric
    ELSE NULL
    END in (null,0,1,-1) then 'ok'
        else 'nok' end as result
    from cases
)

select 1 from test where result = 'nok'
      
    ) dbt_internal_test
2021-11-19 19:59:57.270654 (Thread-1): Postgres error: syntax error at or near ")"
LINE 14: )
         ^

2021-11-19 19:59:57.270805 (Thread-1): On test.my_new_project.cast_numeric: ROLLBACK
2021-11-19 19:59:57.271161 (Thread-1): finished collecting timing info
2021-11-19 19:59:57.271295 (Thread-1): On test.my_new_project.cast_numeric: Close
2021-11-19 19:59:57.271574 (Thread-1): Database Error in test cast_numeric (tests/macro/cast_numeric.sql)
  syntax error at or near ")"
  LINE 14: )
           ^
  compiled SQL at target/run/my_new_project/tests/macro/cast_numeric.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near ")"
LINE 14: )
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/test.py", line 112, in execute
    result = self.execute_test(test, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/test.py", line 82, in execute_test
    macro_func()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 132, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in test cast_numeric (tests/macro/cast_numeric.sql)
  syntax error at or near ")"
  LINE 14: )
           ^
  compiled SQL at target/run/my_new_project/tests/macro/cast_numeric.sql
2021-11-19 19:59:57.272569 (Thread-1): 20:59:57 | 1 of 1 ERROR cast_numeric............................................ [ERROR in 0.02s]
2021-11-19 19:59:57.272715 (Thread-1): Finished running node test.my_new_project.cast_numeric
2021-11-19 19:59:57.273776 (MainThread): Acquiring new postgres connection "master".
2021-11-19 19:59:57.274006 (MainThread): 20:59:57 | 
2021-11-19 19:59:57.274139 (MainThread): 20:59:57 | Finished running 1 test in 0.08s.
2021-11-19 19:59:57.274259 (MainThread): Connection 'master' was properly closed.
2021-11-19 19:59:57.274373 (MainThread): Connection 'list_demo_db_dev_dm' was properly closed.
2021-11-19 19:59:57.274470 (MainThread): Connection 'test.my_new_project.cast_numeric' was properly closed.
2021-11-19 19:59:57.277627 (MainThread): 
2021-11-19 19:59:57.277799 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 19:59:57.277967 (MainThread): 
2021-11-19 19:59:57.278145 (MainThread): Database Error in test cast_numeric (tests/macro/cast_numeric.sql)
2021-11-19 19:59:57.278324 (MainThread):   syntax error at or near ")"
2021-11-19 19:59:57.278493 (MainThread):   LINE 14: )
2021-11-19 19:59:57.278604 (MainThread):            ^
2021-11-19 19:59:57.278713 (MainThread):   compiled SQL at target/run/my_new_project/tests/macro/cast_numeric.sql
2021-11-19 19:59:57.278859 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-11-19 19:59:57.279091 (MainThread): Flushing usage events
2021-11-19 20:00:39.988636 (MainThread): Running with dbt=0.21.0
2021-11-19 20:00:40.042858 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['tag:cast_numeric'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2021-11-19 20:00:40.043327 (MainThread): Tracking: do not track
2021-11-19 20:00:40.053229 (MainThread): Partial parsing not enabled
2021-11-19 20:00:40.059644 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 20:00:40.060410 (MainThread): Parsing macros/adapters.sql
2021-11-19 20:00:40.077932 (MainThread): Parsing macros/catalog.sql
2021-11-19 20:00:40.079599 (MainThread): Parsing macros/relations.sql
2021-11-19 20:00:40.080525 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 20:00:40.081731 (MainThread): Parsing macros/core.sql
2021-11-19 20:00:40.084560 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 20:00:40.124688 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 20:00:40.126708 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 20:00:40.128176 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 20:00:40.129368 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 20:00:40.135726 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 20:00:40.136847 (MainThread): Parsing macros/etc/query.sql
2021-11-19 20:00:40.137573 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 20:00:40.138719 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 20:00:40.149433 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 20:00:40.154933 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 20:00:40.171779 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 20:00:40.172999 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 20:00:40.195504 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 20:00:40.208889 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 20:00:40.223083 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 20:00:40.230812 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 20:00:40.232070 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 20:00:40.242103 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 20:00:40.245107 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 20:00:40.250292 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 20:00:40.255534 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 20:00:40.256551 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 20:00:40.257451 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 20:00:40.258702 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 20:00:40.408541 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 20:00:40.417892 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 20:00:40.420497 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 20:00:40.423225 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:00:40.423436 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:00:40.424224 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 20:00:40.427553 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:00:40.427776 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:00:40.428558 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 20:00:40.433093 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:00:40.433295 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:00:40.440251 (MainThread): Acquiring new postgres connection "test.my_new_project.cast_numeric".
2021-11-19 20:00:40.442189 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:00:40.443738 (MainThread): Acquiring new postgres connection "test.my_new_project.iss_issuer".
2021-11-19 20:00:40.445702 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:00:40.453347 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:00:40.454741 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:00:40.457182 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:00:40.460142 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:00:40.479069 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:00:40.480515 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:00:40.481982 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:00:40.483300 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:00:40.497811 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 20:00:40.498123 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 20:00:40.499532 (MainThread): 
2021-11-19 20:00:40.499883 (MainThread): Acquiring new postgres connection "master".
2021-11-19 20:00:40.500837 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev_dm".
2021-11-19 20:00:40.506457 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev".
2021-11-19 20:00:40.510441 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev".
2021-11-19 20:00:40.512549 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 20:00:40.512753 (ThreadPoolExecutor-1_1): On list_demo_db_dev: BEGIN
2021-11-19 20:00:40.513086 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dm: BEGIN
2021-11-19 20:00:40.513289 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-19 20:00:40.513471 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-11-19 20:00:40.520739 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:00:40.520982 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 20:00:40.521144 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dm'
  
2021-11-19 20:00:40.521618 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:00:40.521805 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev".
2021-11-19 20:00:40.521948 (ThreadPoolExecutor-1_1): On list_demo_db_dev: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev'
  
2021-11-19 20:00:40.523606 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 20:00:40.524818 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dm: ROLLBACK
2021-11-19 20:00:40.524988 (ThreadPoolExecutor-1_1): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 20:00:40.525965 (ThreadPoolExecutor-1_1): On list_demo_db_dev: ROLLBACK
2021-11-19 20:00:40.526116 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dm: Close
2021-11-19 20:00:40.526823 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev_dwh".
2021-11-19 20:00:40.528411 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 20:00:40.528538 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: BEGIN
2021-11-19 20:00:40.528658 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 20:00:40.528913 (ThreadPoolExecutor-1_1): On list_demo_db_dev: Close
2021-11-19 20:00:40.529559 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev_sa".
2021-11-19 20:00:40.531122 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 20:00:40.531480 (ThreadPoolExecutor-1_1): On list_demo_db_dev_sa: BEGIN
2021-11-19 20:00:40.531588 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 20:00:40.536133 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:00:40.536325 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 20:00:40.536413 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dwh'
  
2021-11-19 20:00:40.538130 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:00:40.538255 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 20:00:40.538351 (ThreadPoolExecutor-1_1): On list_demo_db_dev_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_sa'
  
2021-11-19 20:00:40.538527 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 20:00:40.539437 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: ROLLBACK
2021-11-19 20:00:40.539803 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: Close
2021-11-19 20:00:40.540237 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 20:00:40.541187 (ThreadPoolExecutor-1_1): On list_demo_db_dev_sa: ROLLBACK
2021-11-19 20:00:40.541468 (ThreadPoolExecutor-1_1): On list_demo_db_dev_sa: Close
2021-11-19 20:00:40.544870 (MainThread): Using postgres connection "master".
2021-11-19 20:00:40.544987 (MainThread): On master: BEGIN
2021-11-19 20:00:40.545085 (MainThread): Opening a new connection, currently in state init
2021-11-19 20:00:40.551040 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:00:40.551240 (MainThread): Using postgres connection "master".
2021-11-19 20:00:40.551329 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 20:00:40.558614 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-11-19 20:00:40.559509 (MainThread): On master: ROLLBACK
2021-11-19 20:00:40.559907 (MainThread): On master: Close
2021-11-19 20:00:40.560276 (MainThread): 21:00:40 | Concurrency: 2 threads (target='dev')
2021-11-19 20:00:40.560421 (MainThread): 21:00:40 | 
2021-11-19 20:00:40.562742 (Thread-1): Began running node test.my_new_project.cast_numeric
2021-11-19 20:00:40.562951 (Thread-1): 21:00:40 | 1 of 1 START test cast_numeric....................................... [RUN]
2021-11-19 20:00:40.563220 (Thread-1): Acquiring new postgres connection "test.my_new_project.cast_numeric".
2021-11-19 20:00:40.563340 (Thread-1): Compiling test.my_new_project.cast_numeric
2021-11-19 20:00:40.565124 (Thread-1): Writing injected SQL for node "test.my_new_project.cast_numeric"
2021-11-19 20:00:40.565432 (Thread-1): finished collecting timing info
2021-11-19 20:00:40.577085 (Thread-1): Writing runtime SQL for node "test.my_new_project.cast_numeric"
2021-11-19 20:00:40.577321 (Thread-1): Using postgres connection "test.my_new_project.cast_numeric".
2021-11-19 20:00:40.577420 (Thread-1): On test.my_new_project.cast_numeric: BEGIN
2021-11-19 20:00:40.577517 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 20:00:40.584027 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:00:40.584191 (Thread-1): Using postgres connection "test.my_new_project.cast_numeric".
2021-11-19 20:00:40.584303 (Thread-1): On test.my_new_project.cast_numeric: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.cast_numeric"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      

with cases as (
    select 'a'  as the_case union
    select '0'  as the_case union
    select '1'  as the_case union
    select '-1' as the_case 
)
, testing as (
    select
        case when CASE
        WHEN the_case ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN the_case::numeric
    ELSE NULL
    END in (null,0,1,-1) then 'ok'
        else 'nok' end as result
    from cases
)

select 1 from testing where result = 'nok'
      
    ) dbt_internal_test
2021-11-19 20:00:40.585487 (Thread-1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 20:00:40.586873 (Thread-1): finished collecting timing info
2021-11-19 20:00:40.587006 (Thread-1): On test.my_new_project.cast_numeric: ROLLBACK
2021-11-19 20:00:40.587398 (Thread-1): On test.my_new_project.cast_numeric: Close
2021-11-19 20:00:40.587748 (Thread-1): 21:00:40 | 1 of 1 FAIL 1 cast_numeric........................................... [FAIL 1 in 0.02s]
2021-11-19 20:00:40.587893 (Thread-1): Finished running node test.my_new_project.cast_numeric
2021-11-19 20:00:40.589291 (MainThread): Acquiring new postgres connection "master".
2021-11-19 20:00:40.589521 (MainThread): 21:00:40 | 
2021-11-19 20:00:40.589659 (MainThread): 21:00:40 | Finished running 1 test in 0.09s.
2021-11-19 20:00:40.589829 (MainThread): Connection 'master' was properly closed.
2021-11-19 20:00:40.590000 (MainThread): Connection 'test.my_new_project.cast_numeric' was properly closed.
2021-11-19 20:00:40.590083 (MainThread): Connection 'list_demo_db_dev_sa' was properly closed.
2021-11-19 20:00:40.592919 (MainThread): 
2021-11-19 20:00:40.593061 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 20:00:40.593245 (MainThread): 
2021-11-19 20:00:40.593503 (MainThread): Failure in test cast_numeric (tests/macro/cast_numeric.sql)
2021-11-19 20:00:40.593802 (MainThread):   Got 1 result, configured to fail if != 0
2021-11-19 20:00:40.593961 (MainThread): 
2021-11-19 20:00:40.594258 (MainThread):   compiled SQL at target/compiled/my_new_project/tests/macro/cast_numeric.sql
2021-11-19 20:00:40.594493 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-11-19 20:00:40.594781 (MainThread): Flushing usage events
2021-11-19 20:05:45.623297 (MainThread): Running with dbt=0.21.0
2021-11-19 20:05:45.677721 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['tag:cast_numeric'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2021-11-19 20:05:45.678131 (MainThread): Tracking: do not track
2021-11-19 20:05:45.687779 (MainThread): Partial parsing not enabled
2021-11-19 20:05:45.694284 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 20:05:45.694854 (MainThread): Parsing macros/adapters.sql
2021-11-19 20:05:45.711542 (MainThread): Parsing macros/catalog.sql
2021-11-19 20:05:45.714293 (MainThread): Parsing macros/relations.sql
2021-11-19 20:05:45.715381 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 20:05:45.716759 (MainThread): Parsing macros/core.sql
2021-11-19 20:05:45.719516 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 20:05:45.759774 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 20:05:45.761605 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 20:05:45.762937 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 20:05:45.764130 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 20:05:45.770404 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 20:05:45.771604 (MainThread): Parsing macros/etc/query.sql
2021-11-19 20:05:45.772321 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 20:05:45.773421 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 20:05:45.780595 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 20:05:45.785806 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 20:05:45.802636 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 20:05:45.803878 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 20:05:45.826020 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 20:05:45.839356 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 20:05:45.856599 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 20:05:45.864504 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 20:05:45.866100 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 20:05:45.876098 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 20:05:45.879148 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 20:05:45.884482 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 20:05:45.889834 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 20:05:45.890846 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 20:05:45.891720 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 20:05:45.892900 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 20:05:46.046898 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 20:05:46.057068 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 20:05:46.059938 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 20:05:46.064107 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:05:46.064372 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:05:46.065384 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 20:05:46.069476 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:05:46.069712 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:05:46.070622 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 20:05:46.075922 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:05:46.076214 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:05:46.084093 (MainThread): Acquiring new postgres connection "test.my_new_project.cast_numeric".
2021-11-19 20:05:46.086570 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:05:46.088580 (MainThread): Acquiring new postgres connection "test.my_new_project.iss_issuer".
2021-11-19 20:05:46.091615 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:05:46.100090 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:05:46.101865 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:05:46.103569 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:05:46.105035 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:05:46.123608 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:05:46.125306 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:05:46.126796 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:05:46.128082 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:05:46.142239 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 20:05:46.142538 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 20:05:46.143942 (MainThread): 
2021-11-19 20:05:46.144198 (MainThread): Acquiring new postgres connection "master".
2021-11-19 20:05:46.145130 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev_dwh".
2021-11-19 20:05:46.150827 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev_dm".
2021-11-19 20:05:46.158523 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 20:05:46.159457 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 20:05:46.159594 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: BEGIN
2021-11-19 20:05:46.159737 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: BEGIN
2021-11-19 20:05:46.159883 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-11-19 20:05:46.160016 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-19 20:05:46.166175 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:05:46.166396 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:05:46.166553 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 20:05:46.166702 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 20:05:46.166842 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dwh'
  
2021-11-19 20:05:46.167051 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dm'
  
2021-11-19 20:05:46.168917 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 20:05:46.169956 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: ROLLBACK
2021-11-19 20:05:46.170219 (ThreadPoolExecutor-1_1): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 20:05:46.170381 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: Close
2021-11-19 20:05:46.171276 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: ROLLBACK
2021-11-19 20:05:46.171878 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev_sa".
2021-11-19 20:05:46.172044 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: Close
2021-11-19 20:05:46.173302 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 20:05:46.173507 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: BEGIN
2021-11-19 20:05:46.173883 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev".
2021-11-19 20:05:46.174015 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 20:05:46.175056 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev".
2021-11-19 20:05:46.175367 (ThreadPoolExecutor-1_1): On list_demo_db_dev: BEGIN
2021-11-19 20:05:46.175504 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 20:05:46.181060 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:05:46.181316 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 20:05:46.181469 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_sa'
  
2021-11-19 20:05:46.181741 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:05:46.181863 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev".
2021-11-19 20:05:46.181960 (ThreadPoolExecutor-1_1): On list_demo_db_dev: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev'
  
2021-11-19 20:05:46.183288 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 20:05:46.184294 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: ROLLBACK
2021-11-19 20:05:46.184537 (ThreadPoolExecutor-1_1): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 20:05:46.185602 (ThreadPoolExecutor-1_1): On list_demo_db_dev: ROLLBACK
2021-11-19 20:05:46.185743 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: Close
2021-11-19 20:05:46.186202 (ThreadPoolExecutor-1_1): On list_demo_db_dev: Close
2021-11-19 20:05:46.189594 (MainThread): Using postgres connection "master".
2021-11-19 20:05:46.189706 (MainThread): On master: BEGIN
2021-11-19 20:05:46.189803 (MainThread): Opening a new connection, currently in state init
2021-11-19 20:05:46.194877 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:05:46.195013 (MainThread): Using postgres connection "master".
2021-11-19 20:05:46.195102 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 20:05:46.202345 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-11-19 20:05:46.203331 (MainThread): On master: ROLLBACK
2021-11-19 20:05:46.203918 (MainThread): On master: Close
2021-11-19 20:05:46.204431 (MainThread): 21:05:46 | Concurrency: 2 threads (target='dev')
2021-11-19 20:05:46.204576 (MainThread): 21:05:46 | 
2021-11-19 20:05:46.206949 (Thread-1): Began running node test.my_new_project.cast_numeric
2021-11-19 20:05:46.207137 (Thread-1): 21:05:46 | 1 of 1 START test cast_numeric....................................... [RUN]
2021-11-19 20:05:46.207431 (Thread-1): Acquiring new postgres connection "test.my_new_project.cast_numeric".
2021-11-19 20:05:46.207589 (Thread-1): Compiling test.my_new_project.cast_numeric
2021-11-19 20:05:46.209605 (Thread-1): Writing injected SQL for node "test.my_new_project.cast_numeric"
2021-11-19 20:05:46.209809 (Thread-1): finished collecting timing info
2021-11-19 20:05:46.221436 (Thread-1): Writing runtime SQL for node "test.my_new_project.cast_numeric"
2021-11-19 20:05:46.221671 (Thread-1): Using postgres connection "test.my_new_project.cast_numeric".
2021-11-19 20:05:46.221764 (Thread-1): On test.my_new_project.cast_numeric: BEGIN
2021-11-19 20:05:46.221859 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 20:05:46.228223 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:05:46.228452 (Thread-1): Using postgres connection "test.my_new_project.cast_numeric".
2021-11-19 20:05:46.228601 (Thread-1): On test.my_new_project.cast_numeric: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.cast_numeric"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      

with cases as (
    select 'a'  as the_case union
    select '0'  as the_case union
    select '1'  as the_case union
    select '-1' as the_case
)
, testing as (
    select
        case when CASE
        WHEN the_case ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN the_case::numeric
    ELSE NULL
    END in (0,1,-1)
               or CASE
        WHEN the_case ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN the_case::numeric
    ELSE NULL
    END is null
        then 'ok'
        else 'nok' end as result
    from cases
)

select 1 from testing where result = 'nok'
      
    ) dbt_internal_test
2021-11-19 20:05:46.229786 (Thread-1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 20:05:46.231256 (Thread-1): finished collecting timing info
2021-11-19 20:05:46.231387 (Thread-1): On test.my_new_project.cast_numeric: ROLLBACK
2021-11-19 20:05:46.231794 (Thread-1): On test.my_new_project.cast_numeric: Close
2021-11-19 20:05:46.232139 (Thread-1): 21:05:46 | 1 of 1 PASS cast_numeric............................................. [PASS in 0.02s]
2021-11-19 20:05:46.232285 (Thread-1): Finished running node test.my_new_project.cast_numeric
2021-11-19 20:05:46.233939 (MainThread): Acquiring new postgres connection "master".
2021-11-19 20:05:46.234166 (MainThread): 21:05:46 | 
2021-11-19 20:05:46.234299 (MainThread): 21:05:46 | Finished running 1 test in 0.09s.
2021-11-19 20:05:46.234420 (MainThread): Connection 'master' was properly closed.
2021-11-19 20:05:46.234622 (MainThread): Connection 'test.my_new_project.cast_numeric' was properly closed.
2021-11-19 20:05:46.234721 (MainThread): Connection 'list_demo_db_dev' was properly closed.
2021-11-19 20:05:46.237811 (MainThread): 
2021-11-19 20:05:46.237958 (MainThread): Completed successfully
2021-11-19 20:05:46.238129 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-11-19 20:05:46.238363 (MainThread): Flushing usage events
2021-11-19 20:08:53.331116 (MainThread): Running with dbt=0.21.0
2021-11-19 20:08:53.384946 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['tag:cast_numeric'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2021-11-19 20:08:53.385409 (MainThread): Tracking: do not track
2021-11-19 20:08:53.396319 (MainThread): Partial parsing not enabled
2021-11-19 20:08:53.403016 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 20:08:53.403648 (MainThread): Parsing macros/adapters.sql
2021-11-19 20:08:53.420948 (MainThread): Parsing macros/catalog.sql
2021-11-19 20:08:53.422556 (MainThread): Parsing macros/relations.sql
2021-11-19 20:08:53.423503 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 20:08:53.424742 (MainThread): Parsing macros/core.sql
2021-11-19 20:08:53.427816 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 20:08:53.467983 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 20:08:53.469999 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 20:08:53.471354 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 20:08:53.472506 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 20:08:53.478742 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 20:08:53.479846 (MainThread): Parsing macros/etc/query.sql
2021-11-19 20:08:53.480562 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 20:08:53.482099 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 20:08:53.492542 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 20:08:53.498101 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 20:08:53.515362 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 20:08:53.516635 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 20:08:53.538902 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 20:08:53.552002 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 20:08:53.566644 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 20:08:53.574510 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 20:08:53.575899 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 20:08:53.585885 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 20:08:53.589120 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 20:08:53.594536 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 20:08:53.599778 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 20:08:53.600798 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 20:08:53.601700 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 20:08:53.603069 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 20:08:53.757420 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 20:08:53.766859 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 20:08:53.769578 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 20:08:53.772146 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:08:53.772358 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:08:53.773148 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 20:08:53.776459 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:08:53.776663 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:08:53.777443 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 20:08:53.782053 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:08:53.782261 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:08:53.793471 (MainThread): Acquiring new postgres connection "test.my_new_project.cast_numeric".
2021-11-19 20:08:53.796163 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:08:53.797803 (MainThread): Acquiring new postgres connection "test.my_new_project.iss_issuer".
2021-11-19 20:08:53.799914 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:08:53.809043 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:08:53.810545 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:08:53.812056 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:08:53.813483 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:08:53.832315 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:08:53.833729 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:08:53.835206 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:08:53.836967 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:08:53.851052 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 20:08:53.851369 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 20:08:53.852702 (MainThread): 
2021-11-19 20:08:53.853088 (MainThread): Acquiring new postgres connection "master".
2021-11-19 20:08:53.854266 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev_sa".
2021-11-19 20:08:53.859952 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev_dm".
2021-11-19 20:08:53.863773 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 20:08:53.863919 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: BEGIN
2021-11-19 20:08:53.864053 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-19 20:08:53.866600 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 20:08:53.866729 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: BEGIN
2021-11-19 20:08:53.866849 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-11-19 20:08:53.872133 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:08:53.872502 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 20:08:53.872688 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dm'
  
2021-11-19 20:08:53.875075 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:08:53.875292 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 20:08:53.875442 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_sa'
  
2021-11-19 20:08:53.875639 (ThreadPoolExecutor-1_1): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 20:08:53.876803 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: ROLLBACK
2021-11-19 20:08:53.877261 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: Close
2021-11-19 20:08:53.877505 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 20:08:53.878435 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: ROLLBACK
2021-11-19 20:08:53.878849 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev".
2021-11-19 20:08:53.879166 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: Close
2021-11-19 20:08:53.880207 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev".
2021-11-19 20:08:53.880389 (ThreadPoolExecutor-1_1): On list_demo_db_dev: BEGIN
2021-11-19 20:08:53.880769 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev_dwh".
2021-11-19 20:08:53.880896 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 20:08:53.881976 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 20:08:53.882223 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: BEGIN
2021-11-19 20:08:53.882326 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 20:08:53.887898 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:08:53.888190 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:08:53.888352 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev".
2021-11-19 20:08:53.888512 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 20:08:53.888663 (ThreadPoolExecutor-1_1): On list_demo_db_dev: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev'
  
2021-11-19 20:08:53.888807 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dwh'
  
2021-11-19 20:08:53.890633 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 20:08:53.890837 (ThreadPoolExecutor-1_1): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 20:08:53.891765 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: ROLLBACK
2021-11-19 20:08:53.892616 (ThreadPoolExecutor-1_1): On list_demo_db_dev: ROLLBACK
2021-11-19 20:08:53.892924 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: Close
2021-11-19 20:08:53.893060 (ThreadPoolExecutor-1_1): On list_demo_db_dev: Close
2021-11-19 20:08:53.896826 (MainThread): Using postgres connection "master".
2021-11-19 20:08:53.896987 (MainThread): On master: BEGIN
2021-11-19 20:08:53.897095 (MainThread): Opening a new connection, currently in state init
2021-11-19 20:08:53.902642 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:08:53.902824 (MainThread): Using postgres connection "master".
2021-11-19 20:08:53.902919 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 20:08:53.911153 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-11-19 20:08:53.912178 (MainThread): On master: ROLLBACK
2021-11-19 20:08:53.912800 (MainThread): On master: Close
2021-11-19 20:08:53.913212 (MainThread): 21:08:53 | Concurrency: 2 threads (target='dev')
2021-11-19 20:08:53.913388 (MainThread): 21:08:53 | 
2021-11-19 20:08:53.916358 (Thread-1): Began running node test.my_new_project.cast_numeric
2021-11-19 20:08:53.916601 (Thread-1): 21:08:53 | 1 of 1 START test cast_numeric....................................... [RUN]
2021-11-19 20:08:53.917009 (Thread-1): Acquiring new postgres connection "test.my_new_project.cast_numeric".
2021-11-19 20:08:53.917126 (Thread-1): Compiling test.my_new_project.cast_numeric
2021-11-19 20:08:53.919222 (Thread-1): Writing injected SQL for node "test.my_new_project.cast_numeric"
2021-11-19 20:08:53.919438 (Thread-1): finished collecting timing info
2021-11-19 20:08:53.931880 (Thread-1): Writing runtime SQL for node "test.my_new_project.cast_numeric"
2021-11-19 20:08:53.932152 (Thread-1): Using postgres connection "test.my_new_project.cast_numeric".
2021-11-19 20:08:53.932252 (Thread-1): On test.my_new_project.cast_numeric: BEGIN
2021-11-19 20:08:53.932349 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 20:08:53.938810 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:08:53.938990 (Thread-1): Using postgres connection "test.my_new_project.cast_numeric".
2021-11-19 20:08:53.939089 (Thread-1): On test.my_new_project.cast_numeric: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.cast_numeric"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      

with cases as (
    select NULL   as the_case union
    select ''     as the_case union
    select 'a'    as the_case union
    select '0'    as the_case union
    select '1'    as the_case union
    select '-1'   as the_case union
    select '0.1'  as the_case union
    select '-0.1' as the_case union
    select '0.11' as the_case 
)
, testing as (
    select
        case when CASE
        WHEN the_case ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN the_case::numeric
    ELSE NULL
    END in (0,1,-1)
               or CASE
        WHEN the_case ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN the_case::numeric
    ELSE NULL
    END is null
        then 'ok'
        else 'nok' end as result
    from cases
)

select 1 from testing where result = 'nok'
      
    ) dbt_internal_test
2021-11-19 20:08:53.940237 (Thread-1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 20:08:53.941728 (Thread-1): finished collecting timing info
2021-11-19 20:08:53.941869 (Thread-1): On test.my_new_project.cast_numeric: ROLLBACK
2021-11-19 20:08:53.942282 (Thread-1): On test.my_new_project.cast_numeric: Close
2021-11-19 20:08:53.942607 (Thread-1): 21:08:53 | 1 of 1 FAIL 3 cast_numeric........................................... [FAIL 3 in 0.03s]
2021-11-19 20:08:53.942764 (Thread-1): Finished running node test.my_new_project.cast_numeric
2021-11-19 20:08:53.944057 (MainThread): Acquiring new postgres connection "master".
2021-11-19 20:08:53.944282 (MainThread): 21:08:53 | 
2021-11-19 20:08:53.944422 (MainThread): 21:08:53 | Finished running 1 test in 0.09s.
2021-11-19 20:08:53.944550 (MainThread): Connection 'master' was properly closed.
2021-11-19 20:08:53.944680 (MainThread): Connection 'test.my_new_project.cast_numeric' was properly closed.
2021-11-19 20:08:53.944765 (MainThread): Connection 'list_demo_db_dev' was properly closed.
2021-11-19 20:08:53.947890 (MainThread): 
2021-11-19 20:08:53.948039 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 20:08:53.948237 (MainThread): 
2021-11-19 20:08:53.948400 (MainThread): Failure in test cast_numeric (tests/macro/cast_numeric.sql)
2021-11-19 20:08:53.948645 (MainThread):   Got 3 results, configured to fail if != 0
2021-11-19 20:08:53.948875 (MainThread): 
2021-11-19 20:08:53.949044 (MainThread):   compiled SQL at target/compiled/my_new_project/tests/macro/cast_numeric.sql
2021-11-19 20:08:53.949288 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-11-19 20:08:53.949553 (MainThread): Flushing usage events
2021-11-19 20:10:21.419201 (MainThread): Running with dbt=0.21.0
2021-11-19 20:10:21.472448 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['tag:cast_numeric'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2021-11-19 20:10:21.472897 (MainThread): Tracking: do not track
2021-11-19 20:10:21.482174 (MainThread): Partial parsing not enabled
2021-11-19 20:10:21.488484 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 20:10:21.489081 (MainThread): Parsing macros/adapters.sql
2021-11-19 20:10:21.508484 (MainThread): Parsing macros/catalog.sql
2021-11-19 20:10:21.510263 (MainThread): Parsing macros/relations.sql
2021-11-19 20:10:21.511220 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 20:10:21.512487 (MainThread): Parsing macros/core.sql
2021-11-19 20:10:21.515429 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 20:10:21.557177 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 20:10:21.559113 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 20:10:21.560502 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 20:10:21.561777 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 20:10:21.568494 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 20:10:21.569676 (MainThread): Parsing macros/etc/query.sql
2021-11-19 20:10:21.570428 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 20:10:21.571744 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 20:10:21.579357 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 20:10:21.584701 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 20:10:21.602773 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 20:10:21.604071 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 20:10:21.627792 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 20:10:21.641399 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 20:10:21.656911 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 20:10:21.665033 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 20:10:21.666460 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 20:10:21.677322 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 20:10:21.680351 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 20:10:21.685946 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 20:10:21.691568 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 20:10:21.692619 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 20:10:21.693541 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 20:10:21.694872 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 20:10:21.856063 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 20:10:21.865756 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 20:10:21.868540 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 20:10:21.871144 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:10:21.871422 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:10:21.872261 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 20:10:21.875725 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:10:21.876014 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:10:21.876843 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 20:10:21.881804 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:10:21.882020 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:10:21.889532 (MainThread): Acquiring new postgres connection "test.my_new_project.cast_numeric".
2021-11-19 20:10:21.891915 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:10:21.893472 (MainThread): Acquiring new postgres connection "test.my_new_project.iss_issuer".
2021-11-19 20:10:21.895649 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:10:21.904119 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:10:21.905729 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:10:21.907350 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:10:21.908920 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:10:21.927332 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:10:21.928952 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:10:21.930516 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:10:21.931933 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:10:21.946564 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 20:10:21.947043 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 20:10:21.948142 (MainThread): 
2021-11-19 20:10:21.948404 (MainThread): Acquiring new postgres connection "master".
2021-11-19 20:10:21.949423 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev_sa".
2021-11-19 20:10:21.956934 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 20:10:21.957071 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: BEGIN
2021-11-19 20:10:21.957190 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-11-19 20:10:21.957621 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev_dwh".
2021-11-19 20:10:21.959012 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 20:10:21.959241 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: BEGIN
2021-11-19 20:10:21.959404 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-19 20:10:21.964277 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:10:21.964481 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 20:10:21.964567 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_sa'
  
2021-11-19 20:10:21.966192 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:10:21.966346 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 20:10:21.966433 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dwh'
  
2021-11-19 20:10:21.966868 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 20:10:21.967793 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: ROLLBACK
2021-11-19 20:10:21.968047 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 20:10:21.968233 (ThreadPoolExecutor-1_0): On list_demo_db_dev_sa: Close
2021-11-19 20:10:21.969041 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: ROLLBACK
2021-11-19 20:10:21.969661 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev".
2021-11-19 20:10:21.971470 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev".
2021-11-19 20:10:21.971616 (ThreadPoolExecutor-1_0): On list_demo_db_dev: BEGIN
2021-11-19 20:10:21.971730 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 20:10:21.971956 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dwh: Close
2021-11-19 20:10:21.972422 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev_dm".
2021-11-19 20:10:21.973896 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 20:10:21.973997 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: BEGIN
2021-11-19 20:10:21.974086 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 20:10:21.978161 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:10:21.978324 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev".
2021-11-19 20:10:21.978409 (ThreadPoolExecutor-1_0): On list_demo_db_dev: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev'
  
2021-11-19 20:10:21.980403 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 20:10:21.981363 (ThreadPoolExecutor-1_0): On list_demo_db_dev: ROLLBACK
2021-11-19 20:10:21.981616 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:10:21.981763 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 20:10:21.981898 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dm'
  
2021-11-19 20:10:21.982025 (ThreadPoolExecutor-1_0): On list_demo_db_dev: Close
2021-11-19 20:10:21.983898 (ThreadPoolExecutor-1_1): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 20:10:21.984691 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: ROLLBACK
2021-11-19 20:10:21.985078 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: Close
2021-11-19 20:10:21.988693 (MainThread): Using postgres connection "master".
2021-11-19 20:10:21.988813 (MainThread): On master: BEGIN
2021-11-19 20:10:21.988911 (MainThread): Opening a new connection, currently in state init
2021-11-19 20:10:21.994850 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:10:21.995005 (MainThread): Using postgres connection "master".
2021-11-19 20:10:21.995094 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 20:10:22.002082 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-11-19 20:10:22.002978 (MainThread): On master: ROLLBACK
2021-11-19 20:10:22.003227 (MainThread): On master: Close
2021-11-19 20:10:22.003556 (MainThread): 21:10:21 | Concurrency: 2 threads (target='dev')
2021-11-19 20:10:22.003743 (MainThread): 21:10:21 | 
2021-11-19 20:10:22.006710 (Thread-1): Began running node test.my_new_project.cast_numeric
2021-11-19 20:10:22.006972 (Thread-1): 21:10:21 | 1 of 1 START test cast_numeric....................................... [RUN]
2021-11-19 20:10:22.007514 (Thread-1): Acquiring new postgres connection "test.my_new_project.cast_numeric".
2021-11-19 20:10:22.007636 (Thread-1): Compiling test.my_new_project.cast_numeric
2021-11-19 20:10:22.009874 (Thread-1): Writing injected SQL for node "test.my_new_project.cast_numeric"
2021-11-19 20:10:22.010101 (Thread-1): finished collecting timing info
2021-11-19 20:10:22.022164 (Thread-1): Writing runtime SQL for node "test.my_new_project.cast_numeric"
2021-11-19 20:10:22.022456 (Thread-1): Using postgres connection "test.my_new_project.cast_numeric".
2021-11-19 20:10:22.022552 (Thread-1): On test.my_new_project.cast_numeric: BEGIN
2021-11-19 20:10:22.022647 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 20:10:22.029763 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:10:22.029918 (Thread-1): Using postgres connection "test.my_new_project.cast_numeric".
2021-11-19 20:10:22.030010 (Thread-1): On test.my_new_project.cast_numeric: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.cast_numeric"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      

with cases as (
    select NULL   as the_case union
    select ''     as the_case union
    select 'a'    as the_case union
    select '0'    as the_case union
    select '1'    as the_case union
    select '-1'   as the_case union
    select '0.1'  as the_case union
    select '-0.1' as the_case union
    select '0.11' as the_case
)
, testing as (
    select
        case when CASE
        WHEN the_case ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN the_case::numeric
    ELSE NULL
    END in (0,1,-1,0.1,-0.1,0.11)
               or CASE
        WHEN the_case ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN the_case::numeric
    ELSE NULL
    END is null
        then 'ok'
        else 'nok' end as result
    from cases
)

select 1 from testing where result = 'nok'
      
    ) dbt_internal_test
2021-11-19 20:10:22.031288 (Thread-1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 20:10:22.032719 (Thread-1): finished collecting timing info
2021-11-19 20:10:22.032850 (Thread-1): On test.my_new_project.cast_numeric: ROLLBACK
2021-11-19 20:10:22.033329 (Thread-1): On test.my_new_project.cast_numeric: Close
2021-11-19 20:10:22.033751 (Thread-1): 21:10:22 | 1 of 1 PASS cast_numeric............................................. [PASS in 0.03s]
2021-11-19 20:10:22.033898 (Thread-1): Finished running node test.my_new_project.cast_numeric
2021-11-19 20:10:22.035486 (MainThread): Acquiring new postgres connection "master".
2021-11-19 20:10:22.035699 (MainThread): 21:10:22 | 
2021-11-19 20:10:22.035845 (MainThread): 21:10:22 | Finished running 1 test in 0.09s.
2021-11-19 20:10:22.035968 (MainThread): Connection 'master' was properly closed.
2021-11-19 20:10:22.036080 (MainThread): Connection 'test.my_new_project.cast_numeric' was properly closed.
2021-11-19 20:10:22.036176 (MainThread): Connection 'list_demo_db_dev_dm' was properly closed.
2021-11-19 20:10:22.039325 (MainThread): 
2021-11-19 20:10:22.039495 (MainThread): Completed successfully
2021-11-19 20:10:22.039678 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-11-19 20:10:22.040082 (MainThread): Flushing usage events
2021-11-19 20:11:34.449346 (MainThread): Running with dbt=0.21.0
2021-11-19 20:11:34.504851 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/home/qw40wz/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['tag:cast_numeric'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2021-11-19 20:11:34.505252 (MainThread): Tracking: do not track
2021-11-19 20:11:34.514830 (MainThread): Partial parsing not enabled
2021-11-19 20:11:34.521837 (MainThread): Parsing macros/cast_numeric.sql
2021-11-19 20:11:34.522713 (MainThread): Parsing macros/adapters.sql
2021-11-19 20:11:34.539702 (MainThread): Parsing macros/catalog.sql
2021-11-19 20:11:34.541332 (MainThread): Parsing macros/relations.sql
2021-11-19 20:11:34.542258 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-11-19 20:11:34.543492 (MainThread): Parsing macros/core.sql
2021-11-19 20:11:34.546399 (MainThread): Parsing macros/adapters/common.sql
2021-11-19 20:11:34.586906 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-11-19 20:11:34.588922 (MainThread): Parsing macros/etc/where_subquery.sql
2021-11-19 20:11:34.590364 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-11-19 20:11:34.591519 (MainThread): Parsing macros/etc/datetime.sql
2021-11-19 20:11:34.597841 (MainThread): Parsing macros/etc/is_incremental.sql
2021-11-19 20:11:34.598952 (MainThread): Parsing macros/etc/query.sql
2021-11-19 20:11:34.599695 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-11-19 20:11:34.600798 (MainThread): Parsing macros/materializations/helpers.sql
2021-11-19 20:11:34.608227 (MainThread): Parsing macros/materializations/test.sql
2021-11-19 20:11:34.613201 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-11-19 20:11:34.629895 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-11-19 20:11:34.631130 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-11-19 20:11:34.653166 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-11-19 20:11:34.666121 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2021-11-19 20:11:34.680294 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-11-19 20:11:34.687916 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-11-19 20:11:34.689516 (MainThread): Parsing macros/materializations/common/merge.sql
2021-11-19 20:11:34.699538 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-11-19 20:11:34.702404 (MainThread): Parsing macros/materializations/view/view.sql
2021-11-19 20:11:34.707860 (MainThread): Parsing macros/materializations/table/table.sql
2021-11-19 20:11:34.713278 (MainThread): Parsing macros/schema_tests/unique.sql
2021-11-19 20:11:34.714292 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-11-19 20:11:34.715180 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-11-19 20:11:34.716398 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-11-19 20:11:34.874753 (MainThread): Acquiring new postgres connection "model.my_new_project.my_second_dbt_model".
2021-11-19 20:11:34.884340 (MainThread): Acquiring new postgres connection "model.my_new_project.my_first_dbt_model".
2021-11-19 20:11:34.887076 (MainThread): Acquiring new postgres connection "model.my_new_project.dim_issuer".
2021-11-19 20:11:34.889743 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:11:34.889975 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:11:34.890796 (MainThread): Acquiring new postgres connection "model.my_new_project.fct_emissions".
2021-11-19 20:11:34.894171 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:11:34.894415 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:11:34.895225 (MainThread): Acquiring new postgres connection "model.my_new_project.iss_issuer".
2021-11-19 20:11:34.899856 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:11:34.900064 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:11:34.907396 (MainThread): Acquiring new postgres connection "test.my_new_project.cast_numeric".
2021-11-19 20:11:34.909694 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:11:34.911223 (MainThread): Acquiring new postgres connection "test.my_new_project.iss_issuer".
2021-11-19 20:11:34.913312 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:11:34.921323 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:11:34.922995 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:11:34.924583 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:11:34.926088 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:11:34.943251 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:11:34.944761 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:11:34.946283 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:11:34.947621 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2021-11-19 20:11:34.961819 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2021-11-19 20:11:34.962126 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 163 macros, 0 operations, 4 seed files, 0 sources, 0 exposures
2021-11-19 20:11:34.963474 (MainThread): 
2021-11-19 20:11:34.963919 (MainThread): Acquiring new postgres connection "master".
2021-11-19 20:11:34.965306 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev_dwh".
2021-11-19 20:11:34.970906 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev_dm".
2021-11-19 20:11:34.974841 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 20:11:34.974982 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: BEGIN
2021-11-19 20:11:34.975113 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2021-11-19 20:11:34.978033 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 20:11:34.978143 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: BEGIN
2021-11-19 20:11:34.978237 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-11-19 20:11:34.982610 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:11:34.982791 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_dm".
2021-11-19 20:11:34.982878 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dm"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dm'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dm'
  
2021-11-19 20:11:34.985185 (ThreadPoolExecutor-1_1): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 20:11:34.986448 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: ROLLBACK
2021-11-19 20:11:34.986718 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:11:34.986920 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev_dwh".
2021-11-19 20:11:34.987076 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_dwh"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_dwh'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_dwh'
  
2021-11-19 20:11:34.987247 (ThreadPoolExecutor-1_1): On list_demo_db_dev_dm: Close
2021-11-19 20:11:34.987908 (ThreadPoolExecutor-1_1): Acquiring new postgres connection "list_demo_db_dev_sa".
2021-11-19 20:11:34.989287 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 20:11:34.989645 (ThreadPoolExecutor-1_1): On list_demo_db_dev_sa: BEGIN
2021-11-19 20:11:34.990024 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state closed
2021-11-19 20:11:34.990399 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 20:11:34.991583 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: ROLLBACK
2021-11-19 20:11:34.992130 (ThreadPoolExecutor-1_0): On list_demo_db_dev_dwh: Close
2021-11-19 20:11:34.992715 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_demo_db_dev".
2021-11-19 20:11:34.993854 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev".
2021-11-19 20:11:34.994099 (ThreadPoolExecutor-1_0): On list_demo_db_dev: BEGIN
2021-11-19 20:11:34.994211 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-11-19 20:11:34.997100 (ThreadPoolExecutor-1_1): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:11:34.997239 (ThreadPoolExecutor-1_1): Using postgres connection "list_demo_db_dev_sa".
2021-11-19 20:11:34.997329 (ThreadPoolExecutor-1_1): On list_demo_db_dev_sa: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev_sa"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev_sa'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev_sa'
  
2021-11-19 20:11:34.998851 (ThreadPoolExecutor-1_1): SQL status: SELECT 1 in 0.00 seconds
2021-11-19 20:11:34.999921 (ThreadPoolExecutor-1_1): On list_demo_db_dev_sa: ROLLBACK
2021-11-19 20:11:35.000302 (ThreadPoolExecutor-1_1): On list_demo_db_dev_sa: Close
2021-11-19 20:11:35.000826 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:11:35.001125 (ThreadPoolExecutor-1_0): Using postgres connection "list_demo_db_dev".
2021-11-19 20:11:35.001237 (ThreadPoolExecutor-1_0): On list_demo_db_dev: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_demo_db_dev"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dev'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dev'
  
2021-11-19 20:11:35.002858 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2021-11-19 20:11:35.003719 (ThreadPoolExecutor-1_0): On list_demo_db_dev: ROLLBACK
2021-11-19 20:11:35.004021 (ThreadPoolExecutor-1_0): On list_demo_db_dev: Close
2021-11-19 20:11:35.007585 (MainThread): Using postgres connection "master".
2021-11-19 20:11:35.007712 (MainThread): On master: BEGIN
2021-11-19 20:11:35.007809 (MainThread): Opening a new connection, currently in state init
2021-11-19 20:11:35.013535 (MainThread): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:11:35.013721 (MainThread): Using postgres connection "master".
2021-11-19 20:11:35.013810 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-11-19 20:11:35.020835 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2021-11-19 20:11:35.021716 (MainThread): On master: ROLLBACK
2021-11-19 20:11:35.022196 (MainThread): On master: Close
2021-11-19 20:11:35.022691 (MainThread): 21:11:35 | Concurrency: 2 threads (target='dev')
2021-11-19 20:11:35.022976 (MainThread): 21:11:35 | 
2021-11-19 20:11:35.026338 (Thread-1): Began running node test.my_new_project.cast_numeric
2021-11-19 20:11:35.026550 (Thread-1): 21:11:35 | 1 of 1 START test cast_numeric....................................... [RUN]
2021-11-19 20:11:35.026924 (Thread-1): Acquiring new postgres connection "test.my_new_project.cast_numeric".
2021-11-19 20:11:35.027113 (Thread-1): Compiling test.my_new_project.cast_numeric
2021-11-19 20:11:35.029091 (Thread-1): Writing injected SQL for node "test.my_new_project.cast_numeric"
2021-11-19 20:11:35.029296 (Thread-1): finished collecting timing info
2021-11-19 20:11:35.040876 (Thread-1): Writing runtime SQL for node "test.my_new_project.cast_numeric"
2021-11-19 20:11:35.041120 (Thread-1): Using postgres connection "test.my_new_project.cast_numeric".
2021-11-19 20:11:35.041218 (Thread-1): On test.my_new_project.cast_numeric: BEGIN
2021-11-19 20:11:35.041314 (Thread-1): Opening a new connection, currently in state closed
2021-11-19 20:11:35.049745 (Thread-1): SQL status: BEGIN in 0.01 seconds
2021-11-19 20:11:35.050071 (Thread-1): Using postgres connection "test.my_new_project.cast_numeric".
2021-11-19 20:11:35.050228 (Thread-1): On test.my_new_project.cast_numeric: /* {"app": "dbt", "dbt_version": "0.21.0", "profile_name": "default", "target_name": "dev", "node_id": "test.my_new_project.cast_numeric"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      

with cases as (
    select '0,1'  as the_case union
    select NULL   as the_case union
    select ''     as the_case union
    select 'a'    as the_case union
    select '0'    as the_case union
    select '1'    as the_case union
    select '-1'   as the_case union
    select '0.1'  as the_case union
    select '-0.1' as the_case union
    select '0.11' as the_case
)
, testing as (
    select
         the_case
        ,case when CASE
        WHEN the_case ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN the_case::numeric
    ELSE NULL
    END in (0,1,-1,0.1,-0.1,0.11)
               or CASE
        WHEN the_case ~ '[+-]?([0-9]*[.])?[0-9]+'
        THEN the_case::numeric
    ELSE NULL
    END is null
        then 'ok'
        else 'nok' end as result
    from cases
)

select the_case from testing where result = 'nok'
      
    ) dbt_internal_test
2021-11-19 20:11:35.051534 (Thread-1): Postgres error: invalid input syntax for type numeric: "0,1"

2021-11-19 20:11:35.051731 (Thread-1): On test.my_new_project.cast_numeric: ROLLBACK
2021-11-19 20:11:35.052112 (Thread-1): finished collecting timing info
2021-11-19 20:11:35.052272 (Thread-1): On test.my_new_project.cast_numeric: Close
2021-11-19 20:11:35.052582 (Thread-1): Database Error in test cast_numeric (tests/macro/cast_numeric.sql)
  invalid input syntax for type numeric: "0,1"
  compiled SQL at target/run/my_new_project/tests/macro/cast_numeric.sql
Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type numeric: "0,1"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/test.py", line 112, in execute
    result = self.execute_test(test, manifest)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/task/test.py", line 82, in execute_test
    macro_func()
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 132, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/home/qw40wz/.pyenv/versions/3.9.2/lib/python3.9/contextlib.py", line 135, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/qw40wz/.pyenv/versions/3.9.2/envs/dbt-sample/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in test cast_numeric (tests/macro/cast_numeric.sql)
  invalid input syntax for type numeric: "0,1"
  compiled SQL at target/run/my_new_project/tests/macro/cast_numeric.sql
2021-11-19 20:11:35.053677 (Thread-1): 21:11:35 | 1 of 1 ERROR cast_numeric............................................ [ERROR in 0.03s]
2021-11-19 20:11:35.053852 (Thread-1): Finished running node test.my_new_project.cast_numeric
2021-11-19 20:11:35.054933 (MainThread): Acquiring new postgres connection "master".
2021-11-19 20:11:35.055171 (MainThread): 21:11:35 | 
2021-11-19 20:11:35.055352 (MainThread): 21:11:35 | Finished running 1 test in 0.09s.
2021-11-19 20:11:35.055484 (MainThread): Connection 'master' was properly closed.
2021-11-19 20:11:35.055580 (MainThread): Connection 'test.my_new_project.cast_numeric' was properly closed.
2021-11-19 20:11:35.055667 (MainThread): Connection 'list_demo_db_dev_sa' was properly closed.
2021-11-19 20:11:35.059149 (MainThread): 
2021-11-19 20:11:35.059321 (MainThread): Completed with 1 error and 0 warnings:
2021-11-19 20:11:35.059462 (MainThread): 
2021-11-19 20:11:35.059600 (MainThread): Database Error in test cast_numeric (tests/macro/cast_numeric.sql)
2021-11-19 20:11:35.059728 (MainThread):   invalid input syntax for type numeric: "0,1"
2021-11-19 20:11:35.059850 (MainThread):   compiled SQL at target/run/my_new_project/tests/macro/cast_numeric.sql
2021-11-19 20:11:35.059978 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-11-19 20:11:35.060158 (MainThread): Flushing usage events
